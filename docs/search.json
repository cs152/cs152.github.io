[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Syllabus",
    "section": "",
    "text": "In this course, we will introduce neural networks as a tool for machine learning and function approximation. We will start with the fundamentals of how to build and train a neural network from scratch. We will work our way towards discussing state-of-the-art neural networks including networks that power applications like object recognition, image generation and large language models. Throughout the course we will keep a strong focus on the implications of these models and how to apply them responsibly.\nCourse Slack: https://join.slack.com/t/cs152neuralne-fop9003/shared_invite/zt-2ax94g9q8-Av_OBLyv2Lh63Om2WGWYRw\nCourse Survey: https://forms.gle/QaaKDcqpZL8ZvTAB7\n\n\n\n\n\n\n\nProf. Gabe Hope (he/him)\nEmail: ghope@g.hmc.edu\nOffice: MacGregor 311\nOffice hours: TBA\n\n\n\nYou can call me any combination of Prof./Professor/Dr. and Hope/Gabe. My full name is actually John Gabriel Hope.\nI am originally from New York City\nI have a Bachelor of Science (BS) in computer science and finance from Washington University in St. Louis.\nI have a Master of Science (MS) from Brown University (This was actually the start of my Ph.D.)\nI earned my Ph.D. from the University of California, Irvine advised by Erik Sudderth.\nMy research focuses on using neural networks to find interpretable structures in data. I mainly focus on image data, though I have also worked on analyzing motion-capture, audio and climate data among other things!\n\n\n\n\n\n\n\n\n\nLinear and logistic regression\nGradient descent and optimization\nFeature transforms and feed-forward networks\nPerformance tuning and analysis for neural networks\nConvolutional neural networks\nRegularization and normalization\nResidual networks and large-scale architectures\nAttention and transformers\nBiases and fairness in machine learning\n\n\n\n\nProbabilistic Machine Learning by Kevin Murphy. Full text for book 1 and book 2 are available for free online.\nOpen door policy: If my door is open, feel free to stop in, say hi and ask questions about the course, research or any other academic issues. If the door is closed, feel free to knock. I often like to close my door to focus, but it does not always mean I am unable to talk. If I don’t answer promptly I am either out of office or in a meeting and am unable to talk. If in doubt, feel free contact me on slack. Note that I generally prefer to keep longer discussion of course materials to designated office hours."
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Course Syllabus",
    "section": "",
    "text": "Prof. Gabe Hope (he/him)\nEmail: ghope@g.hmc.edu\nOffice: MacGregor 311\nOffice hours: TBA\n\n\n\nYou can call me any combination of Prof./Professor/Dr. and Hope/Gabe. My full name is actually John Gabriel Hope.\nI am originally from New York City\nI have a Bachelor of Science (BS) in computer science and finance from Washington University in St. Louis.\nI have a Master of Science (MS) from Brown University (This was actually the start of my Ph.D.)\nI earned my Ph.D. from the University of California, Irvine advised by Erik Sudderth.\nMy research focuses on using neural networks to find interpretable structures in data. I mainly focus on image data, though I have also worked on analyzing motion-capture, audio and climate data among other things!"
  },
  {
    "objectID": "index.html#topics-covered",
    "href": "index.html#topics-covered",
    "title": "Course Syllabus",
    "section": "",
    "text": "Linear and logistic regression\nGradient descent and optimization\nFeature transforms and feed-forward networks\nPerformance tuning and analysis for neural networks\nConvolutional neural networks\nRegularization and normalization\nResidual networks and large-scale architectures\nAttention and transformers\nBiases and fairness in machine learning"
  },
  {
    "objectID": "index.html#textbook",
    "href": "index.html#textbook",
    "title": "Course Syllabus",
    "section": "",
    "text": "Probabilistic Machine Learning by Kevin Murphy. Full text for book 1 and book 2 are available for free online.\nOpen door policy: If my door is open, feel free to stop in, say hi and ask questions about the course, research or any other academic issues. If the door is closed, feel free to knock. I often like to close my door to focus, but it does not always mean I am unable to talk. If I don’t answer promptly I am either out of office or in a meeting and am unable to talk. If in doubt, feel free contact me on slack. Note that I generally prefer to keep longer discussion of course materials to designated office hours."
  },
  {
    "objectID": "index.html#vscode-optional",
    "href": "index.html#vscode-optional",
    "title": "Course Syllabus",
    "section": "VSCode (Optional)",
    "text": "VSCode (Optional)\nVisual Studio Code is a free development environment developed by Microsoft. It is available for Mac, Windows and Linux, and provides convenient tools for working with Python, Git and Jupyter. It is what I use to develop the materials for this course, and it is what I would recommend using for homework assignments. This is completely optional however. You are welcome to use whatever environment you feel most comfortable with.\nHere are resources for getting started:\n\nRecommended extensions for data science and working with Jupyter notebooks are listed here.\nInstructions for setting up Python in VSCode are here.\nInstructions for working with Jupyter notebooks in VSCode are here.\nInstructions for setting up Git in VSCode are here."
  },
  {
    "objectID": "index.html#python",
    "href": "index.html#python",
    "title": "Course Syllabus",
    "section": "Python",
    "text": "Python\nAssignments and projects in this course will be based on Python 3. We will be using the following packages throughout this course:\n\nNumpy: The industry-standard Python library for working with vectors, matrices and general numerical computing.\nMatplotlib: The most popular and widely supported library for data visualization in Python.\nSciKit-Learn: A popular library for basic machine learning.\nPyTorch: A deep learning library. Currently the most popular library for neural networks research and competitive with TensorFlow in terms of industry deployment.\n\nYou can find this course’s requirements file here. It will also be included in homework distributions. You can install the full set of packages using the command:\npip install -r requirements.txt"
  },
  {
    "objectID": "index.html#jupyter",
    "href": "index.html#jupyter",
    "title": "Course Syllabus",
    "section": "Jupyter",
    "text": "Jupyter\nMost homework assignments will be distributed and submitted as Jupyter notebooks. Jupyterlab is included in the course requirements.txt file, but instructions for installing it are also available here. Once installed, you can launch a JupyterLab server locally on you computer using the command:\njupyter lab\nThis will open the Jupyter Lab application in a web browser. From there you can navigate to the homework’s main.ipynb file. Resources and documentation for working with Jupyter notebooks are available here."
  },
  {
    "objectID": "index.html#latex-style-equations",
    "href": "index.html#latex-style-equations",
    "title": "Course Syllabus",
    "section": "Latex (style) equations",
    "text": "Latex (style) equations\nHomework assignments will ask you to submit answers requiring mathematical derivations as typeset Latex-style equations. Latex equations are supported directly within Jupyter. To write an equation in a text/markdown cell, simply surround the equation with $ symbols as: $y = x^2 + 1$, which produces the output: \\(y=x^2 +1\\). You can write block equation using double dollar-signs as $$y = x^2 + 1$$, which puts the equation on its own centered line.\nAn extensive reference for Latex equations is available here.\nIn general, only the final answer to such problems will be required to be submitted in this way, intermediate steps in derivations can be submitted separately as handwritten notes. To do this, scan or photograph (clearly!) the handwritten derivations and include them (ideally) as images in your notebook or as a separeate derivations.pdf file in the homework repository. You may also omit intermediate steps altogether, but this is not recommended as it may limit your ability to earn partial credit if your answer is incorrect."
  },
  {
    "objectID": "index.html#submitting-pdfs-to-gradescope",
    "href": "index.html#submitting-pdfs-to-gradescope",
    "title": "Course Syllabus",
    "section": "Submitting PDFs to Gradescope",
    "text": "Submitting PDFs to Gradescope\nEach complete homework notebook should be submitted as a PDF file to Gradescope. This primarily where homeworks will be graded and where grades and regrade requests will be handeled. Jupyter notebooks can be converted to PDFs either through VSCode (instructions here), or via online tools such as this one."
  },
  {
    "objectID": "index.html#course-gpu-server",
    "href": "index.html#course-gpu-server",
    "title": "Course Syllabus",
    "section": "Course GPU Server",
    "text": "Course GPU Server\nWe have a GPU server for this course that will be available to you for your final projects. (Thank you to our system administrator Tim Buchheim for setting this up!). The server is located at teapot.cs.hmc.edu (named for the Utah teapot). We will discuss how to allocate resources on this machine at the start of the course project. You will not need GPU access for most homework assignments."
  },
  {
    "objectID": "index.html#homework-assignments-60-of-course-grade",
    "href": "index.html#homework-assignments-60-of-course-grade",
    "title": "Course Syllabus",
    "section": "Homework assignments (60% of course grade)",
    "text": "Homework assignments (60% of course grade)\nFrequency and deadlines: Homeworks will be assigned on a weekly basis throughout the semester, with the exception of weeks where final project checkpoints are due. Homeworks are assigned on Wednesdays and must be submitted on gradescope and Github by the end of the following Thursday (11:59pm Thursday).\nSubmission Homework assignments are submitted by uploading a solution PDF to Gradescope. You must convert your completed notebook to PDF using the CS152 conversion tool. This page will extract and separate the answers for each question. Please make sure to check that all answers are included before submitting the PDF to Gradescope. Incorrectly formatted submissions are subject to a 10% penalty. See further instructions under software and tools!\nLate policy: Homeworks may be submitted up to 1 day late with no penalty (to Friday 11:59pm). Assignments submitted on time will recieve a 5 point bonus (up to 100 total points).\nDrops: The lowest 2 homework scores will be dropped unconditionally. Your homework score will be computed as the average of the remaining scores. Please note that you should still try to complete every homework in this class. These drops are intended to cover normal unforseen circumstances such as minor illness, conference or clinic travel and job interviews, as well as to allow you to balance your work with other classes and take care of your mental health.\nExtension policy: For situations such as extended illnesses, family emergencies, or other significant and unforeseen circumstances preventing you from working, I’m happy to work with you to try to find a way to give you the space you need while being able to come back to the course when you’re able. The best way to start this conversation is by directly emailing me (ghope@g.hmc.edu). To protect your privacy about the reasons for these circumstances and to ensure you get the support you need, I may ask you to reach out about this to your campus’ Division of Student Affairs, Dean of Students office, or your Student Disability Services coordinator to verify what kind of accommodation makes sense and to ensure you’re being supported across your other courses. If it’s more comfortable, you may also choose to reach out to any of these groups to reach out to me before contacting me yourself."
  },
  {
    "objectID": "index.html#participation-10-of-course-grade",
    "href": "index.html#participation-10-of-course-grade",
    "title": "Course Syllabus",
    "section": "Participation (10% of course grade)",
    "text": "Participation (10% of course grade)\nThis course is not generally a discussion-based class, however there will be certain lectures with open-ended discussions throughout the semester. The participation grade will be based on the following factors:\n\nParticipation in open-ended discussion sessions during class\nContriubting to the learning environment by asking or answering questions during regular lectures\nFollowing the guidelines for respectful discussion (as outlined in course policies)\nClass attendance\nAttending office hours outside class\nSupport provided to peers, e.g. by helping others debug or answering questions on Slack.\n\nEarning a perfect participation grade will not require full marks for all of these criteria, and it is expected that most students will earn full credit for participation. A perfect participation grade will be earned by any student who: attends class regularly (&gt; 80% of the time) and at least occasionally participates respectfully in class. Attending office hours is not strictly required, but if you miss class or are struggling to participate, I will assign bonus points to your participation grade for attending. If you have questions about your participation grade at any point, please contact me."
  },
  {
    "objectID": "index.html#final-project-30-of-course-grade",
    "href": "index.html#final-project-30-of-course-grade",
    "title": "Course Syllabus",
    "section": "Final Project (30% of course grade)",
    "text": "Final Project (30% of course grade)\nThe culmination of this course will be a final project completed in teams of 2-4 students. Full project description to follow. Your grade for the final project will depend on:\n\nThe strength of your team’s final presentation and write-up\nYour strength as a team-member (determined by self, peer and instructor evaluations)\nInitial project proposal\nMid-project check-ins\n\nStudents enter this class with highly varying backgrounds and prior experiences with neural networks, so I will help each team determine an appropriate scope for their project. Grades will be evaluated for each team individually based on how the team approached, analyzed and executed on the goals of the project. The relative technical sophistication of other teams projects will not be considered."
  },
  {
    "objectID": "index.html#letter-grade-assignments",
    "href": "index.html#letter-grade-assignments",
    "title": "Course Syllabus",
    "section": "Letter grade assignments",
    "text": "Letter grade assignments\nAs this course is still under active development I cannot yet guarantee exact cutoffs for each grade. Harvey Mudd does not impose expectations for the grade distribution, so every student that meets the requirements for a given grade will earn it. The following is the maximum cutoff of each letter grade, the actual cutoff for each grade may be lower that what is listed below:\n\n&gt;90%: A\n&gt;80%: B\n&gt;70%: C\n&gt;60%: D\n\nAs the semester progresses, I will update this guide to provide a clearer picture of how grades will be assigned."
  },
  {
    "objectID": "index.html#course-feedback",
    "href": "index.html#course-feedback",
    "title": "Course Syllabus",
    "section": "Course feedback",
    "text": "Course feedback\nThis is my first time teaching a college course, so I will need your help! I want to make sure that we go through the material at an appropriate pace and that concepts are presented in a clear and understandable way. To do this, I will be continuously soliciting feedback from you throughout the semester on both the lectures and assignments. I ask that you provide feedback honestly, but kindly. There are three mechanisms I will use for feedback:\nIn-class: In class we will use a thumbs-up, thumbs down system. When I ask if people are following the lecture you can put your thumb up to indicate that you feel you are understanding the material being presented, down to indicate that you are lost or the lecture is confusing, and sideways to indicate that you followed some parts, but not all. You are, of course, also encouraged to give verbal feedback if appropriate.\nWith homework: Each homework will include a link to a survey to give feedback on that week’s assignment and lectures. Submitting this form is a required part of the homework, but your answers will not be tracked or accounted for in grades. This gives you a chance to indicate any issues (or things you like) with the class.\nGeneral anonymous feedback: If you have an issue with the course that you would like me to be aware of, but do not want your name to be associated with, you can use this form to submit an anonymous issue. Please continue to remain constructive and kind when submitting feedback in this way."
  },
  {
    "objectID": "index.html#academic-issues-and-wellness",
    "href": "index.html#academic-issues-and-wellness",
    "title": "Course Syllabus",
    "section": "Academic issues and wellness",
    "text": "Academic issues and wellness\nMy primary goal is for every student to understand the material to the best extent possible and hopefully enjoy learning the material at the same time. If at any point you are concerned about your grade or feel you are struggling for any reason I encourage you to reach out to me either via slack/email or during office hours. I will also try to reach out to you if I notice you are struggling with the material or are not on track to pass the class.\nI also want you to prioritize your mental and physical well-being. The college has several resources that can help you with this. The academic deans (academicdeans@g.hmc.edu) can help you keep on top of your academic progress. The office of health and wellness (https://www.hmc.edu/health-wellness/) can help you with a wide range of physical and metal health issues. I encourage you to be proactive, if you are starting to feel anxious, overwhelmed or depressed seeking help early can be extremely valuable. If you are unsure where to go, I can help guide you to the appropriate resource. The Claremont Care Guide, provides a useful guide if you or someone you know is in urgent distress."
  },
  {
    "objectID": "index.html#accommodations",
    "href": "index.html#accommodations",
    "title": "Course Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\nIf you have a disability (for example, mental health, learning, chronic health, physical, hearing, vision, neurological, etc.) and expect barriers related to this course, it is important to request accommodations and establish a plan. Requests for accommodations must go through the Office of Accessible Education. I am happy to work with them to establish an appropriate plan for this course. I also encourage reaching out to them if you are unsure of your eligibility for accommodations, they can help determine what is appropriate for you.\nRemember that requests for accommodations must be made each semester. If you are not already registered this process can take time and accommodations cannot be applied retroactively, so starting the process early is important."
  },
  {
    "objectID": "index.html#attendence",
    "href": "index.html#attendence",
    "title": "Course Syllabus",
    "section": "Attendence",
    "text": "Attendence\nAttendence is strongly encouraged as it is beneficial for both your own learning and that of your peers who may learn from your knowledge and viewpoints. Not only is attendance reflected in your participation grade, it is also highly correlated with performance on exams and homework. That said, I understand that there are times where student may miss class for a variety of reasons. If you miss a class (or several) please contact me by email or slack and we can work out a plan to catch you up on the material. Up to 1 unexcused absence per month will not affect your participation grade, neither will excused absences due to illness, injury, etc."
  },
  {
    "objectID": "index.html#guidelines-for-respectful-class-discussion",
    "href": "index.html#guidelines-for-respectful-class-discussion",
    "title": "Course Syllabus",
    "section": "Guidelines for respectful class discussion",
    "text": "Guidelines for respectful class discussion\nThe goal of in-class discussions to understand each others perspectives and to contribute to both our own learning and that of our peers. To make sure that in-class discussions are aligned with these goals please be mindful of the following guidelines:\n\nAvoid judgment: Students enter this class with a variety of backgrounds, experience and viewpoints. Be positive and encouraging to your peers even if you feel they are incorrect. Strive to make sure those around you feel comfortable answering questions even if they are not completely sure of their answer and give opinions that they are not sure others will agree with. Remember that giving an answer different from what the instructor was looking for can lead to productive and informative discussions.\nAllow everyone a chance to speak: We want to give every student a chance to participate in the class and in discussions. If you find yourself speaking, answering or asking questions far more than your peers, consider encouraging others to speak instead. Remember that in-class time is not your only opportunity to discuss this material and you are welcome to ask more questions in office hours.\nPractice active listening: When having in-class discussions make sure to acknowledge the answers and opinions of others before offering your own. Avoid interrupting others. Your thoughts deserve to be heard and understood, so it’s important that we work together to make sure everyone’s contributions are considered.\nBe kind: Do not use harsh or disparaging language in class. Avoid blame or speculation about other students. Aim to be charitable in your interpretations of other peoples words. Respect the boundaries set by others.\nBe inclusive: Be respectful of everyone’s background and identity. Avoid making assumptions or generalizations based on someone’s (perceived) social group. Do not ask individuals to speak for their social group."
  },
  {
    "objectID": "index.html#collaboration-policy",
    "href": "index.html#collaboration-policy",
    "title": "Course Syllabus",
    "section": "Collaboration policy",
    "text": "Collaboration policy\nYou are encouraged to discuss and collaborate on homework assignments with other students, but you must write-up all final answers on your own. This means you may:\n\nDiscuss published course materials and topics\nDiscuss approaches to problems with other students, including while working on the assignments (work in small groups).\nShare helpful examples and resources with other students\nHelp other students with technical issues such as setting up GitHub and Python environments.\nView another student’s code for the purpose of debugging small technical issues (exceptions, syntax errors etc.)\n\nYou may not:\n\nCopy/paste another student’s completed answers to any problem or allow another student to copy/paste your answers\nShare answers to completed problems with other students\nDistribute or post online any assignments, problems and/or solutions.\nFail to acknowledge collaborators.\n\nThis collaboration policy is covered by the Harvey Mudd honor code and violations will be referred to the honor code board.\nEach homework will have space for you to indicate who you discussed the assignment with. Please use the #team-matching channel on the course Slack to find study partners."
  },
  {
    "objectID": "index.html#ai-policy",
    "href": "index.html#ai-policy",
    "title": "Course Syllabus",
    "section": "AI Policy",
    "text": "AI Policy\nIn this course we will be learning the fundamental tools for building large language models and chat AIs, such as ChatGPT. Therefore I encourage you to experiment with ChatGPT and it’s competitors during this course, but only for learning about concepts. You may not share any assignment materials with large language models including assignment questions, support code and your own answers. This includes AI-assisted code-helpers such as Github co-pilot and Google Gemini in Colab. Please disable these tools when working on class assignments.\nHomeworks in this class are highly structured, in order to guide you through the often complex tools at the heart of deep learning. While I believe this structure is helpful for learning This makes the assignments particularly susceptible to AI-assisted academic dishonesty."
  },
  {
    "objectID": "index.html#covid-safety",
    "href": "index.html#covid-safety",
    "title": "Course Syllabus",
    "section": "COVID Safety",
    "text": "COVID Safety\nCollege policy states that masks are no longer required indoors for the upcoming semester. I will not require masks in class, but students who prefer to continue wearing masks are should do so. If you are feeling sick please stay home and let me know so that I can provide you with the relevant course materials."
  },
  {
    "objectID": "index.html#courses",
    "href": "index.html#courses",
    "title": "Course Syllabus",
    "section": "Courses",
    "text": "Courses\n\nfastai (website)\nDeep Learning Specialization (Coursera MOOC)\nDeep Learning (Stanford CS230 course)\nConvolutional Neural Networks for Visual Recognition (Stanford CS231n course)\nIntroduction to Deep Learning (MIT 6.S191 course)\nMIT Deep Learning and Artificial Intelligence Lectures (MIT course)\nDeep Reinforcement Learning (Berkeley CS 285 course)\nDeep Reinforcement Learning (free online course)\nDeep Learning Systems"
  },
  {
    "objectID": "index.html#books",
    "href": "index.html#books",
    "title": "Course Syllabus",
    "section": "Books",
    "text": "Books\n\nDive into Deep Learning (UC Berkeley book)\nDeep Learning (free book)\nFirst steps towards Deep Learning with PyTorch (free book)\nNeural Networks and Deep Learning (free book)\nDeep Learning With PyTorch (pdf)\nAnnotated Algorithms in Python (free book)\nLearn Python the Right way (free book)\nThe Linux Command Line by William Shotts"
  },
  {
    "objectID": "index.html#math",
    "href": "index.html#math",
    "title": "Course Syllabus",
    "section": "Math",
    "text": "Math\n\nThe Matrix Calculus You Need For Deep Learning (website)\nThe Mechanics of Machine Learning (free book)\nMathematics for Machine Learning (free book)\nSeeing Theory: A Visual Introduction To Probability And Statistics (free book)"
  },
  {
    "objectID": "index.html#extras",
    "href": "index.html#extras",
    "title": "Course Syllabus",
    "section": "Extras",
    "text": "Extras\n\nCheatsheet (website)\nTensorFlow 2.0 Complete Course - Python Neural Networks for Beginners Tutorial (YouTube)\nNeural Networks (3blue1brown YouTube)\nMachine Learning From Scratch (website)\nA visual introduction to machine learning (website)"
  },
  {
    "objectID": "index.html#python-1",
    "href": "index.html#python-1",
    "title": "Course Syllabus",
    "section": "Python",
    "text": "Python\n\nGoogle’s Python Class\nIntroduction to Python | Microsoft Learn\nList of free free Python books\nPython Programming Tutorials\nLearn Python - Full Course for Beginners (YouTube)\nPython In 1 Minute (YouTube)\nAutomate the Boring Stuff With Python (book)\nIntroduction to Python Programming (free course)\nA Whirlwind Tour of Python (Jupyter Notebooks)\nPython for Everybody Specialization (free course)\nIntroduction to Computer Science and Programming Using Python (MIT course)"
  },
  {
    "objectID": "index.html#ethics",
    "href": "index.html#ethics",
    "title": "Course Syllabus",
    "section": "Ethics",
    "text": "Ethics\n\nAwful AI\nLearning from the past to create Responsible AI\nPractical Data Ethics\nFair ML Book\nMachine Ethics Podcast\nACM Code of Ethics and Professional Conduct\nIEEE Code of Ethics\nCode of Conduct for Professional Data Scientists"
  },
  {
    "objectID": "index.html#librariesframeworkstools",
    "href": "index.html#librariesframeworkstools",
    "title": "Course Syllabus",
    "section": "Libraries/Frameworks/Tools",
    "text": "Libraries/Frameworks/Tools\n\nMlxtend (machine learning extensions)\nStreamlit (Turn data scripts into sharable web apps in minutes)\nDeepnote (The notebook you’ll love to use)"
  },
  {
    "objectID": "calendar/calendar.html",
    "href": "calendar/calendar.html",
    "title": "Course Calendar",
    "section": "",
    "text": "This calendar is subject to change depending on the pace of the class and student interest.\n\n\n\n\n\n\n\n\nDate\nEvent\nTopics\nReadings\nMaterials\n\n\n\n\nWeek 1\n\n\nJan 20, 2025\nMartin Luther King Jr. Day\n\n\n\n\n\nJan 22, 2025\nLecture 1\nCourse introduction, goals of neural networks\nBook 1: 1.2.1-1.2.2, 7.1.1-7.2.4, 7.8.1, 7.8.2\nPrerequisites Notes slides\n\n\nWeek 2\n\n\nJan 27, 2025\nLecture 2\nLinear regression, gradient descent\nBook 1: 4.2.1, 4.2.2, 11.1-11.2.4\nNotes Slides\n\n\nJan 29, 2025\nLecture 3\nLinear regression, maximum likelihood\nBook 1: 4.2.1, 4.2.2, 11.1-11.2.4\nNotes\n\n\nJan 30, 2025\nHomework 1 Due\n\n\nAssignment\n\n\nWeek 3\n\n\nFeb 3, 2025\nLecture 4\nLogistic regression\nBook 1: 10.1, 10.2.1, 10.2.3, 10.3.1-10.3.3\nNotes\n\n\nFeb 5, 2025\nLecture 5\nMultinomial logistic regression\nBook 1: 10.2.2\nNotes\n\n\nFeb 6, 2025\nHomework 2 Due\n\n\nAssignment\n\n\nWeek 4\n\n\nFeb 10, 2025\nLecture 6\nFeature transforms\nBook 1: 13.1, 13.2\nNotes\n\n\nFeb 12, 2025\nlecture 7\nNeural networks\nBook 1: 13.1, 13.2\nNotes\n\n\nFeb 13, 2025\nHomework 3 Due\n\n\nAssignment\n\n\nWeek 5\n\n\nFeb 17, 2025\nLecture 8\nDeep neural networks\nBook 1: 13.1, 13.2\nNotes\n\n\nFeb 19, 2025\nLecture 9\nAutomatic Differentiation\nBook 1: 13.3\nNotes\n\n\nFeb 20, 2025\nHomework 4 Due\n\n\nAssignment\n\n\nWeek 6\n\n\nFeb 24, 2025\nLecture 10\nReverse-mode Automatic Differentiation\nBook 1: 13.4.5, 13.5\nNotes\n\n\nFeb 26, 2025\nLecture 11\nPyTorch\nBook 1: 13.5\nNotebook\n\n\nFeb 27, 2025\nHomework 5 Due\n\n\nAssignment\n\n\nWeek 7\n\n\nMar 3, 2025\nLecture 12\nL1 & L2 regularization\nBook 1: 8.4\nNotes\n\n\nMar 5, 2025\nLecture 13\nRegularization (Cont.), Dropout\nBook 1: 13.4.1-13.4.2\nNotes\n\n\nMar 6, 2025\nHomework 6 Due\n\n\nAssignment\n\n\nWeek 8\n\n\nMar 10, 2025\nLecture 14\nStochastic gradient descent\nBook 1: 14.1-14.3\nNotes\n\n\nMar 12, 2025\nLecture 15\nStochastic gradient descent\nBook 1: 14.1-14.3\nNotes\n\n\nMar 13, 2025\nHomework 7 Due\n\n\nAssignment\n\n\nWeek 9\n\n\nMar 17, 2025\nSpring break\n\n\n\n\n\nWeek 10\n\n\nMar 24, 2025\nLecture 16\nResidual networks and Normalization\nBook 1: 15.1, 15.2.1-15.2.3\nSlides\n\n\nMar 26, 2025\nLecture 17\nResidual networks and Normalization (cont.)\nBook 1: 15.1, 15.2.1-15.2.3\nSlides\n\n\nMar 27, 2025\nEthics Warm-up Due\n\n\nAssignment\n\n\nWeek 11\n\n\nMar 31, 2025\nLecture 18\nConvolutional Networks\nBook 1: 15.2.5-15.2.7\nSlides\n\n\nApr 2, 2025\nLecture 19\nConvolutional Networks (cont.)\nBook 1: 15.2.5-15.2.7\nSlides\n\n\nApr 3, 2025\nHomework 8 Due\n\n\nAssignment\n\n\nWeek 12\n\n\nApr 7, 2025\nLecture 20\nAutoencoders & U-Nets\nBook 1: 15.2.1-15.2.6\n\n\n\nApr 9, 2025\nLecture 21\nImage models\n\n\n\n\nApr 10, 2025\nProject Proposal Due\n\n\nAssignment\n\n\nWeek 13\n\n\nApr 14, 2025\nLecture 22\nLanguage models, RNNs\nBook 1: 15.2.1-15.2.6\nSlides\n\n\nApr 16, 2025\nLecture 23\nAttention layers\n\n\n\n\nApr 17, 2025\nHomework 9 Due\n\n\nAssignment\n\n\nWeek 14\n\n\nApr 21, 2025\nLecture 24\nTransformers\n\n\n\n\nApr 23, 2025\nLecture 25\nTransformers (cont.), Large language models\n\n\n\n\nApr 24, 2025\nProject check-in due\n\n\nAssignment\n\n\nWeek 15\n\n\nApr 28, 2025\nLecture 26\nAddressing bias in machine learning\n\n\n\n\nApr 29, 2025\nLecture 27\nImpacts of machine learning\n\n\n\n\nApr 30, 2025\nHomework 10 Due\n\n\nAssignment\n\n\nFinals\n\n\nMay 9, 2025\nFinal project due\n\n\nAssignment\n\n\nMay 12, 2025\nFinal project feedback due"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html",
    "href": "assignments/homeworks/homeworks.html",
    "title": "Homeworks",
    "section": "",
    "text": "Assignment\nRequirements.txt\nNotebook"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-1",
    "href": "assignments/homeworks/homeworks.html#homework-1",
    "title": "Homeworks",
    "section": "",
    "text": "Assignment\nRequirements.txt\nNotebook"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-2",
    "href": "assignments/homeworks/homeworks.html#homework-2",
    "title": "Homeworks",
    "section": "Homework 2",
    "text": "Homework 2\n\nAssignment\nRequirements.txt\nNotebook"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-3",
    "href": "assignments/homeworks/homeworks.html#homework-3",
    "title": "Homeworks",
    "section": "Homework 3",
    "text": "Homework 3\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-4",
    "href": "assignments/homeworks/homeworks.html#homework-4",
    "title": "Homeworks",
    "section": "Homework 4",
    "text": "Homework 4\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-5",
    "href": "assignments/homeworks/homeworks.html#homework-5",
    "title": "Homeworks",
    "section": "Homework 5",
    "text": "Homework 5\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-6",
    "href": "assignments/homeworks/homeworks.html#homework-6",
    "title": "Homeworks",
    "section": "Homework 6",
    "text": "Homework 6\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-7",
    "href": "assignments/homeworks/homeworks.html#homework-7",
    "title": "Homeworks",
    "section": "Homework 7",
    "text": "Homework 7\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-8",
    "href": "assignments/homeworks/homeworks.html#homework-8",
    "title": "Homeworks",
    "section": "Homework 8",
    "text": "Homework 8\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-9",
    "href": "assignments/homeworks/homeworks.html#homework-9",
    "title": "Homeworks",
    "section": "Homework 9",
    "text": "Homework 9\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/homeworks.html#homework-10",
    "href": "assignments/homeworks/homeworks.html#homework-10",
    "title": "Homeworks",
    "section": "Homework 10",
    "text": "Homework 10\n\nAssignment\nRequirements.txt\nNotebook\nSupport code"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/main.html",
    "href": "assignments/homeworks/Homework 1/main.html",
    "title": "Homework 1: Introduction to Numpy",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/main.html#part-1-numpy-basics",
    "href": "assignments/homeworks/Homework 1/main.html#part-1-numpy-basics",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 1: Numpy basics",
    "text": "Part 1: Numpy basics\nAs discussed in class, a square matrix \\(A\\) defines a linear mapping: \\(\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\). Given a vector \\(\\textbf{x}\\), we can find the corresponding output of this mapping \\(\\textbf{b}\\) using matrix-vector multiplication: \\(\\textbf{b}=A \\textbf{x}\\). We can write an example matrix-multiplication using matrix notation as:\n\\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}\n= \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix}\n\\]\n\nQ1 (5 points)\nPerform this matrix-vector multiplication by hand and write the answer in the cell below.\nWRITE ANSWER HERE\n\n\n\n\n\nQ2 (5 points)\nIn the code cell below, create the matrix \\(A\\) and the vector \\(\\textbf{x}\\) shown above, using Numpy. Then use the np.dot function to find the output of the mapping \\(\\textbf{b} = A\\textbf{x}\\). Verify that the answer matches what you derived above.\n\n# Fill answers here\nA =\nx =\nb =\n\nprint(b)\n\nOften we will have access to the transformed vector \\(\\textbf{b}\\) and need to find the orginal vector \\(\\textbf{x}\\). To do this we need to solve the system of linear equations \\(A\\textbf{x}=\\textbf{b}\\) for \\(\\textbf{x}\\). \\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix} = \\begin{bmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{bmatrix}\n\\]\n\n\nQ3 (5 points)\nFind the missing \\(\\textbf{x}\\) in the equation above using the np.linalg.solve function and verify that \\(A\\textbf{x}=\\textbf{b}\\).\n\n# Fill answer here (A is the same matrix from above)\nb =\nx =\n\nIn linear algebra you may have learned how to solve a system of linear equations using Gaussian elimination. Here we will implement an alternative approach known as Richardson iteration. In this method we start with an inital guess for the solution: \\(\\textbf{x}^{(0)}\\), then we will iteratively update this guess until the solution is reached. Given a matrix \\(A\\), a target \\(\\textbf{b}\\) and a current guess \\(\\textbf{x}^{(k)}\\), we can compute the Richardson update as:\n\\[\\textbf{x}^{(k+1)} \\leftarrow \\textbf{x}^{(k)} + \\omega \\left(\\textbf{b} - A\\textbf{x}^{(k)}\\right)\\]\nHere \\(\\omega\\) is a constant that we can choose to adjust the algorithm. We will set \\(\\omega = 0.1\\).\n\n\nQ4 (5 points)\nFill in the Richardson iteration function below and apply it to the system of linear equations from above using 100 updates. Verify that if gives a similar answer to np.linalg.solve.\n\n# Fill in function below\ndef richardson_iter(x_guess, A, b, omega=0.1):\n\n    return new_x_guess\n\nx_guess = np.zeros(3)\nfor i in range(100):\n    x_guess = richardson_iter(x_guess, A, b)\n\nprint(x_guess, x)\n\nRecall that the length of a vector is given by it’s two-norm, which is defined as: \\[\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.\\]\nCorrespondingly, the (Euclidian) distance between two points \\(\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n\\) can be written as \\(\\|\\mathbf{a} - \\mathbf{b}\\|_2\\). As a convenient measure of error for our Richardson iteration algorithm, we will use the squared Euclidean distance. For a guess \\(\\mathbf{x}^{(k)}\\) we will compute the error \\(e^{(k)}\\) as: \\[e^{(k)} = \\|A\\mathbf{x}^{(k)} - \\mathbf{b}\\|_2^2\\]\nIn expanded form, this would be written as: \\[e^{(k)} = \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\n\n\nQ5 (10 points)\nWrite a function to compute the error of a given guess. Then run Richardson iteration again for 100 steps, computing the error at each step. Finally create a plot of the error for each step (error vs. step). Plot reference\nHint: recall that basic operations in numpy (addition, subtraction, powers) are performed element-wise.\n\n# Fill in function below\ndef error(x_guess, A, b):\n\n    return err\n\n# Add code to plot the error over time\n\nx_guess = np.zeros(3)\nfor step in range(100):\n\n    x_guess = richardson_iter(x_guess, A, b)\n\n\n\n\nQ6 (10 points)\nDerive the partial derivative of the error with respect to a single entry of \\(\\mathbf{x}^{(k)}\\) (without loss of generality, we will say \\(x^{(k)}_1\\)). Work in the expanded form as in the equation above, writing your answer in the markdown cell below.\nHint: You may find it helpful to refer to the latex equation cheatsheet on the course website. You may show intermediate steps here or as handwritten work as a separate file in the repository. The final answer should be filled in here.\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1}= \\]\nYOU MAY ADD WORK HERE\nIn practice, we will likely want to compute the derivative with respect to all entries of \\(\\mathbf{x}\\): \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}} = \\begin{bmatrix}\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1} \\\\\n\\vdots \\\\\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_n}\n\\end{bmatrix}\\]\n\n\nQ7 (10 points)\nUsing the formula you just derived, write the formula for the vector of all partial derivatives in the compact matrix/vector notation (e.g. \\(A\\mathbf{x}=\\mathbf{b}\\)).\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}}= \\]\n\n\nQ8 (5 points)\nDo you notice any relationship between this result and the Richardson iteration algorithm above? (1-2 sentences) We will discuss this more in class!\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/main.html#part-2-working-with-batches-of-vectors",
    "href": "assignments/homeworks/Homework 1/main.html#part-2-working-with-batches-of-vectors",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 2: Working with batches of vectors",
    "text": "Part 2: Working with batches of vectors\nRecall that a vector can also be seen as either an \\(n \\times 1\\) matrix (column vector) or a \\(1 \\times n\\) matrix (row vector).\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x}^T = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nNote that we use the same notation for both as they refer to the same concept (a vector). The difference becomes relevant when we consider matrix-vector multiplication. We can write matrix-vector multiplication in two ways: \\[\\text{Matrix-vector: }A\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}^TA^T= \\mathbf{b}^T\\] In matrix-vector multiplication we treat \\(\\textbf{x}\\) as a column vector (\\(n \\times 1\\) matrix), while in vector-matrix multiplication we treat it as a row vector (\\(n \\times 1\\) matrix). Transposing \\(A\\) for left multiplication ensures that the two forms give the same answer.\n\nQ9 (5 points)\nUsing the previously defined \\(\\mathbf{x}\\), create an explicit column vector and row vector. Then using the previously defined \\(A\\), verify that the matrix-vector and vector-matrix multiplications shown above do produce the same resultant vector \\(\\mathbf{b}\\).\nHint: Recall that np.dot is also used for matrix-matrix multiplication. The values of \\(\\mathbf{x}\\) and \\(A\\) are: \\[\\mathbf{x} = \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}, \\quad A = \\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix}\\]\n\n# Fill in code here\nx_col =\nx_row =\n\nThe distinction between row and column vectors also affects the behaivior of other operations on np.array objects, particularly through the concept of broadcasting.\n\n\nQ10 (5 points)\nConsider a \\(3 \\times 3\\) matrix of all ones as defined in code below, along with the 1-d vector \\(\\mathbf{x}\\).\n\nones = np.ones((3, 3))\nx = np.array([1, -2, 1])\nones\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n\n\nComplete the line of code below such that the result of the operation is:\n\\[\\begin{bmatrix}\n1 & -2 & 1 \\\\\n1 & -2  & 1 \\\\\n1 & -2 & 1\n\\end{bmatrix}\\]\nHint: You should replace SHAPE with an appropriate shape for broadcasting and OPERATION with an appropriate operation (e.g. +, -, *, /)\n\n# Fill in code here\n\nones OPERATION x.reshape( SHAPE )\n\nThroughout this course we will typically use row vectors and vector-matrix multiplication, as this is more conventional in neural-network literature. The concept of row and column vectors becomes handy when transforming collections of vectors.\nRecall that a matrix can be seen as a collection of vectors. In numpy we can create a matrix from a list of (1- dimensional) vectors using the np.stack function. This function assumes that the vectors are row vectors creating the matrix as follows: \\[\\begin{bmatrix}\n3 & 1 & -2\n\\end{bmatrix},\\ \\begin{bmatrix}\n4 & 5 & 3\n\\end{bmatrix},\\ \\begin{bmatrix}\n-2 & -1 & 5\n\\end{bmatrix}\\quad \\overset{\\text{np.stack}}{\\longrightarrow} \\begin{bmatrix}\n3 & 1 & -2 \\\\\n4 & 5 & 3 \\\\\n-2 & -1 & 5\n\\end{bmatrix} \\]\nWe will call this matrix \\(X\\) to denote that it is a collection of vectors, rather than a single vector (\\(\\mathbf{x}\\)).\n\n\nQ11 (5 points)\nCreate this matrix in numpy using th np.stack function.\n\n# Fill code here\n\nX =\nprint(X)\n\nWhen taken together as a matrix in this way, we can apply the linear mapping \\(A\\) to all vectors using matrix-matrix multiplication: \\[B=XA^T\\]\nLet’s put this into practice with a visual example.\n\n\nQ12 (5 points)\nCreate a \\(20 \\times 3\\) matrix, circle, in numpy of the following form\n\\[ \\begin{bmatrix} \\sin(\\theta_1) & \\cos(\\theta_1)  & 1 \\\\\n\\sin(\\theta_2) & \\cos(\\theta_2)  & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\theta_{20}) & \\cos(\\theta_{20})  & 1 \\\\\n\\end{bmatrix}\\] Where \\(\\theta_1...\\theta_{20}\\) are evenly spaced between \\(0\\) and \\(2\\pi\\).\n\ntheta = np.linspace(0, 2 * np.pi, 20) # Generates 20 evenly-spaced numbers between 0 and 2π\n\n# Fill in your code here\ncircle =\n\nThe code we just wrote creates a matrix corresponding to a collection of \\(20\\) row vectors of length 3. Each vector represents a point on the unit circle where the first entry is the x-coordinate, the second entry is the y-coordinate and the third entry is always \\(1\\): \\[ \\begin{bmatrix} x & y & 1 \\end{bmatrix}\\]\n\n\nQ13 (5 points)\nPlot the set of 20 points in circle using the plt.plot function. Use only the x and y coordinates, ignoring the column of 1s.\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\n\n\n\nQ14 (5 points)\nTransform all the vectors in circle with the matrix \\(A\\) using a single call to np.dot. Then plot the original set of points in black and the transformed points in red using the plt.plot function.\nYou might also consider why we added the extra column of 1s! We will discuss the answer to that in class. \\(A\\) is the same matrix from q1.\n\n# Fill your code here\ntransformed_circle =\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\n\n\n\nQ15 (5 points)\nFinally, shift all the vectors in transformed_circle by the vector \\(\\mathbf{b}\\) defined below, that is, add \\(\\mathbf{b}\\) to every row of the output matrix. Again plot the original set of points in black and the transformed points in red using the plt.plot function.\nHint: the solution to this question should not involve any loops, instead use broadcasting.\n\n# Fill your code here\nb = np.array([-0.5, 1.2, 0])\ntransformed_circle =\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\n# Fill your code here"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/main.html#part-3-loading-and-visualizing-data",
    "href": "assignments/homeworks/Homework 1/main.html#part-3-loading-and-visualizing-data",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 3: Loading and visualizing data",
    "text": "Part 3: Loading and visualizing data\nFor most of this class we will be working with real-world data. A very well-known dataset in statistics is the Iris flower dataset collected by Edgar Anderson in 1929. The dataset consists of measurments of iris flowers. Each flower has 4 collected measurements: sepal length, sepal width, petal length, petal width, as well as a classification into one of 3 species: Iris setosa, Iris versicolor and Iris virginica. We will return to this dataset in the next homework.\nWe can load this dataset as Numpy objects using the Scikit-Learn library. Below we’ve extrated 4 relevant arrays: - features: a matrix which has one row per observed flower and one column per measurement. - targets: An array that specifies the species of each flower as a number 0-2. - feature_names: a list of strings with the name of each measurement. - target_names: a list of strings with the name of each species.\nIn this homework, we will only visualize this dataset, which is typically a good first step in working with a new type of data. We’ll start by just looking at 2 measurements sepal length and petal length, along with the species.\n\nQ16 (10 points)\nBased on the Iris dataset loaded below, how many flowers did Edgar Anderson measure?\nIn other words, how many observations are in this dataset?\n\nimport sklearn.datasets as datasets\ndataset = datasets.load_iris()\nfeatures = dataset['data']\ntargets = dataset['target']\nfeature_names = dataset['feature_names']\ntarget_names = dataset['target_names']\n\n# Write any code to determine the number of observations here\n\nFill in the code to create a scatterplot for the Iris dataset below. Plot sepal length on the x-axis and petal length on the y-axis. Set the color to correspond to the species.\n\n# Fill your code here\n\nplt.figure(figsize=(4, 4))"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html",
    "href": "lecture2-linear-regression/notes.html",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "In the previous lecture we reviewed the concept of a function, which is a mapping from a set of possible inputs to a corresponding set of outputs. Here we’ll consider functions with vector inputs and scalar outputs.\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nMathematically, we can easily definite a function using a sequence of basic operations.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThis function gives us the relationship between inputs \\(\\mathbf{x}\\) and outputs \\(f(\\mathbf{x})\\). That is, for any given input \\(x\\), we can find the corresponding output \\(y\\) by applying our function \\(f(\\mathbf{x})\\).\n\n\n\nA linear function is any function \\(f\\) where the following conditions always hold: \\[ f(\\mathbf{x} + \\mathbf{y}) =f(\\mathbf{x}) + f(\\mathbf{y})\\] and \\[ f(a\\mathbf{x}) = a f(\\mathbf{x})\\]For a linear function, the output can be defined as a weighted sum of the inputs. In other words a linear function of a vector can always be written as:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i\n\\]\nWe can add an offset \\(b\\) to create an affine function:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i +b\n\\]\nWe can also write this using a dot-product between our input \\(\\mathbf{x}\\) and parameter vector \\(\\mathbf{w}\\) as:\n\\[\nf(\\mathbf{x}) = \\mathbf{x} \\cdot \\mathbf{w} + b \\quad \\text{or} \\quad f(\\mathbf{x}) = \\mathbf{x}^T  \\mathbf{w} + b\n\\]\nIn one dimension, a linear (or affine) function is always a line, for example:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn higher dimensions, it is a plane or hyperplane:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn numpy we can easily write a function of this form:\n\ndef f(x):\n    w = np.array([-0.6, -0.2])\n    b = -1\n    return np.dot(x, w) + b\n\n\n\n\nLinear and affine functions are examples of classes of functions, they define a general form for many different functions. Using the affine example, we see that we can define a particular function by choosing values for \\(w_i\\) and \\(b\\).\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i +b\n\\]\nWe will refer to the values that define a function within our class (e.g. \\(w_i\\) and \\(b\\)) as the parameters of the function, by changing these values, we can change the function.\nWe typically refer to \\(\\mathbf{w}\\) specifically as the weight vector (or weights) and \\(b\\) as the bias. To summarize:\n\\[\n\\textbf{Affine function:  }f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}+b,\\quad \\textbf{Parameters:}\\quad \\big(\\text{Weights:  } \\mathbf{w},\\ \\text{Bias:  } b \\big)\n\\]\n\n\n\nNotationally, it can be tedious to always write the bias term. A common approach to compactly describing linear or affine functions is to use augmented inputs and weights, such that for \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\in \\mathbb{R}^n\\), we add \\(x_{n+1}=1\\) and \\(w_{n+1}=b\\). So:\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\longrightarrow \\mathbf{x}_{aug}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\\\ 1 \\end{bmatrix} \\quad \\text{and} \\quad \\mathbf{w} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix} \\longrightarrow \\mathbf{w}_{aug}=  \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\\\ b \\end{bmatrix}\n\\]\nWe can easily see then that using this notation:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{w} +b = \\mathbf{x}_{aug}^T \\mathbf{w}_{aug}\n\\]\nThis approach is common enough that we typically won’t bother with the \\(aug\\) notation and just assume that any function defined as \\(f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w}\\) can be defined to include a bias implicitly. Note that in this case the function is a linear function of the augmented input, thus we will still typically refer to functions of this form as linear functions.\nIn numpy this is similarly straightforward:\n\ndef f(x):\n    w = np.array([-0.6, -0.2, -1])\n    x = np.pad(x, ((0,1),), constant_values=1)\n    return np.dot(x, w)\n\n\n\n\nIn the real-world we often have access to inputs and outputs in the form of data, but not to an actual function that we can evaluate.\nSpecifically we will say that we have access to a dataset \\(\\mathcal{D}\\) made up of \\(N\\) pairs of inputs ( \\(\\mathbf{x}\\) ) and outputs ( \\(y\\) ):\n\\[\n\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ...\\ (\\mathbf{x}_N, y_N)\\}\n\\]\nWe call each of these pairs an observation. Let’s take a look at a real world example of a dataset.\n\n\nLet’s imagine we’re designing a car and we would like to know what the fuel efficiency of the car we’re designing will be in miles per gallon (MPG). We know some properties of our current design, such as the weight and horsepower, that we know should affect the efficiency. Ideally we would have access to a function that would give us the MPG rating if we provide these features.\n\\[\n\\text{mpg} = f(\\text{weight},\\ \\text{horsepower}...)\n\\]\nUnfortunately we don’t know the exact relationship between a car’s features and fuel efficiency. However, we can look at other cars on the market and see what the corresponding inputs and outputs would be:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 33mpg}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 21mpg}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\nOur dataset will be this collection of data that we have for all other cars. In general, each observation in this dataset will correspond to a car.\n\\[\n\\text{Dataset: } \\mathcal{D}=\\{(\\mathbf{x}_i,\\ y_i) \\text{  for  } i\\in 1...N\\}\n\\]\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = MPG\n\\]\nJust as with a known function, we can plot the inputs vs the outputs, however in this case, we only know the outputs for the inputs we’ve seen in our dataset. Let’s take a look at a single feature: the weight of a car.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur dataset gives us a set of known inputs and outputs for our unknown functions. The central question we will address in this course is then:\n\n\nFor example, in our car scenario, we might know that the car that we’re designing will weigh 3100 lbs. In our dataset we’ve haven’t seen a car that weighs exactly 3100 lbs, so we need a way to predict the output of the function at input 3100 lbs.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn general, our approach to this problem will be to model our unknown function with a known function that we can evaluate at any input. We want to chose a function \\(f\\) such that for any observation our dataset, the output of this function approximates the true target output that we observed.\n\\[\nf(\\mathbf{x}_i) \\approx y_i, \\quad \\forall (\\mathbf{x}_i, y_i) \\in \\mathcal{D}\n\\]\n\n\n\n\nOne reasonable approach we might consider is linear interpolation. In this approach, we simply connect all the neighboring points with straight lines:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn some cases this can be a reasonable approach! In fact it’s how the plt.plot function works. Real data however tends to be messy. The measurements in our dataset might not be 100% accurate or they might even conflict! What do we do if we have two observations with the same input and different outputs?\n\\[(\\text{Weight: }3100, \\text{MPG: } 34), \\quad (\\text{Weight: }3100, \\text{MPG: } 23) \\longrightarrow f(3100) = ?\\]\nAs the size and number of features in our inputs gets larger, this become even more complex. We can see this if we try to apply interpolation to a much larger MPG dataset:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression is the approach of modeling an unknown function with a linear function. From our discussion of linear functions, we know that this means that we will make predictions using a function of the form:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w} = \\sum_{i=1}^n x_i w_i\n\\]\nMeaning that the output will be a weighted sum of the features of the input. In the case of our car example, we will make predictions as:\n\\[\n\\text{Predicted MPG} = f(\\mathbf{x})=\n\\]\n\\[\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix}\n\\]\nWe see that under this approach each weight \\((w_1, w_2…)\\) tells us how much our prediction changes as we change the corresponding feature. For example, if we were to increase the weight of our car by 1 lb, the predicted MPG would change by \\(w_1\\).\nThe set of weights defines the particular linear regression function. In numpy we can define a generic class for linear regression:\n\nclass Regression:\n    def __init__(self, weights):\n        self.weights = weights\n    \n    def predict(self, x):\n        return np.dot(x, self.weights)\n\nmodel = Regression(np.array([1, 1, 1, 1, 1]))\nmodel.predict(np.array([5, 2, 3, 3, 1]))\n\nnp.int64(14)\n\n\nIf we again look at our plot of weight vs. MPG, we see we could chose many different linear functions to make predictions:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe residual or error of a prediction is the difference between the prediction and the true output:\n\\[\ne_i = y_i - f(\\mathbf{x}_i)\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn deciding what linear function to use, we need a measure of error for the entire dataset. A computationally convenient measure is mean squared error (MSE). The mean squared error is the averaged of the error squared for each observation in our dataset:\n\\[\nMSE = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i) - y_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]It follows that the best choice of linear function \\(f^*\\) is the one that minimizes the mean squared error for our dataset. Since each linear function is defined by a parameter vector \\(\\mathbf{w}\\), this is equivalent to finding \\(\\mathbf{w}^*\\), the parameters vector that minimizes the mean squared error. \\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\]\n\n\n\nNote that the mean squared error depends on the data inputs \\((\\mathbf{x}_1,…,\\mathbf{x}_N)\\), the data targets \\((y_1,…,y_N)\\) and the parameters \\((\\mathbf{w})\\). So we can express the MSE as a function of all three:\n\\[\nMSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nHere we have used \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) to refer to the entire collection of inputs and outputs from our dataset \\((\\mathcal{D})\\) respectively, so:\n\\[\n\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1n} \\\\ x_{21} & x_{22} & \\dots & x_{2n}\\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nn} \\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nThis is an example of loss function, for our given dataset this function tells us how much error (loss) we are incurring for a given choice of \\(\\mathbf{w}\\). If we assume our dataset is fixed we can drop the explicit dependence on \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\), looking at the loss as purely a function of our choice of parameters:\n\\[\n\\textbf{Loss}(\\mathbf{w})= MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nAgain, if our goal is to minimize error, we want to choose the parameters \\(\\mathbf{w}^*\\) that minimize this loss:\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{Loss}(\\mathbf{w})= \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\n\n\n\nIf we consider the case where our inputs are 1-dimensional, as in the weight example above, then our parameter vector \\(\\mathbf{w}\\) only has 2 entries: \\(w_1\\) and \\(b\\). In this case, we can actually plot our loss function directly!\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see that point where the loss is lowest, corresponds to the line that best fits our data!\n\n\n\nNow that we have a way to determine the quality of a choice of parameters \\(\\mathbf{w}\\), using our loss function, we need a way to actually find the \\(\\mathbf{w}^*\\) that minimizes our loss. To do this we will turn to an algorithm called gradient descent. In this lecture we will introduce gradient descent, but we will go into much more depth in a future lecture.\nWe’ll introduce gradient descent as a method to find the minimum of a generic function. We have some function \\(f(\\mathbf{\\cdot})\\) and we would like find the input \\(\\mathbf{w}^*\\) that minimizes the output of the function:\n\\[\n\\text{Find: } \\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ f(\\mathbf{w})\n\\]\nWe don’t know how to find \\(\\mathbf{w}^*\\) directly, but if we have an initial guess \\(\\mathbf{w}^{(0)}\\), we can try to update our guess to improve it.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} + \\mathbf{g}\n\\]\n\n\n\n\n\n\n\n\n\nHere we are changing \\(\\mathbf{w}^{(0)}\\) by moving in the direction of \\(\\mathbf{g}\\). If we recall that the gradient of a function at point \\(\\mathbf{x}\\) corresponds to the slope of \\(f\\) at \\(\\mathbf{w}\\), or equivalently the direction of maximum change. This gives us a natural choice for the update to our guess.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} - \\nabla f(\\mathbf{w}^{(0)})\n\\]\nNote that because the gradient corresponds to the direction that maximally increases \\(f(\\mathbf{w})\\), we actually need to subtract the gradient in order to minimize our function. We can repeat this process many times, continuously updating our estimate.\n\\[\n\\text{For }i \\text{ in 1,...,T}\\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nRecall that it’s minimum value \\(\\mathbf{w}^*\\), a function \\(f\\) must have a gradient of \\(\\mathbf{0}\\).\n\\[\n\\nabla f(\\mathbf{w}^*) = \\mathbf{0}\n\\]\nIt follows that:\n\\[\n\\mathbf{w}^{*} = \\mathbf{w}^{*} - \\nabla f(\\mathbf{w}^{*})\n\\]\nThis means that if our gradient descent reaches the minimum, it will stop updating the guess and we know that we can stop our iteration. So we could write our algorithm to account for this:\n\\[\n\\text{While } \\nabla f(\\mathbf{w}^{(i)}) \\neq \\mathbf{0} \\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]\nIn practice though, it could take infinitely many updates to find the exact minimum. A more common approach is to define a convergence criteria that stops the iteration when the gradient magnitude is sufficiently small:\n\\[\n\\text{While } ||\\nabla f(\\mathbf{w}^{(i)})||_2 &gt; \\epsilon \\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]\n\n\n\nNotice that the gradient descent algorithm we’ve defined so far not only says that we want to update our guess in the direction of the gradient, it also say that we want to move in that direction a distance equal to the magnitude of the gradient. It turns out this is often a very bad idea!\nThis approach says that when the magnitude of the gradient is large, we should take a large step, and vice-versa. This is desirable for many functions as it means when we’re far from the minimum we take large steps, moving toward the minimum more quickly. While when we’re close to the minimum we take small steps to refine our guess more precisely.\n\n\n\n\n\n\n\n\n\nHowever, if we take too large a step, we can overshoot the minimum entirely! In the worst case, this can lead to divergence, where gradient descent overshoots the minimum more and more at each step.\n\n\n\n\n\n\n\n\n\nRemember that the gradient is making a linear approximation to the function. A strait line has no minimum, so the gradient has no information about where along the approximation the true minimum will be.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nAlso remember that the gradient gives us the direction of maximum change of the function, but this is only true in the limit of a very small step.\n\\[\n\\frac{df}{d\\mathbf{w}}= \\underset{\\gamma \\rightarrow 0}{\\lim}\\ \\underset{\\|\\mathbf{\\epsilon}\\|_2 &lt; \\gamma}{\\max} \\frac{f(\\mathbf{w} + \\mathbf{\\epsilon}) - f(\\mathbf{w})}{\\|\\mathbf{\\epsilon}\\|_2}\n\\]\nSo in higher dimensions, the gradient may not point directly to the minimum.\nAll of these issues motivate the need to control the size of our updates. We will typically do this by introducing an additional control to our algorithm: a step size or learning rate. This is a small constant \\(\\alpha\\), that we will multiply the gradient by in each of our updates.\n\\[\n\\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}^{(i)})\n\\]\nUsing a small learning rate \\((\\alpha &lt;&lt; 1)\\) will make gradient descent slower, but much more reliable. Later on in the semester we will explore how to choose \\(\\alpha\\) (and even update it during optimization).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can apply gradient descent to linear regression in order to find the parameters that minimize the mean squared error loss. To do this we need to find the gradient of the mean squared error with respect to the parameters:\n\\[\n\\nabla_{\\mathbf{w}} \\textbf{MSE}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\bigg)\n\\]\n\\[\n= \\frac{2}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWith this gradient our gradient descent update becomes:\n\\[\n\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha\\bigg(\\frac{2 }{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w}^{(i)} - y_i)\\mathbf{x}_i\n\\]\nWe can see that this update is a sum of all the inputs weighted by their corresponding residual given the current value of the parameters.\nWe can see how the the parameters of our regression model change as we run gradient descent.\n\n\n\nGradient descent works well for finding the optimal parameters for a linear regression model, but in fact we can actually find the optimal set of parameters directly, without needing to run an iterative algorithm.\nWe know that at the minimum, the gradient must be \\(\\mathbf{0}\\), so the following condition must hold:\n\\[\n\\mathbf{0} = \\bigg( \\frac{2}{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWe can solve for a \\(\\mathbf{w}\\) that satisfied this condition by first dropping the constant \\(\\frac{2}{N}\\).\n\\[\n\\mathbf{0} = \\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\n\\[\n\\mathbf{0} = \\sum_{i=1}^N \\big( \\mathbf{x}_i\\mathbf{x}_i^T\\mathbf{w} - y_i \\mathbf{x}_i \\big)\n\\]\n\\[\n\\sum_{i=1}^N  y_i \\mathbf{x}_i  =\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)  \\mathbf{w}\n\\]\nNote that \\(\\mathbf{x}_i \\mathbf{x}_i^T\\) is a vector outer product:\n\\[\n\\mathbf{x}_i \\mathbf{x}_i^T = \\begin{bmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\  x_{in}\\end{bmatrix} \\begin{bmatrix} x_{i1} & x_{i2} & \\dots &  x_{in}\\end{bmatrix} =\n\\begin{bmatrix} x_{i1} x_{i1} & x_{i1} x_{i2} & \\dots & x_{i1} x_{in} \\\\\nx_{i2} x_{i1} & x_{i2} x_{i2} & \\dots & x_{i2} x_{in} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{in} x_{i1} & x_{in} x_{i2} & \\dots & x_{in} x_{in} \\\\\n\\end{bmatrix}\n\\]\nThus \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)\\) is a matrix. Multiplying both sides by the inverse \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1}\\) we get:\n\\[\n\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1} \\bigg(\\sum_{i=1}^N  y_i \\mathbf{x}_i\\bigg)  =  \\mathbf{w}^*\n\\]\nWe can write this more compactly using the stacked input matrix and label vector notation we saw in homework 1.\n\\[\n\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_{1} \\\\ \\mathbf{x}_{2} \\\\ \\vdots \\\\  \\mathbf{x}_{N} \\end{bmatrix},\\quad \\mathbf{y} = \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\  y_{N} \\end{bmatrix}\n\\]\nIn this case, the expression becomes:\n\\[\\mathbf{w}^* = \\big( \\mathbf{X}^T \\mathbf{X} \\big)^{-1} \\big(\\mathbf{y}\\mathbf{X}\\big)\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#functions-revisited",
    "href": "lecture2-linear-regression/notes.html#functions-revisited",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "In the previous lecture we reviewed the concept of a function, which is a mapping from a set of possible inputs to a corresponding set of outputs. Here we’ll consider functions with vector inputs and scalar outputs.\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nMathematically, we can easily definite a function using a sequence of basic operations.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThis function gives us the relationship between inputs \\(\\mathbf{x}\\) and outputs \\(f(\\mathbf{x})\\). That is, for any given input \\(x\\), we can find the corresponding output \\(y\\) by applying our function \\(f(\\mathbf{x})\\)."
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#linear-functions",
    "href": "lecture2-linear-regression/notes.html#linear-functions",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "A linear function is any function \\(f\\) where the following conditions always hold: \\[ f(\\mathbf{x} + \\mathbf{y}) =f(\\mathbf{x}) + f(\\mathbf{y})\\] and \\[ f(a\\mathbf{x}) = a f(\\mathbf{x})\\]For a linear function, the output can be defined as a weighted sum of the inputs. In other words a linear function of a vector can always be written as:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i\n\\]\nWe can add an offset \\(b\\) to create an affine function:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i +b\n\\]\nWe can also write this using a dot-product between our input \\(\\mathbf{x}\\) and parameter vector \\(\\mathbf{w}\\) as:\n\\[\nf(\\mathbf{x}) = \\mathbf{x} \\cdot \\mathbf{w} + b \\quad \\text{or} \\quad f(\\mathbf{x}) = \\mathbf{x}^T  \\mathbf{w} + b\n\\]\nIn one dimension, a linear (or affine) function is always a line, for example:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn higher dimensions, it is a plane or hyperplane:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn numpy we can easily write a function of this form:\n\ndef f(x):\n    w = np.array([-0.6, -0.2])\n    b = -1\n    return np.dot(x, w) + b"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#parameterized-functions",
    "href": "lecture2-linear-regression/notes.html#parameterized-functions",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Linear and affine functions are examples of classes of functions, they define a general form for many different functions. Using the affine example, we see that we can define a particular function by choosing values for \\(w_i\\) and \\(b\\).\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i +b\n\\]\nWe will refer to the values that define a function within our class (e.g. \\(w_i\\) and \\(b\\)) as the parameters of the function, by changing these values, we can change the function.\nWe typically refer to \\(\\mathbf{w}\\) specifically as the weight vector (or weights) and \\(b\\) as the bias. To summarize:\n\\[\n\\textbf{Affine function:  }f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}+b,\\quad \\textbf{Parameters:}\\quad \\big(\\text{Weights:  } \\mathbf{w},\\ \\text{Bias:  } b \\big)\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#handling-bias-compactly",
    "href": "lecture2-linear-regression/notes.html#handling-bias-compactly",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Notationally, it can be tedious to always write the bias term. A common approach to compactly describing linear or affine functions is to use augmented inputs and weights, such that for \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\in \\mathbb{R}^n\\), we add \\(x_{n+1}=1\\) and \\(w_{n+1}=b\\). So:\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\longrightarrow \\mathbf{x}_{aug}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\\\ 1 \\end{bmatrix} \\quad \\text{and} \\quad \\mathbf{w} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix} \\longrightarrow \\mathbf{w}_{aug}=  \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\\\ b \\end{bmatrix}\n\\]\nWe can easily see then that using this notation:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{w} +b = \\mathbf{x}_{aug}^T \\mathbf{w}_{aug}\n\\]\nThis approach is common enough that we typically won’t bother with the \\(aug\\) notation and just assume that any function defined as \\(f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w}\\) can be defined to include a bias implicitly. Note that in this case the function is a linear function of the augmented input, thus we will still typically refer to functions of this form as linear functions.\nIn numpy this is similarly straightforward:\n\ndef f(x):\n    w = np.array([-0.6, -0.2, -1])\n    x = np.pad(x, ((0,1),), constant_values=1)\n    return np.dot(x, w)"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#datasets-and-observations",
    "href": "lecture2-linear-regression/notes.html#datasets-and-observations",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "In the real-world we often have access to inputs and outputs in the form of data, but not to an actual function that we can evaluate.\nSpecifically we will say that we have access to a dataset \\(\\mathcal{D}\\) made up of \\(N\\) pairs of inputs ( \\(\\mathbf{x}\\) ) and outputs ( \\(y\\) ):\n\\[\n\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ...\\ (\\mathbf{x}_N, y_N)\\}\n\\]\nWe call each of these pairs an observation. Let’s take a look at a real world example of a dataset.\n\n\nLet’s imagine we’re designing a car and we would like to know what the fuel efficiency of the car we’re designing will be in miles per gallon (MPG). We know some properties of our current design, such as the weight and horsepower, that we know should affect the efficiency. Ideally we would have access to a function that would give us the MPG rating if we provide these features.\n\\[\n\\text{mpg} = f(\\text{weight},\\ \\text{horsepower}...)\n\\]\nUnfortunately we don’t know the exact relationship between a car’s features and fuel efficiency. However, we can look at other cars on the market and see what the corresponding inputs and outputs would be:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 33mpg}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 21mpg}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\nOur dataset will be this collection of data that we have for all other cars. In general, each observation in this dataset will correspond to a car.\n\\[\n\\text{Dataset: } \\mathcal{D}=\\{(\\mathbf{x}_i,\\ y_i) \\text{  for  } i\\in 1...N\\}\n\\]\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = MPG\n\\]\nJust as with a known function, we can plot the inputs vs the outputs, however in this case, we only know the outputs for the inputs we’ve seen in our dataset. Let’s take a look at a single feature: the weight of a car.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#prediction-functions",
    "href": "lecture2-linear-regression/notes.html#prediction-functions",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Our dataset gives us a set of known inputs and outputs for our unknown functions. The central question we will address in this course is then:\n\n\nFor example, in our car scenario, we might know that the car that we’re designing will weigh 3100 lbs. In our dataset we’ve haven’t seen a car that weighs exactly 3100 lbs, so we need a way to predict the output of the function at input 3100 lbs.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn general, our approach to this problem will be to model our unknown function with a known function that we can evaluate at any input. We want to chose a function \\(f\\) such that for any observation our dataset, the output of this function approximates the true target output that we observed.\n\\[\nf(\\mathbf{x}_i) \\approx y_i, \\quad \\forall (\\mathbf{x}_i, y_i) \\in \\mathcal{D}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#linear-interpolation",
    "href": "lecture2-linear-regression/notes.html#linear-interpolation",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "One reasonable approach we might consider is linear interpolation. In this approach, we simply connect all the neighboring points with straight lines:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn some cases this can be a reasonable approach! In fact it’s how the plt.plot function works. Real data however tends to be messy. The measurements in our dataset might not be 100% accurate or they might even conflict! What do we do if we have two observations with the same input and different outputs?\n\\[(\\text{Weight: }3100, \\text{MPG: } 34), \\quad (\\text{Weight: }3100, \\text{MPG: } 23) \\longrightarrow f(3100) = ?\\]\nAs the size and number of features in our inputs gets larger, this become even more complex. We can see this if we try to apply interpolation to a much larger MPG dataset:\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#linear-regression-1",
    "href": "lecture2-linear-regression/notes.html#linear-regression-1",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Linear regression is the approach of modeling an unknown function with a linear function. From our discussion of linear functions, we know that this means that we will make predictions using a function of the form:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w} = \\sum_{i=1}^n x_i w_i\n\\]\nMeaning that the output will be a weighted sum of the features of the input. In the case of our car example, we will make predictions as:\n\\[\n\\text{Predicted MPG} = f(\\mathbf{x})=\n\\]\n\\[\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix}\n\\]\nWe see that under this approach each weight \\((w_1, w_2…)\\) tells us how much our prediction changes as we change the corresponding feature. For example, if we were to increase the weight of our car by 1 lb, the predicted MPG would change by \\(w_1\\).\nThe set of weights defines the particular linear regression function. In numpy we can define a generic class for linear regression:\n\nclass Regression:\n    def __init__(self, weights):\n        self.weights = weights\n    \n    def predict(self, x):\n        return np.dot(x, self.weights)\n\nmodel = Regression(np.array([1, 1, 1, 1, 1]))\nmodel.predict(np.array([5, 2, 3, 3, 1]))\n\nnp.int64(14)\n\n\nIf we again look at our plot of weight vs. MPG, we see we could chose many different linear functions to make predictions:\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#residuals-and-error",
    "href": "lecture2-linear-regression/notes.html#residuals-and-error",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "The residual or error of a prediction is the difference between the prediction and the true output:\n\\[\ne_i = y_i - f(\\mathbf{x}_i)\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#mean-squared-error",
    "href": "lecture2-linear-regression/notes.html#mean-squared-error",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "In deciding what linear function to use, we need a measure of error for the entire dataset. A computationally convenient measure is mean squared error (MSE). The mean squared error is the averaged of the error squared for each observation in our dataset:\n\\[\nMSE = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i) - y_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]It follows that the best choice of linear function \\(f^*\\) is the one that minimizes the mean squared error for our dataset. Since each linear function is defined by a parameter vector \\(\\mathbf{w}\\), this is equivalent to finding \\(\\mathbf{w}^*\\), the parameters vector that minimizes the mean squared error. \\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#loss-functions",
    "href": "lecture2-linear-regression/notes.html#loss-functions",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Note that the mean squared error depends on the data inputs \\((\\mathbf{x}_1,…,\\mathbf{x}_N)\\), the data targets \\((y_1,…,y_N)\\) and the parameters \\((\\mathbf{w})\\). So we can express the MSE as a function of all three:\n\\[\nMSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nHere we have used \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) to refer to the entire collection of inputs and outputs from our dataset \\((\\mathcal{D})\\) respectively, so:\n\\[\n\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1n} \\\\ x_{21} & x_{22} & \\dots & x_{2n}\\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nn} \\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nThis is an example of loss function, for our given dataset this function tells us how much error (loss) we are incurring for a given choice of \\(\\mathbf{w}\\). If we assume our dataset is fixed we can drop the explicit dependence on \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\), looking at the loss as purely a function of our choice of parameters:\n\\[\n\\textbf{Loss}(\\mathbf{w})= MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nAgain, if our goal is to minimize error, we want to choose the parameters \\(\\mathbf{w}^*\\) that minimize this loss:\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{Loss}(\\mathbf{w})= \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#visualizing-loss",
    "href": "lecture2-linear-regression/notes.html#visualizing-loss",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "If we consider the case where our inputs are 1-dimensional, as in the weight example above, then our parameter vector \\(\\mathbf{w}\\) only has 2 entries: \\(w_1\\) and \\(b\\). In this case, we can actually plot our loss function directly!\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see that point where the loss is lowest, corresponds to the line that best fits our data!"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#gradient-descent",
    "href": "lecture2-linear-regression/notes.html#gradient-descent",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Now that we have a way to determine the quality of a choice of parameters \\(\\mathbf{w}\\), using our loss function, we need a way to actually find the \\(\\mathbf{w}^*\\) that minimizes our loss. To do this we will turn to an algorithm called gradient descent. In this lecture we will introduce gradient descent, but we will go into much more depth in a future lecture.\nWe’ll introduce gradient descent as a method to find the minimum of a generic function. We have some function \\(f(\\mathbf{\\cdot})\\) and we would like find the input \\(\\mathbf{w}^*\\) that minimizes the output of the function:\n\\[\n\\text{Find: } \\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ f(\\mathbf{w})\n\\]\nWe don’t know how to find \\(\\mathbf{w}^*\\) directly, but if we have an initial guess \\(\\mathbf{w}^{(0)}\\), we can try to update our guess to improve it.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} + \\mathbf{g}\n\\]\n\n\n\n\n\n\n\n\n\nHere we are changing \\(\\mathbf{w}^{(0)}\\) by moving in the direction of \\(\\mathbf{g}\\). If we recall that the gradient of a function at point \\(\\mathbf{x}\\) corresponds to the slope of \\(f\\) at \\(\\mathbf{w}\\), or equivalently the direction of maximum change. This gives us a natural choice for the update to our guess.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} - \\nabla f(\\mathbf{w}^{(0)})\n\\]\nNote that because the gradient corresponds to the direction that maximally increases \\(f(\\mathbf{w})\\), we actually need to subtract the gradient in order to minimize our function. We can repeat this process many times, continuously updating our estimate.\n\\[\n\\text{For }i \\text{ in 1,...,T}\\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#gradient-descent-convergence",
    "href": "lecture2-linear-regression/notes.html#gradient-descent-convergence",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Recall that it’s minimum value \\(\\mathbf{w}^*\\), a function \\(f\\) must have a gradient of \\(\\mathbf{0}\\).\n\\[\n\\nabla f(\\mathbf{w}^*) = \\mathbf{0}\n\\]\nIt follows that:\n\\[\n\\mathbf{w}^{*} = \\mathbf{w}^{*} - \\nabla f(\\mathbf{w}^{*})\n\\]\nThis means that if our gradient descent reaches the minimum, it will stop updating the guess and we know that we can stop our iteration. So we could write our algorithm to account for this:\n\\[\n\\text{While } \\nabla f(\\mathbf{w}^{(i)}) \\neq \\mathbf{0} \\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]\nIn practice though, it could take infinitely many updates to find the exact minimum. A more common approach is to define a convergence criteria that stops the iteration when the gradient magnitude is sufficiently small:\n\\[\n\\text{While } ||\\nabla f(\\mathbf{w}^{(i)})||_2 &gt; \\epsilon \\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#step-sizes",
    "href": "lecture2-linear-regression/notes.html#step-sizes",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Notice that the gradient descent algorithm we’ve defined so far not only says that we want to update our guess in the direction of the gradient, it also say that we want to move in that direction a distance equal to the magnitude of the gradient. It turns out this is often a very bad idea!\nThis approach says that when the magnitude of the gradient is large, we should take a large step, and vice-versa. This is desirable for many functions as it means when we’re far from the minimum we take large steps, moving toward the minimum more quickly. While when we’re close to the minimum we take small steps to refine our guess more precisely.\n\n\n\n\n\n\n\n\n\nHowever, if we take too large a step, we can overshoot the minimum entirely! In the worst case, this can lead to divergence, where gradient descent overshoots the minimum more and more at each step.\n\n\n\n\n\n\n\n\n\nRemember that the gradient is making a linear approximation to the function. A strait line has no minimum, so the gradient has no information about where along the approximation the true minimum will be.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nAlso remember that the gradient gives us the direction of maximum change of the function, but this is only true in the limit of a very small step.\n\\[\n\\frac{df}{d\\mathbf{w}}= \\underset{\\gamma \\rightarrow 0}{\\lim}\\ \\underset{\\|\\mathbf{\\epsilon}\\|_2 &lt; \\gamma}{\\max} \\frac{f(\\mathbf{w} + \\mathbf{\\epsilon}) - f(\\mathbf{w})}{\\|\\mathbf{\\epsilon}\\|_2}\n\\]\nSo in higher dimensions, the gradient may not point directly to the minimum.\nAll of these issues motivate the need to control the size of our updates. We will typically do this by introducing an additional control to our algorithm: a step size or learning rate. This is a small constant \\(\\alpha\\), that we will multiply the gradient by in each of our updates.\n\\[\n\\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}^{(i)})\n\\]\nUsing a small learning rate \\((\\alpha &lt;&lt; 1)\\) will make gradient descent slower, but much more reliable. Later on in the semester we will explore how to choose \\(\\alpha\\) (and even update it during optimization)."
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#optimizing-linear-regression",
    "href": "lecture2-linear-regression/notes.html#optimizing-linear-regression",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "We can apply gradient descent to linear regression in order to find the parameters that minimize the mean squared error loss. To do this we need to find the gradient of the mean squared error with respect to the parameters:\n\\[\n\\nabla_{\\mathbf{w}} \\textbf{MSE}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\bigg)\n\\]\n\\[\n= \\frac{2}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWith this gradient our gradient descent update becomes:\n\\[\n\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha\\bigg(\\frac{2 }{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w}^{(i)} - y_i)\\mathbf{x}_i\n\\]\nWe can see that this update is a sum of all the inputs weighted by their corresponding residual given the current value of the parameters.\nWe can see how the the parameters of our regression model change as we run gradient descent."
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#optimizing-linear-regression-directly",
    "href": "lecture2-linear-regression/notes.html#optimizing-linear-regression-directly",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Gradient descent works well for finding the optimal parameters for a linear regression model, but in fact we can actually find the optimal set of parameters directly, without needing to run an iterative algorithm.\nWe know that at the minimum, the gradient must be \\(\\mathbf{0}\\), so the following condition must hold:\n\\[\n\\mathbf{0} = \\bigg( \\frac{2}{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWe can solve for a \\(\\mathbf{w}\\) that satisfied this condition by first dropping the constant \\(\\frac{2}{N}\\).\n\\[\n\\mathbf{0} = \\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\n\\[\n\\mathbf{0} = \\sum_{i=1}^N \\big( \\mathbf{x}_i\\mathbf{x}_i^T\\mathbf{w} - y_i \\mathbf{x}_i \\big)\n\\]\n\\[\n\\sum_{i=1}^N  y_i \\mathbf{x}_i  =\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)  \\mathbf{w}\n\\]\nNote that \\(\\mathbf{x}_i \\mathbf{x}_i^T\\) is a vector outer product:\n\\[\n\\mathbf{x}_i \\mathbf{x}_i^T = \\begin{bmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\  x_{in}\\end{bmatrix} \\begin{bmatrix} x_{i1} & x_{i2} & \\dots &  x_{in}\\end{bmatrix} =\n\\begin{bmatrix} x_{i1} x_{i1} & x_{i1} x_{i2} & \\dots & x_{i1} x_{in} \\\\\nx_{i2} x_{i1} & x_{i2} x_{i2} & \\dots & x_{i2} x_{in} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{in} x_{i1} & x_{in} x_{i2} & \\dots & x_{in} x_{in} \\\\\n\\end{bmatrix}\n\\]\nThus \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)\\) is a matrix. Multiplying both sides by the inverse \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1}\\) we get:\n\\[\n\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1} \\bigg(\\sum_{i=1}^N  y_i \\mathbf{x}_i\\bigg)  =  \\mathbf{w}^*\n\\]\nWe can write this more compactly using the stacked input matrix and label vector notation we saw in homework 1.\n\\[\n\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_{1} \\\\ \\mathbf{x}_{2} \\\\ \\vdots \\\\  \\mathbf{x}_{N} \\end{bmatrix},\\quad \\mathbf{y} = \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\  y_{N} \\end{bmatrix}\n\\]\nIn this case, the expression becomes:\n\\[\\mathbf{w}^* = \\big( \\mathbf{X}^T \\mathbf{X} \\big)^{-1} \\big(\\mathbf{y}\\mathbf{X}\\big)\\]"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#normal-distributions",
    "href": "lecture2-linear-regression/notes.html#normal-distributions",
    "title": "Lecture 2: Linear regression",
    "section": "Normal distributions",
    "text": "Normal distributions\nThe Normal distribution (also known as the Gaussian distribution) is a continuous probability distribution with the following probability density function:\n\\[\np(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\]\nThe normal distribution shows up almost everywhere in probability and statistics. Most notably, the central limit theorem tells us that the mean of many independent and identically distributed random outcomes tends towards a normal distribution."
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#linear-regression-as-a-probabilistic-model",
    "href": "lecture2-linear-regression/notes.html#linear-regression-as-a-probabilistic-model",
    "title": "Lecture 2: Linear regression",
    "section": "Linear regression as a probabilistic model",
    "text": "Linear regression as a probabilistic model\nOur function approximation view of linear regression says that we can approximate an unknown function with a linear function. An alternate approach is to define a distribution over the output \\(y_i\\) of our unknown function given an input \\(\\mathbf{x}_i\\). In particular, the probabilistic model for linear regression will make the assumption that the output is normally distributed conditioned on the input:\n\\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\]\nHere we see the assumption we’re making is that the mean of the distribution is a linear function of the input, while the variance is fixed. Under this model, we can write the conditional probability or likelihood of an output as:\n\\[\np(y_i\\mid\\mathbf{x}_i, \\mathbf{w}) =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\n\\]\nWhy view linear regression as a probabilistic model? Well, generally for real data we can’t know if there actually is a function that perfectly maps inputs to outputs. It could be that there are variables we’re not accounting for, that there errors in our measurements for the data we collected or simply that there is some inherent randomness in the outputs. This view of linear regression makes the uncertainty in our predictions explicit.\n\nMathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std())\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  return tf.dot(x, w.T)\n\nwrange = tf.linspace(-3, 3, 25)\nbrange = tf.linspace(-3, 3, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean((predict(w, x) - y) ** 2, 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps &gt; 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-3, 3], 'title': 'Slope (w)'}, 'yaxis': {'range': [-3, 3], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = ybatch.reshape((-1,)) - predict(cweights, xbatch.reshape((-1,)),).flatten()\nlosses = (errors) ** 2\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=2))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'Prediction function: y = %.2f x + %.2f' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-2, 3], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\n\nnx = tf.linspace(-3, 3, 100)\nny = tf.exp(-nx ** 2)\nnormdata = dict(x=nx, y=ny, line=dict(color='red'), yaxis='y2',)\n\nPlotlyReactive(histfig, [ histdata, normdata], {'showlegend': False, 'title': 'Distribution of residuals', 'yaxis': {'title': {'text': 'Frequency'}},  'yaxis2': {'overlaying': 'y', 'range': [0, 1], 'visible': False}, 'xaxis': {'range': [-3, 3], 'title': {'text': 'Error (residual)'} }})\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n\n\n\n\n\n\n\n//viewof learningrate = Inputs.range([0, 3], {value: 1, step: 0.01, label: \" Learning rate\"})\nlearningrate = 0\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//viewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})\nsteps = 0\n\n\n\n\n\n\n\n\nhist = py`\n# Scatterplot figure\nhistfig = PlotlyFigure(width=500, height=500)\nhistfig\n`"
  },
  {
    "objectID": "lecture2-linear-regression/notes.html#maximum-likelihood-estimation-1",
    "href": "lecture2-linear-regression/notes.html#maximum-likelihood-estimation-1",
    "title": "Lecture 2: Linear regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nWith this view of linear regression in mind, let’s ask again how we find the optimal value for \\(\\mathbf{w}\\). Possibly the most widely used approach to this is to simply choose the \\(\\mathbf{w}\\) that maximizes the likelihood (conditional probability) of all of the outputs in our dataset:\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\nGenerally our model also assumes conditional independence across observations so:\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\nFor convenience, it is typical to frame the optimal value in terms of the negative log-likelihood rather than the likelihood, but the two are equivalent.\n\\[\n\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}) = \\underset{\\mathbf{w}}{\\text{argmin}} - \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w}) = \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\nWe see that the negative log-likelihood is a natural loss function to optimize to find \\(\\mathbf{w}^*\\).\n\\[\n\\textbf{Loss}(\\mathbf{w}) =\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\nWe can write out the negative log-likelihood explicitly using the normal PDF:\n\\[\n\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N\\log\\bigg[\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\\bigg]\n\\]\n\\[\n= \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 + N \\log \\sigma \\sqrt{2 \\pi}\n\\]\nWe see that this loss is very similar to the MSE loss. Taking the gradient this becomes even more clear.\n\\[\n\\nabla_{\\mathbf{w}}\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 + N \\log \\sigma \\sqrt{2 \\pi} \\bigg)\n\\]\n\\[\n= \\frac{1}{2\\sigma^2}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nAs we saw in the MSE case, the optimal value \\(\\mathbf{w}^*\\) does not depend on the constant value outside the summation. This means that the optimal value for \\(\\mathbf{w}\\) is the same for both MSE and negative log-likelihood and the optimal value does not depend on \\(\\sigma^2\\)!\n\\[\n\\underset{\\mathbf{w}}{\\text{argmin}}\\  MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html",
    "href": "lecture7-pytorch/notebook.html",
    "title": "Lecture 7: PyTorch",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nimport tqdm\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\ndef plot_boundary(model, X, y, alpha=1, title=''):\n    xrange = (-X[:, 0].min() + X[:, 0].max()) / 10\n    yrange = (-X[:, y].min() + X[:, y].max()) / 10\n    feature_1, feature_2 = np.meshgrid(\n        np.linspace(X[:, 0].min() - xrange, X[:, 0].max() + xrange, 250),\n        np.linspace(X[:, 1].min() - yrange, X[:, 1].max() + yrange, 250)\n    )\n    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n    y_pred = np.reshape(model.predict(torch.tensor(grid).float()).detach().numpy(), feature_1.shape)\n    display = DecisionBoundaryDisplay(\n        xx0=feature_1, xx1=feature_2, response=y_pred\n    )\n    display.plot()\n    display.ax_.scatter(\n        X[:, 0], X[:, 1], c=y, alpha=alpha, edgecolor=\"black\"\n    )\n    plt.title(title)\n    plt.show()"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#introduction-to-pytorch",
    "href": "lecture7-pytorch/notebook.html#introduction-to-pytorch",
    "title": "Lecture 7: PyTorch",
    "section": "Introduction to PyTorch",
    "text": "Introduction to PyTorch\nThe most basic object in PyTorch is a tensor. Tensor objects behave much like the AutogradValue objects we are creating in the homework! We can create a tensor object with a given value as follows\n\nx = torch.tensor(4.)\nx\n\ntensor(4.)\n\n\nPerforming basic operations on tensor objects gives tensor objects.\n\na = x ** 2 + 5\na\n\ntensor(21.)\n\n\ntensor objects also support reverse-mode automatic differentiation! To use this, we must specify that we will want to compute the derivative with respect to a given tensor. We can do this with the requires_grad argument.\n\nx = torch.tensor(4., requires_grad=True)\n\nOnce we have a tensor that requires_grad, we can perform operations on it to compute a loss.\n\na = x ** 2 + 5\nL = torch.log(a) # Functions like log must be called through torch\nL\n\ntensor(3.0445, grad_fn=&lt;LogBackward0&gt;)\n\n\nOnce we have a loss running the backward pass is done exactly as in the homework. First we call backward() on the loss tensor object, then we can access the derivative through the grad property of x.\n\nL.backward()\nx.grad\n\ntensor(0.3810)\n\n\nWe can also create tensor objects that wrap arrays.\n\nx = torch.tensor(np.array([3, 4, 5]))\nx\n\ntensor([3, 4, 5])\n\n\nWe can also just directly create tensors as we would numpy arrays\n\nx = torch.tensor([3, 4, 5])\nx\n\ntensor([3, 4, 5])\n\n\nIncluding convienience constructors.\n\nprint(torch.ones((5,)))\nprint(torch.zeros((2, 3)))\n\ntensor([1., 1., 1., 1., 1.])\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\nAutomatic differentiation still works for arrays. In this case it gives use the gradient of the loss (hence the grad property).\n\nx = torch.tensor([3., 4., 5.], requires_grad=True)\nL = torch.sum(x ** 2)\nL\n\ntensor(50., grad_fn=&lt;SumBackward0&gt;)\n\n\n\nL.grad\n\n/var/folders/t9/fjsr8h1x7c7cg4vqw_xhjq2w0000gn/T/ipykernel_79454/323164392.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:491.)\n  L.grad\n\n\n\nL.backward()\nx.grad\n\ntensor([ 6.,  8., 10.])\n\n\nWe can convert tensor objects back to numpy by calling x.detach().numpy(). (detach removes the variable from any automatic differentiation computations)\n\nx.detach().numpy()\n\narray([3., 4., 5.], dtype=float32)\n\n\nAt this point it’s probably worth remarking on where the name tensor comes from.\nSo far we’ve discussed 3 kinds of array objects - Scalars: which are just single values (0-dimensional) - Vectors: 1-dimensional arrays of numbers - Matrices: 2-dimensional arrays of numbers\n\n\n\nAlt text\n\n\nA tensor is the generalization of a vector or matrix to any number of dimensions. For example, a 3-dimensional tensor can be seen in multiple ways.\n\n\n\nAlt text\n\n\nA tensor object can be created with any number of dimensions. For example, we could create a 2x2x2 tensor as:\n\nt = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nt\n\ntensor([[[1, 2],\n         [3, 4]],\n\n        [[5, 6],\n         [7, 8]]])\n\n\nOr we could create the tensor in the image using arange and reshape.\n\nt = torch.arange(30).reshape((3, 2, 5))\nt\n\ntensor([[[ 0,  1,  2,  3,  4],\n         [ 5,  6,  7,  8,  9]],\n\n        [[10, 11, 12, 13, 14],\n         [15, 16, 17, 18, 19]],\n\n        [[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29]]])\n\n\n4-dimensional tensors can also be visualized\n\n\n\nAlt text\n\n\n\nt = torch.ones((3, 2, 4, 5))\nt.shape\n\ntorch.Size([3, 2, 4, 5])\n\n\nThere are some notable differences between torch and numpy when it comes to operations. The important one to watch out for at this point is matrix multiplation. In numpy we accomplished with with np.dot:\n\nx = np.ones((4, 5))\nw = np.ones((5, 2))\nnp.dot(x, w)\n\narray([[5., 5.],\n       [5., 5.],\n       [5., 5.],\n       [5., 5.]])\n\n\nIn PyTorch torch.dot only does vector dot products and thus only applies to 1-dimensional tensor objects:\n\nx = torch.ones((4, 5))\nw = torch.ones((5, 2))\ntorch.dot(x, w)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb Cell 40 line 3\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; x = torch.ones((4, 5))\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; w = torch.ones((5, 2))\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; torch.dot(x, w)\n\nRuntimeError: 1D tensors expected, but got 2D and 2D tensors\n\n\n\nInstead we use the torch.matmul function for this purpose\n\ntorch.matmul(x, w)\n\ntensor([[5., 5.],\n        [5., 5.],\n        [5., 5.],\n        [5., 5.]])\n\n\nPyTorch also has many handy built-in functions that numpy doesn’t have, such as sigmoid.\n\nx = torch.linspace(-5, 5, 50)\ns = torch.sigmoid(x)\nplt.plot(x, s)\n\n\n\n\n\n\n\n\nThis makes it very easy to implement something like logistic regression.\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        self.weights = torch.ones((dims,), requires_grad=True)\n        self.bias = torch.zeros((), requires_grad=True)\n\n    def predict_probability(self, X):\n        f_X = torch.matmul(X, self.weights) + self.bias\n        return torch.sigmoid(f_X)\n\n    def predict(self, X):\n        return self.predict_probability(X) &gt; 0.5\n\nLet’s try loading a dataset, converting it to tensor and making predictions\n\nX, y = make_moons(noise=0.1)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\nmodel = LogisticRegression(2)\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nWhen working with PyTorch, it is convention to separate the loss function from the model, where the loss function will just take predictions and labels.\n\ndef NLL(pred, y):\n    LL = y * torch.log(pred) + (1. - y) * torch.log(1. - pred)\n    return -LL.sum()"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#gradient-descent",
    "href": "lecture7-pytorch/notebook.html#gradient-descent",
    "title": "Lecture 7: PyTorch",
    "section": "Gradient descent",
    "text": "Gradient descent\nGradient descent is also implemented in PyTorch in the optim module.\n\nfrom torch import optim\n\nGradient descent works a bit differently in PyTorch than what we’ve seen. We first need to construct a gradient descent object which specifies which values we’re optimizing and what the learning rate will be. We specify the values to optimize by simply passing a list of weights/parameters to the constructor.\nIn PyTorch, basic gradient descent is encapsulated in the optim.SGD class (SGD stands for stochastic gradient descent, we’ll talk about what stochastic means in this context next week.)\n\noptimizer = optim.SGD([model.weights, model.bias], lr=0.1)\n\nNotice that this object doesn’t even take in the function we’re trying to optimize, only the inputs. We need to call the function ourselves and run backward() to compute the gradients.\n\npredictions = model.predict_probability(X)\nloss = NLL(predictions, y)\nloss.backward()\n\nLet’s look at our model weights\n\nmodel.weights\nmodel.weights.grad\n\ntensor([-5.6526, 24.1355])\n\n\nWe can take a single step of gradient descent using the step method of the optimizer.\n\noptimizer.step()\nmodel.weights\n\ntensor([ 1.5653, -1.4135], requires_grad=True)\n\n\nWe see that this actually updates the weights themselves!\nIt’s important to note that in PyTorch, calling backward does not clear the value stored in grad. So computing the gradient multiple times will result in updates to the gradient.\n\nprint(model.weights.grad)\nNLL(model.predict_probability(X), y).backward()\nprint(model.weights.grad)\nNLL(model.predict_probability(X), y).backward()\nprint(model.weights.grad)\n\ntensor([-5.6526, 24.1355])\ntensor([-14.5242,  28.7704])\ntensor([-23.3958,  33.4053])\n\n\nWe can clear the stored gradients using the optimizer.\n\noptimizer.zero_grad()\nprint(model.weights.grad)\n\nNone\n\n\nSo far we’ve only taking a single step of gradient descent. In order to run many steps, we need to write a loop to do everything we just saw.\n\nfor i in range(10):\n    predictions = model.predict_probability(X)\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n45.934814453125\n40.60100555419922\n32.82542037963867\n30.3773136138916\n28.918834686279297\n28.118915557861328\n27.602989196777344\n27.248106002807617\n26.989551544189453\n26.794662475585938\n\n\nWe should now see that our model has been optimized!\n\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#torch.nn",
    "href": "lecture7-pytorch/notebook.html#torch.nn",
    "title": "Lecture 7: PyTorch",
    "section": "torch.nn",
    "text": "torch.nn\nWhile PyTorch as a tool for automatic differentiation and optimization would be useful by itself. It actually gives us a lot more than that!\nOn of the most important features of PyTorch is its model-building tools in the torch.nn module. This gives us a lot of powerful features that we can use to build complex neural networks!\n\nfrom torch import nn\n\nLet’s start by building out logistic regression model in the torch.nn framwork. In order for a model to benefit from torch.nn our model class needs to inheret from nn.Module\n\nclass LogisticRegression(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.weights = nn.Parameter(torch.ones((dims,)))\n        self.bias = nn.Parameter(torch.zeros(()))\n\n    def forward(self, X):\n        return torch.sigmoid(torch.matmul(X, self.weights) + self.bias)\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\nThere are 2 changes to note here. The first is that we wrapped our weights and bias terms in nn.Parameter. This tells PyTorch that these are the parameters we will want to optimize. We don’t need to specify requires_grad for parameters, PyTorch will take care of that for us.\nThe second is that we moved the implmentation of predict_probability to forward. In PyTorch models the forward method is special, it defines the model as a function. If we call the model as a function forward will be called internally.\n\nmodel = LogisticRegression(2)\nmodel(X)\n\ntensor([0.5652, 0.7431, 0.8238, 0.5468, 0.8991, 0.5719, 0.8651, 0.7784, 0.6153,\n        0.7053, 0.7419, 0.3129, 0.4502, 0.5031, 0.4508, 0.7075, 0.7626, 0.4756,\n        0.4158, 0.4693, 0.7904, 0.7241, 0.2430, 0.5297, 0.7944, 0.8496, 0.6825,\n        0.6149, 0.6730, 0.5231, 0.6151, 0.6108, 0.5509, 0.7476, 0.6634, 0.8512,\n        0.8117, 0.7527, 0.5092, 0.7742, 0.8012, 0.7604, 0.6411, 0.3242, 0.2805,\n        0.4016, 0.6296, 0.3000, 0.7045, 0.7307, 0.7442, 0.8091, 0.5104, 0.8006,\n        0.6166, 0.5173, 0.6404, 0.5779, 0.8199, 0.9030, 0.7872, 0.6059, 0.8091,\n        0.9367, 0.5806, 0.7576, 0.8079, 0.3847, 0.4926, 0.4909, 0.8605, 0.6233,\n        0.5605, 0.5980, 0.3629, 0.6874, 0.8761, 0.7593, 0.8267, 0.7912, 0.7147,\n        0.4980, 0.4396, 0.9295, 0.8956, 0.5096, 0.7148, 0.7788, 0.7961, 0.2600,\n        0.4964, 0.6008, 0.5710, 0.7882, 0.9379, 0.8573, 0.7131, 0.8105, 0.6835,\n        0.5392], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\nThis means that we can use instances of nn.Module as parameterized functions. For example, we might create a general linear (technically affine) function in the same way.\n\\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{W}^T + \\mathbf{b},  \\quad f: \\mathbb{R}^i \\rightarrow \\mathbb{R}^o\\]\nNote that here we are not assuming an augmented representation of \\(\\mathbf{x}\\).\n\nclass Linear(nn.Module):\n    def __init__(self, inputs, outputs):\n        super().__init__()\n        self.weightsT = nn.Parameter(torch.ones((inputs, outputs)))\n        self.bias = nn.Parameter(torch.zeros((outputs,)))\n\n    def forward(self, X):\n        return torch.matmul(X, self.weightsT) + self.bias\n\nWe can use this module to implement out logistic regression model above.\n\nclass LogisticRegression(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.linear = Linear(dims, 1)                       # Dims input 1 output\n\n    def forward(self, X):\n        return torch.sigmoid(self.linear(X)).reshape((-1,)) # Turn output into a vector\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\n\nmodel = LogisticRegression(2)\nmodel(X)\n\ntensor([0.5652, 0.7431, 0.8238, 0.5468, 0.8991, 0.5719, 0.8651, 0.7784, 0.6153,\n        0.7053, 0.7419, 0.3129, 0.4502, 0.5031, 0.4508, 0.7075, 0.7626, 0.4756,\n        0.4158, 0.4693, 0.7904, 0.7241, 0.2430, 0.5297, 0.7944, 0.8496, 0.6825,\n        0.6149, 0.6730, 0.5231, 0.6151, 0.6108, 0.5509, 0.7476, 0.6634, 0.8512,\n        0.8117, 0.7527, 0.5092, 0.7742, 0.8012, 0.7604, 0.6411, 0.3242, 0.2805,\n        0.4016, 0.6296, 0.3000, 0.7045, 0.7307, 0.7442, 0.8091, 0.5104, 0.8006,\n        0.6166, 0.5173, 0.6404, 0.5779, 0.8199, 0.9030, 0.7872, 0.6059, 0.8091,\n        0.9367, 0.5806, 0.7576, 0.8079, 0.3847, 0.4926, 0.4909, 0.8605, 0.6233,\n        0.5605, 0.5980, 0.3629, 0.6874, 0.8761, 0.7593, 0.8267, 0.7912, 0.7147,\n        0.4980, 0.4396, 0.9295, 0.8956, 0.5096, 0.7148, 0.7788, 0.7961, 0.2600,\n        0.4964, 0.6008, 0.5710, 0.7882, 0.9379, 0.8573, 0.7131, 0.8105, 0.6835,\n        0.5392], grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\nThe power here is that because Linear is also an instance of nn.Module, PyTorch knows that it’s weights should also be considered part of our models weights. We can access the weights of a model using the parameters() method.\n\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[1.],\n         [1.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nThis lets us easily apply gradient descent:\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nfor i in range(10):\n    predictions = model(X)        # Now we can just call model!\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n76.53839111328125\n45.934814453125\n40.60100555419922\n32.82542037963867\n30.3773136138916\n28.918834686279297\n28.118915557861328\n27.602989196777344\n27.248106002807617\n26.989551544189453\n\n\n\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nPyTorch unsurprisingly also provides a built-in Linear module. As nn.Linear.\n\nnn.Linear(2, 1)\n\nLinear(in_features=2, out_features=1, bias=True)\n\n\nKnowing how to make a parameterized function in PyTorch, let’s consider making a neural network layer with a sigmoid activation function.\n\\[f(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}^T + \\mathbf{b})\\]\n\nclass SigmoidLayer(nn.Module):\n    def __init__(self, inputs, outputs):\n        super().__init__()\n        self.linear = nn.Linear(inputs, outputs)\n\n    def forward(self, X):\n        return torch.sigmoid(self.linear(X))\n        \n\nLet’s create a layer with 10 neurons. (So \\(\\mathbf{W}:\\ (10 \\times 2)\\))\n\nlayer = SigmoidLayer(2, 10)\nprint(X.shape)\nlayer(X).shape\n\ntorch.Size([100, 2])\n\n\ntorch.Size([100, 10])\n\n\nLet’s use this to create a neural network class for binary classification!\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self, dims, hidden_size):\n        super().__init__()\n        self.layer = SigmoidLayer(dims, hidden_size)\n        self.linear = Linear(hidden_size, 1)                       \n\n    def forward(self, X):\n        hidden_neurons = self.layer(X)\n        output = self.linear(hidden_neurons)\n        return torch.sigmoid(output).reshape((-1,))\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\nWe see that PyTorch recognizes both the parameters of the logistic regression and the parameters of our neural network feature transform:\n\nmodel = NeuralNetwork(2, 10)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[-0.0632, -0.0324],\n         [-0.4227, -0.0076],\n         [ 0.5793, -0.4920],\n         [ 0.1640, -0.5442],\n         [ 0.2326,  0.3651],\n         [-0.0184,  0.6859],\n         [ 0.0893,  0.1236],\n         [-0.4774, -0.3702],\n         [-0.0048,  0.4830],\n         [-0.4720,  0.5458]], requires_grad=True),\n Parameter containing:\n tensor([-0.2695, -0.1038, -0.7001,  0.3398, -0.0591,  0.6680,  0.3601, -0.3093,\n          0.0831, -0.4315], requires_grad=True),\n Parameter containing:\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nThis means that we can easily run our optimization as before.\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nfor i in range(100):\n    predictions = model(X)        # Now we can just call model!\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nPyTorch also gives us an easier (but less flexible) way to define a composition of modules like this. In PyTorch we can define this simple network using nn.Sequential\n\nmodel = nn.Sequential(\n    nn.Linear(2, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 1),\n    nn.Sigmoid(),\n)\nmodel(X).reshape((-1,))\n\ntensor([0.3653, 0.3638, 0.3685, 0.3575, 0.3788, 0.3567, 0.3749, 0.3824, 0.3716,\n        0.3777, 0.3612, 0.3494, 0.3608, 0.3496, 0.3610, 0.3802, 0.3737, 0.3504,\n        0.3581, 0.3621, 0.3859, 0.3814, 0.3410, 0.3605, 0.3768, 0.3890, 0.3599,\n        0.3586, 0.3567, 0.3529, 0.3723, 0.3711, 0.3682, 0.3644, 0.3774, 0.3742,\n        0.3804, 0.3808, 0.3526, 0.3757, 0.3669, 0.3735, 0.3731, 0.3516, 0.3461,\n        0.3566, 0.3558, 0.3496, 0.3594, 0.3775, 0.3755, 0.3808, 0.3586, 0.3792,\n        0.3543, 0.3657, 0.3559, 0.3642, 0.3848, 0.3816, 0.3824, 0.3546, 0.3808,\n        0.3906, 0.3661, 0.3723, 0.3823, 0.3552, 0.3561, 0.3543, 0.3730, 0.3723,\n        0.3523, 0.3669, 0.3531, 0.3590, 0.3764, 0.3702, 0.3680, 0.3841, 0.3798,\n        0.3555, 0.3480, 0.3861, 0.3814, 0.3495, 0.3793, 0.3814, 0.3839, 0.3427,\n        0.3540, 0.3623, 0.3700, 0.3661, 0.3915, 0.3718, 0.3660, 0.3685, 0.3601,\n        0.3597], grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\nHere nn.Sigmoid is a built-in module that just applies the sigmoid function. Its implementation would look like:\n\nclass SigmoidLayer(nn.Module):\n    def forward(self, X):\n        return torch.sigmoid(X)\n\nWe could use this to create a network with several hidden layers:\n\nmodel = nn.Sequential(\n    nn.Linear(2, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 1),\n    nn.Sigmoid(),\n)\nmodel(X)\n\nPyTorch also provides built-in loss functions. The PyTorch function for the negative log-likelihood for logistic regression is called nn.functional.binary_cross_entropy. It has some sharp edges though.\nFor one, it expects y to be a float type. We can convert a PyTorch int tensor into a float one by calling the float method.\nWe also see that our sequential model returns a column vector, so y should match that as well.\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nyfloat = y.float().reshape((-1, 1))\n\nfor i in range(100):\n    predictions = model(X)        # Now we can just call model!\n    loss = nn.functional.binary_cross_entropy(predictions, yfloat)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\nFor convinience, let’s definie a wrapper class for our model.\n\nclass LogisticRegressionNeuralNetwork(nn.Module):\n    def __init__(self, network):\n        super().__init__()\n        self.network = network                   \n\n    def forward(self, X):\n        return self.network(X).reshape((-1,))\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#evaluating-models",
    "href": "lecture7-pytorch/notebook.html#evaluating-models",
    "title": "Lecture 7: PyTorch",
    "section": "Evaluating models",
    "text": "Evaluating models\nWe see that we have a lot of options when designing a neural network. So far the choices we’ve seen are: - The number of layers - The number of neurons in each layer - The activation function - The learning rate for gradient descent\nAnd this is just the beginning! As we go on, we’ll learn about many more options that we have.\nLet’s take a look at how to make some of these choices. In many real cases, our data will not be a cleanly separated into 2 classes as we’ve seen. For instance, we can look at a noisier version of the dataset we saw before.\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\nplt.scatter(*X.T, c=y, edgecolor=\"black\")\n\n\n\n\n\n\n\n\nIn reality, this dataset was drawn from the distribution shown below! The optimal classifier would still have an “s-shaped” decision boundary\n\nX, y = make_moons(50000, noise=0.5)\nplt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.1)\npass\n\n\n\n\n\n\n\n\nLet’s split this into training and test sets as we’ve seen.\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXtest, ytest = X[inds[150:]], y[inds[150:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.legend()"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#underfittting",
    "href": "lecture7-pytorch/notebook.html#underfittting",
    "title": "Lecture 7: PyTorch",
    "section": "Underfittting",
    "text": "Underfittting\nWe’ll start by fitting a logistic regression model as we’ve seen. This time we’ll keep track of the loss on both the training data and the test data.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(2500)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.501: 100%|██████████| 2500/2500 [00:02&lt;00:00, 892.89it/s] \n\n\n\nplot_boundary(model, Xtrain, ytrain)\n\n\n\n\n\n\n\n\nLet’s compute the accuracy on both the training and the test data\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nprint('Training accuracy: %.3f, Test accuracy: %.3f' % (train_acc, test_acc))\n\nTraining accuracy: 0.793, Test accuracy: 0.793\n\n\nWe can also look at how the loss on both the training and test data changes as we run gradient descent.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\n#plt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nHere wee see that both the training loss/accuracy and the test loss/accuracy are quite poor! From our descision boundary plot we can see quite clearly that this is a consequence of our choice of a linear model for this classification problem. We call this problem underfitting, meaning that our model is not expressive enough to capture all the intricacies of our data. As we’ve already seen we can address this by adding neural network layers to increase the expressivity of our model."
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#overfitting",
    "href": "lecture7-pytorch/notebook.html#overfitting",
    "title": "Lecture 7: PyTorch",
    "section": "Overfitting",
    "text": "Overfitting\nLet’s try creating a much more complex model; one with several large neural network layers and fitting it to our data.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.073: 100%|██████████| 25000/25000 [00:41&lt;00:00, 602.24it/s]\n\n\nWe can view the descision boundary and accuracy for this classifier.\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\nWe see that our model is much more expressive and basically correctly classifies every observation in our training dataset. This is great! However the boundary is quite complex. Let’s see what happens when we evaluate on our test set.\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nThe accuracy is much worse. Rather than capturing the true distribution of classes, our model has captured the training set we happened to draw. This means if we draw a new dataset from the same distribution (like our test set), performance is poor. We call this issue overfitting.\nLet’s see how the training and test loss change over gradient descent.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nMuch of the rest of this class will focus on how to meet the deicate balance of overfitting vs. underfitting!\nIt’s worth noting the the best solution to overfitting is to get more data. If we train with enough data we can avoid overfitting entirely.\n\nX, y = make_moons(2000, noise=0.5)\nplt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.1)\n\n\n\n\n\n\n\n\n\nX, y = torch.tensor(X).float(), torch.tensor(y)\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(2500)\nfor i in pbar:\n    predictions = model(X)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, y.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n/var/folders/t9/fjsr8h1x7c7cg4vqw_xhjq2w0000gn/T/ipykernel_79454/2923296796.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X, y = torch.tensor(X).float(), torch.tensor(y)\nLoss: 0.390: 100%|██████████| 2500/2500 [00:16&lt;00:00, 151.68it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nUnfortunately, this often isn’t realistic. Data is hard to collect and more data means our model is slower and more expensive to train."
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#early-stopping",
    "href": "lecture7-pytorch/notebook.html#early-stopping",
    "title": "Lecture 7: PyTorch",
    "section": "Early stopping",
    "text": "Early stopping\nLet’s return to the original case\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXtest, ytest = X[inds[150:]], y[inds[150:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.legend()\n\n\n\n\n\n\n\n\nLet’s try a network somewhere in-between, with just a single hidden layer.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 100),\n    nn.ReLU(),\n    nn.Linear(100, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.366: 100%|██████████| 25000/25000 [00:28&lt;00:00, 870.32it/s] \n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nWe see that this network is more consistent between train and test, and now performs better on test data! Let’s take a look at the plot of training and test loss.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nWe still see that both drop quickly, but that test loss increases after a point. How might we use this to pick a better model?\nOne option would be to just use the model where the test loss is lowest. After all, that is our ultimate goal. There are different ways we can think about implementing this. One way to to have gradient descent stop when the test loss begins to increase. We call this approach early stopping\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 100),\n    nn.ReLU(),\n    nn.Linear(100, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n    if i &gt; 50 and test_loss.item() &gt; test_losses[-2]:\n        break\n\nLoss: 0.481:   1%|▏         | 346/25000 [00:00&lt;00:30, 810.31it/s]\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nHere we see that actually we do the best so far with this approach!\nWe could also try our early-stopping approach with our more complex network.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n    if i &gt; 50 and test_loss.item() &gt; test_losses[-2]:\n        break\n\nLoss: 0.465:   2%|▏         | 382/25000 [00:00&lt;00:42, 574.88it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')"
  },
  {
    "objectID": "lecture7-pytorch/notebook.html#train-validation-and-test",
    "href": "lecture7-pytorch/notebook.html#train-validation-and-test",
    "title": "Lecture 7: PyTorch",
    "section": "Train, validation and test",
    "text": "Train, validation and test\nThere is an issue here though! We’ve now used out test set to (indirectly) train our model. Both by using it to choose the number of layers and by using it to determine how long to run our optimization! This means that our model choice will be biased by our choice of test set, so how can we trust that our test loss or accuracy will actually be a good measure of the real-world performance of our model?\nTo deal with this issue we will typically split our data into 3 parts that we’ll call training, validation and test. We’ll use the validation portion as the portion to fit the model and the test set as the portion we use to estimate how well it will do in practice.\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXvalid, yvalid = X[inds[150:225]], y[inds[150:225]]\nXtest, ytest = X[inds[225:]], y[inds[225:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.scatter(*Xvalid.T, c=yvalid, edgecolor=\"black\", marker='*', label='valid data')\nplt.legend()\n\n\n\n\n\n\n\n\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, valid_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    valid_loss = torch.nn.functional.binary_cross_entropy(model(Xvalid), yvalid.flatten().float())\n    valid_losses.append(valid_loss.item())\n\n    if i &gt; 50 and valid_loss.item() &gt; valid_losses[-2]:\n        break\n\nLoss: 0.406:   4%|▍         | 1060/25000 [00:02&lt;00:46, 513.32it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xvalid) == yvalid).float().mean()\nplot_boundary(model, Xvalid, yvalid, title='Validation accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)"
  },
  {
    "objectID": "lecture7-pytorch/notebook2.html",
    "href": "lecture7-pytorch/notebook2.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport autograd.numpy as np\nfrom autograd import grad, jacobian, hessian, elementwise_grad\n\n\nx = np.linspace(-3, 3, 300)\n\ndef sigmoid(x):\n    #return (2 - x) ** 2 - 0.5 * x + 1\n    return 1 / (1 + np.exp(-x))\n\ndef tangent(f, x):\n    y = f(x)\n    slope = grad(f)(x)\n\n    def tf(a):\n        return (a - x) * slope + y\n\n    return tf\n\ndef tangent2(f, x):\n    y = f(x)\n    slope = grad(f)(x)\n    curve = 0.5 * grad(grad(f))(x)\n\n    def tf(a):\n        return curve * (a - x) ** 2 + (a - x) * slope + y\n    return tf\n\n\ndsigmoid = elementwise_grad(sigmoid)\nd2sigmoid = elementwise_grad(dsigmoid)\n\npoint = 1.\ntpoint = tangent2(sigmoid, point)\n\n\nplt.scatter(point, sigmoid(point), zorder=10)\nplt.plot(x, sigmoid(x))\nplt.plot(x, tpoint(x))\n\n#plt.plot(x, d2sigmoid(x))"
  },
  {
    "objectID": "lecture1-background/slides.html",
    "href": "lecture1-background/slides.html",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "We will begin with a review of many of the basic concepts from linear algebra that we will need for this course. As we go through these concepts we will see how to implement them in Python.\n\n\nNumpy Is the linear algebra library that we will be using for much of this class. The standard way to import Numpy is:\n\nimport numpy as np\n\nThe most basic object from Numpy that we will just is the array (np.array), which will represent vectors matrices and even higher-dimensional objects known as tensors.\n\n\n\nScalars are just single numbers. In our math we will typically denote scalars with a lower-case letter. For example, we might call a scalar \\(x\\) and give it a value as \\[x=3.5\\] In code:\n\nx = 3.5\n\n# or as a 0-dimensional numpy array\nx = np.array(3.5)\n\n\n\n\nVectors are ordered lists of numbers, as shown below. We will typically denote vectors with bold lower case letters, such as \\(\\mathbf{x}\\).\n\\[\n\\mathbf{x} = \\begin{bmatrix} 2\\\\ 5\\\\ 1\\end{bmatrix}\n\\]\nIn Numpy, we can create an array object representing a vector by passing np.array a list of numbers.\n\nx = np.array([2, 5, 1])\n\n\n\n\nThe individual numbers in the vector are called the entries and we will refer to them individually as subscripted scalars: \\(x_1, x_2,…,x_n\\).\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix}\n\\]\nIn numpy we can access individual elements of a vector using [] operators (note that numpy is 0-indexed!).\n\nx[0]\n\nnp.int64(2)\n\n\n\n\n\nA vector represents either a location or a change in location in \\(n\\) -dimensional space.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA space of vectors could represent students, with each entry corresponding to a student’s grade in a different subject:\n\\[\n\\text{Student } \\mathbf{x} = \\begin{bmatrix} \\text{Math} \\\\ \\text{CS} \\\\ \\text{Literature} \\\\\\text{History} \\end{bmatrix}\n\\]\nAny two students might have different grades across the subjects. We can represent these two students (say \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\)) as two vectors.\n\\[\n\\mathbf{x}_1 = \\begin{bmatrix} 3.0 \\\\ 4.0 \\\\ 3.7 \\\\ 2.3 \\end{bmatrix}, \\quad \\mathbf{x}_2 = \\begin{bmatrix} 3.7 \\\\ 3.3 \\\\ 3.3 \\\\ 4.0 \\end{bmatrix}\n\\]\n\n\n\nWe say that two vectors are equal if and only if all of the corresponding elements are equal, so \\[\\mathbf{x} = \\mathbf{y}\\] implies that \\[x_1=y_1, x_2=y_2…\\]\n\n\n\n\nx = np.array([2, 5, 1])\ny = np.array([3, 5, 2])\nx == y\n\narray([False,  True, False])\n\n\nWe can check if all entries are equal (and therefore the vectors are equal) using the np.all function.\n\nnp.all(x == y), np.all(x == x)\n\n(np.False_, np.True_)\n\n\nOther comparison operators (&gt;,&lt;, &gt;=, &lt;=, !=) also perform element-wise comparison in numpy.\n\n\n\nWhen we add or subtract vectors, we add or subtract the corresponding elements.\n\\[\\mathbf{x} + \\mathbf{y} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} + \\begin{bmatrix} y_1\\\\ y_2\\\\ y_3\\end{bmatrix} = \\begin{bmatrix} x_1 + y_1\\\\ x_2 + y_2\\\\ x_3 + y_3\\end{bmatrix}\\] This works the same in numpy\n\nx + y\n\narray([ 5, 10,  3])\n\n\n\n\n\nAddition corresponds to shifting the point \\(\\mathbf{x}\\) by the vector \\(\\mathbf{y}\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn both mathematical notation and numpy, most operations on vectors will be assumed to be taken element-wise. That is,\n\\[\n\\mathbf{x}^2 = \\begin{bmatrix} x_1^2 \\\\ x_2^2 \\\\ x_3^2 \\end{bmatrix} , \\quad \\log(\\mathbf{x}) = \\begin{bmatrix} \\log x_1 \\\\ \\log x_2 \\\\ \\log x_3 \\end{bmatrix},\\ \\text{etc.}\n\\]\nIn numpy:\n\nx ** 2, np.log(x)\n\n(array([ 4, 25,  1]), array([0.69314718, 1.60943791, 0.        ]))\n\n\n\n\n\nNote that in this class (and in numpy!) logarithms are assumed to be base \\(e\\), otherwise known as natural logarithms.\n\n\n\nOperations between scalars and vectors are also assumed to be element-wise as in this scalar-vector multiplication\n\\[\na\\mathbf{x} = \\begin{bmatrix} a x_1 \\\\ a x_2 \\\\ a x_3 \\end{bmatrix}, \\quad a + \\mathbf{x} = \\begin{bmatrix} a + x_1 \\\\ a + x_2 \\\\ a + x_3 \\end{bmatrix}\n\\]\n\n\n\nThe magnitude of a vector its length in \\(\\mathbb{R}^n\\), or equivalently the Euclidean distance from the origin to the point the vector represents. It is denoted as\\(\\|\\mathbf{x}\\|_2\\) and defined as:\n\\[\n\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}\n\\]\nThe subscript \\(2\\) specifies that we are talking about Euclidean distance. Because of this we will also refer to the magnitude as the two-norm.\nIn numpy we can compute this using the np.linalg.norm function.\n\nxnorm = np.linalg.norm(x)\n\n\n\n\nWe can also compute magnitude explicitly with the np.sum function, which computes the sum of the elements of a vector.\n\nxnorm_explicit = np.sqrt(np.sum(x ** 2))\nxnorm, xnorm_explicit\n\n(np.float64(5.477225575051661), np.float64(5.477225575051661))\n\n\n\n\n\n\n\n\nOther useful aggregation functions\n\n\n\n\n\n\nprint(np.mean(x))    # Take the mean of the elements in x\nprint(np.std(x))     # Take the standard deviation of the elements in x\nprint(np.min(x))     # Find the minimum element in x\nprint(np.max(x))     # Find the maximum element in x\n\n2.6666666666666665\n1.699673171197595\n1\n5\n\n\n\n\n\n\n\n\nA unit vector is a vector with length \\(1\\). We can find a unit vector that has the same direction as \\(\\mathbf{x}\\) by dividing \\(\\mathbf{x}\\) by it’s magnitude:\n\\[\n\\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|_2}\n\\]\n\nx / np.linalg.norm(x)\n\narray([0.36514837, 0.91287093, 0.18257419])\n\n\n\n\n\nThe dot-product operation between two vectors is defined as\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = \\sum_{i=1}^n x_i y_i\n\\]\nThe result is a scalar whose value is equal to \\(\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2 \\cos\\theta\\), where \\(\\theta\\) is the angle between them.\nWe can compute dot products in numpy using the np.dot function\n\nnp.dot(x, y)\n\nnp.int64(33)\n\n\n\n\n\nIf \\(\\theta=\\frac{\\pi}{2}\\), the vectors are orthogonal and the dot product with be \\(0\\). If \\(\\theta&gt;\\frac{\\pi}{2}\\) or \\(\\theta &lt; -\\frac{\\pi}{2}\\) , the dot product will be negative.\nIf \\(\\theta=0\\) then \\(\\cos(\\theta)=1\\). In this case we say the vectors are colinear. This formulation implies that given two vectors of fixed length, the dot product is maximized with they are colinear ( \\(\\theta=0\\) ).\n\n\n\nGeometrically, \\(\\|\\mathbf{x}\\|_2\\cos\\theta\\) is the length of the projection of \\(\\mathbf{x}\\) onto \\(\\mathbf{y}\\). Thus, we can compute the length of this projection using the dot-product as \\(\\frac{\\mathbf{x}\\cdot\\mathbf{y}}{\\|\\mathbf{y}\\|}\\) .\n\n\n\nA matrix is a 2-dimensional collection of numbers. We will denote matrices using bold capital letters, e.g. \\(\\mathbf{A}\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2  \\end{bmatrix}\n\\]\nIn numpy we can create a matrix by passing np.array as list-of-lists, where each inner list specifies a row of the matrix.\n\nA = np.array([[3, 5, 4], [1, 1, 2]])\nA\n\narray([[3, 5, 4],\n       [1, 1, 2]])\n\n\n\n\n\nAs with vectors we will denote individual elements of a matrix using subscripts. In this case, each element has 2 coordinates. Conventions is to always list the row first.\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can access elements in a matrix similarly.\n\nA[1, 2]\n\nnp.int64(2)\n\n\nAs with vectors, we say that two matrices are equal if and only if all of the corresponding elements are equal.\n\n\n\nBasic creation functions\n\nA0 = np.zeros((3, 4))          # create a 3x4 matrix of all zeros\nA1 = np.ones((4, 4))           # create a 4x4 matrix of all ones\nAinf = np.full((3, 3), np.inf) # create a 3x3 matrix of all infinities\nI = np.eye(3)                  # create a 3x3 itentity matrix\n\nCreating a matrix by “reshaping” a vector with the same number of elements\n\nV = np.arange(1, 13).reshape((3, 4)) # Create a 3x4 matrix with elements 1-12\n\nCreating matrices by combining matrices\n\nB = np.tile(A0, (3, 2))               # create a matrix by \"tiling\" copies of A0 (3 copies by 2 copies)\nB = np.concatenate([A0, A1], axis=0)  # create a (2n x m) matrix by stacking two matrices vertically\nB = np.concatenate([A0, I], axis=1)  # create a (n x 2m) matrix by stacking two matrices horizontally\n\n\n\n\nOften we will refer to an entire row of a matrix (which is itself a vector) using matrix notation with a single index\n\\[\n\\mathbf{A}_i = \\begin{bmatrix} A_{i1} \\\\ A_{i2} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access a single row similarly.\n\nA[1]\n\narray([1, 1, 2])\n\n\n\n\n\nWe can refer to an entire column by replacing the row index with a \\(*\\), indicating we are referring to all rows in that column.\n\\[\n\\mathbf{A}_{*i} = \\begin{bmatrix} A_{1i} \\\\ A_{2i} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access an entire column (or row) using the slice operator :, which takes all elements along an axis.\n\nA[:, 1] # Take all elements in column 1\n\narray([5, 1])\n\n\n\n\n\nWe can also use the slice operator to take a subset of elements along an axis.\n\nA[:, 1:3] #Take the second and third columns of A\n\narray([[5, 4],\n       [1, 2]])\n\n\n\n\n\nOpen-ended slices\n\nprint(\"A[:2]=\", A[:2]) # Take rows up to 2 (not inucluding 2)\nprint(\"A[1:]=\", A[1:]) # Take rows starting at (and including) 1\n\nA[:2]= [[1 2 3 4]\n [5 6 7 8]]\nA[1:]= [[ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nTaking rows and colmns\n\nprint(\"A[0, :]=\", A[0, :])   # first row, all columns\nprint(\"A[:, 1]=\", A[:, 1])   # all rows, second column\nprint(\"A[-1, :]\", A[-1, :])  # all columns of the last row\nprint(\"A[:, -2]\", A[:, -2])  # second to last column of every row\n\nA[0, :]= [1 2 3 4]\nA[:, 1]= [ 2  6 10]\nA[-1, :] [ 9 10 11 12]\nA[:, -2] [ 3  7 11]\n\n\n\n\n\nMore general slicing with steps\n\nprint(\"A[1,0:2]=\", A[1,0:2])\nprint(\"A[0,0:4:2]=\", A[0,0:4:2])\nprint(\"A[:,0:4:2]=\\n\", A[:,0:4:2])\n\nA[1,0:2]= [5 6]\nA[0,0:4:2]= [1 3]\nA[:,0:4:2]=\n [[ 1  3]\n [ 5  7]\n [ 9 11]]\n\n\nTaking one row and selected columns\n\nprint(\"A[2, [1,4]]=\",A[2, [0,3]])\n\nA[2, [1,4]]= [ 9 12]\n\n\nTaking all rows and selected columns\n\nprint(\"A[:, [1,4]]=\\n\",A[:, [0,3]])\n\nA[:, [1,4]]=\n [[ 1  4]\n [ 5  8]\n [ 9 12]]\n\n\n\n\n\nThe matrix \\(\\mathbf{A}\\) above has 2 rows and 3 columns, thus we would specify it’s shape as \\(2\\times3\\). A square matrix has the same number of rows and columns.\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2 \\\\ 4 & 1 & 3 \\end{bmatrix}\n\\]\nWe can access the shape of a matrix in numpy using its shape property.\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nprint(A.shape)\n\n(3, 3)\n\n\n\n\n\nThe transpose of a matrix is an operation that swaps the rows and columns of the matrix. We denote the transpose of a matrix \\(\\mathbf{A}\\) as \\(\\mathbf{A}^T\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}, \\quad \\mathbf{A}^T = \\begin{bmatrix} A_{11} & A_{21} \\\\  A_{12} & A_{22} \\\\  A_{13} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can transpose a matrix by using the T property.\n\nA = np.array([[1, 1, 1], [2, 2, 2]])\nA.T\n\narray([[1, 2],\n       [1, 2],\n       [1, 2]])\n\n\n\n\n\nAs with vectors, many operations on matrices are performed element-wise:\n\\[\n\\mathbf{A} + \\mathbf{B} = \\begin{bmatrix} A_{11} + B_{11}  & A_{12} + B_{12} & A_{13} + B_{13} \\\\ A_{21} + B_{21} & A_{22} + B_{22} & A_{23} + B_{23} \\end{bmatrix}, \\quad \\log\\mathbf{A} = \\begin{bmatrix} \\log A_{11}  & \\log A_{12} & \\log A_{13} \\\\ \\log A_{21} & \\log A_{22} & \\log A_{23} \\end{bmatrix}\n\\]\nScalar-matrix operation are also element-wise:\n\\[\nc\\mathbf{A} = \\begin{bmatrix} cA_{11}  & cA_{12} & cA_{13} \\\\ cA_{21} & cA_{22} & cA_{23} \\end{bmatrix}\n\\]\nIn numpy:\n\nB = 5 * A \nA + B\n\narray([[ 6,  6,  6],\n       [12, 12, 12]])\n\n\n\n\n\nA matrix-vector product is an operation between a matrix and a vector that produces a new vector. Given a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we write the matrix-vector product as:\n\\[\n\\mathbf{A}\\mathbf{x} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^n x_i A_{1i} \\\\  \\sum_{i=1}^n x_i A_{2i} \\\\  \\sum_{i=1}^n x_i A_{3i} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}\\cdot  \\mathbf{A}_{1} \\\\ \\mathbf{x}\\cdot  \\mathbf{A}_{2} \\\\ \\mathbf{x} \\cdot \\mathbf{A}_{2} \\end{bmatrix}\n\\]\nIn other words, each entry of the resulting vector is the dot product between \\(\\mathbf{x}\\) and a row of \\(A\\). In numpy we also use np.dot for matrix-vector products:\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nx = np.array([2, 5, 1])\n\nnp.dot(A, x)\n\narray([35,  9, 16])\n\n\nGeometrically the matrix \\(A\\) defines a transformation that scales and rotates any vector \\(\\mathbf{x}\\) about the origin.\n\n\n\nThe number of columns of \\(A\\) must match the size of the vector \\(\\mathbf{x}\\), but if \\(A\\) has a different number of rows, the output will simply have a different size.\n\nnp.dot(A[:2], x)\n\narray([35,  9])\n\n\n\n\n\nMatrix multiplication is a fundamental operation between two matrices. It is defined as:\n\\[\n\\mathbf{A}\\mathbf{B}  = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\\\ B_{31} & B_{32} \\end{bmatrix}  =\\begin{bmatrix} \\sum_{i=1}^n A_{1i} B_{i1} & \\sum_{i=1}^n A_{i1}B_{i2} \\\\  \\sum_{i=1}^n A_{2i}B_{i1} & \\sum_{i=1}^n A_{2i}B_{i2}  \\\\  \\sum_{i=1}^n A_{3i}B_{i1} & \\sum_{i=1}^n A_{3i}B_{i2} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2} \\\\ \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*2}  \\\\ \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2}  \\end{bmatrix}\n\\]\nThis means that if we multiply an \\(n\\times m\\) matrix \\(\\mathbf{A}\\) with an \\(m\\times k\\) matrix \\(\\mathbf{B}\\) we get an \\(n\\times k\\) matrix \\(\\mathbf{C}\\), such that \\(\\mathbf{C}_{ij}\\) is the dot product of the \\(i\\)-th row of \\(\\mathbf{A}\\) with the \\(j\\)-th row of \\(\\mathbf{B}\\).\nIn numpy we once again use the np.dot function to perform matrix-multiplications.\n\nB = np.array([[2, -1], [3, 1], [-2, 5]])\nC = np.dot(A, B)\n\n\n\n\nThe number of rows of \\(\\mathbf{A}\\) must match the number of columns of \\(\\mathbf{B}\\) for the matrix multiplication \\(\\mathbf{A}\\mathbf{B}\\) to be defined. This implies that matrix multiplication is non-communitive:\n\\[\n\\mathbf{A}\\mathbf{B}\\neq \\mathbf{B}\\mathbf{A}\n\\]\nHowever matrix multiplication is associative and distributive:\n\\[\n\\mathbf{A}(\\mathbf{B}\\mathbf{C})=(\\mathbf{A}\\mathbf{B})\\mathbf{C}, \\quad \\mathbf{A}(\\mathbf{B} +\\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}\n\\]\n\n\n\nMatrix multiplication is a composition of linear maps, meaning that if we take the product \\(\\mathbf{A}\\mathbf{B}\\) and apply the resulting matrix to a vector \\(\\mathbf{x}\\), it is equivalent to first transforming \\(\\mathbf{x}\\) with \\(\\mathbf{B}\\) and then with \\(\\mathbf{A}\\). We can state this succinctly as:\n\\[\n(\\mathbf{A}\\mathbf{B})\\mathbf{x} = \\mathbf{A}(\\mathbf{B}\\mathbf{x})\n\\]\nWe can see this in numpy:\n\nx = np.array([1, 3])\nnp.dot(np.dot(A, B), x), np.dot(A, np.dot(B, x))\n\n(array([79, 31, 41]), array([79, 31, 41]))\n\n\n\n\n\nIt is important to note that in numpy the * operator does not perform matrix multiplication, instead it performs element-wise multiplication for both matrices and vectors.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nB = np.array([[1, 2], [1, 2], [1, 2]])\nA * B\n\narray([[1, 2],\n       [2, 4],\n       [3, 6]])\n\n\nIn mathematical notation we will denote element-wise multiplication as:\n\\[\n\\mathbf{A} \\odot \\mathbf{B} = \\begin{bmatrix} A_{11} B_{11}  & A_{12}  B_{12} & A_{13}  B_{13} \\\\ A_{21}  B_{21} & A_{22}  B_{22} & A_{23}  B_{23} \\end{bmatrix}\n\\]\n\n\n\nAs we saw with vectors, we can take the sum of the elements of a matrix using the np.sum function:\n\nnp.sum(A)\n\nnp.int64(12)\n\n\nThe result is a scalar of the form:\n\\[\n\\text{sum}(\\mathbf{A}) = \\sum_{i=1}^n\\sum_{j=1}^m A_{ij}\n\\]\n\n\n\nIn many cases we may wish to take the sum along an axis of a matrix. This operation results in a vector where each entry is the sum of elements from the corresponding row or column of the matrix.\n\\[\n\\text{rowsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{i=1}^n A_{i1} \\\\ \\sum_{i=1}^n A_{i2} \\\\ \\sum_{i=1}^n A_{i3} \\\\ \\vdots\\end{bmatrix}, \\quad \\text{colsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{j=1}^m A_{1j} \\\\ \\sum_{j=1}^m A_{2j} \\\\ \\sum_{j=1}^m A_{3j} \\\\ \\vdots\\end{bmatrix}\n\\]\nIn numpy we can specify a sum along an axis by providing an axis argument to np.sum. Setting axis=0 specifies a row-sum, while axis=1 specifies a column sum.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nprint(A)\nnp.sum(A, axis=0), np.sum(A, axis=1)\n\n[[1 1]\n [2 2]\n [3 3]]\n\n\n(array([6, 6]), array([2, 4, 6]))\n\n\n\n\n\n\nprint(np.mean(A))            # Take the mean of all elements in x\nprint(np.std(A, axis=0))     # Take the standard deviation of each column of x\nprint(np.min(A, axis=1))     # Find the minimum element in each row of x\nprint(np.max(A))             # Find the maximum element in x\n\n2.0\n[0.81649658 0.81649658]\n[1 2 3]\n3\n\n\n\n\n\nThe identity matrix, denoted at \\(\\mathbf{I}\\) is a special type of square matrix. It is defined as the matrix with \\(1\\) for every diagonal element (\\(\\mathbf{I}_{i=j}=1\\)) and \\(0\\) for every other element (\\(\\mathbf{I}_{i\\neq j}=0\\)). A \\(3\\times 3\\) identity matrix looks like:\n\\[\\mathbf{I} = \\begin{bmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}\\]\nThe identify matrix has the unique property that any appropriately sized matrix (or vector) multiplied with \\(\\mathbf{I}\\) will equal itself:\n\\[\n\\mathbf{I}\\mathbf{A} = \\mathbf{A}\n\\]\nIf we think of matrices as linear mappings the identity matrix simply maps any vector to itself.\n\\[\n\\mathbf{I} \\mathbf{x} = \\mathbf{x}\n\\]\nIn numpy we can create an identity matrix using the np.eye function:\n\nI = np.eye(3) # Create a 3x3 identity matrix\n\n\n\n\nConsider the matrix-vector product between a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we can denote the result of this multiplication as \\(\\mathbf{b}\\):\n\\[\n\\mathbf{A}\\mathbf{x} =\\mathbf{b}\n\\]\nIn many common cases we will know the matrix \\(\\mathbf{A}\\) and the vector \\(\\mathbf{b}\\), but not the vector \\(\\mathbf{x}\\). In such cases we need to solve this equation for \\(\\mathbf{x}\\):\n\\[\n\\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} \\textbf{?}\\\\ \\textbf{?}\\\\ \\textbf{?}\\end{bmatrix} = \\begin{bmatrix} b_1 \\\\  b_2 \\\\  b_3 \\end{bmatrix}\n\\]\nIn Numpy:\n\nA = np.array([[3, 1], [-1, 4]])\nb = np.array([-2, 1])\nx = np.linalg.solve(A, b)\n\nNote that in some cases there may not be any \\(\\mathbf{x}\\) that satisfies the equation (or there may be infinitely many). The conditions for this are beyond the scope of this course.\n\n\n\nThe inverse of a square matrix is denoted by \\(\\mathbf{A}^{-1}\\) and is defined as the matrix such that:\n\\[\n\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}\n\\]\nThis corresponds to the inverse of the linear map defined by \\(\\mathbf{A}\\). Any vector transformed by \\(\\mathbf{A}\\) can be transformed back by applying the inverse matrix:\n\\[\n\\mathbf{A}^{-1}\\left(\\mathbf{A}\\mathbf{x}\\right) =\\mathbf{x}\n\\]\nWe can also write the solution to a system of linear equations in terms of the inverse, by multiplying both sides by \\(\\mathbf{A}^{-1}\\):\n\\[\n\\mathbf{A}\\mathbf{x}=\\mathbf{b}\\quad \\longrightarrow \\quad \\mathbf{A}^{-1}(\\mathbf{A}\\mathbf{x})=\\mathbf{A}^{-1}\\mathbf{b} \\quad \\longrightarrow \\quad \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}\n\\]\nIn numpy we can find the inverse of a matrix using the np.linalg.inv function:\n\nA_inv = np.linalg.inv(A)\n\nNote that not every matrix has an inverse! Again, we won’t worry about these cases for now."
  },
  {
    "objectID": "lecture1-background/slides.html#numpy",
    "href": "lecture1-background/slides.html#numpy",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Numpy Is the linear algebra library that we will be using for much of this class. The standard way to import Numpy is:\n\nimport numpy as np\n\nThe most basic object from Numpy that we will just is the array (np.array), which will represent vectors matrices and even higher-dimensional objects known as tensors."
  },
  {
    "objectID": "lecture1-background/slides.html#scalars",
    "href": "lecture1-background/slides.html#scalars",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Scalars are just single numbers. In our math we will typically denote scalars with a lower-case letter. For example, we might call a scalar \\(x\\) and give it a value as \\[x=3.5\\] In code:\n\nx = 3.5\n\n# or as a 0-dimensional numpy array\nx = np.array(3.5)"
  },
  {
    "objectID": "lecture1-background/slides.html#vectors",
    "href": "lecture1-background/slides.html#vectors",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Vectors are ordered lists of numbers, as shown below. We will typically denote vectors with bold lower case letters, such as \\(\\mathbf{x}\\).\n\\[\n\\mathbf{x} = \\begin{bmatrix} 2\\\\ 5\\\\ 1\\end{bmatrix}\n\\]\nIn Numpy, we can create an array object representing a vector by passing np.array a list of numbers.\n\nx = np.array([2, 5, 1])"
  },
  {
    "objectID": "lecture1-background/slides.html#entries",
    "href": "lecture1-background/slides.html#entries",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The individual numbers in the vector are called the entries and we will refer to them individually as subscripted scalars: \\(x_1, x_2,…,x_n\\).\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix}\n\\]\nIn numpy we can access individual elements of a vector using [] operators (note that numpy is 0-indexed!).\n\nx[0]\n\nnp.int64(2)"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-interpretation",
    "href": "lecture1-background/slides.html#vector-interpretation",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "A vector represents either a location or a change in location in \\(n\\) -dimensional space.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture1-background/slides.html#vectors-as-data",
    "href": "lecture1-background/slides.html#vectors-as-data",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "A space of vectors could represent students, with each entry corresponding to a student’s grade in a different subject:\n\\[\n\\text{Student } \\mathbf{x} = \\begin{bmatrix} \\text{Math} \\\\ \\text{CS} \\\\ \\text{Literature} \\\\\\text{History} \\end{bmatrix}\n\\]\nAny two students might have different grades across the subjects. We can represent these two students (say \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\)) as two vectors.\n\\[\n\\mathbf{x}_1 = \\begin{bmatrix} 3.0 \\\\ 4.0 \\\\ 3.7 \\\\ 2.3 \\end{bmatrix}, \\quad \\mathbf{x}_2 = \\begin{bmatrix} 3.7 \\\\ 3.3 \\\\ 3.3 \\\\ 4.0 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-equality",
    "href": "lecture1-background/slides.html#vector-equality",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "We say that two vectors are equal if and only if all of the corresponding elements are equal, so \\[\\mathbf{x} = \\mathbf{y}\\] implies that \\[x_1=y_1, x_2=y_2…\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-equality-in-numpy",
    "href": "lecture1-background/slides.html#vector-equality-in-numpy",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "x = np.array([2, 5, 1])\ny = np.array([3, 5, 2])\nx == y\n\narray([False,  True, False])\n\n\nWe can check if all entries are equal (and therefore the vectors are equal) using the np.all function.\n\nnp.all(x == y), np.all(x == x)\n\n(np.False_, np.True_)\n\n\nOther comparison operators (&gt;,&lt;, &gt;=, &lt;=, !=) also perform element-wise comparison in numpy."
  },
  {
    "objectID": "lecture1-background/slides.html#vector-addition",
    "href": "lecture1-background/slides.html#vector-addition",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "When we add or subtract vectors, we add or subtract the corresponding elements.\n\\[\\mathbf{x} + \\mathbf{y} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} + \\begin{bmatrix} y_1\\\\ y_2\\\\ y_3\\end{bmatrix} = \\begin{bmatrix} x_1 + y_1\\\\ x_2 + y_2\\\\ x_3 + y_3\\end{bmatrix}\\] This works the same in numpy\n\nx + y\n\narray([ 5, 10,  3])"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-addition-1",
    "href": "lecture1-background/slides.html#vector-addition-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Addition corresponds to shifting the point \\(\\mathbf{x}\\) by the vector \\(\\mathbf{y}\\).\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture1-background/slides.html#element-wise-operations",
    "href": "lecture1-background/slides.html#element-wise-operations",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "In both mathematical notation and numpy, most operations on vectors will be assumed to be taken element-wise. That is,\n\\[\n\\mathbf{x}^2 = \\begin{bmatrix} x_1^2 \\\\ x_2^2 \\\\ x_3^2 \\end{bmatrix} , \\quad \\log(\\mathbf{x}) = \\begin{bmatrix} \\log x_1 \\\\ \\log x_2 \\\\ \\log x_3 \\end{bmatrix},\\ \\text{etc.}\n\\]\nIn numpy:\n\nx ** 2, np.log(x)\n\n(array([ 4, 25,  1]), array([0.69314718, 1.60943791, 0.        ]))"
  },
  {
    "objectID": "lecture1-background/slides.html#note-on-logarithms",
    "href": "lecture1-background/slides.html#note-on-logarithms",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Note that in this class (and in numpy!) logarithms are assumed to be base \\(e\\), otherwise known as natural logarithms."
  },
  {
    "objectID": "lecture1-background/slides.html#scalar-vector-operations",
    "href": "lecture1-background/slides.html#scalar-vector-operations",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Operations between scalars and vectors are also assumed to be element-wise as in this scalar-vector multiplication\n\\[\na\\mathbf{x} = \\begin{bmatrix} a x_1 \\\\ a x_2 \\\\ a x_3 \\end{bmatrix}, \\quad a + \\mathbf{x} = \\begin{bmatrix} a + x_1 \\\\ a + x_2 \\\\ a + x_3 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-magnitude",
    "href": "lecture1-background/slides.html#vector-magnitude",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The magnitude of a vector its length in \\(\\mathbb{R}^n\\), or equivalently the Euclidean distance from the origin to the point the vector represents. It is denoted as\\(\\|\\mathbf{x}\\|_2\\) and defined as:\n\\[\n\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}\n\\]\nThe subscript \\(2\\) specifies that we are talking about Euclidean distance. Because of this we will also refer to the magnitude as the two-norm.\nIn numpy we can compute this using the np.linalg.norm function.\n\nxnorm = np.linalg.norm(x)"
  },
  {
    "objectID": "lecture1-background/slides.html#vector-magnitude-1",
    "href": "lecture1-background/slides.html#vector-magnitude-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "We can also compute magnitude explicitly with the np.sum function, which computes the sum of the elements of a vector.\n\nxnorm_explicit = np.sqrt(np.sum(x ** 2))\nxnorm, xnorm_explicit\n\n(np.float64(5.477225575051661), np.float64(5.477225575051661))\n\n\n\n\n\n\n\n\nOther useful aggregation functions\n\n\n\n\n\n\nprint(np.mean(x))    # Take the mean of the elements in x\nprint(np.std(x))     # Take the standard deviation of the elements in x\nprint(np.min(x))     # Find the minimum element in x\nprint(np.max(x))     # Find the maximum element in x\n\n2.6666666666666665\n1.699673171197595\n1\n5"
  },
  {
    "objectID": "lecture1-background/slides.html#unit-vectors",
    "href": "lecture1-background/slides.html#unit-vectors",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "A unit vector is a vector with length \\(1\\). We can find a unit vector that has the same direction as \\(\\mathbf{x}\\) by dividing \\(\\mathbf{x}\\) by it’s magnitude:\n\\[\n\\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|_2}\n\\]\n\nx / np.linalg.norm(x)\n\narray([0.36514837, 0.91287093, 0.18257419])"
  },
  {
    "objectID": "lecture1-background/slides.html#dot-products",
    "href": "lecture1-background/slides.html#dot-products",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The dot-product operation between two vectors is defined as\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = \\sum_{i=1}^n x_i y_i\n\\]\nThe result is a scalar whose value is equal to \\(\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2 \\cos\\theta\\), where \\(\\theta\\) is the angle between them.\nWe can compute dot products in numpy using the np.dot function\n\nnp.dot(x, y)\n\nnp.int64(33)"
  },
  {
    "objectID": "lecture1-background/slides.html#dot-products-1",
    "href": "lecture1-background/slides.html#dot-products-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "If \\(\\theta=\\frac{\\pi}{2}\\), the vectors are orthogonal and the dot product with be \\(0\\). If \\(\\theta&gt;\\frac{\\pi}{2}\\) or \\(\\theta &lt; -\\frac{\\pi}{2}\\) , the dot product will be negative.\nIf \\(\\theta=0\\) then \\(\\cos(\\theta)=1\\). In this case we say the vectors are colinear. This formulation implies that given two vectors of fixed length, the dot product is maximized with they are colinear ( \\(\\theta=0\\) )."
  },
  {
    "objectID": "lecture1-background/slides.html#dot-products-2",
    "href": "lecture1-background/slides.html#dot-products-2",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Geometrically, \\(\\|\\mathbf{x}\\|_2\\cos\\theta\\) is the length of the projection of \\(\\mathbf{x}\\) onto \\(\\mathbf{y}\\). Thus, we can compute the length of this projection using the dot-product as \\(\\frac{\\mathbf{x}\\cdot\\mathbf{y}}{\\|\\mathbf{y}\\|}\\) ."
  },
  {
    "objectID": "lecture1-background/slides.html#matrices",
    "href": "lecture1-background/slides.html#matrices",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "A matrix is a 2-dimensional collection of numbers. We will denote matrices using bold capital letters, e.g. \\(\\mathbf{A}\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2  \\end{bmatrix}\n\\]\nIn numpy we can create a matrix by passing np.array as list-of-lists, where each inner list specifies a row of the matrix.\n\nA = np.array([[3, 5, 4], [1, 1, 2]])\nA\n\narray([[3, 5, 4],\n       [1, 1, 2]])"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-elements",
    "href": "lecture1-background/slides.html#matrix-elements",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "As with vectors we will denote individual elements of a matrix using subscripts. In this case, each element has 2 coordinates. Conventions is to always list the row first.\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can access elements in a matrix similarly.\n\nA[1, 2]\n\nnp.int64(2)\n\n\nAs with vectors, we say that two matrices are equal if and only if all of the corresponding elements are equal."
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-creation-in-numpy",
    "href": "lecture1-background/slides.html#matrix-creation-in-numpy",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Basic creation functions\n\nA0 = np.zeros((3, 4))          # create a 3x4 matrix of all zeros\nA1 = np.ones((4, 4))           # create a 4x4 matrix of all ones\nAinf = np.full((3, 3), np.inf) # create a 3x3 matrix of all infinities\nI = np.eye(3)                  # create a 3x3 itentity matrix\n\nCreating a matrix by “reshaping” a vector with the same number of elements\n\nV = np.arange(1, 13).reshape((3, 4)) # Create a 3x4 matrix with elements 1-12\n\nCreating matrices by combining matrices\n\nB = np.tile(A0, (3, 2))               # create a matrix by \"tiling\" copies of A0 (3 copies by 2 copies)\nB = np.concatenate([A0, A1], axis=0)  # create a (2n x m) matrix by stacking two matrices vertically\nB = np.concatenate([A0, I], axis=1)  # create a (n x 2m) matrix by stacking two matrices horizontally"
  },
  {
    "objectID": "lecture1-background/slides.html#slicing-matrices",
    "href": "lecture1-background/slides.html#slicing-matrices",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Often we will refer to an entire row of a matrix (which is itself a vector) using matrix notation with a single index\n\\[\n\\mathbf{A}_i = \\begin{bmatrix} A_{i1} \\\\ A_{i2} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access a single row similarly.\n\nA[1]\n\narray([1, 1, 2])"
  },
  {
    "objectID": "lecture1-background/slides.html#slicing-matrices-1",
    "href": "lecture1-background/slides.html#slicing-matrices-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "We can refer to an entire column by replacing the row index with a \\(*\\), indicating we are referring to all rows in that column.\n\\[\n\\mathbf{A}_{*i} = \\begin{bmatrix} A_{1i} \\\\ A_{2i} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access an entire column (or row) using the slice operator :, which takes all elements along an axis.\n\nA[:, 1] # Take all elements in column 1\n\narray([5, 1])"
  },
  {
    "objectID": "lecture1-background/slides.html#slicing-matrices-2",
    "href": "lecture1-background/slides.html#slicing-matrices-2",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "We can also use the slice operator to take a subset of elements along an axis.\n\nA[:, 1:3] #Take the second and third columns of A\n\narray([[5, 4],\n       [1, 2]])"
  },
  {
    "objectID": "lecture1-background/slides.html#advanced-slicing-in-numpy",
    "href": "lecture1-background/slides.html#advanced-slicing-in-numpy",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Open-ended slices\n\nprint(\"A[:2]=\", A[:2]) # Take rows up to 2 (not inucluding 2)\nprint(\"A[1:]=\", A[1:]) # Take rows starting at (and including) 1\n\nA[:2]= [[1 2 3 4]\n [5 6 7 8]]\nA[1:]= [[ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nTaking rows and colmns\n\nprint(\"A[0, :]=\", A[0, :])   # first row, all columns\nprint(\"A[:, 1]=\", A[:, 1])   # all rows, second column\nprint(\"A[-1, :]\", A[-1, :])  # all columns of the last row\nprint(\"A[:, -2]\", A[:, -2])  # second to last column of every row\n\nA[0, :]= [1 2 3 4]\nA[:, 1]= [ 2  6 10]\nA[-1, :] [ 9 10 11 12]\nA[:, -2] [ 3  7 11]"
  },
  {
    "objectID": "lecture1-background/slides.html#advanced-slicing-in-numpy-1",
    "href": "lecture1-background/slides.html#advanced-slicing-in-numpy-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "More general slicing with steps\n\nprint(\"A[1,0:2]=\", A[1,0:2])\nprint(\"A[0,0:4:2]=\", A[0,0:4:2])\nprint(\"A[:,0:4:2]=\\n\", A[:,0:4:2])\n\nA[1,0:2]= [5 6]\nA[0,0:4:2]= [1 3]\nA[:,0:4:2]=\n [[ 1  3]\n [ 5  7]\n [ 9 11]]\n\n\nTaking one row and selected columns\n\nprint(\"A[2, [1,4]]=\",A[2, [0,3]])\n\nA[2, [1,4]]= [ 9 12]\n\n\nTaking all rows and selected columns\n\nprint(\"A[:, [1,4]]=\\n\",A[:, [0,3]])\n\nA[:, [1,4]]=\n [[ 1  4]\n [ 5  8]\n [ 9 12]]"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-shapes",
    "href": "lecture1-background/slides.html#matrix-shapes",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The matrix \\(\\mathbf{A}\\) above has 2 rows and 3 columns, thus we would specify it’s shape as \\(2\\times3\\). A square matrix has the same number of rows and columns.\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2 \\\\ 4 & 1 & 3 \\end{bmatrix}\n\\]\nWe can access the shape of a matrix in numpy using its shape property.\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nprint(A.shape)\n\n(3, 3)"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-transpose",
    "href": "lecture1-background/slides.html#matrix-transpose",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The transpose of a matrix is an operation that swaps the rows and columns of the matrix. We denote the transpose of a matrix \\(\\mathbf{A}\\) as \\(\\mathbf{A}^T\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}, \\quad \\mathbf{A}^T = \\begin{bmatrix} A_{11} & A_{21} \\\\  A_{12} & A_{22} \\\\  A_{13} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can transpose a matrix by using the T property.\n\nA = np.array([[1, 1, 1], [2, 2, 2]])\nA.T\n\narray([[1, 2],\n       [1, 2],\n       [1, 2]])"
  },
  {
    "objectID": "lecture1-background/slides.html#element-wise-matrix-operations",
    "href": "lecture1-background/slides.html#element-wise-matrix-operations",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "As with vectors, many operations on matrices are performed element-wise:\n\\[\n\\mathbf{A} + \\mathbf{B} = \\begin{bmatrix} A_{11} + B_{11}  & A_{12} + B_{12} & A_{13} + B_{13} \\\\ A_{21} + B_{21} & A_{22} + B_{22} & A_{23} + B_{23} \\end{bmatrix}, \\quad \\log\\mathbf{A} = \\begin{bmatrix} \\log A_{11}  & \\log A_{12} & \\log A_{13} \\\\ \\log A_{21} & \\log A_{22} & \\log A_{23} \\end{bmatrix}\n\\]\nScalar-matrix operation are also element-wise:\n\\[\nc\\mathbf{A} = \\begin{bmatrix} cA_{11}  & cA_{12} & cA_{13} \\\\ cA_{21} & cA_{22} & cA_{23} \\end{bmatrix}\n\\]\nIn numpy:\n\nB = 5 * A \nA + B\n\narray([[ 6,  6,  6],\n       [12, 12, 12]])"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-vector-products",
    "href": "lecture1-background/slides.html#matrix-vector-products",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "A matrix-vector product is an operation between a matrix and a vector that produces a new vector. Given a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we write the matrix-vector product as:\n\\[\n\\mathbf{A}\\mathbf{x} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^n x_i A_{1i} \\\\  \\sum_{i=1}^n x_i A_{2i} \\\\  \\sum_{i=1}^n x_i A_{3i} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}\\cdot  \\mathbf{A}_{1} \\\\ \\mathbf{x}\\cdot  \\mathbf{A}_{2} \\\\ \\mathbf{x} \\cdot \\mathbf{A}_{2} \\end{bmatrix}\n\\]\nIn other words, each entry of the resulting vector is the dot product between \\(\\mathbf{x}\\) and a row of \\(A\\). In numpy we also use np.dot for matrix-vector products:\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nx = np.array([2, 5, 1])\n\nnp.dot(A, x)\n\narray([35,  9, 16])\n\n\nGeometrically the matrix \\(A\\) defines a transformation that scales and rotates any vector \\(\\mathbf{x}\\) about the origin."
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-vector-products-1",
    "href": "lecture1-background/slides.html#matrix-vector-products-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The number of columns of \\(A\\) must match the size of the vector \\(\\mathbf{x}\\), but if \\(A\\) has a different number of rows, the output will simply have a different size.\n\nnp.dot(A[:2], x)\n\narray([35,  9])"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-multiplication",
    "href": "lecture1-background/slides.html#matrix-multiplication",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Matrix multiplication is a fundamental operation between two matrices. It is defined as:\n\\[\n\\mathbf{A}\\mathbf{B}  = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\\\ B_{31} & B_{32} \\end{bmatrix}  =\\begin{bmatrix} \\sum_{i=1}^n A_{1i} B_{i1} & \\sum_{i=1}^n A_{i1}B_{i2} \\\\  \\sum_{i=1}^n A_{2i}B_{i1} & \\sum_{i=1}^n A_{2i}B_{i2}  \\\\  \\sum_{i=1}^n A_{3i}B_{i1} & \\sum_{i=1}^n A_{3i}B_{i2} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2} \\\\ \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*2}  \\\\ \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2}  \\end{bmatrix}\n\\]\nThis means that if we multiply an \\(n\\times m\\) matrix \\(\\mathbf{A}\\) with an \\(m\\times k\\) matrix \\(\\mathbf{B}\\) we get an \\(n\\times k\\) matrix \\(\\mathbf{C}\\), such that \\(\\mathbf{C}_{ij}\\) is the dot product of the \\(i\\)-th row of \\(\\mathbf{A}\\) with the \\(j\\)-th row of \\(\\mathbf{B}\\).\nIn numpy we once again use the np.dot function to perform matrix-multiplications.\n\nB = np.array([[2, -1], [3, 1], [-2, 5]])\nC = np.dot(A, B)"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-multiplication-1",
    "href": "lecture1-background/slides.html#matrix-multiplication-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The number of rows of \\(\\mathbf{A}\\) must match the number of columns of \\(\\mathbf{B}\\) for the matrix multiplication \\(\\mathbf{A}\\mathbf{B}\\) to be defined. This implies that matrix multiplication is non-communitive:\n\\[\n\\mathbf{A}\\mathbf{B}\\neq \\mathbf{B}\\mathbf{A}\n\\]\nHowever matrix multiplication is associative and distributive:\n\\[\n\\mathbf{A}(\\mathbf{B}\\mathbf{C})=(\\mathbf{A}\\mathbf{B})\\mathbf{C}, \\quad \\mathbf{A}(\\mathbf{B} +\\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-multiplication-2",
    "href": "lecture1-background/slides.html#matrix-multiplication-2",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Matrix multiplication is a composition of linear maps, meaning that if we take the product \\(\\mathbf{A}\\mathbf{B}\\) and apply the resulting matrix to a vector \\(\\mathbf{x}\\), it is equivalent to first transforming \\(\\mathbf{x}\\) with \\(\\mathbf{B}\\) and then with \\(\\mathbf{A}\\). We can state this succinctly as:\n\\[\n(\\mathbf{A}\\mathbf{B})\\mathbf{x} = \\mathbf{A}(\\mathbf{B}\\mathbf{x})\n\\]\nWe can see this in numpy:\n\nx = np.array([1, 3])\nnp.dot(np.dot(A, B), x), np.dot(A, np.dot(B, x))\n\n(array([79, 31, 41]), array([79, 31, 41]))"
  },
  {
    "objectID": "lecture1-background/slides.html#element-wise-multiplication",
    "href": "lecture1-background/slides.html#element-wise-multiplication",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "It is important to note that in numpy the * operator does not perform matrix multiplication, instead it performs element-wise multiplication for both matrices and vectors.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nB = np.array([[1, 2], [1, 2], [1, 2]])\nA * B\n\narray([[1, 2],\n       [2, 4],\n       [3, 6]])\n\n\nIn mathematical notation we will denote element-wise multiplication as:\n\\[\n\\mathbf{A} \\odot \\mathbf{B} = \\begin{bmatrix} A_{11} B_{11}  & A_{12}  B_{12} & A_{13}  B_{13} \\\\ A_{21}  B_{21} & A_{22}  B_{22} & A_{23}  B_{23} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-reductions",
    "href": "lecture1-background/slides.html#matrix-reductions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "As we saw with vectors, we can take the sum of the elements of a matrix using the np.sum function:\n\nnp.sum(A)\n\nnp.int64(12)\n\n\nThe result is a scalar of the form:\n\\[\n\\text{sum}(\\mathbf{A}) = \\sum_{i=1}^n\\sum_{j=1}^m A_{ij}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#matrix-reductions-1",
    "href": "lecture1-background/slides.html#matrix-reductions-1",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "In many cases we may wish to take the sum along an axis of a matrix. This operation results in a vector where each entry is the sum of elements from the corresponding row or column of the matrix.\n\\[\n\\text{rowsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{i=1}^n A_{i1} \\\\ \\sum_{i=1}^n A_{i2} \\\\ \\sum_{i=1}^n A_{i3} \\\\ \\vdots\\end{bmatrix}, \\quad \\text{colsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{j=1}^m A_{1j} \\\\ \\sum_{j=1}^m A_{2j} \\\\ \\sum_{j=1}^m A_{3j} \\\\ \\vdots\\end{bmatrix}\n\\]\nIn numpy we can specify a sum along an axis by providing an axis argument to np.sum. Setting axis=0 specifies a row-sum, while axis=1 specifies a column sum.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nprint(A)\nnp.sum(A, axis=0), np.sum(A, axis=1)\n\n[[1 1]\n [2 2]\n [3 3]]\n\n\n(array([6, 6]), array([2, 4, 6]))"
  },
  {
    "objectID": "lecture1-background/slides.html#other-matrix-reduction-examples",
    "href": "lecture1-background/slides.html#other-matrix-reduction-examples",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "print(np.mean(A))            # Take the mean of all elements in x\nprint(np.std(A, axis=0))     # Take the standard deviation of each column of x\nprint(np.min(A, axis=1))     # Find the minimum element in each row of x\nprint(np.max(A))             # Find the maximum element in x\n\n2.0\n[0.81649658 0.81649658]\n[1 2 3]\n3"
  },
  {
    "objectID": "lecture1-background/slides.html#identity-matrices",
    "href": "lecture1-background/slides.html#identity-matrices",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The identity matrix, denoted at \\(\\mathbf{I}\\) is a special type of square matrix. It is defined as the matrix with \\(1\\) for every diagonal element (\\(\\mathbf{I}_{i=j}=1\\)) and \\(0\\) for every other element (\\(\\mathbf{I}_{i\\neq j}=0\\)). A \\(3\\times 3\\) identity matrix looks like:\n\\[\\mathbf{I} = \\begin{bmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}\\]\nThe identify matrix has the unique property that any appropriately sized matrix (or vector) multiplied with \\(\\mathbf{I}\\) will equal itself:\n\\[\n\\mathbf{I}\\mathbf{A} = \\mathbf{A}\n\\]\nIf we think of matrices as linear mappings the identity matrix simply maps any vector to itself.\n\\[\n\\mathbf{I} \\mathbf{x} = \\mathbf{x}\n\\]\nIn numpy we can create an identity matrix using the np.eye function:\n\nI = np.eye(3) # Create a 3x3 identity matrix"
  },
  {
    "objectID": "lecture1-background/slides.html#solving-systems-of-linear-equations",
    "href": "lecture1-background/slides.html#solving-systems-of-linear-equations",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "Consider the matrix-vector product between a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we can denote the result of this multiplication as \\(\\mathbf{b}\\):\n\\[\n\\mathbf{A}\\mathbf{x} =\\mathbf{b}\n\\]\nIn many common cases we will know the matrix \\(\\mathbf{A}\\) and the vector \\(\\mathbf{b}\\), but not the vector \\(\\mathbf{x}\\). In such cases we need to solve this equation for \\(\\mathbf{x}\\):\n\\[\n\\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} \\textbf{?}\\\\ \\textbf{?}\\\\ \\textbf{?}\\end{bmatrix} = \\begin{bmatrix} b_1 \\\\  b_2 \\\\  b_3 \\end{bmatrix}\n\\]\nIn Numpy:\n\nA = np.array([[3, 1], [-1, 4]])\nb = np.array([-2, 1])\nx = np.linalg.solve(A, b)\n\nNote that in some cases there may not be any \\(\\mathbf{x}\\) that satisfies the equation (or there may be infinitely many). The conditions for this are beyond the scope of this course."
  },
  {
    "objectID": "lecture1-background/slides.html#inverse-matrices",
    "href": "lecture1-background/slides.html#inverse-matrices",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "",
    "text": "The inverse of a square matrix is denoted by \\(\\mathbf{A}^{-1}\\) and is defined as the matrix such that:\n\\[\n\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}\n\\]\nThis corresponds to the inverse of the linear map defined by \\(\\mathbf{A}\\). Any vector transformed by \\(\\mathbf{A}\\) can be transformed back by applying the inverse matrix:\n\\[\n\\mathbf{A}^{-1}\\left(\\mathbf{A}\\mathbf{x}\\right) =\\mathbf{x}\n\\]\nWe can also write the solution to a system of linear equations in terms of the inverse, by multiplying both sides by \\(\\mathbf{A}^{-1}\\):\n\\[\n\\mathbf{A}\\mathbf{x}=\\mathbf{b}\\quad \\longrightarrow \\quad \\mathbf{A}^{-1}(\\mathbf{A}\\mathbf{x})=\\mathbf{A}^{-1}\\mathbf{b} \\quad \\longrightarrow \\quad \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}\n\\]\nIn numpy we can find the inverse of a matrix using the np.linalg.inv function:\n\nA_inv = np.linalg.inv(A)\n\nNote that not every matrix has an inverse! Again, we won’t worry about these cases for now."
  },
  {
    "objectID": "lecture1-background/slides.html#functions",
    "href": "lecture1-background/slides.html#functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Functions",
    "text": "Functions\nA function is a general mapping from one set to another.\n\\[\ny=f(x),\\quad f:\\mathbb{R}\\rightarrow\\mathbb{R}\n\\]\nWe can definite functions as compositions of simple operations. For example we could define a polynomial function as:\n\\[\nf(x) = x^2 + 3x + 1\n\\]\nIn code we can implement functions as, well, functions:\n\ndef f(x):\n    return x ** 2 + 3 * x + 1\n\nf(5)\n\n41"
  },
  {
    "objectID": "lecture1-background/slides.html#derivatives",
    "href": "lecture1-background/slides.html#derivatives",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Derivatives",
    "text": "Derivatives\nThe derivative of a function at input \\(x\\) defines how the function’s output changes as the input changes from \\(x\\). It is equivalent to the slope of the line tangent to the function at the input \\(x\\). We’ll use the notation \\(\\frac{df}{dx}\\) to denote the derivative of the function \\(f\\) at input \\(x\\). Formally:\n\\[\n\\frac{df}{dx} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x+\\epsilon) - f(x)}{\\epsilon}\n\\]\nIntunitively, this means if we change our input \\(x\\) by some small amount \\(\\epsilon\\), the output of our function will change by approximately \\(\\frac{df}{dx}\\epsilon\\)\n\\[\nf(x+\\epsilon) \\approx f(x)+\\frac{df}{dx}\\epsilon\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#derivative-operator",
    "href": "lecture1-background/slides.html#derivative-operator",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Derivative operator",
    "text": "Derivative operator\nWe can also use the notation \\(\\frac{d}{dx}\\) to denote the derivative operator. This means “find the derivative of the following expression with respect to \\(x\\)”.\n\\[\n\\frac{d}{dx}f(x) = \\frac{df}{dx}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#derivative-functions",
    "href": "lecture1-background/slides.html#derivative-functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Derivative functions",
    "text": "Derivative functions\nWe can also talk about the function that maps any input \\(x\\) to the derivative \\(\\frac{df}{dx}\\) we call this the derivative function and denote it as \\(f'(x)\\). So:\n\\[\n\\frac{df}{dx}=f'(x)\n\\]\nGiven a function defined as a composition of basic operations, we can use a set of standard rules to find the corresponding derivative function. For example using the rules \\(\\frac{d}{dx}x^a=ax\\) , \\(\\frac{d}{dx}ax=a\\) and \\(\\frac{d}{dx}a=0\\), we can derive the derivative function for the polynomial above:\n\\[\nf(x) = x^2 + 3x + 1\n\\]\n\\[\nf'(x) = 2x + 3\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#basic-derivative-rules",
    "href": "lecture1-background/slides.html#basic-derivative-rules",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Basic derivative rules",
    "text": "Basic derivative rules\n\n\n\nOperation\nDerivative \\(\\frac{d}{dx}\\)\n\n\n\n\n\\(a\\)\n\\(0\\)\n\n\n\\(ax\\)\n\\(a\\)\n\n\n\\(x^a\\)\n\\(ax\\)\n\n\n\\(\\log(x)\\)\n\\(\\frac{1}{x}\\)\n\n\n\\(e^x\\)\n\\(e^x\\)\n\n\n\\(f(x) + g(x)\\)\n\\(f'(x)+g'(x)\\)\n\n\n\\(f(x)g(x)\\)\n\\(f'(x)g(x) + f(x)g'(x)\\)\n\n\n\\(\\frac{f(x)}{g(x)}\\)\n\\(\\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}\\)"
  },
  {
    "objectID": "lecture1-background/slides.html#compositions-of-functions",
    "href": "lecture1-background/slides.html#compositions-of-functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Compositions of functions",
    "text": "Compositions of functions\nComposing two functions means to apply one function to the output of another, for example we could apply \\(f\\) to the output of \\(g\\):\n\\[\ny = f\\big(g\\left(x\\right)\\big)\n\\]\nThis is easily replicated in code:\n\ndef f(x):\n    return x ** 2 + 3 * x + 1\n\ndef g(x):\n    return 5 * x - 2\n\nf(g(3))\n\n209"
  },
  {
    "objectID": "lecture1-background/slides.html#chain-rule",
    "href": "lecture1-background/slides.html#chain-rule",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Chain rule",
    "text": "Chain rule\nThe chain rule tells us how to find the derivative of a composition of functions like this. We can write the rule either in terms of derivatives or derivative functions\n\\[\n\\frac{d}{dx}f\\big(g\\left(x\\right)\\big) = \\frac{df}{dg}\\frac{dg}{dx} \\quad \\text{or} \\quad \\frac{d}{dx}f\\big(g\\left(x\\right)\\big) =  f'\\big(g\\left(x\\right)\\big)g'\\left(x\\right)\n\\]\nNote that in our derivative notation we’re using \\(f\\) and \\(g\\) to denote the outputs of the respective functions."
  },
  {
    "objectID": "lecture1-background/slides.html#multivariate-functions",
    "href": "lecture1-background/slides.html#multivariate-functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Multivariate functions",
    "text": "Multivariate functions\nA function does not need to be restricted to having a single input. We can specify a function with multiple inputs as follows:\n\\[\nf(x, y, z) = x^2 + 3xy - \\log(z)\n\\]\nIn code this would look like;\n\ndef f(x, y, z):\n    return x ** 2 + 3 * y + np.log(z)"
  },
  {
    "objectID": "lecture1-background/slides.html#partial-derivatives",
    "href": "lecture1-background/slides.html#partial-derivatives",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nA partial derivative is the derivative of a multiple-input function with respect to a single input, assuming all other inputs are constant.\n\\[\n\\frac{\\partial f}{\\partial x} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x+\\epsilon, y, z) - f(x,y,z)}{\\epsilon}, \\quad \\frac{\\partial f}{\\partial y} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x, y+\\epsilon, z) - f(x,y,z)}{\\epsilon}\n\\]\nThese partial derivatives tell us how the output of the function changes as we change each of the inputs individually."
  },
  {
    "objectID": "lecture1-background/slides.html#partial-derivative-functions",
    "href": "lecture1-background/slides.html#partial-derivative-functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Partial derivative functions",
    "text": "Partial derivative functions\nWe can also specify partial derivative functions in the same way as derivative functions. We’ll use subscript notation to specify which input we are differentiating with respect to.\n\\[\n\\frac{\\partial f}{\\partial x} = f_x'(x, y, z)\n\\]\nWe can derive partial derivative functions using the same set of derivative rules:\n\\[\nf(x, y, z) = x^2 + 3xy - \\log(z)\n\\]\n\\[\nf_x'(x, y, z) = 2x + 3y\n\\]\n\\[\nf_y'(x, y, z) = 3x\n\\]\n\\[\nf_z'(x, y, z) = -\\frac{1}{z}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#functions-of-vectors",
    "href": "lecture1-background/slides.html#functions-of-vectors",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Functions of vectors",
    "text": "Functions of vectors\nWe can also define functions that take vectors (or matrices) as inputs.\n\\[\ny = f(\\mathbf{x}) \\quad f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\n\\]\nHere \\(f\\) is a mapping from length \\(n\\) vectors to real numbers. As a concrete example we could define the function:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_i^3 + 1\n\\]\nHere’s the same function in numpy:\n\ndef f(x):\n    return np.sum(x ** 3) + 1\n\nf(np.array([1, 2, 3]))\n\nnp.int64(37)\n\n\nNote that functions of vectors are equivalent to multiple-input functions, but with a more compact notation!"
  },
  {
    "objectID": "lecture1-background/slides.html#gradients",
    "href": "lecture1-background/slides.html#gradients",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Gradients",
    "text": "Gradients\nThe gradient of a vector-input function is a vector such that each element is the partial derivative of the function with respect to the corresponding element of the input vector. We’ll use the same notation as derivatives for gradients.\n\\[\n\\frac{df}{d\\mathbf{x}} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\frac{\\partial f}{\\partial x_3} \\\\ \\vdots \\end{bmatrix}\n\\]\nThe gradient is a vector that tangent to the function \\(f\\) at the input \\(\\mathbf{x}\\). Just as with derivatives, this means that the gradient defines a linear approximation to the function at the point \\(\\mathbf{x}\\).\n\\[\nf(\\mathbf{x}+\\mathbf{\\epsilon}) \\approx f(\\mathbf{x}) + \\frac{df}{d\\mathbf{x}} \\cdot \\mathbf{\\epsilon}\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#gradient-functions",
    "href": "lecture1-background/slides.html#gradient-functions",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Gradient functions",
    "text": "Gradient functions\nJust as with derivatives and partial derivatives, we can define a gradient function that maps an input vector \\(\\mathbf{x}\\) to the gradient of the function \\(f\\) at \\(\\mathbf{x}\\) as:\n\\[\n\\frac{df}{d\\mathbf{x}}=\\nabla f(\\mathbf{x})\n\\]\nHere \\(\\nabla f\\) is the gradient function for \\(f\\). If the function takes multiple vectors as input, we can specify the gradient function with respect to a particular input using subscript notation:\n\\[\n\\frac{df}{d\\mathbf{x}}= \\nabla_{\\mathbf{x}} f(\\mathbf{x}, \\mathbf{y}), \\quad \\frac{df}{d\\mathbf{y}}= \\nabla_{\\mathbf{y}} f(\\mathbf{x}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "lecture1-background/slides.html#getting-started",
    "href": "lecture1-background/slides.html#getting-started",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Getting started",
    "text": "Getting started\nThe standard way to import MatPlotLib is:\n\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "lecture1-background/slides.html#scatterplots",
    "href": "lecture1-background/slides.html#scatterplots",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Scatterplots",
    "text": "Scatterplots\nPlotting a scatter of data points:\n\nx_values = np.random.rand(1,10)   # unformly in [0,1)\ny_values = np.random.randn(1,10)  # Gaussian distribution\nplt.plot(x_values, y_values, 'ko');\n\n\n\n\n\n\n\n\nThe string determines the plot appearance -- in this case, black circles. You can use color strings (‘r’, ‘g’, ‘b’, ‘m’, ‘c’, ‘y’, ...) or use the “Color” keyword to specify an RGB color. Marker appearance (‘o’,‘s’,‘v’,‘.’, ...) controls how the points look."
  },
  {
    "objectID": "lecture1-background/slides.html#line-plots",
    "href": "lecture1-background/slides.html#line-plots",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Line plots",
    "text": "Line plots\nIf we connect points using a line appearance specification (‘-’,‘--’,‘:’,...), it will not look very good, because the points are not ordered in any meaningful way. Let’s try a line plot using an ordered sequence of x values:\n\nx_values = np.linspace(0,8,100)\ny_values = np.sin(x_values)\nplt.plot(x_values,y_values,'b');\n\n\n\n\n\n\n\n\nThis is actually a plot of a large number of points (100), with no marker shape and connected by a solid line."
  },
  {
    "objectID": "lecture1-background/slides.html#multiple-plots",
    "href": "lecture1-background/slides.html#multiple-plots",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Multiple plots",
    "text": "Multiple plots\nFor plotting multiple point sets or curves, you can pass more vectors into the plot function, or call the function multiple times:\n\nx_values = np.linspace(0,8,100)\ny1 = np.sin(x_values)         # sinusoidal function\ny2 = (x_values - 3)**2 / 12   # a simple quadratic curve\ny3 = 0.5*x_values - 1.0       # a simple linear function\n\nplt.plot(x_values, y1, 'b-', x_values, y2, 'g--');  # plot two curves\nplt.plot(x_values, y3, 'r:'); # add a curve to the plot"
  },
  {
    "objectID": "lecture1-background/slides.html#plot-ranges",
    "href": "lecture1-background/slides.html#plot-ranges",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Plot ranges",
    "text": "Plot ranges\nYou may want to explicitly set the plot ranges -- perhaps the most common pattern is to plot something, get the plot’s ranges, and then restore them later after plotting another function:\n\nx_values = np.linspace(0,8,100)\ny1 = np.sin(x_values)         # sinusoidal function\ny3 = 0.5*x_values - 1.0       # a simple linear function\n\nplt.plot(x_values, y1, 'b-') \nax = plt.axis()               # get the x and y axis ranges\nprint(ax)\n# now plot something else (which will change the axis ranges):\nplt.plot(x_values, y3, 'r:'); # add the linear curve\nplt.axis(ax);                 # restore the original plot's axis ranges\n\n(np.float64(-0.4), np.float64(8.4), np.float64(-1.099652011574681), np.float64(1.0998559934443881))"
  },
  {
    "objectID": "lecture1-background/slides.html#histograms",
    "href": "lecture1-background/slides.html#histograms",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Histograms",
    "text": "Histograms\nHistograms are also useful visualizations:\n\nplt.hist(y2, bins=20);\n\n\n\n\n\n\n\n\nThe outputs of hist include the bin locations, the number of data in each bin, and the “handles” to the plot elements to manipulate their appearance, if desired."
  },
  {
    "objectID": "lecture1-background/slides.html#subplots-and-plot-sizes",
    "href": "lecture1-background/slides.html#subplots-and-plot-sizes",
    "title": "Lecture 1: Background and Prerequisites",
    "section": "Subplots and plot sizes",
    "text": "Subplots and plot sizes\nIt is often useful to put more than one plot together in a group; you can do this using the subplot function. There are various options; for example, “sharex” and “sharey” allow multiple plots to share a single axis range (or, you can set it manually, of course).\n\nfig,ax = plt.subplots(1,3, figsize=(8.0, 2.0))      # make a 1 x 3 grid of plots:\nax[0].plot(x_values, y1, 'b-');   # plot y1 in the first subplot\nax[1].plot(x_values, y2, 'g--');  #   y2 in the 2nd\nax[2].plot(x_values, y3, 'r:');   #   and y3 in the last"
  },
  {
    "objectID": "lecture8-regularization/slides.html",
    "href": "lecture8-regularization/slides.html",
    "title": "Initialization",
    "section": "",
    "text": "\\[\\mathbb{E}\\big[X \\big] = \\int_{x} x p(x) dx\\quad \\text{(Continuous random variables)}\\]\n\n\n\n\n\\[\\mathbb{E}\\big[X \\big] = \\sum_{x} x p(x) \\quad \\text{(Discrete random variables)}\\]\n\n\n\n\n\\[\\mathbb{E}\\big[ aX \\big] =  a\\mathbb{E}\\big[ X \\big] \\]\n\\[\\mathbb{E}\\bigg[ \\sum_{i=1}^n X_i \\bigg] =  \\sum_{i=1}^n \\mathbb{E}\\bigg[ X_i \\bigg]\\]\n\n\n\n\\[\nVar\\big[X\\big] = \\mathbb{E}\\big[(X - \\mathbb{E}[X])^2\\big]\n\\]\n\n\n\n\n\\[\nVar[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n\\]\n\\[\nVar[aX] = a^2 Var[X]\n\\]\nIf \\(X\\) and \\(Y\\) are independent: \\[\nVar[X + Y] = Var[X] + Var[Y]\n\\]\n\n\n\n\n\n\n\nDropout rate: \\(r\\)\n\\[\\text{DO}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix} \\] \\[d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\n\n\n\nWithin a NN layer:\n\\[\n\\phi(\\mathbf{x}) = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b})\n\\]\n\n\n\nA network with several dropout layers:\n\\[f(\\mathbf{x}, \\mathbf{w}_0,...) = \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma(\\text{DO}_r( \\mathbf{x})^T  \\mathbf{W}_2 + \\mathbf{b}_2))^T \\mathbf{W}_1 + \\mathbf{b}_1))^T \\mathbf{w}_0 + \\mathbf{b}_0\\]\n\n\n\nA network with several dropout layers:\n\\[\n\\mathbf{a} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\mathbf{b} = \\sigma(\\text{DO}_r(\\mathbf{a})^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\mathbf{f} = \\text{DO}_r(\\mathbf{b})^T\\mathbf{w}_0 + b_0\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\phi(\\mathbf{x})_{train} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b})\\] \\[ \\rightarrow \\quad \\phi(\\mathbf{x})_{eval} = \\sigma(\\mathbf{x}^T\\mathbf{W} + \\mathbf{b})\n\\]\nThis has a problem!\n\n\n\nConsider the expected value of a linear function with dropout:\n\\[\n\\mathbb{E}[ \\text{DO}_r(\\mathbf{x})^T\\mathbf{w}] = \\sum_i d_i x_i w_i, \\quad d_i \\sim \\text{Bernoulli}(1-r)\n\\]\n\n\n\nConsider the expected value of a linear function with dropout:\n\\[\n\\mathbb{E}[ \\text{DO}_r(\\mathbf{x})^T\\mathbf{w}] = \\sum_i d_i x_i w_i, \\quad d_i \\sim \\text{Bernoulli}(1-r)\n\\]\n\\[\n= \\sum_i p(d_i=1) x_i w_i = (1-r)\\sum_i  x_i w_i &lt;  \\sum_i  x_i w_i\n\\]\nIf \\(r=0.5\\) then on average the output of our function with dropout will only be half as large as the function without dropout!\n\n\n\nCorrect solution\n\n\n\nSimple (but not quite correct) solution\n\\[\n\\text{Dropout}_{eval}(\\mathbf{X}, r) = (1-r) \\mathbf{X}\n\\]\nThis gives use the smooth prediction function we’re looking for:\n\n\n\n\n\n# 2 Hidden-layer network with dropout\nmodel = nn.Sequential(nn.Dropout(0.5), nn.Linear(2, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 1)\n                     )"
  },
  {
    "objectID": "lecture8-regularization/slides.html#expectation",
    "href": "lecture8-regularization/slides.html#expectation",
    "title": "Initialization",
    "section": "",
    "text": "\\[\\mathbb{E}\\big[X \\big] = \\int_{x} x p(x) dx\\quad \\text{(Continuous random variables)}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#expectation-1",
    "href": "lecture8-regularization/slides.html#expectation-1",
    "title": "Initialization",
    "section": "",
    "text": "\\[\\mathbb{E}\\big[X \\big] = \\sum_{x} x p(x) \\quad \\text{(Discrete random variables)}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#linearity-of-expectation",
    "href": "lecture8-regularization/slides.html#linearity-of-expectation",
    "title": "Initialization",
    "section": "",
    "text": "\\[\\mathbb{E}\\big[ aX \\big] =  a\\mathbb{E}\\big[ X \\big] \\]\n\\[\\mathbb{E}\\bigg[ \\sum_{i=1}^n X_i \\bigg] =  \\sum_{i=1}^n \\mathbb{E}\\bigg[ X_i \\bigg]\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#variance",
    "href": "lecture8-regularization/slides.html#variance",
    "title": "Initialization",
    "section": "",
    "text": "\\[\nVar\\big[X\\big] = \\mathbb{E}\\big[(X - \\mathbb{E}[X])^2\\big]\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#properties-of-variance",
    "href": "lecture8-regularization/slides.html#properties-of-variance",
    "title": "Initialization",
    "section": "",
    "text": "\\[\nVar[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n\\]\n\\[\nVar[aX] = a^2 Var[X]\n\\]\nIf \\(X\\) and \\(Y\\) are independent: \\[\nVar[X + Y] = Var[X] + Var[Y]\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-1",
    "href": "lecture8-regularization/slides.html#dropout-1",
    "title": "Initialization",
    "section": "",
    "text": "Dropout rate: \\(r\\)\n\\[\\text{DO}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix} \\] \\[d_{ij} \\sim \\text{Bernoulli}(1-r)\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-2",
    "href": "lecture8-regularization/slides.html#dropout-2",
    "title": "Initialization",
    "section": "",
    "text": "Within a NN layer:\n\\[\n\\phi(\\mathbf{x}) = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b})\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-3",
    "href": "lecture8-regularization/slides.html#dropout-3",
    "title": "Initialization",
    "section": "",
    "text": "A network with several dropout layers:\n\\[f(\\mathbf{x}, \\mathbf{w}_0,...) = \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma(\\text{DO}_r( \\mathbf{x})^T  \\mathbf{W}_2 + \\mathbf{b}_2))^T \\mathbf{W}_1 + \\mathbf{b}_1))^T \\mathbf{w}_0 + \\mathbf{b}_0\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-4",
    "href": "lecture8-regularization/slides.html#dropout-4",
    "title": "Initialization",
    "section": "",
    "text": "A network with several dropout layers:\n\\[\n\\mathbf{a} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\mathbf{b} = \\sigma(\\text{DO}_r(\\mathbf{a})^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\mathbf{f} = \\text{DO}_r(\\mathbf{b})^T\\mathbf{w}_0 + b_0\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-at-evaluation-time",
    "href": "lecture8-regularization/slides.html#dropout-at-evaluation-time",
    "title": "Initialization",
    "section": "",
    "text": "\\[\n\\phi(\\mathbf{x})_{train} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b})\\] \\[ \\rightarrow \\quad \\phi(\\mathbf{x})_{eval} = \\sigma(\\mathbf{x}^T\\mathbf{W} + \\mathbf{b})\n\\]\nThis has a problem!"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-at-evaluation-time-1",
    "href": "lecture8-regularization/slides.html#dropout-at-evaluation-time-1",
    "title": "Initialization",
    "section": "",
    "text": "Consider the expected value of a linear function with dropout:\n\\[\n\\mathbb{E}[ \\text{DO}_r(\\mathbf{x})^T\\mathbf{w}] = \\sum_i d_i x_i w_i, \\quad d_i \\sim \\text{Bernoulli}(1-r)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-at-evaluation-time-2",
    "href": "lecture8-regularization/slides.html#dropout-at-evaluation-time-2",
    "title": "Initialization",
    "section": "",
    "text": "Consider the expected value of a linear function with dropout:\n\\[\n\\mathbb{E}[ \\text{DO}_r(\\mathbf{x})^T\\mathbf{w}] = \\sum_i d_i x_i w_i, \\quad d_i \\sim \\text{Bernoulli}(1-r)\n\\]\n\\[\n= \\sum_i p(d_i=1) x_i w_i = (1-r)\\sum_i  x_i w_i &lt;  \\sum_i  x_i w_i\n\\]\nIf \\(r=0.5\\) then on average the output of our function with dropout will only be half as large as the function without dropout!"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-at-evaluation-time-3",
    "href": "lecture8-regularization/slides.html#dropout-at-evaluation-time-3",
    "title": "Initialization",
    "section": "",
    "text": "Correct solution"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-at-evaluation-time-4",
    "href": "lecture8-regularization/slides.html#dropout-at-evaluation-time-4",
    "title": "Initialization",
    "section": "",
    "text": "Simple (but not quite correct) solution\n\\[\n\\text{Dropout}_{eval}(\\mathbf{X}, r) = (1-r) \\mathbf{X}\n\\]\nThis gives use the smooth prediction function we’re looking for:"
  },
  {
    "objectID": "lecture8-regularization/slides.html#dropout-in-pytorch",
    "href": "lecture8-regularization/slides.html#dropout-in-pytorch",
    "title": "Initialization",
    "section": "",
    "text": "# 2 Hidden-layer network with dropout\nmodel = nn.Sequential(nn.Dropout(0.5), nn.Linear(2, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 1)\n                     )"
  },
  {
    "objectID": "lecture8-regularization/slides.html#initialization",
    "href": "lecture8-regularization/slides.html#initialization",
    "title": "Initialization",
    "section": "Initialization",
    "text": "Initialization\nGradient descent: \\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nWhat do we choose for \\(\\mathbf{w}^{(0)}\\)?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity",
    "href": "lecture8-regularization/slides.html#convexity",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nConvex function \\(f\\)\n\\[\nf(t x_1 + (1-t)x_2) \\leq tf(x_1) + (1-t)f(x_2)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity-1",
    "href": "lecture8-regularization/slides.html#convexity-1",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nStrictly convex function \\(f\\)\n\\[\nf(t x_1 + (1-t)x_2)\\ {\\color{red}{&lt;}}\\ tf(x_1) + (1-t)f(x_2)\n\\]\n\n\n\nSingle optimum, gradient is non-zero away from the optimum."
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity-2",
    "href": "lecture8-regularization/slides.html#convexity-2",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nLinear and logistic regression losses are convex (usually strictly)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity-3",
    "href": "lecture8-regularization/slides.html#convexity-3",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nLinear and logistic regression losses are convex (usually strictly)\n\nGradient descent will always* get us to the right answer."
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity-4",
    "href": "lecture8-regularization/slides.html#convexity-4",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nNeural network losses are (usually) not convex!\n\nWhy?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#convexity-5",
    "href": "lecture8-regularization/slides.html#convexity-5",
    "title": "Initialization",
    "section": "Convexity",
    "text": "Convexity\nTwo equivalent solutions"
  },
  {
    "objectID": "lecture8-regularization/slides.html#symmetry-breaking",
    "href": "lecture8-regularization/slides.html#symmetry-breaking",
    "title": "Initialization",
    "section": "Symmetry-breaking",
    "text": "Symmetry-breaking\nA simple network\n\\[\nf(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}_1)^T\\mathbf{w}_0=\\sigma(x_1 w_{11}) w_{01} +\\sigma (x_1 w_{12})w_{02}\n\\]\n\\[\n\\frac{d}{dw_{01}} f(\\mathbf{x}) =\n\\]\n\\[\n\\frac{d}{dw_{02}} f(\\mathbf{x}) =\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#symmetry-breaking-1",
    "href": "lecture8-regularization/slides.html#symmetry-breaking-1",
    "title": "Initialization",
    "section": "Symmetry-breaking",
    "text": "Symmetry-breaking\nA simple network\n\\[\nf(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}_1)^T\\mathbf{w}_0=\\sigma(x_1 w_{11}) w_{01} +\\sigma (x_1 w_{12})w_{02}\n\\]\n\\[\n\\frac{d}{dw_{01}} f(\\mathbf{x}) = \\sigma(x_1 w_{11}) = \\sigma(x_1 a)\n\\]\n\\[\n\\frac{d}{dw_{02}} f(\\mathbf{x}) = \\sigma(x_1 w_{12}) = \\sigma(x_1 a)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#symmetry-breaking-2",
    "href": "lecture8-regularization/slides.html#symmetry-breaking-2",
    "title": "Initialization",
    "section": "Symmetry-breaking",
    "text": "Symmetry-breaking\n\n\n\nWhen the network is initialized with symmetry, the two neurons will always have the same output and our solution is poor.\n\n\n\n\nWhen initialized randomly, the two neurons can create different transforms and a much better solution is found."
  },
  {
    "objectID": "lecture8-regularization/slides.html#symmetry-breaking-3",
    "href": "lecture8-regularization/slides.html#symmetry-breaking-3",
    "title": "Initialization",
    "section": "Symmetry-breaking",
    "text": "Symmetry-breaking"
  },
  {
    "objectID": "lecture8-regularization/slides.html#visualizing-learning-rates",
    "href": "lecture8-regularization/slides.html#visualizing-learning-rates",
    "title": "Initialization",
    "section": "Visualizing learning rates",
    "text": "Visualizing learning rates\n\n\n\nA small learning rate means we will move slowly, so It may take a long time to find the minimum.\n\n\n\n\nA well-chosen learning rate lets us find a minimum quickly.\n\n\n\n\nA too-large learning rate means that steps may take us flying past the minimum!"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization",
    "href": "lecture8-regularization/slides.html#scaled-initialization",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nInitializing randomly:\n\\[w_{i} \\sim \\mathcal{N}(0, 1) \\quad \\forall\\ w_{i} \\in \\mathbf{w}\\]This has a subtle issue though. Why?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-1",
    "href": "lecture8-regularization/slides.html#scaled-initialization-1",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nTo see why let’s consider a linear function defined by randomly initialized weights:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\n\\]\nLet’s consider the mean and variance of this output with respect to \\(\\mathbf{w}\\):\n\\[\n\\mathbb{E} \\big[f(\\mathbf{x})\\big] =\n\\]\n\\[\n\\text{Var} \\big[f(\\mathbf{x})\\big] =\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-2",
    "href": "lecture8-regularization/slides.html#scaled-initialization-2",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nTo see why let’s consider a linear function defined by randomly initialized weights:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\n\\]\nLet’s consider the mean and variance of this output with respect to \\(\\mathbf{w}\\):\n\\[\n\\mathbb{E} \\big[f(\\mathbf{x})\\big] = \\mathbb{E} \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg]\n\\]\n\\[\n=   \\sum_{i=1}^d x_i \\mathbb{E} \\big[w_i \\big] = 0, \\quad w_i \\sim \\mathcal{N}(0, 1)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-3",
    "href": "lecture8-regularization/slides.html#scaled-initialization-3",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nTo see why let’s consider a linear function defined by randomly initialized weights:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\n\\]\nLet’s consider the mean and variance of this output with respect to \\(\\mathbf{w}\\):\n\\[\n\\text{Var} \\big[f(\\mathbf{x})\\big] = \\text{Var}  \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg]\n\\]\n\\[\n=\\sum_{i=1}^d \\text{Var} \\big[ x_i w_i \\big] = \\sum_{i=1}^d x_i^2 \\text{Var} [w_i] = \\sum_{i=1}^d x_i^2\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-4",
    "href": "lecture8-regularization/slides.html#scaled-initialization-4",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-5",
    "href": "lecture8-regularization/slides.html#scaled-initialization-5",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nScaling\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\\bigg(\\frac{1}{s}\\bigg)\n\\]\nIf we want the variance to be independent of \\(d\\), then we want:\n\\[\ns =\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-6",
    "href": "lecture8-regularization/slides.html#scaled-initialization-6",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nScaling\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\\bigg(\\frac{1}{s}\\bigg)\n\\]\nIf we want the variance to be independent of \\(d\\), then we want:\n\\[\ns = \\sqrt{d}\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-7",
    "href": "lecture8-regularization/slides.html#scaled-initialization-7",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nComputing the variance\n\\[\n\\text{Var}  \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg(\\frac{1}{\\sqrt{d}}\\bigg) \\bigg] =   \n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-8",
    "href": "lecture8-regularization/slides.html#scaled-initialization-8",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nComputing the variance\n\\[\n\\text{Var}  \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg(\\frac{1}{\\sqrt{d}}\\bigg) \\bigg] =   \n\\]\n\\[\n\\sum_{i=1}^d \\text{Var} \\bigg[ x_i w_i \\bigg(\\frac{1}{\\sqrt{d}}\\bigg) \\bigg]\n\\]\n\\[\n= \\sum_{i=1}^d x_i^2 \\bigg(\\frac{1}{\\sqrt{d}}\\bigg)^2 \\text{Var} [w_i] = \\frac{1}{d}\\sum_{i=1}^d x_i^2\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-9",
    "href": "lecture8-regularization/slides.html#scaled-initialization-9",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nFor neural network layers where the weights are a matrix \\(\\mathbf{W} \\in \\mathbb{R}^{d \\times e}\\), this works the same way:\n\\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\forall\\ w_{ij} \\in \\mathbf{W},\\ \\mathbf{w}\\in \\mathbb{R}^{d \\times e}\\]\nA popular alternative scales the distribution according to both the number of inputs and outputs of the layer:\n\\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\sqrt{\\frac{2}{d + e}}\\bigg) \\quad \\forall\\ w_{ij} \\in \\mathbf{W},\\ \\mathbf{w}\\in \\mathbb{R}^{d \\times e}\\]\nThis is known as Xavier initialization (or Glorot initialization after the inventor Xavier Glorot)."
  },
  {
    "objectID": "lecture8-regularization/slides.html#scaled-initialization-10",
    "href": "lecture8-regularization/slides.html#scaled-initialization-10",
    "title": "Initialization",
    "section": "Scaled initialization",
    "text": "Scaled initialization"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computational-complexity",
    "href": "lecture8-regularization/slides.html#computational-complexity",
    "title": "Initialization",
    "section": "Computational complexity",
    "text": "Computational complexity\n\n\n\nDataset size: \\(N\\)\nDimensionality : \\(d\\)\nNumber of layers: \\(L\\)\nNumber of steps: \\(S\\)\n\n\nWe can consider one of the networks shown above as a specific example:"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computational-complexity-1",
    "href": "lecture8-regularization/slides.html#computational-complexity-1",
    "title": "Initialization",
    "section": "Computational complexity",
    "text": "Computational complexity\nLoss function\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nGradient with respect to the parameters, \\(\\mathbf{w}\\).\n\\[\\nabla_{\\mathbf{w}}\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\nabla_{\\mathbf{w}}\\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nOur analysis would be equivalent for classification problems."
  },
  {
    "objectID": "lecture8-regularization/slides.html#computing-a-single-neuron",
    "href": "lecture8-regularization/slides.html#computing-a-single-neuron",
    "title": "Initialization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\n\n\n\\[\\phi(\\mathbf{x})=\\sigma\\big(\\mathbf{x}^T\\mathbf{w} \\big) = \\sigma\\bigg(\\sum_{i=1}^d x_i w_i \\bigg)\\]\nActivation function \\(\\sigma(\\cdot)\\): Constant, \\(\\mathcal{O}(1)\\)\nSummation: \\(\\sum_{i=1}^d x_i w_i\\) : Linear, \\(\\mathcal{O}(d)\\)."
  },
  {
    "objectID": "lecture8-regularization/slides.html#computing-a-single-neuron-1",
    "href": "lecture8-regularization/slides.html#computing-a-single-neuron-1",
    "title": "Initialization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\n\n\n\\(\\phi(\\mathbf{x})=\\sigma\\big(\\mathbf{x}^T\\mathbf{w} \\big) = \\sigma\\bigg(\\sum_{i=1}^d x_i w_i \\bigg)\\)\nBackward pass?\n\nGiven: \\(\\frac{dLoss}{d\\phi}\\)\nUpdate: \\(\\frac{dLoss}{dx_i}\\) \\(\\frac{dLoss}{dw_i}\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computing-a-single-neuron-2",
    "href": "lecture8-regularization/slides.html#computing-a-single-neuron-2",
    "title": "Initialization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\n\n\nBackward pass?\n\nGiven: \\(\\frac{dLoss}{d\\phi}\\)\nUpdate: \\(\\frac{dLoss}{dx_i}\\) \\(\\frac{dLoss}{dw_i}\\)\n\n\n\n\n\nActivation function: \\[\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}=\\frac{dLoss}{d\\phi}\\frac{d\\phi}{d(\\mathbf{x}^T\\mathbf{w})}\\] All scalars! \\(\\mathcal{O}(1)\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computing-a-single-neuron-3",
    "href": "lecture8-regularization/slides.html#computing-a-single-neuron-3",
    "title": "Initialization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\n\n\nBackward pass?\n\nGiven: \\(\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\)\nUpdate: \\(\\frac{dLoss}{dx_i}\\) \\(\\frac{dLoss}{dw_i}\\)\n\n\n\n\n\n\\[\n\\mathbf{x}^T\\mathbf{w}=\\sum_{i=1}^d x_i w_i\\]\n\\(\\frac{dLoss}{dw_i}=\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computing-a-single-neuron-4",
    "href": "lecture8-regularization/slides.html#computing-a-single-neuron-4",
    "title": "Initialization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\n\n\nBackward pass?\n\nGiven: \\(\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\)\nUpdate: \\(\\frac{dLoss}{dx_i}\\) \\(\\frac{dLoss}{dw_i}\\)\n\n\n\n\n\n\\[\n\\frac{dLoss}{dx_i}=\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\frac{d(\\mathbf{x}^T\\mathbf{w})}{dx_i}= \\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})} w_i\\] \\[\n\\frac{dLoss}{dw_i}=\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\frac{d(\\mathbf{x}^T\\mathbf{w})}{dw_i}= \\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})} x_i\n\\]\n\\(\\mathcal{O}(1)\\) per entry. Total: \\(\\mathcal{O}(d)\\)."
  },
  {
    "objectID": "lecture8-regularization/slides.html#cost-per-layer",
    "href": "lecture8-regularization/slides.html#cost-per-layer",
    "title": "Initialization",
    "section": "Cost per layer",
    "text": "Cost per layer\n\n\n\\(\\mathcal{O}(d)\\) Neurons per layer\nTotal cost: \\(\\mathcal{O}(d^2)\\)\n\n\n\n\nFull network: \\(\\mathcal{O}(Ld^2)\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#computational-complexity-2",
    "href": "lecture8-regularization/slides.html#computational-complexity-2",
    "title": "Initialization",
    "section": "Computational complexity",
    "text": "Computational complexity\nWe’ve bounded the time it takes to compute one of our predictions: \\(f(\\mathbf{x}_i, \\mathbf{w})\\).\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\n\\(N\\) terms in summation, total cost of \\(\\mathcal{O}(NLd^2)\\) for a single gradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nTotal cost of gradient descent: \\(\\mathcal{O}(SNLd^2)\\)."
  },
  {
    "objectID": "lecture8-regularization/slides.html#alexnet-2012",
    "href": "lecture8-regularization/slides.html#alexnet-2012",
    "title": "Initialization",
    "section": "AlexNet (2012)",
    "text": "AlexNet (2012)\n\n\n\nDataset size: \\(N=\\)\nDimensionality : \\(d=\\)\nNumber of layers: \\(L=\\)\nNumber of steps: \\(S=\\)\n\n\nNetwork:"
  },
  {
    "objectID": "lecture8-regularization/slides.html#alexnet-2012-1",
    "href": "lecture8-regularization/slides.html#alexnet-2012-1",
    "title": "Initialization",
    "section": "AlexNet (2012)",
    "text": "AlexNet (2012)\n\n\n\nDataset size: \\(N=\\)\nDimensionality : \\(d=4000\\)\nNumber of layers: \\(L=10\\)\nNumber of steps: \\(S=\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-loss",
    "href": "lecture8-regularization/slides.html#estimating-loss",
    "title": "Initialization",
    "section": "Estimating loss",
    "text": "Estimating loss\nNeural network MSE loss:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-loss-1",
    "href": "lecture8-regularization/slides.html#estimating-loss-1",
    "title": "Initialization",
    "section": "Estimating loss",
    "text": "Estimating loss\nNeural network MSE loss:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nEstimate by sampling:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2, \\quad i \\sim \\text{Uniform}(1, N)\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-loss-2",
    "href": "lecture8-regularization/slides.html#estimating-loss-2",
    "title": "Initialization",
    "section": "Estimating loss",
    "text": "Estimating loss\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2, \\quad i \\sim \\text{Uniform}(1, N)\\]\nExpectation of sampled loss\n\\[\\mathbb{E}_i[(f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2] = ?\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-loss-3",
    "href": "lecture8-regularization/slides.html#estimating-loss-3",
    "title": "Initialization",
    "section": "Estimating loss",
    "text": "Estimating loss\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2, \\quad i \\sim \\text{Uniform}(1, N)\\]\nExpectation of sampled loss is the true loss!\n\\[\\mathbb{E}_i[(f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2] = \\sum_{i=1}^N p(i)(f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\n\\[\n=\\frac{1}{N} \\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-loss-4",
    "href": "lecture8-regularization/slides.html#estimating-loss-4",
    "title": "Initialization",
    "section": "Estimating loss",
    "text": "Estimating loss\nIn general any loss that can be written as a mean of individual losses can be estimated in this way:\n\\[\\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N} \\sum_{i=1}^N \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)\\]\n\\[\\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\mathbb{E}[\\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)], \\  i\\sim \\text{Uniform}(1,N)\\]\nCost for full loss: \\(\\mathcal{O}(N)\\)\nCost of estimated loss: \\(\\mathcal{O}(1)\\)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-gradients",
    "href": "lecture8-regularization/slides.html#estimating-gradients",
    "title": "Initialization",
    "section": "Estimating gradients",
    "text": "Estimating gradients\nGradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nGradient can be composed into a sum of gradients and estimated the same way!\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\nabla_{\\mathbf{w}} \\bigg( \\frac{1}{N} \\sum_{i=1}^N \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)\\bigg)\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-gradients-1",
    "href": "lecture8-regularization/slides.html#estimating-gradients-1",
    "title": "Initialization",
    "section": "Estimating gradients",
    "text": "Estimating gradients\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\nabla_{\\mathbf{w}} \\bigg( \\frac{1}{N} \\sum_{i=1}^N \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)\\bigg)\\]\n\\[=\\frac{1}{N} \\sum_{i=1}^N  \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i) = \\mathbb{E}[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)])\\]\nStochastic gradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{x}_i, y_i)\\]\n\\[\ni\\sim \\text{Uniform}(1, N)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#estimating-gradients-2",
    "href": "lecture8-regularization/slides.html#estimating-gradients-2",
    "title": "Initialization",
    "section": "Estimating gradients",
    "text": "Estimating gradients"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd",
    "href": "lecture8-regularization/slides.html#minibatch-sgd",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nCan estimate gradients with a minibatch of \\(B\\) observations:\n\\[\\text{Batch:}\\ \\{(\\mathbf{x}_{b_1}, y_{b_1}), (\\mathbf{x}_{b_2}, y_{b_2}), ...,  (\\mathbf{x}_{b_B}, y_{b_B})\\}\\]\n\\[\n\\{b_1, b_2, ...,b_B\\} \\sim \\text{Uniform}(1, N)\n\\]\nNew estimate:\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx \\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\]\n\\[\n\\{b_1, b_2, ...,b_B\\} \\sim \\text{Uniform}(1, N)\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd-1",
    "href": "lecture8-regularization/slides.html#minibatch-sgd-1",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nDoes this still give the correct expectation?\n\\[\\mathbb{E}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] = ?\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd-2",
    "href": "lecture8-regularization/slides.html#minibatch-sgd-2",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nDoes this still give the correct expectation?\n\\[\\mathbb{E}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] \\]\n\\[= \\bigg(\\frac{1}{B}\\bigg) \\sum_{i=1}^B\\mathbb{E}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\\] \\[ = \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd-3",
    "href": "lecture8-regularization/slides.html#minibatch-sgd-3",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nWhat about variance?\n\\[\n\\text{Var}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] = ?\n\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd-4",
    "href": "lecture8-regularization/slides.html#minibatch-sgd-4",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nThe variance decreases with the size of the batch!\n\\[\\text{Var}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] \\]\n\\[\n=  \\bigg(\\frac{1}{B^2}\\bigg) \\sum_{i=1}^B\\text{Var}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\n\\]\n\\[= \\bigg(\\frac{1}{B}\\bigg)\\text{Var}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#minibatch-sgd-5",
    "href": "lecture8-regularization/slides.html#minibatch-sgd-5",
    "title": "Initialization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD"
  },
  {
    "objectID": "lecture8-regularization/slides.html#local-optima",
    "href": "lecture8-regularization/slides.html#local-optima",
    "title": "Initialization",
    "section": "Local optima",
    "text": "Local optima\nCan we escape local optima?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#saddle-points",
    "href": "lecture8-regularization/slides.html#saddle-points",
    "title": "Initialization",
    "section": "Saddle points",
    "text": "Saddle points\nWhat about saddle points?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#momentum",
    "href": "lecture8-regularization/slides.html#momentum",
    "title": "Initialization",
    "section": "Momentum",
    "text": "Momentum\nGradient descent with momentum updates the average gradient then uses the running average to take descent steps.\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta \\mathbf{v}^{(k)} + (1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nUpdate weights using velocity\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha v^{(k+1)}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#sgd-momentum",
    "href": "lecture8-regularization/slides.html#sgd-momentum",
    "title": "Initialization",
    "section": "SGD + Momentum",
    "text": "SGD + Momentum\nWe can apply momentum for stochastic gradient descent as well\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta \\mathbf{v}^{(k)} + (1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{x}_i, y_i), \\quad i\\sim \\text{Uniform}(1,N)\\]\nUpdate weights using velocity\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha v^{(k+1)}\\]\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}) \\approx \\sum_{j=1}^k \\beta^{k-j}(1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(j)}, \\mathbf{x}_{i^{(j)}}, y_{i^{(j)}})\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#sgd-momentum-1",
    "href": "lecture8-regularization/slides.html#sgd-momentum-1",
    "title": "Initialization",
    "section": "SGD + Momentum",
    "text": "SGD + Momentum\nMomentum also smooths our SGD path!"
  },
  {
    "objectID": "lecture8-regularization/slides.html#sgd-momentum-2",
    "href": "lecture8-regularization/slides.html#sgd-momentum-2",
    "title": "Initialization",
    "section": "SGD + Momentum",
    "text": "SGD + Momentum"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}) = \\begin{bmatrix} \\frac{dL}{dw^{(k)}_1} \\\\ \\frac{dL}{dw^{(k)}_2} \\\\ \\vdots \\end{bmatrix}\\]\n\\[\\begin{bmatrix} 3.1\\\\ 2.2 \\\\ \\vdots \\end{bmatrix} \\leftarrow\n\\begin{bmatrix} 5.0 \\\\ 1.8 \\\\ \\vdots \\end{bmatrix}\\leftarrow\n\\begin{bmatrix} 1.5 \\\\ 4.4 \\\\ \\vdots \\end{bmatrix}...\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-1",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-1",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-2",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-2",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-3",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-3",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}) = \\begin{bmatrix} \\frac{dL}{dw^{(k)}_1} \\\\ \\frac{dL}{dw^{(k)}_2} \\\\ \\vdots \\end{bmatrix}\\]\n\\[\\begin{bmatrix} 10.1\\\\ 0.04 \\\\ \\vdots \\end{bmatrix} \\leftarrow\n\\begin{bmatrix} 8.6 \\\\ 0.02 \\\\ \\vdots \\end{bmatrix}\\leftarrow\n\\begin{bmatrix} 9.4 \\\\ 0.009 \\\\ \\vdots \\end{bmatrix}...\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-4",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-4",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-5",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-5",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-6",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-6",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-7",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-7",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#second-order-optimization",
    "href": "lecture8-regularization/slides.html#second-order-optimization",
    "title": "Initialization",
    "section": "Second-order optimization",
    "text": "Second-order optimization\nSecond derivative tells us how quickly the derivative changes (curvature)\nIdea (Newton’s method): Divide our step by the second derivative\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\nabla^2_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#second-order-optimization-1",
    "href": "lecture8-regularization/slides.html#second-order-optimization-1",
    "title": "Initialization",
    "section": "Second-order optimization",
    "text": "Second-order optimization\nTake a big step when the gradient changes slowly and a small step when it changes quickly"
  },
  {
    "objectID": "lecture8-regularization/slides.html#second-order-optimization-2",
    "href": "lecture8-regularization/slides.html#second-order-optimization-2",
    "title": "Initialization",
    "section": "Second-order optimization",
    "text": "Second-order optimization\nTake a big step when the gradient changes slowly and a small step when it changes quickly"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-8",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-8",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\nUpdate scales\n\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta \\mathbf{s}^{(k)} + (1-\\beta) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\nUpdate weights\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-9",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-9",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\n\n\nSecond derivative tells us how quickly the derivative changes (curvature)\nIdea (Newton’s method): Divide our step by the second derivative\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\nabla^2_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}\\]\n\n\n\n\nUpdate scales\n\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta \\mathbf{s}^{(k)} + (1-\\beta) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\nRunning average magnitude tells us how steep the function has been recently\nIdea (RMSProp): Divide our step by average magnitude of the gradient\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-10",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-10",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-11",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-11",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-12",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-12",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\nUpdate scales\n\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta \\mathbf{s}^{(k)} + (1-\\beta) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\nUpdate weights\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\] What is epsilon for?\n\\[\\epsilon &lt;&lt; 1, \\quad \\text{e.g. } \\epsilon = 1e^{-7}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-13",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-13",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\nWhat if we just scaled the gradient directly (not using the history?)\n\\[\\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)}}} =\n\\begin{bmatrix} \\frac{\\frac{dL}{dw_1}}{\\sqrt{\\big(\\frac{dL}{dw_1}}\\big)^2} \\\\ \\frac{\\frac{dL}{dw_2}}{\\sqrt{\\big(\\frac{dL}{dw_2}}\\big)^2} \\\\ \\vdots \\end{bmatrix}  =\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-14",
    "href": "lecture8-regularization/slides.html#adaptive-gradients-rmsprop-14",
    "title": "Initialization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\nWhat if we just scaled the gradient directly (not using the history?)\n\\[\\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)}}} =\n\\begin{bmatrix} \\frac{\\frac{dL}{dw_1}}{\\sqrt{\\big(\\frac{dL}{dw_1}}\\big)^2} \\\\ \\frac{\\frac{dL}{dw_2}}{\\sqrt{\\big(\\frac{dL}{dw_2}}\\big)^2} \\\\ \\vdots \\end{bmatrix}  =\n\\begin{bmatrix} \\text{sign}\\big(\\frac{dL}{dw_1} \\big) \\\\ \\text{sign}\\big(\\frac{dL}{dw_2} \\big) \\\\ \\vdots \\end{bmatrix} = \\begin{bmatrix} +1 \\\\ -1 \\\\ \\vdots \\end{bmatrix} \\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adam",
    "href": "lecture8-regularization/slides.html#adam",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nCan we combine adaptive scaling and momentum?"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adam-1",
    "href": "lecture8-regularization/slides.html#adam-1",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta_1 \\mathbf{v}^{(k)} + (1-\\beta_1) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\] Update scaling\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta_2 \\mathbf{s}^{(k)} + (1-\\beta_2) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\] Update weights\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\mathbf{v}^{(k+1)}\n}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adam-2",
    "href": "lecture8-regularization/slides.html#adam-2",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta_1 \\mathbf{v}^{(k)} + (1-\\beta_1) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\] Update scaling\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta_2 \\mathbf{s}^{(k)} + (1-\\beta_2) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\nModified weight update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)}\n}{\\sqrt{\\frac{\\mathbf{s}^{(k+1)}}{(1-\\beta_2^k)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#adam-3",
    "href": "lecture8-regularization/slides.html#adam-3",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nAt step 0:\n\\[\\mathbf{v}^{(0)} = \\mathbf{0}, \\quad \\mathbf{s}^{(0)} = \\mathbf{0}\\] \\[\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)} = \\frac{\\beta_1 \\mathbf{0} + (1-\\beta_1)\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{(1-\\beta_1^1)} = \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]"
  },
  {
    "objectID": "lecture8-regularization/slides.html#choosing-learning-rates",
    "href": "lecture8-regularization/slides.html#choosing-learning-rates",
    "title": "Initialization",
    "section": "Choosing learning rates",
    "text": "Choosing learning rates"
  },
  {
    "objectID": "lecture8-regularization/slides.html#learning-rate-schedules",
    "href": "lecture8-regularization/slides.html#learning-rate-schedules",
    "title": "Initialization",
    "section": "Learning rate schedules",
    "text": "Learning rate schedules"
  },
  {
    "objectID": "lecture8-regularization/slides.html#summary-of-gradient-descent-issues",
    "href": "lecture8-regularization/slides.html#summary-of-gradient-descent-issues",
    "title": "Initialization",
    "section": "Summary of gradient descent issues",
    "text": "Summary of gradient descent issues\nUpdates are too slow\n\nStochastic/minibatch gradient descent\n\nSGD gradients are very noisy (high variance)\n\nIncrease batch size, use momentum\n\nStuck at saddle points or shallow optima\n\nUse momentum\n\nInconsistant scaling of the gradient\n\nUse RMSProp scaling\n\nValidation loss plateaus\n\nUse a learning rate schedule"
  },
  {
    "objectID": "lecture2-linear-regression/equations.html",
    "href": "lecture2-linear-regression/equations.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "\\[\n\\text{Dataset: } \\mathcal{D}=\\{(\\mathbf{x}_i,\\ y_i) \\text{  for  } i\\in 1...N\\}\n\\]\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = MPG\n\\] \\[f(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{w} + b = \\sum_{i=1}^d x_i w_i + b\\]\n\\[\n\\text{Predicted MPG} =\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]\n\\[\nf(\\mathbf{x})= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\end{bmatrix} + b\n\\] \\[\nf(\\mathbf{x})= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix}\n\\]\n\\[\nMSE = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i) - y_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\n\\[\n\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1n} \\\\ x_{21} & x_{22} & \\dots & x_{2n}\\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nn} \\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\n\\[\nMSE = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i) - y_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^T(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n\\]\n\\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\]\n\\[\n\\text{While } ||\\nabla f(\\mathbf{w}^{(i)})||_2 &gt; \\epsilon \\text{ :} \\\\\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]\n\\[\np(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\]\n\\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\]\n\\[\ne_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w} - y_i,\\ \\sigma^2\\big)\n\\]\n\\[\np(y_i\\mid\\mathbf{x}_i, \\mathbf{w}) =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\n\\]\n\\[\np(e_i\\mid\\mathbf{x}_i, \\mathbf{w}) =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\n\\]\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\n\\[\n\\textbf{Loss}(\\mathbf{w}) =\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\n\\[\n\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N\\log\\bigg[\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\\bigg]\n\\]\n\\[\n= \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 + N \\log \\sigma \\sqrt{2 \\pi}\n\\]\n\\[\n\\nabla_{\\mathbf{w}}\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 + N \\log \\sigma \\sqrt{2 \\pi} \\bigg)\n\\]\n\\[\n= \\frac{1}{2\\sigma^2}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\n\\[\n\\underset{\\mathbf{w}}{\\text{argmin}}\\  MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1\\}\n\\]\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = \\begin{cases} 1: \\text{Meets target } (MPG \\geq 30) \\\\ 0:\n\\text{Fails to meet target } (MPG &lt; 30) \\\\  \\end{cases}\n\\]\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{1   (Meets target)}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow  \\text{0   (Does not meet target)}\n\\]\n\\[\nf(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} \\quad \\longrightarrow \\quad f(\\mathbf{x})=\\begin{cases} 1\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} \\geq 0 \\\\\n0\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} &lt; 0\\end{cases}\n\\]\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\n\\]\n\\[\n\\text{Meets target} = f(\\mathbf{x})=\n\\]\n\\[\n\\big((\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\\big) \\geq 0\n\\]\n\\[\nf(\\mathbf{x})= \\left( \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix} \\geq  0\\right)\n\\]\n\\[\n\\mathbf{x}^T\\mathbf{w} = ||\\mathbf{x}||_2 ||\\mathbf{w}||_2 \\cos \\theta\n\\]\n\\[\n\\mathbf{x}^T \\mathbf{w} = 0\n\\]\n\\[\n\\textbf{Accuracy: }\\quad \\frac{\\text{\\# of correct predictions}}{\\text{Total predictions}}\n\\]\n\\[\n\\textbf{Accuracy} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}\\big(f(\\mathbf{x}_i) = y_i\\big)\n\\]\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\ \\mathbf{Loss}(\\mathbf{w})\n\\]\n\\[\n\\mathbf{w}^{(k+1)} \\quad \\longleftarrow \\quad \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{Loss}(\\mathbf{w})\n\\]\n\\[\n\\text{Probability of }\\textbf{heads: } \\ \\ q, \\quad \\text{Probability of }\\textbf{tails: } 1-q\n\\]\n\\[\np(y)=\\begin{cases} q\\quad\\ \\ \\ \\ \\ \\ \\  \\text{if }\\ y=1\\\\\n1-q\\quad \\text{if }\\ y=0\\\\\n\\end{cases}\\quad q\\in[0,1],\\ y\\in\\{0, 1\\}\n\\]\n\\[\np(y) = q^y(1-q)^{1-y}\n\\]\n\\[\n\\log p(y) = y\\log q + (1-y)\\log(1-q)\n\\]\n\\[\n\\mathbf{x}^T\\mathbf{w}\\notin [0, 1] \\quad \\longrightarrow \\quad y_i \\sim \\mathbf{Bernoulli}(\\mathbf{ q=? })\\quad\n\\]\n\\[\n\\textbf{Need }\\ g(x):\\ \\mathbb{R} \\longrightarrow [0,1]\n\\]\n\\[\n\\textbf{Input: } x \\in \\mathbb{R} \\longrightarrow \\textbf{Output: } y \\in [0,1]\n\\]\n\\[\n\\sigma(x) = \\frac{1}{1+e^{-x}}\n\\]\n\\[\n\\frac{d}{dx}\\sigma(x) = \\sigma(x)\\big(1-\\sigma(x)\\big)\n\\]\n\\[\n\\sigma(0) = 0.5\n\\]\n\\[\n1-\\sigma(x) = \\sigma(-x)\n\\]\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\mathbf{x}_i^T\\mathbf{w} })\\big)\n\\]\n\\[\np(y_i = 1\\mid \\mathbf{x}_i, \\mathbf{w}) = \\sigma(\\mathbf{x}_i^T\\mathbf{w}), \\quad p(y_i=0\\mid \\mathbf{x}_i, \\mathbf{w})=1-\\sigma(\\mathbf{x}_i^T\\mathbf{w})=\\sigma(-\\mathbf{x}_i^T\\mathbf{w})\n\\]\n\\[\n\\textbf{Prediction function: } f(\\mathbf{x}) = \\begin{cases}1 \\ \\text{if } p(y=1\\mid\\mathbf{x}, \\mathbf{w}) \\geq p(y=0\\mid\\mathbf{x}, \\mathbf{w}) \\\\\n0 \\text{ otherwise} \\end{cases}\n\\]\n\\[p(y=1\\mid \\mathbf{x}, \\mathbf{w}) =\\sigma(\\mathbf{x}^T\\mathbf{w})\\geq 0.5\\]\n\\[\np(y_i=1)\\geq 0.5 \\quad \\longrightarrow \\quad \\mathbf{x}^T\\mathbf{w}\\geq 0\n\\]\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\bigg[ y_i\\log \\sigma(\\mathbf{x}_i^T\\mathbf{w}) + (1-y_i)\\log(1-\\sigma(\\mathbf{x}_i^T\\mathbf{w})) \\bigg]\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html",
    "href": "lecture2-linear-regression/slides.html",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Homework 1 due next Tuesday 9/5 at 11:59pm\nFill out Github username survey!\nOffice hours tomorrow 4-5:30pm in MacGregor 322\nCourse calendar added to website with lecture notes.\nLecture notes are open source!"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#logistics-1",
    "href": "lecture2-linear-regression/slides.html#logistics-1",
    "title": "Lecture 2: Linear regression",
    "section": "",
    "text": "Homework 1 due next Tuesday 9/5 at 11:59pm\nFill out Github username survey!\nOffice hours tomorrow 4-5:30pm in MacGregor 322\nCourse calendar added to website with lecture notes.\nLecture notes are open source!"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#functions-revisited",
    "href": "lecture2-linear-regression/slides.html#functions-revisited",
    "title": "Lecture 2: Linear regression",
    "section": "Functions revisited",
    "text": "Functions revisited\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-functions",
    "href": "lecture2-linear-regression/slides.html#linear-functions",
    "title": "Lecture 2: Linear regression",
    "section": "Linear Functions",
    "text": "Linear Functions\nA linear function is any function \\(f\\) where the following conditions always hold: \\[ f(\\mathbf{x} + \\mathbf{y}) =f(\\mathbf{x}) + f(\\mathbf{y})\\] and \\[ f(a\\mathbf{x}) = a f(\\mathbf{x})\\] For a linear function, the output can be defined as a weighted sum of the inputs.\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_iw_i + b\n\\]\nHere, \\(w_i\\) and \\(b\\) are the parameters of the function."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-functions-1",
    "href": "lecture2-linear-regression/slides.html#linear-functions-1",
    "title": "Lecture 2: Linear regression",
    "section": "Linear Functions",
    "text": "Linear Functions\nWe can also write a linear function using a dot-product between our input \\(\\mathbf{x}\\) and parameter vector \\(\\mathbf{w}\\) as:\n\\[\nf(\\mathbf{x}) = \\mathbf{x} \\cdot \\mathbf{w} + b \\quad \\text{or} \\quad f(\\mathbf{x}) = \\mathbf{x}^T  \\mathbf{w} + b\n\\]\nWe typically refer to \\(\\mathbf{w}\\) specifically as the weight vector (or weights) and \\(b\\) as the bias.\n\\[\n\\textbf{Linear function:  }f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}+b,\\quad \\textbf{Parameters:}\\quad \\big(\\text{Weights:  } \\mathbf{w},\\ \\text{Bias:  } b \\big)\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-functions-2",
    "href": "lecture2-linear-regression/slides.html#linear-functions-2",
    "title": "Lecture 2: Linear regression",
    "section": "Linear Functions",
    "text": "Linear Functions\nIn one dimension, a linear function is always a line, for example:"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-functions-3",
    "href": "lecture2-linear-regression/slides.html#linear-functions-3",
    "title": "Lecture 2: Linear regression",
    "section": "Linear Functions",
    "text": "Linear Functions\nIn higher dimensions, it is a plane or hyperplane:"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-functions-4",
    "href": "lecture2-linear-regression/slides.html#linear-functions-4",
    "title": "Lecture 2: Linear regression",
    "section": "Linear Functions",
    "text": "Linear Functions\nIn numpy we can easily write a linear function of this form:\n\ndef f(x):\n    w = np.array([-0.6, -0.2])\n    b = -1\n    return np.dot(x, w) + b"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#handling-bias-compactly",
    "href": "lecture2-linear-regression/slides.html#handling-bias-compactly",
    "title": "Lecture 2: Linear regression",
    "section": "Handling bias compactly",
    "text": "Handling bias compactly\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\longrightarrow \\mathbf{x}_{aug}= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\\\ 1 \\end{bmatrix} \\quad \\text{and} \\quad \\mathbf{w} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix} \\longrightarrow \\mathbf{w}_{aug}=  \\begin{bmatrix} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\\\ b \\end{bmatrix}\n\\]\nWe can easily see then that using this notation:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{w} +b = \\mathbf{x}_{aug}^T \\mathbf{w}_{aug}\n\\]\nWe won’t bother with the \\(aug\\) notation and just assume that any linear function defined as \\(f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w}\\) can be defined to include a bias implicitly.\nIn numpy this is similarly straightforward:\n\ndef f(x):\n    w = np.array([-0.6, -0.2, -1])\n    x = np.pad(x, ((0,1),), constant_values=1)\n    return np.dot(x, w)"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#datasets-and-observations",
    "href": "lecture2-linear-regression/slides.html#datasets-and-observations",
    "title": "Lecture 2: Linear regression",
    "section": "Datasets and observations",
    "text": "Datasets and observations\nDataset \\(\\mathbf{D}\\) made up of \\(N\\) pairs of inputs ( \\(\\mathbf{x}\\) ) and outputs ( \\(y\\) ):\n\\[\n\\mathbf{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ...\\ (\\mathbf{x}_N, y_N)\\}\n\\]\nWe call each of these pairs an observation."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#fuel-efficiency",
    "href": "lecture2-linear-regression/slides.html#fuel-efficiency",
    "title": "Lecture 2: Linear regression",
    "section": "Fuel efficiency",
    "text": "Fuel efficiency\nLet’s imagine we’re designing a car and we would like to know what the fuel efficiency of the car we’re designing will be in miles per gallon (MPG). Ideally we would have access to a function that would give us the MPG rating if we provide some features.\n\\[\n\\text{mpg} = f(\\text{weight},\\ \\text{horsepower}...)\n\\]\nWe don’t know the exact relationship between a car’s features and fuel efficiency. However, we can look at other cars on the market and see what the corresponding inputs and outputs would be:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 33mpg}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: 21mpg}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#fuel-efficiency-1",
    "href": "lecture2-linear-regression/slides.html#fuel-efficiency-1",
    "title": "Lecture 2: Linear regression",
    "section": "Fuel efficiency",
    "text": "Fuel efficiency\nOur dataset will be this collection of data that we have for all other cars. In general, each observation in this dataset will correspond to a car.\n\\[\n\\text{Dataset: } \\mathbf{D}=\\{(\\mathbf{x}_i,\\ y_i) \\text{  for  } i\\in 1...N\\}\n\\]\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = MPG\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#fuel-efficiency-2",
    "href": "lecture2-linear-regression/slides.html#fuel-efficiency-2",
    "title": "Lecture 2: Linear regression",
    "section": "Fuel efficiency",
    "text": "Fuel efficiency\nLet’s take a look at a single feature: the weight of a car."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#prediction-functions",
    "href": "lecture2-linear-regression/slides.html#prediction-functions",
    "title": "Lecture 2: Linear regression",
    "section": "Prediction functions",
    "text": "Prediction functions\n\nHow do we predict the output for an input that we haven’t seen before?"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#prediction-functions-1",
    "href": "lecture2-linear-regression/slides.html#prediction-functions-1",
    "title": "Lecture 2: Linear regression",
    "section": "Prediction functions",
    "text": "Prediction functions\nModel our unknown function with a known function that we can evaluate at any input. Chose a function \\(f\\) such that for any observation our dataset, the output of this function approximates the true target output that we observed.\n\\[\nf(\\mathbf{x}_i) \\approx y_i, \\quad \\forall (\\mathbf{x}_i, y_i) \\in \\mathbf{D}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-interpolation",
    "href": "lecture2-linear-regression/slides.html#linear-interpolation",
    "title": "Lecture 2: Linear regression",
    "section": "Linear interpolation",
    "text": "Linear interpolation\nIn some cases this can be a reasonable approach! In fact it’s how the plt.plot function works."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-interpolation-1",
    "href": "lecture2-linear-regression/slides.html#linear-interpolation-1",
    "title": "Lecture 2: Linear regression",
    "section": "Linear interpolation",
    "text": "Linear interpolation\nReal data however is messy. Measurements in our dataset might not be 100% accurate or might even conflict!\n\\[(\\text{Weight: }3100, \\text{MPG: } 34), \\quad (\\text{Weight: }3100, \\text{MPG: } 23) \\longrightarrow f(3100) = ?\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-interpolation-2",
    "href": "lecture2-linear-regression/slides.html#linear-interpolation-2",
    "title": "Lecture 2: Linear regression",
    "section": "Linear interpolation",
    "text": "Linear interpolation"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-regression-1",
    "href": "lecture2-linear-regression/slides.html#linear-regression-1",
    "title": "Lecture 2: Linear regression",
    "section": "Linear regression",
    "text": "Linear regression\nLinear regression models an unknown function with a linear function.\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w} = \\sum_{i=1}^n x_i w_i\n\\]\nMeaning that the output will be a weighted sum of the features of the input.\n\\[\n\\text{Predicted MPG} = f(\\mathbf{x})=\n\\]\n\\[\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-regression-2",
    "href": "lecture2-linear-regression/slides.html#linear-regression-2",
    "title": "Lecture 2: Linear regression",
    "section": "Linear regression",
    "text": "Linear regression\n\nclass Regression:\n    def __init__(self, weights):\n        self.weights = weights\n    \n    def predict(self, x):\n        return np.dot(x, self.weights)\n\nmodel = Regression(np.array([1, 1, 1, 1, 1]))\nmodel.predict(np.array([5, 2, 3, 3, 1]))"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-regression-3",
    "href": "lecture2-linear-regression/slides.html#linear-regression-3",
    "title": "Lecture 2: Linear regression",
    "section": "Linear regression",
    "text": "Linear regression\nWe could chose many different linear functions to make predictions:"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#residuals-and-error",
    "href": "lecture2-linear-regression/slides.html#residuals-and-error",
    "title": "Lecture 2: Linear regression",
    "section": "Residuals and error",
    "text": "Residuals and error\nThe residual or error of a prediction is the difference between the prediction and the true output:\n\\[\ne_i = y_i - f(\\mathbf{x}_i)\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#mean-squared-error",
    "href": "lecture2-linear-regression/slides.html#mean-squared-error",
    "title": "Lecture 2: Linear regression",
    "section": "Mean squared error",
    "text": "Mean squared error\nWe need a measure of error for the entire dataset. The mean squared error is the average of the residual squared for each observation in our dataset:\n\\[\nMSE = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i) - y_i)^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]It follows that the best choice of linear function \\(f^*\\) is the one that minimizes the mean squared error for our dataset. \\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#loss-functions",
    "href": "lecture2-linear-regression/slides.html#loss-functions",
    "title": "Lecture 2: Linear regression",
    "section": "Loss functions",
    "text": "Loss functions\nMean squared error depends on the data inputs \\((\\mathbf{x}_1,…,\\mathbf{x}_N)\\), the data targets \\((y_1,…,y_N)\\) and the parameters \\((\\mathbf{w})\\). So we can express the MSE as a function of all three:\n\\[\nMSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nHere we have used \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) to refer to the entire collection of inputs and outputs from our dataset \\(( \\mathbf{D})\\) respectively, so:\n\\[\n\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1 \\\\ \\mathbf{x}_2 \\\\ \\vdots \\\\ \\mathbf{x}_N \\end{bmatrix} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1n} \\\\ x_{21} & x_{22} & \\dots & x_{2n}\\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nn} \\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#loss-functions-1",
    "href": "lecture2-linear-regression/slides.html#loss-functions-1",
    "title": "Lecture 2: Linear regression",
    "section": "Loss functions",
    "text": "Loss functions\nThis is an example of loss function. We can drop the explicit dependence on \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\), looking at the loss as purely a function of our choice of parameters:\n\\[\n\\textbf{Loss}(\\mathbf{w})= MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]\nAgain, if our goal is to minimize error, we want to choose the parameters \\(\\mathbf{w}^*\\) that minimize this loss:\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{Loss}(\\mathbf{w})= \\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#visualizing-loss",
    "href": "lecture2-linear-regression/slides.html#visualizing-loss",
    "title": "Lecture 2: Linear regression",
    "section": "Visualizing loss",
    "text": "Visualizing loss\nIf we consider the case where our inputs are 1-dimensional, as in the weight example above, then our parameter vector \\(\\mathbf{w}\\) only has 2 entries: \\(w_1\\) and \\(b\\).\nWe see that point where the loss is lowest, corresponds to the line that best fits our data!"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#gradient-descent",
    "href": "lecture2-linear-regression/slides.html#gradient-descent",
    "title": "Lecture 2: Linear regression",
    "section": "Gradient descent",
    "text": "Gradient descent\nWe have a function \\(f(\\mathbf{\\cdot})\\) and we would like find the input \\(\\mathbf{w}^*\\) that minimizes the output of the function:\n\\[\n\\text{Find: } \\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ f(\\mathbf{w})\n\\]\nWe don’t know how to find \\(\\mathbf{w}^*\\) directly, but if we have an initial guess \\(\\mathbf{w}^{(0)}\\), we can try to update our guess to improve it.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} + \\mathbf{g}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#gradient-descent-1",
    "href": "lecture2-linear-regression/slides.html#gradient-descent-1",
    "title": "Lecture 2: Linear regression",
    "section": "Gradient descent",
    "text": "Gradient descent\nThe gradient of a function at point \\(\\mathbf{x}\\) corresponds to the slope of \\(f\\) at \\(\\mathbf{w}\\), or equivalently the direction of maximum change. This gives us a natural choice for the update to our guess.\n\\[\n\\mathbf{w}^{(1)} \\leftarrow \\mathbf{w}^{(0)} - \\nabla f(\\mathbf{w}^{(0)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#gradient-descent-2",
    "href": "lecture2-linear-regression/slides.html#gradient-descent-2",
    "title": "Lecture 2: Linear regression",
    "section": "Gradient descent",
    "text": "Gradient descent\nWe can repeat this process many times, continuously updating our estimate.\n\\[\n\\text{For }i \\text{ in 1,...,T}\\text{ :}\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#gradient-descent-convergence",
    "href": "lecture2-linear-regression/slides.html#gradient-descent-convergence",
    "title": "Lecture 2: Linear regression",
    "section": "Gradient descent convergence",
    "text": "Gradient descent convergence\nAt it’s minimum value \\(\\mathbf{w}^*\\), a function \\(f\\) must have a gradient of \\(\\mathbf{0}\\).\n\\[\n\\nabla f(\\mathbf{w}^*) = \\mathbf{0}\n\\]\nIt follows that:\n\\[\n\\mathbf{w}^{*} = \\mathbf{w}^{*} - \\nabla f(\\mathbf{w}^{*})\n\\]\nWe could write our algorithm to account for this:\n\\[\n\\text{While } \\nabla f(\\mathbf{w}^{(i)}) \\neq \\mathbf{0} \\text{ :}\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#gradient-descent-convergence-1",
    "href": "lecture2-linear-regression/slides.html#gradient-descent-convergence-1",
    "title": "Lecture 2: Linear regression",
    "section": "Gradient descent convergence",
    "text": "Gradient descent convergence\nStops the iteration when the gradient magnitude is sufficiently small:\n\\[\n\\text{While } ||\\nabla f(\\mathbf{w}^{(i)})||_2 &gt; \\epsilon \\text{ :}\n\\quad \\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\nabla f(\\mathbf{w}^{(i)})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#step-sizes",
    "href": "lecture2-linear-regression/slides.html#step-sizes",
    "title": "Lecture 2: Linear regression",
    "section": "Step sizes",
    "text": "Step sizes\nThis approach says that when the magnitude of the gradient is large, we should take a large step, and vice-versa."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#step-sizes-1",
    "href": "lecture2-linear-regression/slides.html#step-sizes-1",
    "title": "Lecture 2: Linear regression",
    "section": "Step sizes",
    "text": "Step sizes\nHowever, if we take too large a step, we can overshoot the minimum entirely! In the worst case, this can lead to divergence, where gradient descent overshoots the minimum more and more at each step."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#step-sizes-2",
    "href": "lecture2-linear-regression/slides.html#step-sizes-2",
    "title": "Lecture 2: Linear regression",
    "section": "Step sizes",
    "text": "Step sizes\nThe gradient is making a linear approximation to the function. A strait line has no minimum, so the gradient has no information about where along the approximation the true minimum will be."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#step-sizes-3",
    "href": "lecture2-linear-regression/slides.html#step-sizes-3",
    "title": "Lecture 2: Linear regression",
    "section": "Step sizes",
    "text": "Step sizes\nThe gradient gives us the direction of maximum change of the function, but this is only true in the limit of a very small step.\n\\[\n\\frac{df}{d\\mathbf{w}}= \\underset{\\gamma \\rightarrow 0}{\\lim}\\ \\underset{\\|\\mathbf{\\epsilon}\\|_2 &lt; \\gamma}{\\max} \\frac{f(\\mathbf{w} + \\mathbf{\\epsilon}) - f(\\mathbf{w})}{\\|\\mathbf{\\epsilon}\\|_2}\n\\]\nIn higher dimensions, the gradient may not point directly to the minimum."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#step-sizes-4",
    "href": "lecture2-linear-regression/slides.html#step-sizes-4",
    "title": "Lecture 2: Linear regression",
    "section": "Step sizes",
    "text": "Step sizes\nWe can introduce an additional control to our algorithm: a step size or learning rate. This is a small constant \\(\\alpha\\), that we will multiply the gradient by in each of our updates.\n\\[\n\\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}^{(i)})\n\\]\nUsing a small learning rate \\((\\alpha &lt;&lt; 1)\\) will make gradient descent slower, but much more reliable."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#optimizing-linear-regression",
    "href": "lecture2-linear-regression/slides.html#optimizing-linear-regression",
    "title": "Lecture 2: Linear regression",
    "section": "Optimizing linear regression",
    "text": "Optimizing linear regression\nWe can apply gradient descent to linear regression in order to find the parameters that minimize the mean squared error loss.\n\\[\n\\nabla_{\\mathbf{w}} \\textbf{MSE}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)^2 \\bigg)\n\\]\n\\[\n= \\frac{2}{N}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWith this gradient our gradient descent update becomes:\n\\[\n\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha\\bigg(\\frac{2 }{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w}^{(i)} - y_i)\\mathbf{x}_i\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly",
    "href": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly",
    "title": "Lecture 2: Linear regression",
    "section": "Optimizing linear regression directly",
    "text": "Optimizing linear regression directly\nWe know that at the minimum, the gradient must be \\(\\mathbf{0}\\), so the following condition must hold:\n\\[\n\\mathbf{0} = \\bigg( \\frac{2}{N}\\bigg)\\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nWe can solve for a \\(\\mathbf{w}\\) that satisfied this condition by first dropping the constant \\(\\frac{2}{N}\\).\n\\[\n\\mathbf{0} = \\sum_{i=1}^N  (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\n\\[\n\\mathbf{0} = \\sum_{i=1}^N \\big( \\mathbf{x}_i\\mathbf{x}_i^T\\mathbf{w} - y_i \\mathbf{x}_i \\big)\n\\]\n\\[\n\\sum_{i=1}^N  y_i \\mathbf{x}_i  =\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)  \\mathbf{w}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-1",
    "href": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-1",
    "title": "Lecture 2: Linear regression",
    "section": "Optimizing linear regression directly",
    "text": "Optimizing linear regression directly\nNote that \\(\\mathbf{x}_i \\mathbf{x}_i^T\\) is a vector outer product:\n\\[\n\\mathbf{x}_i \\mathbf{x}_i^T = \\begin{bmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\  x_{in}\\end{bmatrix} \\begin{bmatrix} x_{i1} & x_{i2} & \\dots &  x_{in}\\end{bmatrix} =\n\\begin{bmatrix} x_{i1} x_{i1} & x_{i1} x_{i2} & \\dots & x_{i1} x_{in} \\\\\nx_{i2} x_{i1} & x_{i2} x_{i2} & \\dots & x_{i2} x_{in} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{in} x_{i1} & x_{in} x_{i2} & \\dots & x_{in} x_{in} \\\\\n\\end{bmatrix}\n\\]\nThus \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)\\) is a matrix."
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-2",
    "href": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-2",
    "title": "Lecture 2: Linear regression",
    "section": "Optimizing linear regression directly",
    "text": "Optimizing linear regression directly\n\\[\n\\sum_{i=1}^N  y_i \\mathbf{x}_i  =\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)  \\mathbf{w}\n\\]\nMultiplying both sides by the inverse \\(\\bigg(\\sum_{i=1}^N \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1}\\) we get:\n\\[\n\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1} \\bigg(\\sum_{i=1}^N  y_i \\mathbf{x}_i\\bigg)  =  \\mathbf{w}^*\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-3",
    "href": "lecture2-linear-regression/slides.html#optimizing-linear-regression-directly-3",
    "title": "Lecture 2: Linear regression",
    "section": "Optimizing linear regression directly",
    "text": "Optimizing linear regression directly\n\\[\n\\bigg(\\sum_{i=1}^N  \\mathbf{x}_i\\mathbf{x}_i^T \\bigg)^{-1} \\bigg(\\sum_{i=1}^N  y_i \\mathbf{x}_i\\bigg)  =  \\mathbf{w}^*\n\\]\nWe can write this more compactly using the stacked input matrix and label vector notation we saw in homework 1.\n\\[\n\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_{1} \\\\ \\mathbf{x}_{2} \\\\ \\vdots \\\\  \\mathbf{x}_{N} \\end{bmatrix},\\quad \\mathbf{y} = \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\  y_{N} \\end{bmatrix}\n\\]\nIn this case, the expression becomes:\n\\[\\mathbf{w}^* = \\big( \\mathbf{X}^T \\mathbf{X} \\big)^{-1} \\big(\\mathbf{y}\\mathbf{X}\\big)\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#normal-distributions",
    "href": "lecture2-linear-regression/slides.html#normal-distributions",
    "title": "Lecture 2: Linear regression",
    "section": "Normal distributions",
    "text": "Normal distributions\nThe Normal distribution (also known as the Gaussian distribution) is a continuous probability distribution with the following probability density function:\n\\[\np(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\mathbf{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#linear-regression-as-a-probabilistic-model",
    "href": "lecture2-linear-regression/slides.html#linear-regression-as-a-probabilistic-model",
    "title": "Lecture 2: Linear regression",
    "section": "Linear regression as a probabilistic model",
    "text": "Linear regression as a probabilistic model\nThe probabilistic model for linear regression will make the assumption that the output is normally distributed conditioned on the input:\n\\[\ny_i \\sim N\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\]\nWe can write the conditional probability or likelihood of an output as:\n\\[\np(y_i\\mid\\mathbf{x}_i, \\mathbf{w}) =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\mathbf{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\n\\]\n\n\n\nImage credit: Lily Chen Towards Data Science"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-1",
    "href": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-1",
    "title": "Lecture 2: Linear regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nHow do we find the optimal value for \\(\\mathbf{w}\\)? Choose the \\(\\mathbf{w}\\) that maximizes the likelihood (conditional probability) of all of the outputs in our dataset:\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\nGenerally our model also assumes conditional independence across observations so:\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-2",
    "href": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-2",
    "title": "Lecture 2: Linear regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nEquivalently frame the optimal value in terms of the negative log-likelihood rather than the likelihood.\n\\[\n\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}) = \\underset{\\mathbf{w}}{\\text{argmin}} - \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w}) = \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\nWe see that the negative log-likelihood is a natural loss function to optimize to find \\(\\mathbf{w}^*\\).\n\\[\n\\textbf{Loss}(\\mathbf{w}) =\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-3",
    "href": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-3",
    "title": "Lecture 2: Linear regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nWe can write out the negative log-likelihood explicitly using the normal PDF:\n\\[\n\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N\\log\\bigg[\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^T\\mathbf{w})^2\\bigg)\\bigg]\n\\]\n\\[\n= \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 - \\frac{N}{\\sigma \\sqrt{2 \\pi}}\n\\]"
  },
  {
    "objectID": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-4",
    "href": "lecture2-linear-regression/slides.html#maximum-likelihood-estimation-4",
    "title": "Lecture 2: Linear regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\n\\[\n\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 - \\frac{N}{\\sigma \\sqrt{2 \\pi}}\n\\]\nWe see that this loss is very similar to the MSE loss. Taking the gradient this becomes even more clear.\n\\[\n\\nabla_{\\mathbf{w}}\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =\n\\frac{d}{d\\mathbf{w}}\\bigg( \\frac{1}{2\\sigma^2} \\sum_{i=1}^N(y_i - \\mathbf{x}_i^T\\mathbf{w})^2 - \\frac{N}{\\sigma \\sqrt{2 \\pi}} \\bigg)\n\\]\n\\[\n= \\frac{1}{2\\sigma^2}\\sum_{i=1}^N (\\mathbf{x}_i^T\\mathbf{w} - y_i)\\mathbf{x}_i\n\\]\nThe optimal value for \\(\\mathbf{w}\\) is the same for both MSE and negative log-likelihood and the optimal value does not depend on \\(\\sigma^2\\)!\n\\[\n\\underset{\\mathbf{w}}{\\text{argmin}}\\  MSE(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html",
    "href": "lecture4-feature-transforms/slides.html",
    "title": "Lecture 4: Feature transforms",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\ndata = transpose(data_raw)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#training-and-test-datasets",
    "href": "lecture4-feature-transforms/slides.html#training-and-test-datasets",
    "title": "Lecture 4: Feature transforms",
    "section": "Training and test datasets",
    "text": "Training and test datasets\nTo evaluate our model fairly, we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model.\n\\[D = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\]\n\\[\nD_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \nD_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\n\n\n\nTraining data\n\n\n\n\n\n\n\n\n\ncar name\nweight\ndisplacement\nhorsepower\nacceleration\n\n\n\n\n0\nchevrolet chevelle malibu\n3504\n307.0\n130\n12.0\n\n\n1\nbuick skylark 320\n3693\n350.0\n165\n11.5\n\n\n2\nplymouth satellite\n3436\n318.0\n150\n11.0\n\n\n3\namc rebel sst\n3433\n304.0\n150\n12.0\n\n\n4\nford torino\n3449\n302.0\n140\n10.5\n\n\n...\n...\n...\n...\n...\n...\n\n\n295\ndodge colt hatchback custom\n1915\n98.0\n80\n14.4\n\n\n296\namc spirit dl\n2670\n121.0\n80\n15.0\n\n\n297\nmercedes benz 300d\n3530\n183.0\n77\n20.1\n\n\n298\ncadillac eldorado\n3900\n350.0\n125\n17.4\n\n\n299\npeugeot 504\n3190\n141.0\n71\n24.8\n\n\n\n\n300 rows × 5 columns\n\n\n\n\n\n\n\n\nTest data\n\n\n\n\n\n\n\n\n\ncar name\nweight\ndisplacement\nhorsepower\nacceleration\n\n\n\n\n300\noldsmobile cutlass salon brougham\n3420\n260.0\n90\n22.2\n\n\n301\nplymouth horizon\n2200\n105.0\n70\n13.2\n\n\n302\nplymouth horizon tc3\n2150\n105.0\n70\n14.9\n\n\n303\ndatsun 210\n2020\n85.0\n65\n19.2\n\n\n304\nfiat strada custom\n2130\n91.0\n69\n14.7\n\n\n...\n...\n...\n...\n...\n...\n\n\n393\nford mustang gl\n2790\n140.0\n86\n15.6\n\n\n394\nvw pickup\n2130\n97.0\n52\n24.6\n\n\n395\ndodge rampage\n2295\n135.0\n84\n11.6\n\n\n396\nford ranger\n2625\n120.0\n79\n18.6\n\n\n397\nchevy s-10\n2720\n119.0\n82\n19.4\n\n\n\n\n98 rows × 5 columns"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#training-and-test-datasets-1",
    "href": "lecture4-feature-transforms/slides.html#training-and-test-datasets-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Training and test datasets",
    "text": "Training and test datasets\nFor example, we might see that our model does well on the data it was fit on and poorly on new data.\n\n\n\nTraining data\n\nregressionPlot(data.slice(0,300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")\n\n\n\n\n\n\n\n\n\nTest data\n\nregressionPlot(data.slice(300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#spliting-data-in-practice",
    "href": "lecture4-feature-transforms/slides.html#spliting-data-in-practice",
    "title": "Lecture 4: Feature transforms",
    "section": "Spliting data in practice",
    "text": "Spliting data in practice\nIn general a good rule of thumb is to reserve \\(30\\%\\) of you data for evaluation, but anywhere from \\(10\\%\\) to \\(50\\%\\) is common in practice.\nIt is also very import very important to split data at random.\n\n\n\nTraining data\n\nsdata = data.slice()\na = shuffle(sdata)\nregressionPlot(sdata.slice(0,300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest data\n\nregressionPlot(sdata.slice(300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#spliting-data-in-practice-1",
    "href": "lecture4-feature-transforms/slides.html#spliting-data-in-practice-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Spliting data in practice",
    "text": "Spliting data in practice\nIn numpy we can accomplish this splitting by creating a random order of observations and applying it to both \\(X\\) and \\(y\\)\n\norder = np.arange(X.shape[0])    # Get an array of indices (1...N)\nnp.random.shuffle(order)         # Permute the data\n\nnumTrain = int(X.shape[0] * 0.7) # Get the number of training obs. (70%)\ntrainInds = order[:numTrain]     # Get the indices of training obs. (70%)\ntestInds = order[numTrain:]      # Get the indices of test obs. (30%)\n\n# Get the data and labels for each split\ntrainX, trainy = X[trainInds], y[trainInds]\ntestX, testy = X[testInds], y[testInds]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#linear-predictions",
    "href": "lecture4-feature-transforms/slides.html#linear-predictions",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear predictions",
    "text": "Linear predictions\nIn the previous two lectures, we saw that the linear regression model makes predictions of the form:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w} = \\sum_{i=1}^n x_i w_i\n\\]\nMeaning that the output will be a weighted sum of the features of the input.\n\\[\n\\text{Predicted MPG} = f(\\mathbf{x})=\n\\]\n\\[\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#linear-predictions-1",
    "href": "lecture4-feature-transforms/slides.html#linear-predictions-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear predictions",
    "text": "Linear predictions\nGraphically we see this corresponds to a prediction function that is a line or a plane.\n\nregressionPlot(data, [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#non-linear-data",
    "href": "lecture4-feature-transforms/slides.html#non-linear-data",
    "title": "Lecture 4: Feature transforms",
    "section": "Non-linear data",
    "text": "Non-linear data\nUnfortunately, in the real world the relationship between inputs and outputs is not always linear.\n\nviewof form_quadratic = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 2.89}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w\", value: 2.0165}),\n  ]\n)\n\n\n\n\n\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_quadratic, [\"0\"], \"1\", 0, se)\n\n\n\n\n\n\nWe see that there is no straight line that is a good fit to our data."
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#non-linear-data-1",
    "href": "lecture4-feature-transforms/slides.html#non-linear-data-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Non-linear data",
    "text": "Non-linear data\nWe see this with our real-world fuel efficiency dataset as well.\n\nviewof form_mpg_linear = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w\", value: -0.0077}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_linear, [\"weight\"], \"mpg\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#polynomial-functions",
    "href": "lecture4-feature-transforms/slides.html#polynomial-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Polynomial functions",
    "text": "Polynomial functions\nIf we’re trying to approximate a non-linear relationship between inputs and outputs, it follows that we may want to fit a non-linear approximation.\nOne of the simplest types of non-linear functions we could use are polynomial functions.\nThe simplest type of non-linear polynomial is a quadratic function, which involves powers of up to \\(2\\).\n\\[\nf(x) = w_2 x^2 + w_1x +b\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-functions",
    "href": "lecture4-feature-transforms/slides.html#quadratic-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic functions",
    "text": "Quadratic functions\nA quadratic function of \\(2\\) variables can be written as:\n\\[\nf(x, y) = w_5 x^2 + w_4y^2 + w_3 xy + w_2x + w_1y +b\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#cubic-functions",
    "href": "lecture4-feature-transforms/slides.html#cubic-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Cubic functions",
    "text": "Cubic functions\nSimilarly a cubic function involves powers up to 3:\n\\[\nf(x) = w_3 x^3 + w_2 x^2 + w_1x +b\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#polynomial-functions-1",
    "href": "lecture4-feature-transforms/slides.html#polynomial-functions-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Polynomial functions",
    "text": "Polynomial functions\nIn general the degree of a polynomial is the largest exponent in any term of the polynomial (or sum of exponents for terms involving more than 1 input). For example we can look at 2 different degree 4 polynomial functions:\n\\[\nf(x, y) = 3 x^4 + 2 xy + y - 2\n\\]\n\\[\nf(x, y) = -2 x^2y^2 + 2 x^3 + y^2 - 5\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#polynomial-functions-as-vector-functions",
    "href": "lecture4-feature-transforms/slides.html#polynomial-functions-as-vector-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Polynomial functions as vector functions",
    "text": "Polynomial functions as vector functions\nWe can also write polynomial functions as vector-input functions. For example a quadratic function of two variables could be written as:\n\\[\nf(\\mathbf{x}) = w_5 x_2^2 + w_4x_1^2 + w_3 x_1 x_2 + w_2x_2 + w_1x_1 +b\n\\]\nFrom this form we see that a polynomial is a weighted sum of powers of \\(\\mathbf{x}\\)!\n\\[\nw_5 x_2^2 + w_4x_1^2 + w_3 x_1 x_2 + w_2x + w_1y +b = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix} \\cdot \\begin{bmatrix}  w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\\\ w_5 \\\\  b \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms",
    "href": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic feature transforms",
    "text": "Quadratic feature transforms\nLet’s consider the mapping from \\(\\mathbf{x}\\) to powers of the elements of \\(\\mathbf{x}\\). We’ll call this mapping \\(\\phi\\):\n\\[\n\\begin{bmatrix}  x_1 \\\\ x_2 \\end{bmatrix}\\underset{\\phi}{\\longrightarrow}\\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nIn this quadratic example \\(\\phi\\) is a non-linear function that maps vectors to vectors \\((\\mathbb{R}^2 \\rightarrow \\mathbb{R}^6)\\). We call this a quadratic feature transform\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms-1",
    "href": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic feature transforms",
    "text": "Quadratic feature transforms\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\] With this mapping we can our quadratic prediction function simply as:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}\n\\]\nThis is a linear function of \\(\\phi(\\mathbf{x})\\) and \\(\\mathbf{w}\\)!"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms-2",
    "href": "lecture4-feature-transforms/slides.html#quadratic-feature-transforms-2",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic feature transforms",
    "text": "Quadratic feature transforms\nAs a simpler example, let’s look at the case where our input has only a single element \\((x_1)\\).\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\  1 \\end{bmatrix}\n\\]\n\nviewof form_quadratic_2 = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 2.89}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_1\", value: 2.0165}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_2\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_quadratic_2, [[\"0\", x =&gt; x], [\"0\", x =&gt; x * x]], \"1\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression",
    "href": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression",
    "title": "Lecture 4: Feature transforms",
    "section": "Fitting quadratic regression",
    "text": "Fitting quadratic regression\nIf we treat \\(\\phi(\\mathbf{x})\\) as our new set of inputs, we see that we can apply all the same tools of linear regression that we learned before.\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nWe can then define a quadratic probabilistic model as:\n\\[\ny_i \\sim N\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}, \\sigma^2\\big)\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-1",
    "href": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Fitting quadratic regression",
    "text": "Fitting quadratic regression\n\\[\ny_i \\sim N\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}, \\sigma^2\\big)\n\\] The corresponding negative log-likelihood loss becomes\n\\[\n\\textbf{Loss}(\\mathbf{w})=\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\n\\[\n= \\frac{1}{2\\sigma^2} \\sum_{i=1}^N\\big(y_i - \\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)^2 + N \\log \\sigma \\sqrt{2 \\pi}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-2",
    "href": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-2",
    "title": "Lecture 4: Feature transforms",
    "section": "Fitting quadratic regression",
    "text": "Fitting quadratic regression\n\\[\ny_i \\sim N\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}, \\sigma^2\\big)\n\\]\nWe can now find the optimal \\(\\mathbf{w}\\) by once again minimizing this loss!\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-3",
    "href": "lecture4-feature-transforms/slides.html#fitting-quadratic-regression-3",
    "title": "Lecture 4: Feature transforms",
    "section": "Fitting quadratic regression",
    "text": "Fitting quadratic regression\n\\[\n\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=y_i \\sim N\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}, \\sigma^2\\big)\n\\] We see that the gradient doesn’t change, it simply involves \\(\\phi(\\mathbf{x}_i)\\) instead of \\(\\mathbf{x}_i\\).\n\\[\n\\nabla_{\\mathbf{w}}\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n= \\frac{1}{2\\sigma^2}\\sum_{i=1}^N \\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w} - y_i\\big)\\phi(\\mathbf{x}_i)\n\\] This is because we are only taking the gradient with respect to \\(\\mathbf{w}\\). From the perspective of \\(\\mathbf{w}\\), the prediction funciton is still linear."
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-regression-on-real-data",
    "href": "lecture4-feature-transforms/slides.html#quadratic-regression-on-real-data",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic regression on real data",
    "text": "Quadratic regression on real data\nLet’s look at our new quadratic regression model on the problem of predicting fuel efficiency from a car’s weight.\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\  1 \\end{bmatrix}\n\\]\nWe see that by varying \\(w_2\\), we can now fit a curve to our data and get a better overall loss!\n\nviewof form_mpg_2 = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_2\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_2, [\"weight\", [\"weight\", x =&gt; (x / 100) * (x / 100)]], \"mpg\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression",
    "href": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic logistic regression",
    "text": "Quadratic logistic regression\nJust like with our regression example, we can apply our quadratic feature transform to the logistic regression model as well! In this case our prediction function becomes:\n\\[\nf(\\mathbf{x}) = \\mathbf{I}(\\phi(\\mathbf{x})^T\\mathbf{w} \\geq 0), \\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nOur Bernoulli probabilistic model becomes:\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\phi(\\mathbf{x}_i)^T\\mathbf{w} })\\big), \\quad p(y_i = 1\\mid \\mathbf{x}_i, \\mathbf{w}) = \\sigma\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-1",
    "href": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic logistic regression",
    "text": "Quadratic logistic regression\nThe corresponding negative log-likelihood is:\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log\\sigma\\big((2y_i-1)\\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)\n\\]\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\phi(\\mathbf{x}_i)^T\\mathbf{w} })\\big), \\quad p(y_i = 1\\mid \\mathbf{x}_i, \\mathbf{w}) = \\sigma\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)\n\\] Which we can once again optimize with gradient descent."
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-2",
    "href": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-2",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic logistic regression",
    "text": "Quadratic logistic regression\nWith this approach our decision boundary is no longer restricted to be a line!\n\n\n\n\n\n\nviewof form_circles = Inputs.form(\n  [\n    Inputs.range([-100, 100], {step: 0.01, label: \"b\", value: 0}),\n    Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 20}),\n    Inputs.range([-100, 100], {step: 0.0001, label: \"w_2\", value: 20}),\n      Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 0}),\n      Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\n\n\nlogisticPlot2d(circles, form_circles, [\"0\", \"1\", [\"0\", x=&gt;x*x], [\"1\", x=&gt;x*x]], \"2\")\n\n\n\n\n\n\n\n\nlogisticLossPlot2d(circles, form_circles, [\"0\", \"1\", [\"0\", x=&gt;x*x], [\"1\", x=&gt;x*x]], \"2\")"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-3",
    "href": "lecture4-feature-transforms/slides.html#quadratic-logistic-regression-3",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic logistic regression",
    "text": "Quadratic logistic regression\nRecall that our linear classifier made predictions by thresholding a linear function. Our quadratic classifer thresholds a quadratic function of 1 or more variables.\n\n\n\nLinear decision boundary\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuadratic decision boundary\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-polynomial-transforms",
    "href": "lecture4-feature-transforms/slides.html#general-polynomial-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "General polynomial transforms",
    "text": "General polynomial transforms\nWe’re not restricted to just quadratic transform! For example, for a model with \\(1\\) input, we could definite a cubic feature transform as:\n\\[\n\\begin{bmatrix}  x_1  \\end{bmatrix}\\underset{\\phi}{\\longrightarrow}\\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\ x_1^3\\\\  1 \\end{bmatrix}\n\\]\nOur prediction function will be:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_3 x_1^3 + w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2\\\\ x_1^3 \\\\  1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-polynomial-transforms-1",
    "href": "lecture4-feature-transforms/slides.html#general-polynomial-transforms-1",
    "title": "Lecture 4: Feature transforms",
    "section": "General polynomial transforms",
    "text": "General polynomial transforms\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_3 x_1^3 + w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2\\\\ x_1^3 \\\\  1 \\end{bmatrix}\n\\] We can apply this to our regression model for fuel efficiency as before.\n\nviewof form_mpg_3 = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_2\", value: 0}),\n    Inputs.range([-0.05, 0.05], {step: 0.0001, label: \"w_3\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_3, [\"weight\", [\"weight\", x =&gt; (x / 100) * (x / 100)], [\"weight\", x =&gt; (x / 250) * (x / 250) * (x / 250)]], \"mpg\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-polynomial-transforms-2",
    "href": "lecture4-feature-transforms/slides.html#general-polynomial-transforms-2",
    "title": "Lecture 4: Feature transforms",
    "section": "General polynomial transforms",
    "text": "General polynomial transforms\nWe can also similarly define general polynomial transforms using polynomials of higher degrees or a subset of the features.\nFor example we might define the following quadratic transform for 3-feature inputs:\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_3 \\\\ x_1^2\\\\ x_2^2 \\\\  x_3^2 \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-feature-transforms",
    "href": "lecture4-feature-transforms/slides.html#general-feature-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "General feature transforms",
    "text": "General feature transforms\nWe can also use any scalar non-linear functions we want. For example we could define a transform using \\(\\sin\\) and \\(\\cos\\):\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ \\sin(x_1) \\\\ \\sin(x_2) \\\\ \\cos(x_1) \\\\ \\cos(x_2) \\\\ 1 \\end{bmatrix}\n\\]\nOr using the sigmoid function:\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ \\sigma(x_1) \\\\ \\sigma(x_2)  \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-feature-transforms-1",
    "href": "lecture4-feature-transforms/slides.html#general-feature-transforms-1",
    "title": "Lecture 4: Feature transforms",
    "section": "General feature transforms",
    "text": "General feature transforms\nWe can see how different features allow us to define different nonlinear functions.\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_3 e^{x_1} + w_2 \\sin(x_1) + w_1x_1^2 +b ,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\ \\sin(x_1) \\\\ e^{x_1}  \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-feature-transforms-2",
    "href": "lecture4-feature-transforms/slides.html#general-feature-transforms-2",
    "title": "Lecture 4: Feature transforms",
    "section": "General feature transforms",
    "text": "General feature transforms\n\nviewof form_mpg_4 = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 1}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_1 (x)\", value: -0.0077}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_2 (x^2)\", value: 0}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_3 (sin x)\", value: 0}),\n    Inputs.range([-0.5, 0.5], {step: 0.0001, label: \"w_4 (exp(x))\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_mpg_4, [\"0\", [\"0\", x =&gt; (x) * (x)], [\"0\", x =&gt; Math.sin(x)], [\"0\", x =&gt; Math.exp(x)]], \"1\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/slides.html#general-feature-transforms-3",
    "href": "lecture4-feature-transforms/slides.html#general-feature-transforms-3",
    "title": "Lecture 4: Feature transforms",
    "section": "General feature transforms",
    "text": "General feature transforms\nIn numpy we can write this as:\n\nsin_X = np.sin(X)               # sin(x)\nsquared_X = X ** 2              # x^2\nexp_X = np.exp(X)               # e^x\nones = np.ones((X.shape[0], 1)) # Column of 1s\n\ntransformedX = np.concatenate([X, squared_X, sin_X, exp_X, ones], axis=1)"
  },
  {
    "objectID": "utilities/notebook-converter/nb.html",
    "href": "utilities/notebook-converter/nb.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import nbformat\nfrom nbconvert import WebPDFExporter\n\n\n'Q1' in nbformat.read('main.ipynb', nbformat.NO_CONVERT).cells[7].metadata.tags\n\nTrue\n\n\n\nnb = nbformat.read('main.ipynb', 4)\n\n\nprint('\\n')\n\n\n\n\n\n\npagebreak = r'''&lt;div style=\"page-break-after: always; visibility: hidden\"&gt; \n\\pagebreak \n&lt;/div&gt;'''\n\ncells = []\nfor question in range(20):\n    qstr = f'Q{question}'\n    if question &gt; 0:\n        cells.append(nbformat.v4.new_markdown_cell(source='# ' + qstr))\n\n    for cell in nb.cells:\n        checksource = cell.source.strip().replace(' ', '').find('#!' + qstr) == 0\n        if ('tags' in cell.metadata and qstr in cell.metadata.tags) or checksource:\n            if checksource:\n                cell.source = '\\n'.join(cell.source.splitlines()[1:])\n            cells.append(cell)\n            \n    cells.append(nbformat.v4.new_markdown_cell(source=pagebreak))\n\noutput = nbformat.v4.new_notebook()\noutput.cells = cells\n\n\n#! Q1\nnbformat.v4.new_markdown_cell(source='')\n\n{'id': '8da0209c', 'cell_type': 'markdown', 'source': '', 'metadata': {}}\n\n\n#! Q1\n\n(pdf, _) = WebPDFExporter().from_notebook_node(output)\nwith open('main2.pdf', 'wb') as f:\n    f.write(pdf)\n\n/Users/gabehope/Documents/Courses/cs152.github.io/.venv/lib/python3.12/site-packages/nbconvert/exporters/exporter.py:348: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n  _, nbc = validator.normalize(nbc)\n\n\n\npagebreak = r'''&lt;div style=\"page-break-after: always; visibility: hidden\"&gt; \n\\pagebreak \n&lt;/div&gt;'''\n\n\npagebreak\n\n'&lt;div style=\"page-break-after: always; visibility: hidden\"&gt; \\n\\\\pagebreak \\n&lt;/div&gt;'"
  },
  {
    "objectID": "code/ojs.html",
    "href": "code/ojs.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html",
    "href": "lecture5-neural-networks-intro/slides.html",
    "title": "Lecture 4: Feature transforms",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\ndata = transpose(data_raw)"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nIn the last lecture we saw that we can define more complex and expressive functions by transforming the inputs in various ways. For example, we can define a function as:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_4 e^{x_1} + w_3 \\sin(x_1) + w_2x_1^2 + w_1 x_1 + b ,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\ \\sin(x_1) \\\\ e^{x_1}  \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-1",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\n\n\n\n\n\n\nviewof form_mpg_4 = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 1}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_2\", value: 0}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_3\", value: 0}),\n    Inputs.range([-0.5, 0.5], {step: 0.0001, label: \"w_4\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_mpg_4, [\"0\", [\"0\", x =&gt; (x) * (x)], [\"0\", x =&gt; Math.sin(x)], [\"0\", x =&gt; Math.exp(x)]], \"1\", 0, se)\n\n\n\n\n\n\nWe see that by varying the weights \\(w_1...w_4\\), we can get a variety of complex, non-linear functions of our input \\(\\mathbf{x}\\)!"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-2",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-2",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nHow do we actually choose what transforms of our inputs to use?"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#learned-feature-transforms",
    "href": "lecture5-neural-networks-intro/slides.html#learned-feature-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "Learned feature transforms",
    "text": "Learned feature transforms\nWe’ve already seen that we can learn a function by defining our function in terms of a set of parameters \\(\\mathbf{w}\\): \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\] and then minimizing a loss as a function of \\(\\mathbf{w}\\) \\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\mathbf{Loss}(\\mathbf{w})\\] Which we can do with gradient descent: \\[\\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{Loss}(\\mathbf{w})\\]\nSo we didn’t choose \\(\\mathbf{w}\\) explicitly, we let our algorithm find the optimal values. Ideally, we could do the same thing for our feature transforms: let our algorithm choose the optimal functions to use."
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-3",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-3",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nCan we learn the functions in our feature transform?"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-4",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-4",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} ,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  g_1(x_1) \\\\ g_2(x_1) \\\\ g_3(x_1) \\\\ g_4(x_1) \\\\ 1 \\end{bmatrix}\n\\]\nThe key insight we’ll use here is that we’ve already seen how to learn functions: this is exactly what our regression models are doing! \\[g_i(\\mathbf{x}) = \\sigma(\\mathbf{x}^T \\mathbf{w}_i)\\] With this form we get a new feature transform: \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_4) \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-5",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-5",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nLet’s look at a very simple example: \\[\\mathbf{x} = \\begin{bmatrix} x_1\\\\ 1 \\end{bmatrix}, \\quad \\mathbf{w}_0 = \\begin{bmatrix} w_{01} \\\\ b_0 \\end{bmatrix}\\] \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ 1 \\end{bmatrix} =\n\\begin{bmatrix}  \\sigma(x_1 w_{11} + b_1) \\\\ \\sigma(x_1 w_{21} + b_2) \\\\ 1 \\end{bmatrix}\n\\] In this case, we can write out our prediction function explicitly as: \\[f(\\mathbf{x}) = w_{01} \\cdot\\sigma(x_1 w_{11} + b_1) + w_{02}\\cdot \\sigma(x_1 w_{21} + b_2) + b_0 \\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-6",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-6",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\n\\[f(\\mathbf{x}) = w_{01} \\cdot\\sigma(x_1 w_{11} + b_1) + w_{02}\\cdot \\sigma(x_1 w_{21} + b_2) + b_0 \\]\n\n\n\nviewof form_nn = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b_0\", value: 0.33}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_01\", value: 9.2376}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_02\", value: 8.3719}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_11\", value: -2.4219}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"b_1\", value: -5.457}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_21\", value: 2.6795}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"b_2\", value: -5.4557}),\n    Inputs.checkbox([\"Show feature transforms\"], {}),\n\n  ]\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\n\n\n\n\n\n\n\nnnPlot(quadratic_data2, [form_nn[0], 0, form_nn[1], form_nn[2]],\n    \n        [\"0\", [\"0\", x =&gt; sigmoid(form_nn[3] * x + form_nn[4], 0)], \n        [\"0\", x =&gt; sigmoid(form_nn[5] * x + form_nn[6], 0)], \n        ], \"1\", 0, se, \"\", form_nn[7])"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-7",
    "href": "lecture5-neural-networks-intro/slides.html#feature-transforms-revisited-7",
    "title": "Lecture 4: Feature transforms",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nIf we let \\[\\mathbf{W}_1 = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\mathbf{w}_3^T \\\\ \\vdots \\end{bmatrix}\\] We can write this more compactly as: \\[f(\\mathbf{x})= \\sigma(\\mathbf{x}^T \\mathbf{W}_1^T)^T \\mathbf{w_0}  \\] Or for a whole dataset: \\[\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\mathbf{x}_3^T \\\\ \\vdots \\end{bmatrix}\\] \\[f(\\mathbf{X})= \\sigma(\\mathbf{X} \\mathbf{W}_1^T)^T \\mathbf{w_0}  \\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#neural-networks-1",
    "href": "lecture5-neural-networks-intro/slides.html#neural-networks-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Neural networks",
    "text": "Neural networks\nWhat we’ve just seen is a neural network!\nTerminology-wise we call a single feature transform like \\[\\sigma(x_1 w_{11} + b_1)\\] a neuron.\nWe call the whole set of transformed features the hidden layer: \\[\\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_4) \\\\ 1 \\end{bmatrix} \\]\nWe call \\(\\mathbf{X}\\) the input and \\(f(\\mathbf{X})\\) the output.\nWe often describe neural networks using a node-link diagram:"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#linear-transforms",
    "href": "lecture5-neural-networks-intro/slides.html#linear-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear transforms",
    "text": "Linear transforms\nCan we use linear regression as a feature transform?\nLet’s see what happens in our simple example: \\[\\mathbf{x} = \\begin{bmatrix} x_1\\\\ 1 \\end{bmatrix}, \\quad \\mathbf{w}_0 = \\begin{bmatrix} w_{01} \\\\ b_0 \\end{bmatrix}\\] \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2 \\\\ 1 \\end{bmatrix} =\n\\begin{bmatrix}  x_1 w_{11} + b_1 \\\\ x_1 w_{21} + b_2 \\\\ 1 \\end{bmatrix}\n\\] In this case, we can write out our prediction function explicitly as: \\[f(\\mathbf{x}) = w_{01} \\cdot x_1 w_{11} + b_1 + w_{02}\\cdot x_1 w_{21} + b_2 + b_0 \\] \\[= (w_{11}w_{01}) x_1 + (w_{21}w_{02}) x_1 + (b_0 + b_1 + b2)\\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#linear-transforms-1",
    "href": "lecture5-neural-networks-intro/slides.html#linear-transforms-1",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear transforms",
    "text": "Linear transforms\n\n\n\nviewof form_lnn = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b_0\", value: 0.33}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_01\", value: 9.2376}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_02\", value: 8.3719}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_11\", value: -2.4219}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"b_1\", value: -5.457}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_21\", value: 2.6795}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"b_2\", value: -5.4557}),\n    Inputs.checkbox([\"Show feature transforms\"], {}),\n\n  ]\n)\n\n\n\n\n\n\n\n\nnnPlot(quadratic_data2, [form_lnn[0], 0, form_lnn[1], form_lnn[2]],\n    \n        [\"0\", [\"0\", x =&gt; form_lnn[3] * x + form_lnn[4]], \n        [\"0\", x =&gt; form_lnn[5] * x + form_lnn[6]], \n        ], \"1\", 0, se, \"\", form_lnn[7])"
  },
  {
    "objectID": "lecture5-neural-networks-intro/slides.html#linear-transforms-2",
    "href": "lecture5-neural-networks-intro/slides.html#linear-transforms-2",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear transforms",
    "text": "Linear transforms\nIn general: \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2\\\\ \\mathbf{x}^T \\mathbf{w}_3 \\\\ \\mathbf{x}^T \\mathbf{w}_4\\\\ 1 \\end{bmatrix}\n\\]\n\\[\nf(\\mathbf{x})= w_{01} (\\mathbf{x}^T \\mathbf{w}_1) +  w_{02} (\\mathbf{x}^T \\mathbf{w}_2) +...\n\\] \\[= \\mathbf{x}^T ( w_{01}\\mathbf{w}_1) +  \\mathbf{x}^T (w_{02} \\mathbf{w}_2) +...\n\\] Which is again just a linear function. The motivates the need for using a non-linear function like \\(\\sigma(\\cdot)\\) in our neurons. We’ll see more about this next week!"
  },
  {
    "objectID": "lecture5-neural-networks-intro/other_notes.html",
    "href": "lecture5-neural-networks-intro/other_notes.html",
    "title": "Lecture 5: Introduction to Neural Networks",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}"
  },
  {
    "objectID": "lecture5-neural-networks-intro/other_notes.html#data",
    "href": "lecture5-neural-networks-intro/other_notes.html#data",
    "title": "Lecture 5: Introduction to Neural Networks",
    "section": "Data",
    "text": "Data\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: ?}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow \\text{   MPG: ?}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\n\\[\n\\mathcal{D}  = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ...\\ (\\mathbf{x}_N, y_N)\\} = \\big(\\mathbf{X}, \\mathbf{y}\\big)\n\\]\n\n\n\nInputs\n\n\n\n\n\n\n\n\n\n\nweight\nhorsepower\ndisplacement\nacceleration\n\n\ncar name\n\n\n\n\n\n\n\n\nchevrolet chevelle malibu\n3504\n130.0\n307.0\n12.0\n\n\nbuick skylark 320\n3693\n165.0\n350.0\n11.5\n\n\nplymouth satellite\n3436\n150.0\n318.0\n11.0\n\n\namc rebel sst\n3433\n150.0\n304.0\n12.0\n\n\nford torino\n3449\n140.0\n302.0\n10.5\n\n\n...\n...\n...\n...\n...\n\n\nford mustang gl\n2790\n86.0\n140.0\n15.6\n\n\nvw pickup\n2130\n52.0\n97.0\n24.6\n\n\ndodge rampage\n2295\n84.0\n135.0\n11.6\n\n\nford ranger\n2625\n79.0\n120.0\n18.6\n\n\nchevy s-10\n2720\n82.0\n119.0\n19.4\n\n\n\n\n305 rows × 4 columns\n\n\n\n\\[ \\mathbf{X} =\n\\begin{bmatrix}\n                X_{11} & X_{12} & X_{13} & X_{14} \\\\\n                X_{21} & X_{22} & X_{23} & X_{24} \\\\\n                X_{31} & X_{32} & X_{33} & X_{34} \\\\\n                \\vdots & \\vdots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & X_{N3} & X_{N4} \\\\\n                                 \\end{bmatrix} \\underset{\\text{Car data}}{\\longrightarrow}\n\\begin{bmatrix}\n                3504 & 130 & 307.0 & 12.0 \\\\\n                3693 & 165 & 350.0 & 11.5 \\\\\n                3493 & 150 & 318.0 & 11.0 \\\\\n                \\vdots & \\vdots & \\vdots & \\vdots \\\\\n                2720 & 82 & 119.0 & 19.4 \\\\\n                                 \\end{bmatrix}\\]\n\\[\\mathbf{X}:\\ N \\times d \\ \\text{matrix} , \\quad (\\mathbf{X} \\in \\mathbb{R}^{N\\times d})\\] \\[ N: \\text{number of observations}, \\quad d: \\text{number of features}\\]\n\nprint(X)\n\n[[3504.   130.   307.    12. ]\n [3693.   165.   350.    11.5]\n [3436.   150.   318.    11. ]\n ...\n [2295.    84.   135.    11.6]\n [2625.    79.   120.    18.6]\n [2720.    82.   119.    19.4]]\n\n\n\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\n\n\nmpg\n\n\ncar name\n\n\n\n\n\nchevrolet chevelle malibu\n18.0\n\n\nbuick skylark 320\n15.0\n\n\nplymouth satellite\n18.0\n\n\namc rebel sst\n16.0\n\n\nford torino\n17.0\n\n\n...\n...\n\n\nford mustang gl\n27.0\n\n\nvw pickup\n44.0\n\n\ndodge rampage\n32.0\n\n\nford ranger\n28.0\n\n\nchevy s-10\n31.0\n\n\n\n\n305 rows × 1 columns\n\n\n\n\\[ \\mathbf{y} =\n\\begin{bmatrix}\n                y_{1} \\\\\n                y_{2} \\\\\n                y_{3} \\\\\n                \\vdots \\\\\n                y_{N} \\\\\n                                 \\end{bmatrix} \\underset{\\text{Car data}}{\\longrightarrow}\n\\begin{bmatrix}\n                18.0  \\\\\n                15.0  \\\\\n                16.0  \\\\\n                \\vdots \\\\\n                31.0 \\\\\n                                 \\end{bmatrix}\\]\n\\[\\mathbf{y}:\\ N \\ \\text{vector}, \\quad (\\mathbf{y} \\in \\mathbb{R}^N)\\] \\[ N: \\text{number of observations}\\]\n\nprint(y)\n\n[18. 15. 18. ... 32. 28. 31.]\n\n\n\n\n\n\n\n\n\nInputs\n\n\n\n\n\n\n\n\n \nweight\nhorsepower\ndisplacement\nacceleration\n\n\ncar name\n \n \n \n \n\n\n\n\nchevrolet chevelle malibu\n3504\n130.000000\n307.000000\n12.000000\n\n\nbuick skylark 320\n3693\n165.000000\n350.000000\n11.500000\n\n\nplymouth satellite\n3436\n150.000000\n318.000000\n11.000000\n\n\namc rebel sst\n3433\n150.000000\n304.000000\n12.000000\n\n\nford torino\n3449\n140.000000\n302.000000\n10.500000\n\n\n\n\n\n\\[\\mathbf{x}_3 = \\begin{bmatrix} 3433 \\\\ 150 \\\\ 304 \\\\ 12 \\end{bmatrix}, \\quad (d \\text{ vector})\\]\n\nprint(X[3])\n\n[3433.  150.  304.   12.]\n\n\n\nAs a column vector\n\\[\\mathbf{x}_3 = \\begin{bmatrix} 3433 \\\\ 150 \\\\ 304 \\\\ 12 \\end{bmatrix}, \\quad (d \\text{ vector})\\quad \\underset{\\text{same notation!}}{\\longleftrightarrow} \\quad \\mathbf{x}_3 = \\begin{bmatrix} 3433 \\\\ 150 \\\\ 304 \\\\ 12 \\end{bmatrix}, \\quad (d \\times 1 \\text{ matrix}) \\]\n\nprint(X[3].reshape((-1, 1)))\n\n[[3433.]\n [ 150.]\n [ 304.]\n [  12.]]\n\n\n\n\nAs a row vector\n\\[\\mathbf{x}_3^T = \\begin{bmatrix} 3433 & 150 & 304 & 12 \\end{bmatrix}, \\quad (d \\times 1 \\text{ matrix}) \\]\n\nprint(X[3].reshape((1, -1)))\n\n[[3433.  150.  304.   12.]]\n\n\n\\[\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^ T \\end{bmatrix}\\]\n\n\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\n \nmpg\n\n\ncar name\n \n\n\n\n\nchevrolet chevelle malibu\n18.000000\n\n\nbuick skylark 320\n15.000000\n\n\nplymouth satellite\n18.000000\n\n\namc rebel sst\n16.000000\n\n\nford torino\n17.000000\n\n\n\n\n\n\\[y_3 = 16, \\quad (\\text{scalar})\\]\n\nprint(y[3])\n\n16.0\n\n\n\n\n\n\n\n\n\nInputs\n\n\n\n\n\n\n\n\n \nweight\nhorsepower\ndisplacement\nacceleration\n\n\ncar name\n \n \n \n \n\n\n\n\nchevrolet chevelle malibu\n3504\n130.000000\n307.000000\n12.000000\n\n\nbuick skylark 320\n3693\n165.000000\n350.000000\n11.500000\n\n\nplymouth satellite\n3436\n150.000000\n318.000000\n11.000000\n\n\namc rebel sst\n3433\n150.000000\n304.000000\n12.000000\n\n\nford torino\n3449\n140.000000\n302.000000\n10.500000\n\n\n\n\n\n\nweight = X[:, 0]\nprint(weight[:5])\n\n[3504. 3693. 3436. 3433. 3449.]\n\n\n\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\n \nmpg\n\n\ncar name\n \n\n\n\n\nchevrolet chevelle malibu\n18.000000\n\n\nbuick skylark 320\n15.000000\n\n\nplymouth satellite\n18.000000\n\n\namc rebel sst\n16.000000\n\n\nford torino\n17.000000\n\n\n\n\n\n\nprint(y[:5])\n\n[[18.]\n [15.]\n [18.]\n [16.]\n [17.]]\n\n\n\n\n\n\n\nf = plt.scatter(weight, y)\n\n\n\n\n\n\n\n\n\nLinear predictions\nFind simple function that predicts output \\[f(\\mathbf{X}) = \\mathbf{x}^T \\mathbf{w}\\] \\[\\mathbf{x}: \\text{input} (d \\text{ vector}), \\quad\\mathbf{w}: \\text{weights or parameters} (d \\text{ vector})\\]\n\n\n\n\n\n\n\n \nweight\nhorsepower\ndisplacement\nacceleration\n\n\ncar name\n \n \n \n \n\n\n\n\nchevrolet chevelle malibu\n3504\n130.000000\n307.000000\n12.000000\n\n\nbuick skylark 320\n3693\n165.000000\n350.000000\n11.500000\n\n\nplymouth satellite\n3436\n150.000000\n318.000000\n11.000000\n\n\namc rebel sst\n3433\n150.000000\n304.000000\n12.000000\n\n\nford torino\n3449\n140.000000\n302.000000\n10.500000\n\n\n\n\n\n\\[f(\\mathbf{x}_4) = \\mathbf{x}_4^T \\mathbf{w} =  \\begin{bmatrix} 3433 \\\\ 150 \\\\ 304 \\\\ 12 \\end{bmatrix}^T \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\end{bmatrix} = 3433 w_1  +  150 w_2 + 304  w_3 + 12w_4 \\]\n\nw = np.array([0.02, 0.2, -0.1, -1.5])\n\ndef f(x, w):\n    # Transpose not needed because x and w are 1-dimensional vectors\n    # (Not column/row vectors!)\n    return np.dot(x, w)\n\nprint(f(X[3], w))\n\n50.25999999999999\n\n\n\n# Make everything explicit column vectors\nw = w.reshape((-1, 1))\nx3 = X[3].reshape((-1, 1))\n\n# Works!\ndef f(x, w):\n    return np.dot(x.T, w)\n\nf(X[3], w)\n\narray([50.26])\n\n\nFind simple function that predicts output \\[f(\\mathbf{X}) = \\mathbf{X} \\mathbf{w}\\] \\[\\mathbf{x}: \\text{all inputs} (N\\times d \\text{ matrix}), \\quad\\mathbf{w}: \\text{weights or parameters} (d \\text{ vector})\\]\n\n\n\n\n\n\n\n \nweight\nhorsepower\ndisplacement\nacceleration\n\n\ncar name\n \n \n \n \n\n\n\n\nchevrolet chevelle malibu\n3504\n130.000000\n307.000000\n12.000000\n\n\nbuick skylark 320\n3693\n165.000000\n350.000000\n11.500000\n\n\nplymouth satellite\n3436\n150.000000\n318.000000\n11.000000\n\n\namc rebel sst\n3433\n150.000000\n304.000000\n12.000000\n\n\nford torino\n3449\n140.000000\n302.000000\n10.500000\n\n\n\n\n\n\\[f(\\mathbf{X}) = \\mathbf{X} \\mathbf{w} =  \\begin{bmatrix} 3504 & 130 & 307 & 12 \\\\\n3693 & 165 & 350 & 11.5 \\\\\n3436 & 150 & 318 & 11 \\\\\n3433 & 150 & 304 & 12 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n\\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\end{bmatrix}  \\]\n\nw = np.array([0.02, 0.2, -0.1, -1.5])\n\ndef f(x, w):\n    return np.dot(x, w)\n\nprint(f(X, w) [:4])\n\n[47.38 54.61 50.42 50.26]\n\n\nFind x"
  },
  {
    "objectID": "lecture9-optimization/viz-animated.html",
    "href": "lecture9-optimization/viz-animated.html",
    "title": "Stochastic Gradient descent visualization",
    "section": "",
    "text": "MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {stop: 'STOP'};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n\n    console.log(result === 'STOP');\n    if (result === 'STOP') {\n      console.log('wtf');\n      return new Promise(() =&gt; {}); \n    }\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {stop: 'STOP'};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n\n    console.log(result === 'STOP');\n    if (result === 'STOP') {\n      return new Promise(() =&gt; {}); \n    }\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None, events=['mousedown', 'mousemove']):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown and event.type in events:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure()\nscatterfig\n`\n\n\n\n\n\n\n\nviewof batchsize = Inputs.range([1, 250], {value: 5, step: 1, label: \" Batch size\"})\n\n\n\n\n\n\n\nviewof learningrate = Inputs.range([0, 3], {value: 1, step: 0.01, label: \" Learning rate\"})\n\n\n\n\n\n\n\nviewof steps = Inputs.range([1, 100], {value: 1, step: 1, label: \"  Steps\"})\n\n\n\n\n\n\n\nviewof threed = Inputs.toggle({value: false, label: \"Show 3D\"})\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(events=['mousedown'])\nthreedlossplot = PlotlyFigure(hide_toolbar=False, overlay=False)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof l2 = Inputs.range([0, 10], {value: 0, step: 0.01, label: \"  L2 weight\"})\n\n\n\n\n\n\n\nviewof l1 = Inputs.range([0, 10], {value: 0, step: 0.01, label: \"  L1 weight\"})\n\n\n\n\n\n\n\nviewof momentum = Inputs.range([0, 1], {value: 0, step: 0.01, label: \" Momentum\"})\n\n\n\n\n\n\n\nviewof rmsprop = Inputs.range([0, 1], {value: 0, step: 0.01, label: \" RMSProp\"})\n\n\n\n\n\n\n\npy`\n# ${plots}\nthreedlossplot  if bool(${threed}) else ''\n`\n\n\n\n\n\n\n\nviewof newbatch = Inputs.button('New Batch')\n\n\n\n\n\n\nviewof transform = Inputs.select(['none', 'sin', 'cos', 'square'], {label: 'Weight transform'})\n\n\n\n\n\n\nviewof bscale = Inputs.range([0, 10], {value: 1, step: 0.01, label: \" Bias scale\"})\n\n\n\n\n\n\n\n:::\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std())\n\ndef get_batch(batchsize, x, y):\n  batchinds = tf.randomUniformInt((batchsize,), 0, x.shape[0])\n  xbatch = tf.gather(x, batchinds)\n  ybatch = tf.gather(y, batchinds)\n  return xbatch, ybatch\n\ntransforms = dict(none=lambda a: a, sin=tf.sin, cos=tf.cos, square=tf.square)\ntransform = transforms[str(${transform})]\nscale = Tensor([[float(${bscale}), 1.]])\n\ndef predict(w, x):\n  w = transform(w.reshape((-1, 2)) * scale)\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  return tf.dot(x, w.T)\n\nwrange = tf.linspace(-3, 3, 25)\nbrange = tf.linspace(-3, 3, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = float(${l1})\nl2weight = float(${l2})\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean((predict(w, x) - y) ** 2, 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8, contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\nstart = py`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\nlr = float(${learningrate})\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\n\nmomentum = float(${momentum})\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = float(${rmsprop})\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nbatchi = 1\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n`\n\nstep = py`\n# ${start} ${now}\n\ngoing = batchi &lt; steps\nif going:\n  (nxbatch, nybatch) = batches[batchi]\n  batchi += 1\n\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n\n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n  fullweights = tf.stack(fullweightlist)\n  batchweights = tf.stack(batchweightlist)\n\nTrue if going else 'STOP'\n`\n\nupdate = py`\n# ${step}\nprint('Updating')\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'xaxis': {'range': [-3, 3]}, 'yaxis': {'range': [-3, 3]}})\n\nthreed = bool(${threed})\nif threed:\n  print('Threedeee')\n  PlotlyReactive(threedlossplot, [losssurface, threedgradplot, threedbatchgradplot], {'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}}})\nelse:\n  PlotlyReactive(threedlossplot, [])\n`\n\npy`\n# ${batch} ${update}\n# Plot the data scatterplot and prediction function\nscatterdata = dict(x=x.reshape((-1,)), y=y.reshape((-1,)), mode='markers', label='All data', marker=dict(color='rgba(17, 157, 255,0.5)'))\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color='firebrick'))\n\nxrange = tf.linspace(-2, 3, 50)\ncweights = Tensor(${weights})\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\nPlotlyReactive(scatterfig, [scatterdata, batchdata, pfunction], {'xaxis': {'range': [-2, 3]}, 'yaxis': {'range': [-2, 3]}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbatch = py`\n# ${data}, ${newbatch}\nbatchsize = int(${batchsize})\nbatches = [get_batch(batchsize, x, y) for i in range(int(${steps}))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\npy`\n#eyetheta += 0.01\n\nthreed = bool(${threed})\nif False:\n  def rotate_z(x, y, z, theta):\n    w = x+1j*y\n    return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n\n  xe, ye, ze = rotate_z(1.25, 1.25, 1.25, eyetheta)\n\n  Plotly.relayout(threedlossplot.childNodes[0], to_js({'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}, 'dragmode': False, 'camera': {'eye': {'x': float(xe), 'y': float(ye), 'z': float(ze)}}}}, dict_converter=Object.fromEntries))\n  Plotly.relayout(threedbatchlossplot.childNodes[0], to_js({'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}, 'dragmode': False, 'camera': {'eye': {'x': float(xe), 'y': float(ye), 'z': float(ze)}}}}, dict_converter=Object.fromEntries))\n`"
  },
  {
    "objectID": "lecture9-optimization/notes.html",
    "href": "lecture9-optimization/notes.html",
    "title": "Lecture 9: Optimization",
    "section": "",
    "text": "Try out the concepts from this lecture in the Neural Network Playground!"
  },
  {
    "objectID": "lecture9-optimization/notes.html#symmetry-breaking",
    "href": "lecture9-optimization/notes.html#symmetry-breaking",
    "title": "Lecture 9: Optimization",
    "section": "Symmetry-breaking",
    "text": "Symmetry-breaking\nIn neural networks, we typically initialize parameters randomly. One important reason for random initialization is to make sure that different parameters have different starting values. To see why this is needed, let’s consider the prediction function for a simple neural network that takes in 1-dimensional inputs:\n\\[\nf(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}_1)^T\\mathbf{w}_0=\\sigma(x_1 w_{11}) w_{01} +\\sigma (x_1 w_{12})w_{02}\n\\]\nIn this case we have 4 parameters: \\(w_{01}, w_{02}, w_{11}, w_{12}\\). If we initialize all to the same value, say \\(w_{**} = a\\), let’s see what happens to the derivatives we compute:\n\\[\n\\frac{d}{dw_{01}} f(\\mathbf{x}) = \\sigma(x_1 w_{11}) = \\sigma(x_1 a)\n\\]\n\\[\n\\frac{d}{dw_{02}} f(\\mathbf{x}) = \\sigma(x_1 w_{12}) = \\sigma(x_1 a)\n\\]\nWe see that \\(\\frac{d}{dw_{01}} = \\frac{d}{dw_{02}}\\)! Our gradient descent update will set:\n\\[\nw_{01}^{(1)} \\longleftarrow w_{01}^{(0)} - \\alpha \\frac{d}{dw_{01}} = a - \\alpha \\sigma(x_1 a)\n\\]\n\\[\nw_{02}^{(1)} \\longleftarrow w_{02}^{(0)} - \\alpha \\frac{d}{dw_{02}} = a - \\alpha \\sigma(x_1 a)\n\\]\nSo after each gradient descent update the two values will continue to be the same! The gradient decent algorithm has no way to distinguish between these two weights and so it is stuck finding solutions where \\(w_{01} = w_{02}\\) and \\(w_{11}=w_{12}\\). We call this the symmetry problem, and it means we no longer get any benefit from having multiple neurons.\nWe can see this in practice with a simple network:\n\n\n\nWhen the network is initialized with symmetry, the two neurons will always have the same output and our solution is poor.\n\n\n\n\nWhen initialized randomly, the two neurons can create different transforms and a much better solution is found.\n\n\nIf we plot the loss as a function of two \\(w_{01}\\) and \\(w_{02}\\) we can see what is happening graphically.\n\n\n\nInitializing the two parameters equal corresponds to sitting on a ridge of the loss surface, there are equally valid solutions on either side, but gradient descent gives us no way to chose between them.\n\n\n\n\nIf we plot the (negative) gradient of the loss we see that the gradient of any point on the ridge always points along the ridge. Gradient descent corresponds to following these arrows to find a minimum."
  },
  {
    "objectID": "lecture9-optimization/notes.html#visualizing-learning-rates",
    "href": "lecture9-optimization/notes.html#visualizing-learning-rates",
    "title": "Lecture 9: Optimization",
    "section": "Visualizing learning rates",
    "text": "Visualizing learning rates\nAs an aside, plotting the gradient as a vector field also gives us an convenient way to visualize the effects of different learning rates. Recall that the learning rate corresponds to how much we scale the gradient each time we take a step.\n\n\n\nA small learning rate means we will move slowly, so It may take a long time to find the minimum.\n\n\n\n\nA well-chosen learning rate lets us find a minimum quickly.\n\n\n\n\nA too-large learning rate means that steps may take us flying past the minimum!"
  },
  {
    "objectID": "lecture9-optimization/notes.html#scaled-initialization",
    "href": "lecture9-optimization/notes.html#scaled-initialization",
    "title": "Lecture 9: Optimization",
    "section": "Scaled initialization",
    "text": "Scaled initialization\nNow that we’ve seen the benefits of initializing randomly, we need to consider what distribution to initialize from. An obvious choice might be a standard normal distribution, with mean \\(0\\) and standard deviation \\(1\\).\n\\[w_{i} \\sim \\mathcal{N}(0, 1) \\quad \\forall\\ w_{i} \\in \\mathbf{w}\\]This has a subtle issue though. To see why let’s consider a linear function defined by randomly initialized weights:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\n\\]\nLet’s consider the mean and variance of this output with respect to \\(\\mathbf{w}\\):\n\\[\n\\mathbb{E} \\big[f(\\mathbf{x})\\big] = \\mathbb{E} \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg] =   \\sum_{i=1}^d x_i \\mathbb{E} \\big[w_i \\big] = 0, \\quad w_i \\sim \\mathcal{N}(0, 1)\n\\]\n\\[\n\\text{Var} \\big[f(\\mathbf{x})\\big] = \\text{Var}  \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg] =   \\sum_{i=1}^d \\text{Var} \\big[ x_i w_i \\big] = \\sum_{i=1}^d x_i^2 \\text{Var} [w_i] = \\sum_{i=1}^d x_i^2\n\\]\nWe see a few things here, the mean is \\(0\\) and the variance depends on \\(x_i\\), which is reasonable. However we see that the variance also depends on \\(d\\), the dimensionality of the input. In particular it’s \\(\\mathcal{O}(d)\\). Why is this important? Because it means that if we increase the number of neurons at each layer in our network, the variance of the network’s predictions will also increase!\nIf our network has many neurons in each layer (large networks can have 1000’s!) the variance of outputs can be extreme, leading to poor initializations that correspond to extremely steep prediction functions. Here we can compare a few intializations from a network with just 8 neurons per layer to a network with 2.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn practice this can make gradient descent difficult as these initialization are often very far from the minimum and the gradients are typically large, meaning small learning rates are needed to prevent divergence.\nA better approach would keep the variance consistent no matter how many inputs there are. We can reduce the variance by dividing our initial weights by some scale factor \\(s\\).\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^d x_i w_i\\bigg(\\frac{1}{s}\\bigg)\n\\]\nIf we want the variance to be independent of \\(d\\), then we want:\n\\[\ns = \\sqrt{d}\n\\]\nWe can verify this by computing the variance:\n\\[\n\\text{Var}  \\bigg[  \\sum_{i=1}^d x_i w_i \\bigg(\\frac{1}{\\sqrt{d}}\\bigg) \\bigg] =   \\sum_{i=1}^d \\text{Var} \\bigg[ x_i w_i \\bigg(\\frac{1}{\\sqrt{d}}\\bigg) \\bigg] = \\sum_{i=1}^d x_i^2 \\bigg(\\frac{1}{\\sqrt{d}}\\bigg)^2 \\text{Var} [w_i] = \\frac{1}{d}\\sum_{i=1}^d x_i^2\n\\]\nThis is equivalent to drawing our initial weights for each layer from a normal distribution with standard deviation equal to 1 over the square root of the number of inputs:\n\\[w_{i} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\forall\\ w_{i} \\in \\mathbf{w},\\ \\mathbf{w}\\in \\mathbb{R}^{d}\\]\nThis is known as Kaiming normal initialization (sometimes also called He initialization, after the inventor Kaiming He).\nFor neural network layers where the weights are a matrix \\(\\mathbf{W} \\in \\mathbb{R}^{d \\times e}\\), this works the same way:\n\\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\forall\\ w_{ij} \\in \\mathbf{W},\\ \\mathbf{w}\\in \\mathbb{R}^{d \\times e}\\]\nA popular alternative scales the distribution according to both the number of inputs and outputs of the layer:\n\\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\sqrt{\\frac{2}{d + e}}\\bigg) \\quad \\forall\\ w_{ij} \\in \\mathbf{W},\\ \\mathbf{w}\\in \\mathbb{R}^{d \\times e}\\]\nThis is known as Xavier initialization (or Glorot initialization after the inventor Xavier Glorot).\nWe can compare initializations from a standard normal with initializations from a Kaiming normal.\n\n\nStandard normal \\(w_{i} \\sim \\mathcal{N}\\bigg(0, 1\\bigg)\\)\n\n\n\n\n\n\nKaiming normal \\(w_{i} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg)\\)"
  },
  {
    "objectID": "lecture9-optimization/notes.html#computational-complexity",
    "href": "lecture9-optimization/notes.html#computational-complexity",
    "title": "Lecture 9: Optimization",
    "section": "Computational complexity",
    "text": "Computational complexity\nAn important consideration for any algorithm is the computational complexity. So far we’ve ignored the computational cost of training a neural network, but in practice it can be quite significant! It’s worthwhile to think about what this complexity is and if there’s any way to improve it.\nLet’s start by reviewing the factors that will determine the cost of running gradient descent to train a network and define some notation for each:\n\nDataset size ( \\(N\\) ): As we have previously, we’ll use \\(N\\) to denote the number of observations in the dataset that we’ll use to train our model (the training set).\nDimensionality ( \\(d\\) ): We’ll use the notation \\(d\\) to refer to both the number of input features and the number of neurons per layer. In general this will let us conveniently refer to the number of inputs and outputs for any given layer with a single number. In practice the number of input dimensions may not match the number of neurons per layer (and the number of neurons per layer may not actually be constant!), but since we’re mostly concerned with an asymptotic upper bound on complexity, we’ll just assume \\(d\\) is the size of the largest layer.\nNumber of layers ( \\(L\\) ): The other factor of our network architecture is of course the number of layers, which we’ll call \\(L\\).\nNumber of steps ( \\(S\\) ): Finally how steps of gradient descent we take will of course also have an input on the running time. We’ll use \\(S\\) to denote this number.\n\nWe can consider one of the networks shown above as a specific example:\n\nHere we see that this network has \\(8\\) neurons per layer, so \\(d=8\\), a total of \\(6\\) hidden layers, so \\(L=6\\) and the training set shown has roughly \\(100\\) observations, so \\(N=100\\). We won’t worry about the number of steps ( \\(S\\) ) for now.\nIn this example our neural network is being used on a regression task, so at each step of gradient descent we’ll to compute the mean squared error loss:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]And then it’s gradient with respect to the parameters, \\(\\mathbf{w}\\).\n\\[\\nabla_{\\mathbf{w}}\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\nabla_{\\mathbf{w}}\\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nOur analysis would be equivalent for classification problems."
  },
  {
    "objectID": "lecture9-optimization/notes.html#computing-a-single-neuron",
    "href": "lecture9-optimization/notes.html#computing-a-single-neuron",
    "title": "Lecture 9: Optimization",
    "section": "Computing a single neuron",
    "text": "Computing a single neuron\nLet’s start simple, what is the cost computing a single neuron in our network? We know that the calculation that a single neuron performs is (we’ll ignore a bias term because it could be analyzed as a single extra term of the summation) :\n\\[\\phi(\\mathbf{x})=\\sigma\\big(\\mathbf{x}^T\\mathbf{w} \\big) = \\sigma\\bigg(\\sum_{i=1}^d x_i w_i \\bigg)\\]\nWe see that computing activation function \\(\\sigma(\\cdot)\\) is constant time, but the cost of the summation: \\(\\sum_{i=1}^d x_i w_i\\) will scale linearly with the dimension \\(d\\), so we can write the running time generally as \\(\\mathcal{O}(d)\\).\nThat was straightforward, but we’re not quite done with a single neuron yet! Remember that we’re also going to be computing gradients, so we’ll need to make sure that the cost of our backward pass update for this neuron won’t increase our asymptotic running time.\nRecall that in our backward pass update we’re provided \\(\\frac{dLoss}{d\\phi}\\) and we need to compute\\(\\frac{dLoss}{dx_i}\\) \\(\\frac{dLoss}{dw_i}\\). Once again we see that the activation \\(\\sigma\\) only acts on a single value, so the update will simply be: \\[\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}=\\frac{dLoss}{d\\phi}\\frac{d\\phi}{d(\\mathbf{x}^T\\mathbf{w})}\\] As all of these terms are scalars, the cost is once again constant.\nNow given the scalar \\(\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\), we compute the derivative with respect to \\(x_i\\) or \\(w_i\\) as:\n\\[\n\\frac{dLoss}{dx_i}=\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\frac{d(\\mathbf{x}^T\\mathbf{w})}{dx_i}= \\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})} w_i\\] \\[\n\\frac{dLoss}{dw_i}=\\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})}\\frac{d(\\mathbf{x}^T\\mathbf{w})}{dw_i}= \\frac{dLoss}{d(\\mathbf{x}^T\\mathbf{w})} x_i\n\\]\nA constant ( \\(\\mathcal{O}(1)\\) ) operation per entry. Since \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\) both have \\(d\\) entries, the cost of the backward pass update will still be \\(\\mathcal{O}(d)\\)."
  },
  {
    "objectID": "lecture9-optimization/notes.html#computing-the-full-loss",
    "href": "lecture9-optimization/notes.html#computing-the-full-loss",
    "title": "Lecture 9: Optimization",
    "section": "Computing the full loss",
    "text": "Computing the full loss\nThings get a little easier from here. We know that each layer of our network has \\(d\\) neurons, each of which takes \\(\\mathcal{O}(d)\\) time to compute. Therefore the total cost for a layer will be \\(\\mathcal{O}(d^2)\\).\nOur full network has \\(L\\) layers, therefore the full network will take \\(\\mathcal{O}(Ld^2)\\) time to compute.\nLooking back at our loss:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nWe see that so far we’ve bounded the time it takes to compute one of our predictions: \\(f(\\mathbf{x}_i, \\mathbf{w})\\). In order to compute the full loss (and therefore gradient), we need to do this for every term in our summation, a total of \\(N\\) times. This give us a total cost to compute the loss of \\(\\mathcal{O}(NLd^2)\\). We already saw that our backward pass updates don’t increase our asymptotic cost, so in total the cost of a single gradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nIs \\(\\mathcal{O}(NLd^2)\\).\nAccounting for the number of update steps ( \\(S\\) ) we perform we see that the total cost of gradient descent is: \\(\\mathcal{O}(SNLd^2)\\)."
  },
  {
    "objectID": "lecture9-optimization/notes.html#real-world-costs",
    "href": "lecture9-optimization/notes.html#real-world-costs",
    "title": "Lecture 9: Optimization",
    "section": "Real world costs",
    "text": "Real world costs\nLet’s asses how bad this running time actually is. To do so we’ll need to consider how large each of these factors actually is in practice. We’ll start by looking at a state-of-the-art (for 2012) neural network for classifying images: AlexNet."
  },
  {
    "objectID": "lecture9-optimization/notes.html#estimating-loss",
    "href": "lecture9-optimization/notes.html#estimating-loss",
    "title": "Lecture 9: Optimization",
    "section": "Estimating loss",
    "text": "Estimating loss\nNeural network MSE loss:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nEstimate by sampling:\n\\[\\underset{\\text{MSE}}{\\textbf{Loss}} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2, \\quad i \\sim \\text{Uniform}(1, N)\\]\nExpectation of sampled loss is the true loss!\n\\[\\mathbb{E}_i[(f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2] = \\sum_{i=1}^N p(i)(f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2 =\\frac{1}{N} \\sum_{i=1}^N (f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2\\]\nIn general any loss that can be written as a mean of individual losses can be estimated in this way:\n\\[\\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{1}{N} \\sum_{i=1}^N \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)\\]\n\\[\\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\mathbb{E}[\\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)], \\quad i\\sim \\text{Uniform}(1,N)\\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#estimating-gradients",
    "href": "lecture9-optimization/notes.html#estimating-gradients",
    "title": "Lecture 9: Optimization",
    "section": "Estimating gradients",
    "text": "Estimating gradients\nGradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\nGradient can be composed into a sum of gradients and estimated the same way!\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\nabla_{\\mathbf{w}} \\bigg( \\frac{1}{N} \\sum_{i=1}^N \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)\\bigg)\\]\n\\[=\\frac{1}{N} \\sum_{i=1}^N  \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i) = \\mathbb{E}[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_i, y_i)], \\quad i\\sim \\text{Uniform}(1, N)\\]\nStochastic gradient descent update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{x}_i, y_i), \\quad i\\sim \\text{Uniform}(1, N)\\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#minibatch-sgd",
    "href": "lecture9-optimization/notes.html#minibatch-sgd",
    "title": "Lecture 9: Optimization",
    "section": "Minibatch SGD",
    "text": "Minibatch SGD\nCan estimate gradients with a minibatch of \\(B\\) observations:\n\\[\\text{Batch:}\\ \\{(\\mathbf{x}_{b_1}, y_{b_1}), (\\mathbf{x}_{b_2}, y_{b_2}), ...,  (\\mathbf{x}_{b_B}, y_{b_B})\\}, \\quad \\{b_1, b_2, ...,b_B\\} \\sim \\text{Uniform}(1, N)\\]\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) \\approx \\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i}), \\quad \\{b_1, b_2, ...,b_B\\} \\sim \\text{Uniform}(1, N)\\]\nThis still gives the correct expectation\n\\[\\mathbb{E}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] = \\bigg(\\frac{1}{B}\\bigg) \\sum_{i=1}^B\\mathbb{E}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\\] \\[ = \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\\]\nThe variance decreases with the size of the batch!\n\\[\\text{Var}\\bigg[\\frac{1}{B} \\sum_{i=1}^B \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg] =  \\bigg(\\frac{1}{B^2}\\bigg) \\sum_{i=1}^B\\text{Var}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\\] \\[= \\bigg(\\frac{1}{B}\\bigg)\\text{Var}\\bigg[ \\nabla_{\\mathbf{w}} \\textbf{Loss} (\\mathbf{w}, \\mathbf{x}_{b_i}, y_{b_i})\\bigg]\\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#momentum",
    "href": "lecture9-optimization/notes.html#momentum",
    "title": "Lecture 9: Optimization",
    "section": "Momentum",
    "text": "Momentum\nGradient descent with momentum updates the average gradient then uses the running average to take descent steps.\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta \\mathbf{v}^{(k)} + (1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha v^{(k+1)}\\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#sgd-momentum",
    "href": "lecture9-optimization/notes.html#sgd-momentum",
    "title": "Lecture 9: Optimization",
    "section": "SGD + Momentum",
    "text": "SGD + Momentum\nWe can apply momentum for stochastic gradient descent as well\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta \\mathbf{v}^{(k)} + (1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{x}_i, y_i), \\quad i\\sim \\text{Uniform}(1,N)\\]\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha v^{(k+1)}\\]\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}) \\approx \\sum_{j=1}^k \\beta^{k-j}(1-\\beta) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(j)}, \\mathbf{x}_{i^{(j)}}, y_{i^{(j)}})\\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#adaptive-gradients-rmsprop",
    "href": "lecture9-optimization/notes.html#adaptive-gradients-rmsprop",
    "title": "Lecture 9: Optimization",
    "section": "Adaptive gradients (RMSProp)",
    "text": "Adaptive gradients (RMSProp)\n\\[\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}) = \\begin{bmatrix} \\frac{dL}{dw^{(k)}_1} \\\\ \\frac{dL}{dw^{(k)}_2} \\\\ \\vdots \\end{bmatrix}\\]\n\\[\\begin{bmatrix} 3.1\\\\ 2.2 \\\\ \\vdots \\end{bmatrix} \\leftarrow\n\\begin{bmatrix} 5.0 \\\\ 1.8 \\\\ \\vdots \\end{bmatrix}\\leftarrow\n\\begin{bmatrix} 1.5 \\\\ 4.4 \\\\ \\vdots \\end{bmatrix}...\\]\n\\[\\begin{bmatrix} 10.1\\\\ 0.04 \\\\ \\vdots \\end{bmatrix} \\leftarrow\n\\begin{bmatrix} 8.6 \\\\ 0.02 \\\\ \\vdots \\end{bmatrix}\\leftarrow\n\\begin{bmatrix} 9.4 \\\\ 0.009 \\\\ \\vdots \\end{bmatrix}...\\]\n\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta \\mathbf{s}^{(k)} + (1-\\beta) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\] \\[\\epsilon &lt;&lt; 1, \\quad \\text{e.g. } \\epsilon = 1e^{-7}\\]\n\\[\\frac{\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{\\sqrt{\\mathbf{s}^{(k+1)}}} =\n\\begin{bmatrix} \\frac{\\frac{dL}{dw_1}}{\\sqrt{\\big(\\frac{dL}{dw_1}}\\big)^2} \\\\ \\frac{\\frac{dL}{dw_2}}{\\sqrt{\\big(\\frac{dL}{dw_2}}\\big)^2} \\\\ \\vdots \\end{bmatrix}  =\n\\begin{bmatrix} \\text{sign}\\big(\\frac{dL}{dw_1} \\big) \\\\ \\text{sign}\\big(\\frac{dL}{dw_2} \\big) \\\\ \\vdots \\end{bmatrix} = \\begin{bmatrix} +1 \\\\ -1 \\\\ \\vdots \\end{bmatrix} \\]"
  },
  {
    "objectID": "lecture9-optimization/notes.html#adam",
    "href": "lecture9-optimization/notes.html#adam",
    "title": "Lecture 9: Optimization",
    "section": "Adam",
    "text": "Adam\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta_1 \\mathbf{v}^{(k)} + (1-\\beta_1) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\] \\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta_2 \\mathbf{s}^{(k)} + (1-\\beta_2) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\] \\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\mathbf{v}^{(k+1)}\n}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\] \\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)}\n}{\\sqrt{\\frac{\\mathbf{s}^{(k+1)}}{(1-\\beta_2^k)} + \\epsilon}}\\] \\[\\mathbf{v}^{(0)} = \\mathbf{0}, \\quad \\mathbf{s}^{(0)} = \\mathbf{0}\\] \\[\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)} = \\frac{\\beta_1 \\mathbf{0} + (1-\\beta_1)\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{(1-\\beta_1^1)} = \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]"
  },
  {
    "objectID": "playground/CONTRIBUTING.html",
    "href": "playground/CONTRIBUTING.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "Want to contribute? Great! First, read this page (including the small print at the end).\n\nBefore you contribute\nBefore we can use your code, you must sign the [Google Individual Contributor License Agreement] (https://cla.developers.google.com/about/google-individual) (CLA), which you can do online. The CLA is necessary mainly because you own the copyright to your changes, even after your contribution becomes part of our codebase, so we need your permission to use and distribute your code. We also need to be sure of various other things—for instance that you’ll tell us if you know that your code infringes on other people’s patents. You don’t have to sign the CLA until after you’ve submitted your code for review and a member has approved it, but you must do it before we can put your code into our codebase. Before you start working on a larger contribution, you should get in touch with us first through the issue tracker with your idea so that we can help out and possibly guide you. Coordinating up front makes it much easier to avoid frustration later on.\n\n\nCode reviews\nAll submissions, including submissions by project members, require review. We use Github pull requests for this purpose.\n\n\nThe small print\nContributions made by corporations are covered by a different agreement than the one above, the [Software Grant and Corporate Contributor License Agreement] (https://cla.developers.google.com/about/google-corporate)."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html",
    "href": "lecture3-logistic-regression/slides.html",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the last lecture we considered approximating functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nIn many real-world problems, the output we want to model is not a continuous value, but a categorical value.\n\n\n\n\n\n\n\n\nIn the simplest case there are two possible outputs.\n\n\n\n\n\nWe use the set \\(\\{0, 1\\}\\) to denote the possible outputs for a binary categorical function.\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1\\}\n\\]\nWe might say that \\(0 = \\textbf{\"cat\"}\\) and \\(1=\\textbf{\"dog\"}\\).\nWe call prediction of a categorical output classification.\n\n\n\nConsider the fuel efficiency example from the previous lecture.\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = \\begin{cases} 1: \\text{Meets target } (MPG \\geq 30) \\\\ 0:\n\\text{Fails to meet target } (MPG &lt; 30) \\\\  \\end{cases}\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith this new output definition our dataset will look like:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{1   (Meets target)}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow  \\text{0   (Does not meet target)}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\n\n\n\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe could fit a linear regression model to our binary data, by simply treating the labels \\(0\\) and \\(1\\) as real-valued outputs.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA more suitable prediction function would only output one of our two possible labels \\(\\{0, 1\\}\\). Using a cutoff (typically 0), as follows:\n\\[\nf(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} \\quad \\longrightarrow \\quad f(\\mathbf{x})=\\begin{cases} 1\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} \\geq 0 \\\\\n0\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} &lt; 0\\end{cases}\n\\]\nWe might also write this as:\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\n\\]\nWhere \\(\\mathbb{I}\\) is an indicator function that is simply \\(1\\) if the boolean expression is true and \\(0\\) otherwise.\n\n\n\nThis gives us a prediction function that looks like step function in 1 dimension:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor our efficiency example, the binary prediction function can be written as:\n\\[\n\\text{Meets target} = f(\\mathbf{x})=\n\\]\n\\[\n\\big((\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\\big) \\geq 0\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\left( \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix} \\geq  0\\right)\n\\]\nIn this form we can see that the sign of each weight parameter determines whether the corresponding feature is more predictive of label \\(1\\) or \\(0\\) and to what extent.\n\n\n\nThis has a geometric interpretation if we think of \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) as vectors. If the angle between \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) is in the range \\([-\\frac{\\pi}{2}, \\frac{\\pi}{2}]\\) (or \\([-90^o, 90^o]\\) in degrees), then the prediction will be \\(1\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe decision boundary is the border between regions of the input space corresponding to each prediction. For a linear classification model the decision boundary is line or plane:\n\\[\\mathbf{x}^T\\mathbf{w}=0\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA natural measure for error for binary classifiers is accuracy. The accuracy of a prediction function is the fraction of observations where the prediction matches the true output:\n\\[\n\\textbf{Accuracy} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}\\big(f(\\mathbf{x}_i) = y_i\\big)\n\\]\n\n\nModel accuracy: 0.8291\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#categorical-outputs",
    "href": "lecture3-logistic-regression/slides.html#categorical-outputs",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the last lecture we considered approximating functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nIn many real-world problems, the output we want to model is not a continuous value, but a categorical value."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#binary-outputs",
    "href": "lecture3-logistic-regression/slides.html#binary-outputs",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the simplest case there are two possible outputs.\n\n\n\n\n\nWe use the set \\(\\{0, 1\\}\\) to denote the possible outputs for a binary categorical function.\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1\\}\n\\]\nWe might say that \\(0 = \\textbf{\"cat\"}\\) and \\(1=\\textbf{\"dog\"}\\).\nWe call prediction of a categorical output classification."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions",
    "href": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "Consider the fuel efficiency example from the previous lecture.\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = \\begin{cases} 1: \\text{Meets target } (MPG \\geq 30) \\\\ 0:\n\\text{Fails to meet target } (MPG &lt; 30) \\\\  \\end{cases}\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions-1",
    "href": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions-1",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "With this new output definition our dataset will look like:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{1   (Meets target)}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow  \\text{0   (Does not meet target)}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions-2",
    "href": "lecture3-logistic-regression/slides.html#visualizing-categorical-functions-2",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "Manim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#making-binary-predictions",
    "href": "lecture3-logistic-regression/slides.html#making-binary-predictions",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "We could fit a linear regression model to our binary data, by simply treating the labels \\(0\\) and \\(1\\) as real-valued outputs.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#making-binary-predictions-1",
    "href": "lecture3-logistic-regression/slides.html#making-binary-predictions-1",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "A more suitable prediction function would only output one of our two possible labels \\(\\{0, 1\\}\\). Using a cutoff (typically 0), as follows:\n\\[\nf(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} \\quad \\longrightarrow \\quad f(\\mathbf{x})=\\begin{cases} 1\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} \\geq 0 \\\\\n0\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} &lt; 0\\end{cases}\n\\]\nWe might also write this as:\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\n\\]\nWhere \\(\\mathbb{I}\\) is an indicator function that is simply \\(1\\) if the boolean expression is true and \\(0\\) otherwise."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#making-binary-predictions-2",
    "href": "lecture3-logistic-regression/slides.html#making-binary-predictions-2",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "This gives us a prediction function that looks like step function in 1 dimension:\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#making-binary-predictions-3",
    "href": "lecture3-logistic-regression/slides.html#making-binary-predictions-3",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "For our efficiency example, the binary prediction function can be written as:\n\\[\n\\text{Meets target} = f(\\mathbf{x})=\n\\]\n\\[\n\\big((\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\\big) \\geq 0\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\left( \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix} \\geq  0\\right)\n\\]\nIn this form we can see that the sign of each weight parameter determines whether the corresponding feature is more predictive of label \\(1\\) or \\(0\\) and to what extent."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#making-binary-predictions-4",
    "href": "lecture3-logistic-regression/slides.html#making-binary-predictions-4",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "This has a geometric interpretation if we think of \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) as vectors. If the angle between \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) is in the range \\([-\\frac{\\pi}{2}, \\frac{\\pi}{2}]\\) (or \\([-90^o, 90^o]\\) in degrees), then the prediction will be \\(1\\).\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#descision-boundaries",
    "href": "lecture3-logistic-regression/slides.html#descision-boundaries",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "We can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#descision-boundaries-1",
    "href": "lecture3-logistic-regression/slides.html#descision-boundaries-1",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "The decision boundary is the border between regions of the input space corresponding to each prediction. For a linear classification model the decision boundary is line or plane:\n\\[\\mathbf{x}^T\\mathbf{w}=0\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#measuring-error",
    "href": "lecture3-logistic-regression/slides.html#measuring-error",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "A natural measure for error for binary classifiers is accuracy. The accuracy of a prediction function is the fraction of observations where the prediction matches the true output:\n\\[\n\\textbf{Accuracy} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}\\big(f(\\mathbf{x}_i) = y_i\\big)\n\\]\n\n\nModel accuracy: 0.8291\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#the-bernoulli-distribution",
    "href": "lecture3-logistic-regression/slides.html#the-bernoulli-distribution",
    "title": "Lecture 3: Logistic regression",
    "section": "The Bernoulli distribution",
    "text": "The Bernoulli distribution\nThe Beroulli distribution is a distribution over binary outcomes (0 or 1). It is parameterized simply by \\(q=p(y=1)\\)\n\\[\np(y)=\\begin{cases} q\\quad\\ \\ \\ \\ \\ \\ \\  \\text{if }\\ y=1\\\\\n1-q\\quad \\text{if }\\ y=0\\\\\n\\end{cases}\\quad q\\in[0,1],\\ y\\in\\{0, 1\\}\n\\]\nWe can also write this as:\n\\[\np(y) = q^y(1-q)^{1-y}\n\\]\nThe log-probability or log-likelihood is then:\n\\[\n\\log p(y) = y\\log q + (1-y)\\log(1-q)\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification",
    "href": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for binary classification",
    "text": "A probabilistic model for binary classification\nLast lecture saw a probabilistic model for linear regression could be defined as:\n\\[\ny_i \\sim \\mathcal{N}(\\mathbf{x}^T\\mathbf{w},\\ \\sigma^2)\n\\]\nWe’d ideally like to define a similar model for the case of binary outputs using the Bernoulli distribution. However we need to enforce that the Bernoulli parameter is in \\([0,1]\\)\n\\[\n\\mathbf{x}^T\\mathbf{w}\\notin [0, 1] \\quad \\longrightarrow \\quad y_i \\sim \\mathbf{Bernoulli}(\\mathbf{ q=? })\\quad\n\\]\nSo we need a function that can map \\(\\mathbf{x}^T\\mathbf{w}\\) to \\([0,1]\\)\n\\[\n\\textbf{Need }\\ f(x):\\ \\mathbb{R} \\longrightarrow [0,1]\n\\]\n\\[\n\\textbf{Input: } x \\in \\mathbb{R} \\longrightarrow \\textbf{Output: } y \\in [0,1]\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#sigmoid-function",
    "href": "lecture3-logistic-regression/slides.html#sigmoid-function",
    "title": "Lecture 3: Logistic regression",
    "section": "Sigmoid function",
    "text": "Sigmoid function\nThe sigmoid (or logistic) function is a convenient choice\n\\[\n\\sigma(x) = \\frac{1}{1+e^{-x}}\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#sigmoid-function-1",
    "href": "lecture3-logistic-regression/slides.html#sigmoid-function-1",
    "title": "Lecture 3: Logistic regression",
    "section": "Sigmoid function",
    "text": "Sigmoid function\nThe sigmoid function has some nice properties\n\\[\n\\sigma(0) = 0.5\n\\]\n\\[\n1-\\sigma(x) = \\sigma(-x)\n\\]\n\\[\n\\frac{d}{dx}\\sigma(x) = \\sigma(x)\\big(1-\\sigma(x)\\big)\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification-1",
    "href": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification-1",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for binary classification",
    "text": "A probabilistic model for binary classification\nWith the sigmoid function we can define our probabilistic model\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\mathbf{x}_i^T\\mathbf{w} })\\big)\n\\]\n\\[\np(y_i = 1) = \\sigma(\\mathbf{x}_i^T\\mathbf{w}), \\quad p(y_i=0)=1-\\sigma(\\mathbf{x}_i^T\\mathbf{w})=\\sigma(-\\mathbf{x}_i^T\\mathbf{w})\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification-2",
    "href": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-binary-classification-2",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for binary classification",
    "text": "A probabilistic model for binary classification\nWe see that if we choose a probability cutoff of \\(0.5\\), our decision boundary doesn’t change!\n\\[\np(y_i=1)\\geq 0.5 \\quad \\longrightarrow \\quad \\mathbf{x}^T\\mathbf{w}\\geq 0\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation",
    "href": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nLet’s review how to find the parameters of a model using maximum likelihood estimation\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\nGenerally our model also assumes conditional independence across observations so:\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-1",
    "href": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-1",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nFor convenience, it is typical to frame the optimal value in terms of the negative log-likelihood rather than the likelihood, but the two are equivalent.\n\\[\n\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}) = \\underset{\\mathbf{w}}{\\text{argmin}} - \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w}) = \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\nWe see that the negative log-likelihood is a natural loss function to optimize to find \\(\\mathbf{w}^*\\).\n\\[\n\\textbf{Loss}(\\mathbf{w}) =\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-2",
    "href": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-2",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nWe can now write the maximum likelihood loss for logistic regression.\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N y_i\\log \\sigma(\\mathbf{x}^T\\mathbf{w}) + (1-y_i)\\log(1-\\sigma(\\mathbf{x}^T\\mathbf{w}))\n\\]\n\\[\n=-\\sum_{i=1}^N y_i\\log \\sigma(\\mathbf{x}^T\\mathbf{w}) + (1-y_i)\\log \\sigma(-\\mathbf{x}^T\\mathbf{w})\n\\]\n\\[\n\\textbf{Ideally: }\\ p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})=1,\\ \\forall (\\mathbf{x}_i, y_i)\\in \\mathcal{D}\n\\]\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\mathbf{y}^T\\log \\sigma(\\mathbf{X}\\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#comparing-loss-functions",
    "href": "lecture3-logistic-regression/slides.html#comparing-loss-functions",
    "title": "Lecture 3: Logistic regression",
    "section": "Comparing loss functions",
    "text": "Comparing loss functions\nLoss for \\(y=0\\) as a function of \\(z=\\mathbf{x}^T\\mathbf{w}\\)\n\\[\n\\textbf{Let: }\\ z=\\mathbf{x}^T\\mathbf{w}\n\\]\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions",
    "href": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class prediction functions",
    "text": "Multi-class prediction functions\nWe will typically use a set of integers \\(\\{0,1, 2,...,C\\}\\) to denote the possible outputs for a general categorical function.\n\n\n\n\n\nTherefore in general we are considering functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1, 2, ...,C\\}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-1",
    "href": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-1",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class prediction functions",
    "text": "Multi-class prediction functions\nIt’s important to note that we are not assuming that the ordering of labels is meaningful For instance if we’re classifying images of animals we might set the labels such that:\n\\[\n\\textbf{0:  Cat},\\quad\n\\textbf{1:  Dog},\\quad\n\\textbf{2:  Mouse}\n\\]\nBut this is equally valid:\n\\[\n\\textbf{0:  Dog},\\quad\n\\textbf{1:  Mouse},\\quad\n\\textbf{2:  Cat}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-2",
    "href": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-2",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class prediction functions",
    "text": "Multi-class prediction functions\nA simple prediction function for multiclass classification is:\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{0...C\\}}{\\text{argmax}}\\ \\mathbf{x}^T\\mathbf{w}_c\n\\]\nAlternatively:\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{0...C\\}}{\\text{argmax}}\\ (\\mathbf{x}^T\\mathbf{W})_c, \\quad \\mathbf{W} \\in \\mathbb{R}^{d\\times C}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-3",
    "href": "lecture3-logistic-regression/slides.html#multi-class-prediction-functions-3",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class prediction functions",
    "text": "Multi-class prediction functions\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{0...C\\}}{\\text{argmax}}\\ (\\mathbf{x}^T\\mathbf{W})_c, \\quad \\mathbf{W} \\in \\mathbb{R}^{d\\times C}\n\\]\nThis function reduces to the same one we saw before for the case of \\(C=2\\):\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{0,1\\}}{\\text{argmax}}\\ (\\mathbf{x}^T\\mathbf{W})_c = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w}_1 - \\mathbf{x}^T\\mathbf{w}_0 \\geq 0)\n\\]\n\\[\n=\\mathbb{I}(\\mathbf{x}^T(\\mathbf{w}_1 - \\mathbf{w}_0) \\geq 0) \\quad \\longrightarrow \\quad \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0), \\quad \\mathbf{w}=\\mathbf{w}_1-\\mathbf{w}_0\n\\]\nThis means the boundary between any two predictions is linear."
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#categorical-distribution",
    "href": "lecture3-logistic-regression/slides.html#categorical-distribution",
    "title": "Lecture 3: Logistic regression",
    "section": "Categorical distribution",
    "text": "Categorical distribution\nThe Categorical distribution is a distribution over several distinct (discrete) outcomes. It’s parameterized by a vector of probabilities for each outcome:\n\\[\np(y=c) = q_c, \\quad y\\in \\{1...C\\}\n\\]\n\\[\n\\mathbf{q} \\in \\mathbb{R}^C\\quad q_c \\geq 0\\ \\forall c\\in \\{1...C\\}\\quad \\sum_{c=1}^C q_c=1\n\\]\nIt can also be written as:\n\\[\np(y)=\\prod q_c^{\\mathbb{I}(y=c)}\n\\]\nThe log-likelihood is then:\n\\[\n\\log p(y) = \\sum_{c=1}^C \\mathbb{I}(y=c)\\log q_c = \\log q_y\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-multi-class-classification",
    "href": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-multi-class-classification",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for multi-class classification",
    "text": "A probabilistic model for multi-class classification\nOnce again we need to translate our linear function output into a valid parameter for this distribution:\n\\[\ny_i\\sim \\mathbf{Categorical}(\\mathbf{q}=?)\n\\]\n\\[\n\\mathbf{q}=\\mathbf{x}^T\\mathbf{W}?\n\\]\n\\[\n\\mathbf{x}^T\\mathbf{W}\\in \\mathbb{R}^C,\\quad  q_c \\ngeq 0\\ \\forall c\\in \\{1...C\\}, \\quad \\sum_{c=1}^C q_c\\neq1\n\\]\n\\[\n\\textbf{Need }\\ f(\\mathbf{x}):\\ \\mathbb{R}^C \\longrightarrow [0,\\infty)^C,\\ \\sum_{i=1}^Cf(\\mathbf{x})_c = 1\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#softmax-function",
    "href": "lecture3-logistic-regression/slides.html#softmax-function",
    "title": "Lecture 3: Logistic regression",
    "section": "Softmax function",
    "text": "Softmax function\nHere we can use the softmax function!\n\\[\n\\text{softmax}(\\mathbf{x})_c = \\frac{e^{x_c}}{\\sum_{j=1}^Ce^{x_j}}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-multi-class-classification-1",
    "href": "lecture3-logistic-regression/slides.html#a-probabilistic-model-for-multi-class-classification-1",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for multi-class classification",
    "text": "A probabilistic model for multi-class classification\nNow we can define our probabilistic model as:\n\\[\ny_i\\sim \\mathbf{Categorical}\\big(\\text{softmax}(\\mathbf{x}^T\\mathbf{W})\\big)\n\\]\n\\[\np(y_i=c) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c=\\frac{e^{\\mathbf{x}^T\\mathbf{w}_c}}{\\sum_{j=1}^Ce^{\\mathbf{x}^T\\mathbf{w}_j}}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-3",
    "href": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-3",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\n\\[\n\\textbf{Loss}(\\mathbf{W}) =\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{W})\n\\]\n\\[\n= \\sum_{i=1}^N \\log\\ \\text{softmax}(\\mathbf{x}_i^T\\mathbf{W})_{y_i} = \\sum_{i=1}^N  \\log \\frac{e^{\\mathbf{x}_i^T\\mathbf{w}_{y_i}}}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\n\\]\n\\[\n=\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-4",
    "href": "lecture3-logistic-regression/slides.html#maximum-likelihood-estimation-4",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\nIn this case our parameters are a matrix\n\\[\n\\nabla_{\\mathbf{W}} \\mathbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})= \\begin{bmatrix} \\frac{\\partial \\mathbf{NLL}}{\\partial W_{11}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{12}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{1C}} \\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{21}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{22}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{2C}} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{d1}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{d2}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{dC}}\n\\end{bmatrix}\n\\]\nWe can still perform gradient descent as before.\n\\[\n\\mathbf{W}^{(i+1)} \\leftarrow \\mathbf{W}^{(i)} - \\alpha \\nabla_{\\mathbf{W}} \\mathbf{NLL}(\\mathbf{W}^{(i)}, \\mathbf{X}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/slides.html#training-and-test-datasets",
    "href": "lecture3-logistic-regression/slides.html#training-and-test-datasets",
    "title": "Lecture 3: Logistic regression",
    "section": "Training and test datasets",
    "text": "Training and test datasets\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\]\n\\[\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html",
    "href": "lecture3-logistic-regression/notes.html",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the last lecture we considered approximating functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nIn that setup our function takes in a vector and produces a real number as an output (for example a miles per gallon rating).\nIn many real-world problems, the output we want to model is not a continuous value, but a categorical value, meaning the function produces one choice from an unordered of possible outputs. A well-studied example of this kind of prediction is labeling; we might want to assign a label to an image based on the image’s content.\n\nWe call the prediction of categorical outputs classification. The output is often also called the class of the obserc\n\n\n\nIn the simplest binary case our function produces one of two possible outputs.\nFor example: consider the problem of labeling images as containing either cats or dogs. Conceptually we would like a function that maps images to either a cat label or a dog label:\n\n\n\n\n\nFor convenience and generality, we will typically use the set \\(\\{0, 1\\}\\) to denote the possible outputs for a binary classification function. Therefore in general we are considering functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1\\}\n\\]\nWe can assign these outputs to correspond to our actual target labels. For instance we might say that \\(0 = \\textbf{\"cat\"}\\) and \\(1=\\textbf{\"dog\"}\\).\n\n\n\nAs a simpler example, let’s again consider the fuel efficiency example from the previous lecture. Perhaps our company has set a target fuel efficiency of 30 miles per gallon for our new model and we want to predict whether our design will meet that target. In this case our inputs will be the same as before, but our output will become a binary label:\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = \\begin{cases} 1: \\text{Meets target } (MPG \\geq 30) \\\\ 0:\n\\text{Fails to meet target } (MPG &lt; 30) \\\\  \\end{cases}\n\\]\nWe can visualize which observations meet our target efficiency by again plotting weight against MPG and using colors to distinguish observations would have label \\(1\\) vs. label \\(0\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWith this new output definition our dataset will look like:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{1   (Meets target)}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow  \\text{0   (Does not meet target)}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\nIn this case, we’ve gotten rid of the \\(MPG\\) output variable and replaced it with a binary output \\(y_i \\in \\{0, 1\\}\\). If we plot this version of the data, we can see more directly how this classification task differs from the regression task we saw in the last lecture.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe could fit a linear regression model to our binary data, by simply treating the labels \\(0\\) and \\(1\\) as real-valued outputs. For our fuel economy example, such a model would look like this:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nHowever, this doesn’t really address our problem. How do we interpret a prediction of \\(-1\\) or \\(10\\) or \\(0.5\\)?\nA more suitable prediction function would only output one of our two possible labels \\(\\{0, 1\\}\\). Fortunately, we can adapt our linear regression function in this way by defining a cutoff (typically 0), as follows:\n\\[\nf(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} \\quad \\longrightarrow \\quad f(\\mathbf{x})=\\begin{cases} 1\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} \\geq 0 \\\\\n0\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} &lt; 0\\end{cases}\n\\]\nWe might also write this as:\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\n\\]\nWhere \\(\\mathbb{I}\\) is an indicator function that is \\(1\\) if the boolean expression is true and \\(0\\) otherwise.\nThis gives us a prediction function that looks like step function in 1 dimension:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor our efficiency example, the binary prediction function can be written as:\n\\[\n\\text{Meets target} = f(\\mathbf{x})=\n\\]\n\\[\n\\big((\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\\big) \\geq 0\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\left( \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix} \\geq  0\\right)\n\\]\nIn this form we can see that the sign of each weight parameter determines whether the corresponding feature is more predictive of label \\(1\\) or \\(0\\) and to what extent. For instance, large positive weights indicate features that are very predictive of \\(1\\).\n\n\n\nOur binary prediction function also has a geometric interpretation if we think of \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) as vectors. Reall that the dot product between the vectors \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\) can be written as:\n\\[\n\\mathbf{x}^T\\mathbf{w} = ||\\mathbf{x}||_2 ||\\mathbf{w}||_2 \\cos \\theta\n\\]\nWhere \\(\\theta\\) is the angle between the two vectors. If the angle between \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) is in the range \\([-\\frac{\\pi}{2}, \\frac{\\pi}{2}]\\) (or \\([-90^o, 90^o]\\) in degrees), then the prediction will be \\(1\\), otherwise it will be 0.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThe blue line in the figure above is the set of points such that:\n\\[\n\\mathbf{x}^T \\mathbf{w} = 0\n\\]\nthus it represents the boundary between the regions where \\(1\\) and \\(0\\) predictions are made. By definition, it is perpendicular to the direction of \\(\\mathbf{w}\\).\n\n\n\nWe can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nFor a binary classification model the decision boundary is the border between regions of the input space corresponding to each prediction that we saw in the previous section. For a linear classification model the decision boundary is line or plane:\n\\[\\mathbf{x}^T\\mathbf{w}=0\\]\nHere we’ll plot the decision boundary in the input space and color code observations by the predicted label.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA natural measure for error for binary classifiers is accuracy. The accuracy of a prediction function is the fraction of observations where the prediction matches the true output:\n\\[\n\\textbf{Accuracy: }\\quad \\frac{\\text{\\# of correct predictions}}{\\text{Total predictions}}\n\\]\nWe can write this in terms of our prediction function as:\n\\[\n\\textbf{Accuracy} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}\\big(f(\\mathbf{x}_i) = y_i\\big)\n\\]\nBelow we can plot the decision boundary compared to the true outputs and calculate the accuracy of our predictions.\n\n\nAccuracy: 0.8291\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the last lecture we saw that we can find an optimal choice of parameters \\(\\mathbf{w}\\) for a linear regression model by defining a measure of error or loss for our approximation on our dataset and minimizing that error as a function of \\(\\mathbf{w}\\), either directly or with gradient descent.\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\ \\mathbf{Loss}(\\mathbf{w})\n\\]\nGradient descent update:\n\\[\n\\mathbf{w}^{(k+1)} \\quad \\longleftarrow \\quad \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{Loss}(\\mathbf{w})\n\\]\nWe might consider using (negative) accuracy as a loss function or the same mean squared error that we used for linear regression. However, if we tried to minimize one of these losses with gradient descent, we would run into a fundamental problem: the derivative of the indicator function is always \\(0\\), meaning gradient descent will never update our model.\nTo get around this problem, we need to turn back to our maximum likelihood estimation approach."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#functions-with-categorical-outputs",
    "href": "lecture3-logistic-regression/notes.html#functions-with-categorical-outputs",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the last lecture we considered approximating functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in\\mathbb{R}\n\\]\nIn that setup our function takes in a vector and produces a real number as an output (for example a miles per gallon rating).\nIn many real-world problems, the output we want to model is not a continuous value, but a categorical value, meaning the function produces one choice from an unordered of possible outputs. A well-studied example of this kind of prediction is labeling; we might want to assign a label to an image based on the image’s content.\n\nWe call the prediction of categorical outputs classification. The output is often also called the class of the obserc"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#binary-outputs",
    "href": "lecture3-logistic-regression/notes.html#binary-outputs",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the simplest binary case our function produces one of two possible outputs.\nFor example: consider the problem of labeling images as containing either cats or dogs. Conceptually we would like a function that maps images to either a cat label or a dog label:\n\n\n\n\n\nFor convenience and generality, we will typically use the set \\(\\{0, 1\\}\\) to denote the possible outputs for a binary classification function. Therefore in general we are considering functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{0, 1\\}\n\\]\nWe can assign these outputs to correspond to our actual target labels. For instance we might say that \\(0 = \\textbf{\"cat\"}\\) and \\(1=\\textbf{\"dog\"}\\)."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#visualizing-categorical-outputs",
    "href": "lecture3-logistic-regression/notes.html#visualizing-categorical-outputs",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "As a simpler example, let’s again consider the fuel efficiency example from the previous lecture. Perhaps our company has set a target fuel efficiency of 30 miles per gallon for our new model and we want to predict whether our design will meet that target. In this case our inputs will be the same as before, but our output will become a binary label:\n\\[\n\\text{Input: } \\mathbf{x}_i= \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph}  \\end{bmatrix}, \\quad \\text{Output: } y_i = \\begin{cases} 1: \\text{Meets target } (MPG \\geq 30) \\\\ 0:\n\\text{Fails to meet target } (MPG &lt; 30) \\\\  \\end{cases}\n\\]\nWe can visualize which observations meet our target efficiency by again plotting weight against MPG and using colors to distinguish observations would have label \\(1\\) vs. label \\(0\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWith this new output definition our dataset will look like:\n\\[\n\\text{Honda Accord: } \\begin{bmatrix} \\text{Weight:} & \\text{2500 lbs} \\\\ \\text{Horsepower:} & \\text{ 123 HP} \\\\ \\text{Displacement:} & \\text{ 2.4 L} \\\\ \\text{0-60mph:} & \\text{ 7.8 Sec} \\end{bmatrix} \\longrightarrow \\text{1   (Meets target)}\n\\]\n\\[\n\\text{Dodge Aspen: } \\begin{bmatrix} \\text{Weight:} & \\text{3800 lbs} \\\\ \\text{Horsepower:} & \\text{ 155 HP} \\\\ \\text{Displacement:} & \\text{ 3.2 L} \\\\ \\text{0-60mph:} & \\text{ 6.8 Sec} \\end{bmatrix} \\longrightarrow  \\text{0   (Does not meet target)}\n\\]\n\\[\n\\vdots \\quad \\vdots\n\\]\nIn this case, we’ve gotten rid of the \\(MPG\\) output variable and replaced it with a binary output \\(y_i \\in \\{0, 1\\}\\). If we plot this version of the data, we can see more directly how this classification task differs from the regression task we saw in the last lecture.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#making-binary-predictions",
    "href": "lecture3-logistic-regression/notes.html#making-binary-predictions",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "We could fit a linear regression model to our binary data, by simply treating the labels \\(0\\) and \\(1\\) as real-valued outputs. For our fuel economy example, such a model would look like this:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nHowever, this doesn’t really address our problem. How do we interpret a prediction of \\(-1\\) or \\(10\\) or \\(0.5\\)?\nA more suitable prediction function would only output one of our two possible labels \\(\\{0, 1\\}\\). Fortunately, we can adapt our linear regression function in this way by defining a cutoff (typically 0), as follows:\n\\[\nf(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} \\quad \\longrightarrow \\quad f(\\mathbf{x})=\\begin{cases} 1\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} \\geq 0 \\\\\n0\\ \\text{   if   }\\ \\mathbf{x}^T\\mathbf{w} &lt; 0\\end{cases}\n\\]\nWe might also write this as:\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\n\\]\nWhere \\(\\mathbb{I}\\) is an indicator function that is \\(1\\) if the boolean expression is true and \\(0\\) otherwise.\nThis gives us a prediction function that looks like step function in 1 dimension:\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#interpreting-parameters",
    "href": "lecture3-logistic-regression/notes.html#interpreting-parameters",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "For our efficiency example, the binary prediction function can be written as:\n\\[\n\\text{Meets target} = f(\\mathbf{x})=\n\\]\n\\[\n\\big((\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\\big) \\geq 0\n\\]\nOr in matrix notation:\n\\[\nf(\\mathbf{x})= \\left( \\begin{bmatrix} \\text{Weight} \\\\ \\text{Horsepower} \\\\ \\text{Displacement} \\\\ \\text{0-60mph} \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} w_1 \\\\ w_2\\\\ w_3 \\\\ w_4\\\\ b\\end{bmatrix} \\geq  0\\right)\n\\]\nIn this form we can see that the sign of each weight parameter determines whether the corresponding feature is more predictive of label \\(1\\) or \\(0\\) and to what extent. For instance, large positive weights indicate features that are very predictive of \\(1\\)."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#geometric-interpretation-of-predictions",
    "href": "lecture3-logistic-regression/notes.html#geometric-interpretation-of-predictions",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "Our binary prediction function also has a geometric interpretation if we think of \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) as vectors. Reall that the dot product between the vectors \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\) can be written as:\n\\[\n\\mathbf{x}^T\\mathbf{w} = ||\\mathbf{x}||_2 ||\\mathbf{w}||_2 \\cos \\theta\n\\]\nWhere \\(\\theta\\) is the angle between the two vectors. If the angle between \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) is in the range \\([-\\frac{\\pi}{2}, \\frac{\\pi}{2}]\\) (or \\([-90^o, 90^o]\\) in degrees), then the prediction will be \\(1\\), otherwise it will be 0.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThe blue line in the figure above is the set of points such that:\n\\[\n\\mathbf{x}^T \\mathbf{w} = 0\n\\]\nthus it represents the boundary between the regions where \\(1\\) and \\(0\\) predictions are made. By definition, it is perpendicular to the direction of \\(\\mathbf{w}\\)."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#decision-boundaries",
    "href": "lecture3-logistic-regression/notes.html#decision-boundaries",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "We can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nFor a binary classification model the decision boundary is the border between regions of the input space corresponding to each prediction that we saw in the previous section. For a linear classification model the decision boundary is line or plane:\n\\[\\mathbf{x}^T\\mathbf{w}=0\\]\nHere we’ll plot the decision boundary in the input space and color code observations by the predicted label.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#measuring-error",
    "href": "lecture3-logistic-regression/notes.html#measuring-error",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "A natural measure for error for binary classifiers is accuracy. The accuracy of a prediction function is the fraction of observations where the prediction matches the true output:\n\\[\n\\textbf{Accuracy: }\\quad \\frac{\\text{\\# of correct predictions}}{\\text{Total predictions}}\n\\]\nWe can write this in terms of our prediction function as:\n\\[\n\\textbf{Accuracy} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}\\big(f(\\mathbf{x}_i) = y_i\\big)\n\\]\nBelow we can plot the decision boundary compared to the true outputs and calculate the accuracy of our predictions.\n\n\nAccuracy: 0.8291\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#defining-a-loss-function",
    "href": "lecture3-logistic-regression/notes.html#defining-a-loss-function",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "In the last lecture we saw that we can find an optimal choice of parameters \\(\\mathbf{w}\\) for a linear regression model by defining a measure of error or loss for our approximation on our dataset and minimizing that error as a function of \\(\\mathbf{w}\\), either directly or with gradient descent.\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\ \\mathbf{Loss}(\\mathbf{w})\n\\]\nGradient descent update:\n\\[\n\\mathbf{w}^{(k+1)} \\quad \\longleftarrow \\quad \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{Loss}(\\mathbf{w})\n\\]\nWe might consider using (negative) accuracy as a loss function or the same mean squared error that we used for linear regression. However, if we tried to minimize one of these losses with gradient descent, we would run into a fundamental problem: the derivative of the indicator function is always \\(0\\), meaning gradient descent will never update our model.\nTo get around this problem, we need to turn back to our maximum likelihood estimation approach."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#the-bernoulli-distribution",
    "href": "lecture3-logistic-regression/notes.html#the-bernoulli-distribution",
    "title": "Lecture 3: Logistic regression",
    "section": "The Bernoulli distribution",
    "text": "The Bernoulli distribution\nThe Bernoulli distribution is a probability distribution over two possible outcomes. It is often thought of as the distribution of a coin flip, where the probability of heads is defined by a parameter \\(q\\) in the range \\([0,1]\\).\n\\[\n\\text{Probability of }\\textbf{heads: } \\ \\ q, \\quad \\text{Probability of }\\textbf{tails: } 1-q\n\\]\nAgain we typically use \\(0\\) and \\(1\\) to denote the two possible outcomes, so we can write the probability mass function (or likelihood) of the Bernoulli distribution as:\n\\[\np(y)=\\begin{cases} q\\quad\\ \\ \\ \\ \\ \\ \\  \\text{if }\\ y=1\\\\\n1-q\\quad \\text{if }\\ y=0\\\\\n\\end{cases}\\quad q\\in[0,1],\\ y\\in\\{0, 1\\}\n\\]\nUsing the fact that \\(y\\) can only be \\(0\\) or \\(1\\), we can write this more compactly as:\n\\[\np(y) = q^y(1-q)^{1-y}\n\\]\nRecall that the probability mass function tells us the probability of any outcome under our distribution. We can write the log probability mass function as:\n\\[\n\\log p(y) = y\\log q + (1-y)\\log(1-q)\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-binary-classification",
    "href": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-binary-classification",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for binary classification",
    "text": "A probabilistic model for binary classification\nIn the previous lecture we saw that we could define a probabilistic model for outcomes given inputs by making an strong assumption about how the observed outputs were generated. In particular, we assumed that each \\(y_i\\) was sampled from a Normal distribution where the mean was a linear function of the input \\(\\mathbf{x}_i\\).\n\\[\ny_i \\sim \\mathcal{N}(\\mathbf{x}_i^T\\mathbf{w},\\ \\sigma^2)\n\\]\nGiven everything we’ve seen, we might want to do the same for binary outputs by defining a probabilistic model where each binary label $y$_i$ is drawn from a Bernoulli where \\(q\\) is a linear function of \\(\\mathbf{x}_i\\). Unfortunately \\(q\\) needs to be restricted to the interval \\([0,1]\\) and a linear function can make no such guarantee about its output.\n\\[\n\\mathbf{x}^T\\mathbf{w}\\notin [0, 1] \\quad \\longrightarrow \\quad y_i \\sim \\mathbf{Bernoulli}(\\mathbf{ q=? })\\quad\n\\]\nHowever, if we had a way to map the outputs of our linear function into the range \\([0,1]\\), we could define such a model. This means we need a function of the form:\n\\[\n\\textbf{Need }\\ g(x):\\ \\mathbb{R} \\longrightarrow [0,1]\n\\]\n\\[\n\\textbf{Input: } x \\in \\mathbb{R} \\longrightarrow \\textbf{Output: } y \\in [0,1]\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#sigmoid-function",
    "href": "lecture3-logistic-regression/notes.html#sigmoid-function",
    "title": "Lecture 3: Logistic regression",
    "section": "Sigmoid function",
    "text": "Sigmoid function\nThe sigmoid (or logistic) function is exactly such a function.\n\\[\n\\sigma(x) = \\frac{1}{1+e^{-x}}\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThis “S”-shaped function squashes any real number into the range \\([0,1]\\). The sigmoid function has a number of other nice properties. It is smooth, monotonic and differentiable. It’s derivative has a convenient form that can be written in terms of the sigmoid function itself.\n\\[\n\\frac{d}{dx}\\sigma(x) = \\sigma(x)\\big(1-\\sigma(x)\\big)\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIt’s particularly useful for modeling probabilities because:\n\\[\n\\sigma(0) = 0.5\n\\]\nand\n\\[\n1-\\sigma(x) = \\sigma(-x)\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-binary-classification-1",
    "href": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-binary-classification-1",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for binary classification",
    "text": "A probabilistic model for binary classification\nWith the sigmoid as our mapping function, we can now define our linear probabilistic model for binary classification as:\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\mathbf{x}_i^T\\mathbf{w} })\\big)\n\\]\nUsing this definition, we can easily write out the probability of each output given the input \\((\\mathbf{x}_i)\\) and model parameters \\((\\mathbf{w})\\).\n\\[\np(y_i = 1\\mid \\mathbf{x}_i, \\mathbf{w}) = \\sigma(\\mathbf{x}_i^T\\mathbf{w}), \\quad p(y_i=0\\mid \\mathbf{x}_i, \\mathbf{w})=1-\\sigma(\\mathbf{x}_i^T\\mathbf{w})=\\sigma(-\\mathbf{x}_i^T\\mathbf{w})\n\\]\nFor our fuel efficiency example, we can plot the predicted probability that our target is met, \\(p(y=1\\mid \\mathbf{x}, \\mathbf{w})\\) under our model as a function of the input (in this case weight). We see that the result is again an s-curve.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe call this probabilistic model for binary outputs: logistic regression."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#logistic-regression-decision-boundary",
    "href": "lecture3-logistic-regression/notes.html#logistic-regression-decision-boundary",
    "title": "Lecture 3: Logistic regression",
    "section": "Logistic regression decision boundary",
    "text": "Logistic regression decision boundary\nWhen we’re making predictions we typically don’t want to sample an output, we want to make a definite prediction. In this case either \\(0\\) or \\(1\\). A reasonable way to do this is to simply predict the output that is most likely under our model:\n\\[\n\\textbf{Prediction function: } f(\\mathbf{x}) = \\begin{cases}1 \\ \\text{if } p(y=1\\mid\\mathbf{x}, \\mathbf{w}) \\geq p(y=0\\mid\\mathbf{x}, \\mathbf{w}) \\\\\n0 \\text{ otherwise} \\end{cases}\n\\]\nSince there’s only two possible outcomes, this is equivalent to checking if the probability of class \\(1\\) is greater than 50%. \\[p(y=1\\mid \\mathbf{x}, \\mathbf{w}) =\\sigma(\\mathbf{x}^T\\mathbf{w})\\geq 0.5\\]\nSince \\(\\sigma(0) =0.5\\), we see that this is equivalent to the decision rule for classification we defined earlier!\n\\[\np(y_i=1)\\geq 0.5 \\quad \\longrightarrow \\quad \\mathbf{x}^T\\mathbf{w}\\geq 0\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#maximum-likelihood-estimation-review",
    "href": "lecture3-logistic-regression/notes.html#maximum-likelihood-estimation-review",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation review",
    "text": "Maximum likelihood estimation review\nNow that we’ve setup our model, we can look at how to find the optimal \\(\\mathbf{w}\\) using the principle of maximum likelihood estimation.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#section",
    "href": "lecture3-logistic-regression/notes.html#section",
    "title": "Lecture 3: Logistic regression",
    "section": "",
    "text": "Recall that the maximum likelihood estimate of our parameter \\(\\mathbf{w}\\) is the choice of \\(\\mathbf{w}\\) that maximizes the (conditional) probability of the data we observed under our model\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmax}} \\ p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) =\\underset{\\mathbf{w}}{\\text{argmax}} \\ p(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) \\]\nAgain, our model also assumes conditional independence across observations so:\n\\[\np(y_1,...,y_N \\mid \\mathbf{x}_1, ...,\\mathbf{x}_N, \\mathbf{w}) = \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\nFor convenience, it is typical to frame the optimal value in terms of the negative log-likelihood rather than the likelihood, but the two are equivalent.\n\\[\n\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}) = \\underset{\\mathbf{w}}{\\text{argmin}} - \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w}) = \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\nThus, the negative log-likelihood is a natural loss function to optimize to find \\(\\mathbf{w}^*\\).\n\\[\n\\textbf{Loss}(\\mathbf{w}) =\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#maximum-likelihood-for-logistic-regression",
    "href": "lecture3-logistic-regression/notes.html#maximum-likelihood-for-logistic-regression",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood for logistic regression",
    "text": "Maximum likelihood for logistic regression\nWe can now write out the negative log-likelihood for our logistic regression model using the Bernoulli PMF we defined above\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\bigg[ y_i\\log \\sigma(\\mathbf{x}_i^T\\mathbf{w}) + (1-y_i)\\log(1-\\sigma(\\mathbf{x}_i^T\\mathbf{w})) \\bigg]\n\\]\nUsing our knowledge of the sigmoid function, we can write this even more compactly:\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) =-\\sum_{i=1}^N \\bigg[ y_i\\log \\sigma(\\mathbf{x}_i^T\\mathbf{w}) + (1-y_i)\\log \\sigma(-\\mathbf{x}_i^T\\mathbf{w}) \\bigg]\n\\]\n\\[\n= -\\sum_{i=1}^N \\log\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nNote that \\(2y_i-1\\) is \\(1\\) if \\(y_i=1\\) and is \\(-1\\) if \\(y_i=0\\).\nFor our logistic regression model, maximum likelihood is intuitive. In the ideal case our model would always predict the correct class with probability 1.\n\\[\n\\textbf{Best case scenerio: } p(y_i\\mid \\mathbf{x}_i, \\mathbf{w})=1, \\quad \\forall i \\in \\{1,...,N\\}\n\\]\nThis is generally not possible though due to the constraints of our linear function.\nWe can also write the negative log-likelihood compactly using matrix-vector notation.\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\mathbf{y}^T\\log \\sigma(\\mathbf{X}\\mathbf{w}) - (1-\\mathbf{y})^T\\log \\sigma(-\\mathbf{X}\\mathbf{w})\n\\]\nIt’s worth noting that in neural network literature, this loss is often called the binary cross-entropy loss."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#optimizing-logistic-regression",
    "href": "lecture3-logistic-regression/notes.html#optimizing-logistic-regression",
    "title": "Lecture 3: Logistic regression",
    "section": "Optimizing logistic regression",
    "text": "Optimizing logistic regression\nAs we saw with linear regression, we can find the optimal paramters \\(\\mathbf{w}^*\\) under this loss function using gradient descent:\n\\[\n\\mathbf{w}^{(i+1)} \\leftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{NLL}(\\mathbf{w}^{(i)}, \\mathbf{X}, \\mathbf{y})\n\\]\nTo use this, we first need to derive the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}\\). We’ll start by writing out the simplest version of the NLL that we saw above:\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\n\\[\n\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = \\frac{d}{d\\mathbf{w}}-\\sum_{i=1}^N \\log\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nAs a first step, recall that the addition rule tells us that the derivative of a sum is a sum of derivatives:\n\\[\n= -\\sum_{i=1}^N \\frac{d}{d\\mathbf{w}} \\log\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nNext we’ll apply the chain rule to the \\(\\log\\) function, remembering that \\(\\frac{d}{dx} \\log x = \\frac{1}{x}\\):\n\\[\n= -\\sum_{i=1}^N \\bigg(\\frac{1}{ \\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big) }\\bigg)\\frac{d}{d\\mathbf{w}} \\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nThen we can apply the chain rule to the sigmoid function, using the fact that \\(\\frac{d}{dx} \\sigma(x)=\\sigma(x)(1-\\sigma(x))\\):\n\\[\n= -\\sum_{i=1}^N \\bigg(\\frac{1}{ \\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big) } \\bigg)\n\\bigg(\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\bigg) \\bigg(1-\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)  \\bigg)\n\\frac{d}{d\\mathbf{w}}\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nWe now see that the first 2 terms cancel!\n\\[\n= -\\sum_{i=1}^N  \\bigg(1-\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)  \\bigg)\n\\frac{d}{d\\mathbf{w}}\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)\n\\]\nFinally we’re left with the gradient of a linear function, which is just:\n\\[\\frac{d}{d\\mathbf{w}}\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)=(2y_i-1)\\mathbf{x}_i\\]\nNote that the transpose is irrelevant as we’re no longer signifying a dot-product and \\(\\mathbf{x}_i\\) is just a vector. So finally we’re left with\n\\[\n\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N  \\bigg(1-\\sigma\\big((2y_i-1)\\mathbf{x}_i^T\\mathbf{w}\\big)  \\bigg)\n\\bigg((2y_i-1)\\mathbf{x}_i \\bigg)\n\\]\n\nMathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std()) &gt; -0\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x, y=None):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  if y is None:\n    return tf.sigmoid(tf.dot(x, w.T))\n  else:\n    y = y.reshape((-1, 1))\n    z = tf.dot(x, w.T)\n    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) \n\nwrange = tf.linspace(-15, 5, 25)\nbrange = tf.linspace(-10, 10, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps &gt; 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())\nlosses = (errors)\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = σ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n\n\n\n\n\n\n\nviewof learningrate = Inputs.range([0, 100], {value: 1, step: 0.01, label: \" Learning rate\"})\n//learningrate = 0\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#comparing-loss-functions",
    "href": "lecture3-logistic-regression/notes.html#comparing-loss-functions",
    "title": "Lecture 3: Logistic regression",
    "section": "Comparing loss functions",
    "text": "Comparing loss functions\nLet’s look at how this loss function compares to the mean squared error loss we derived for logistic regression. One way to do this is to visualize the loss for a single observation as a function of the output of \\(\\mathbf{x}^T\\mathbf{w}\\). Here we’ll look at the loss for different models trying to predict an output of \\(y=0\\):\n\\[\n\\textbf{Let: }\\ y=0, \\quad z=\\mathbf{x}^T\\mathbf{w}\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe see that the squared error loss is best when the output is exactly 0, while the logistic regression NLL wants the output of \\(\\mathbf{x}^T\\mathbf{w}\\) to be a negative as possible so that \\(p(y=0\\mid \\mathbf{x}, \\mathbf{w}) \\longrightarrow 1\\). Meanwhile the “accuracy” loss has no slope, making it impossible to optimize with gradient descent."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#multi-class-classification",
    "href": "lecture3-logistic-regression/notes.html#multi-class-classification",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class classification",
    "text": "Multi-class classification\nWe’ve now seen a useful model for binary classification, but in many cases we want to predict between many different classes.\n\n\n\n\n\nWe will typically use a set of integers \\(\\{1, 2,...,C\\}\\) to denote the possible outputs for a general categorical function. Therefore we are considering functions of the form:\n\\[\ny=f(\\mathbf{x}), \\quad \\text{Input: } \\mathbf{x} \\in\\mathbb{R}^n \\longrightarrow \\text{ Output: }y \\in \\{1, 2, ...,C\\}\n\\]\nIt’s important to note that we do not want to assume that the ordering of labels is meaningful. For instance if we’re classifying images of animals we might set the labels such that:\n\\[\n\\textbf{1:  Cat},\\quad\n\\textbf{2:  Dog},\\quad\n\\textbf{3:  Mouse}\n\\]\nBut this shouldn’t lead to different results to the case where we assign the labels as:\n\\[\n\\textbf{1:  Dog},\\quad\n\\textbf{2:  Mouse},\\quad\n\\textbf{3:  Cat}\n\\]\nWe call prediction of a categorical output with more than two possibilities multi-class classification."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#multi-class-prediction-functions",
    "href": "lecture3-logistic-regression/notes.html#multi-class-prediction-functions",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class prediction functions",
    "text": "Multi-class prediction functions\nA symmetric approach to defining a prediction function for multi-class classification is to define a separate linear function for each class and choose the class whose function gives the largest output.\nIf \\(C\\) is the number of possible classes, we will therefore have \\(C\\) different parameter vectors \\(\\mathbf{w}_1,…,\\mathbf{w}_C\\) and our prediction function will be defined as:\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{1...C\\}}{\\text{argmax}}\\ \\mathbf{x}^T\\mathbf{w}_c\n\\]\nFor convenience, we can also define a matrix that contains all \\(C\\) parameter vectors:\n\\[\n\\mathbf{W} = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_C^T\\end{bmatrix} = \\begin{bmatrix} W_{11} & W_{12} & \\dots & W_{1d} \\\\\nW_{21} & W_{22} & \\dots & W_{2d} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nW_{C1} & W_{C2} & \\dots & W_{Cd}\n\\end{bmatrix}\n\\]\nWith this notation, our prediction function becomes:\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{1...C\\}}{\\text{argmax}}\\ (\\mathbf{x}^T\\mathbf{W}^T)_c, \\quad \\mathbf{W} \\in \\mathbb{R}^{C\\times d}\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#multi-class-decision-boundaries",
    "href": "lecture3-logistic-regression/notes.html#multi-class-decision-boundaries",
    "title": "Lecture 3: Logistic regression",
    "section": "Multi-class decision boundaries",
    "text": "Multi-class decision boundaries\nIf we only have two classes \\(0\\) and \\(1\\), so \\(C=2\\), then this multi-class prediction function reduces to the same as our binary prediction function. We can see this by noting that \\(x &gt; y \\equiv x-y&gt;0\\):\n\\[\nf(\\mathbf{x}) = \\underset{c\\in\\{0,1\\}}{\\text{argmax}}\\ (\\mathbf{x}^T\\mathbf{W}^T)_c = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w}_1 - \\mathbf{x}^T\\mathbf{w}_0 \\geq 0)\n\\]\nIf we factor out \\(\\mathbf{x}\\) we see that we can simply define a new parameter vector in order to get the same decision rule.\n\\[\n=\\mathbb{I}(\\mathbf{x}^T(\\mathbf{w}_1 - \\mathbf{w}_0) \\geq 0) \\quad \\longrightarrow \\quad \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0), \\quad \\mathbf{w}=\\mathbf{w}_1-\\mathbf{w}_0\n\\]\nIt follows that the decision boundary between any two classes is also linear! We can see this by plotting a prediction function. In this case for the Iris dataset we saw in the homework."
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#categorical-distribution",
    "href": "lecture3-logistic-regression/notes.html#categorical-distribution",
    "title": "Lecture 3: Logistic regression",
    "section": "Categorical distribution",
    "text": "Categorical distribution\nAs a first step towards finding the optimal \\(\\mathbf{W}\\) for a multi-class model, let’s look at a distribution over multiple discrete outcomes: the Categorical distribution.\nA categorical distribution needs to define a probability for each possible output. We’ll use \\(q_c\\) to denote the probability of output \\(c\\).\n\\[\np(y=c) = q_c, \\quad y\\in \\{1...C\\}\n\\]\nWe can then denote the vector of all \\(C\\) probabilities as \\(\\mathbf{q}\\). Note that in order for this to be valid, every probability needs to be in the range \\([0,1]\\) and the total probability of all outcomes needs to be \\(1\\), so:\n\\[\n\\mathbf{q} \\in \\mathbb{R}^C\\quad q_c \\geq 0\\ \\forall c\\in \\{1...C\\}\\quad \\sum_{c=1}^C q_c=1\n\\]\nAs with the Bernoulli distribution, we can write this in a more compact form. Here we see that the probability of a given outcome is simply the corresponding entry in \\(\\mathbf{q}\\)\n\\[\np(y)=\\prod q_c^{\\mathbb{I}(y=c)} = q_y\n\\]\nThus the log-probability is simply:\n\\[\n\\log p(y) = \\sum_{c=1}^C \\mathbb{I}(y=c)\\log q_c = \\log q_y\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-multi-class-classification",
    "href": "lecture3-logistic-regression/notes.html#a-probabilistic-model-for-multi-class-classification",
    "title": "Lecture 3: Logistic regression",
    "section": "A probabilistic model for multi-class classification",
    "text": "A probabilistic model for multi-class classification\nWith the Categorical distribution defined, we can now ask if we can use it to define a linear probabilistic model for multi-class categorical outputs. As with our other models we’ll consider making the distribution parameter a linear function of our input.\n\\[\ny_i\\sim \\mathbf{Categorical}(\\mathbf{q}=?), \\quad \\mathbf{q}=\\mathbf{x}_i^T\\mathbf{W}^T?\n\\]\nHowever, we once again run into the issue that the output of our linear function likely won’t satisfy the conditions we need for the parameter of a categorical distribution. In particular, the output is not guaranteed to be positive or to sum to \\(1\\).\n\\[\n\\mathbf{x}^T\\mathbf{W}^T\\in \\mathbb{R}^C,\\quad  q_c \\ngeq 0\\ \\forall c\\in \\{1...C\\}, \\quad \\sum_{c=1}^C q_c\\neq1\n\\]\nIn this case we need a way to map arbitrary vectors to vectors that satisfy these conditions:\n\\[\n\\textbf{Need }\\ f(\\mathbf{x}):\\ \\mathbb{R}^C \\longrightarrow [0,\\infty)^C,\\ \\sum_{i=1}^Cf(\\mathbf{x})_c = 1\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#softmax-function",
    "href": "lecture3-logistic-regression/notes.html#softmax-function",
    "title": "Lecture 3: Logistic regression",
    "section": "Softmax function",
    "text": "Softmax function\nSuch a mapping exists in the softmax function. This function maps vectors to positive vectors such that the entries sum to \\(1\\). Entry \\(c\\) of \\(\\text{softmax}(\\mathbf{x})\\) can be written as:\n\\[\n\\text{softmax}(\\mathbf{x})_c = \\frac{e^{x_c}}{\\sum_{j=1}^Ce^{x_j}}\n\\]\nWe can also define the softmax function using vector notation as:\n\\[\n\\text{softmax}(\\mathbf{x}) = \\begin{bmatrix}\\frac{e^{x_1}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\frac{e^{x_2}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\vdots \\\\ \\frac{e^{x_C}}{\\sum_{j=1}^Ce^{x_j}} \\end{bmatrix}\n\\]\nIntuitively, \\(e^x\\) is positive for any \\(x\\), while dividing by the sum ensure the entries sum to 1 as:\n\\[\n\\sum_{i=1}^C \\frac{e^{x_i}}{\\sum_{j=1}^Ce^{x_j}} = \\frac{\\sum_{i=1}^C e^{x_i}}{\\sum_{j=1}^Ce^{x_j}} = 1\n\\]\nThe softmax function also has the nice property that\n\\[\n\\underset{c\\in\\{1,...,C\\}}{\\text{argmax}}\\ \\mathbf{x}_c = \\underset{c\\in\\{1,...,C\\}}{\\text{argmax}}\\ \\text{softmax}(\\mathbf{x})_c\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#multonomial-logistic-regression",
    "href": "lecture3-logistic-regression/notes.html#multonomial-logistic-regression",
    "title": "Lecture 3: Logistic regression",
    "section": "Multonomial logistic regression",
    "text": "Multonomial logistic regression\nWith the softmax function we can now define our probabilistic model for categorical labels as:\n\\[\ny_i\\sim \\mathbf{Categorical}\\big(\\text{softmax}(\\mathbf{x}^T\\mathbf{W})\\big)\n\\]\nWe see that under this assumption, the probability of a particular output \\((c)\\) is:\n\\[\np(y_i=c \\mid \\mathbf{x}, \\mathbf{W}) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c=\\frac{e^{\\mathbf{x}^T\\mathbf{w}_c}}{\\sum_{j=1}^Ce^{\\mathbf{x}^T\\mathbf{w}_j}}\n\\]\nWe call this particular probabilistic model: multinomial logistic regression"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#maximum-likelihood-estimation-for-multinomial-logistic-regression",
    "href": "lecture3-logistic-regression/notes.html#maximum-likelihood-estimation-for-multinomial-logistic-regression",
    "title": "Lecture 3: Logistic regression",
    "section": "Maximum likelihood estimation for multinomial logistic regression",
    "text": "Maximum likelihood estimation for multinomial logistic regression\nWe now have everything we need to define our negative log-likelihood loss for the multi-class classification model. Once again our loss is the negative sum of the log-probability of each observed output:\n\\[\n\\textbf{Loss}(\\mathbf{W}) =\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{W})\n\\]\nUsing the log-probability of the multinomial logistic regression model we get:\n\\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})= -\\sum_{i=1}^N \\log\\ \\text{softmax}(\\mathbf{x}_i^T\\mathbf{W}^T)_{y_i} = -\\sum_{i=1}^N  \\log \\frac{e^{\\mathbf{x}_i^T\\mathbf{w}_{y_i}}}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\n\\]\nWe can simplify this further to:\n\\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]"
  },
  {
    "objectID": "lecture3-logistic-regression/notes.html#gradient-descent",
    "href": "lecture3-logistic-regression/notes.html#gradient-descent",
    "title": "Lecture 3: Logistic regression",
    "section": "Gradient descent",
    "text": "Gradient descent\nIn this case our parameters are a matrix \\(\\mathbf{W}\\). The concept of a gradient, extends naturally to a matrix; we simply define the gradient matrix such that each element is the partial derivative with respect to the corresponding element of the input. For the multinomial logistic regression loss, the gradient this looks like:\n\\[\n\\nabla_{\\mathbf{W}} \\mathbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})= \\begin{bmatrix} \\frac{\\partial \\mathbf{NLL}}{\\partial W_{11}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{12}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{1C}} \\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{21}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{22}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{2C}} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{d1}} & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{d2}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{dC}}\n\\end{bmatrix}\n\\]\nWe can still apply the same gradient descent updates in this case!\n\\[\n\\mathbf{W}^{(i+1)} \\leftarrow \\mathbf{W}^{(i)} - \\alpha \\nabla_{\\mathbf{W}} \\mathbf{NLL}(\\mathbf{W}^{(i)}, \\mathbf{X}, \\mathbf{y})\n\\]"
  },
  {
    "objectID": "assignments/homeworks/Homework 3/submission.html",
    "href": "assignments/homeworks/Homework 3/submission.html",
    "title": "Homework 3: Logistic regression and classification",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%203/hw3_support.py\n\n\n# Run me first!\nimport autograd.numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom hw3_support import MultinomialLogisticRegression, linear_function, sigmoid, LogisticRegression, get_dataset, gradient_descent, test_nll, test_nll_grad, test_predict, plot_boundary, test_softmax, test_split,test_predict_probability, test_nll_gradient_c\n\n\n\n\n\nQ1\n\ndef split_data(X, y):\n    ## YOUR CODE HERE\n\n    return Xtrain, ytrain, Xtest, ytest\n\n# Test the function\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\ntest_split(X, y, Xtrain, ytrain, Xtest, ytest)\n\n\n\n\n\n\nQ2\n\n## YOUR CODE HERE\n\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\n\n\n\n\n\nQ3\nYOUR ANSWER HERE\n\\[\\nabla_{\\mathbf{w}} \\textbf{ExpLoss}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\n\n\n\nQ4\n\nclass ExponentialRegression(LogisticRegression):\n  def nll(self, X, y):\n        xw = linear_function(X, self.weights)\n        return -np.sum(np.exp(-xw))\n\n  def nll_gradient(self, X, y):\n      # YOUR CODE HERE\n\n\n\n\n\n\nQ5\n\n## YOUR CODE HERE\n\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\nplot_boundary(model, X, y)\n\nWhat differences (if any) do you notice between this and the log-likelihood loss?\nYOUR ANSWER HERE\n\n\n\n\n\nQ6\nYOUR ANSWER HERE\n\n\n\n\n\nQ7\n\ndef multiclass_predict(self, X):\n    W = self.weights\n\n    ## YOUR CODE HERE\n    pred =\n\n    return pred\n\n## Test the function\ntest_predict(multiclass_predict)\n\n## Add it to our class\nMultinomialLogisticRegression.predict = multiclass_predict\n\n\n\n\n\n\nQ8\n\ndef softmax(x):\n    ## YOUR CODE HERE\n\ndef multiclass_predict_probability(self, X):\n    ## YOUR CODE HERE\n\n\ntest_softmax(softmax)\ntest_predict_probability(multiclass_predict_probability)\n\n\n\n\n\n\nQ9\n\ndef nll(self, X, y):\n    W = self.weights\n    ## YOUR CODE HERE\n\n    return nll\n\ntest_nll(nll)\nMultinomialLogisticRegression.nll = nll\n\n\n\n\n\n\nQ10\nYOUR ANSWER HERE\n\\[\\nabla_{\\mathbf{w}_c} \\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\n\n\n\nQ11\n\ndef nll_gradient_c(W, X, y, c):\n    ## YOUR CODE HERE\n\n    return grad\n\ntest_nll_gradient_c(nll_gradient_c)\n\n\n\n\n\n\nQ12\n\ndef nll_gradient(self, X, y, c):\n    ## YOUR CODE HERE\n    W = self.weights\n\n    return grad\n\ntest_nll_grad(nll_gradient)\nMultinomialLogisticRegression.nll_gradient = nll_gradient\n\nNote if you are struggling with this problem, you can uncomment the following cell to get a valid gradient function based on your nll function. You can use this for testing to to complete the remaining questions.\n\n'''\ndef autograd_nll_gradient(self, X, y):\n    import autograd\n    def autograd_nll(W):\n        temp_model = MultinomialLogisticRegression(self.classes, X.shape[1])\n        temp_model.weights = W\n        return temp_model.nll(X, y)\n    return autograd.grad(autograd_nll)(self.weights)\nMultinomialLogisticRegression.nll_gradient = autograd_nll_gradient\n'''\n\n\nimages, labels, label_names = get_dataset('mnist')\n\nimage_shape = images[0].shape                # Keep track of the original image shape\nX = images.reshape((images.shape[0], -1))    # Reshape into an N x d matrix X\ny = labels\nprint('Image shape: ', images.shape, ', X shape: ', X.shape)\n\n# Create the initial model\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\n\n\n\n\n\n\nQ13\n\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\n\nmodel = ## YOUR CODE HERE\n\n## Note that we need to pass \"image_shape\" here to reshape our data to a vector\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-4, steps=2500, image_shape=image_shape, watch=False)\n\n## YOUR CODE HERE\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nHere we’ll show an image and the corresponding prediction made by the model.\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = probabilities[np.arange(probabilities.shape[0]), prediction]\n\n# Show an image and the corresponding prediction\nplt.imshow(X[0].reshape(image_shape), cmap='gray')\nprint('Prediction: %s, probability: %.3f' % (label_names[prediction[0]], probability_of_prediction[0]))\n\n\n\n\n\n\nQ14\n\n## YOUR CODE HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 3/main.html",
    "href": "assignments/homeworks/Homework 3/main.html",
    "title": "Homework 3: Logistic regression and classification",
    "section": "",
    "text": "Important notes\nThis homework requires installing additional python libraries. You can install all the nessecary dependencies by running: pip install -r requirements.txt in the homework directory. If using Colab, this step should not be needed.\nIn this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)\n\\(C: \\quad\\ \\text{Number of classes, so } y_i \\in \\{1,...,C\\}\\)\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/2f0c3af9eed3b910037df98e21c6c035/raw/925ff6b8ad5dcc2c17674b6ec609d854a811c453/hw2_code.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw3_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nimport autograd.numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom hw3_support import get_dataset, gradient_descent, test_nll, test_nll_grad, test_predict, plot_boundary, test_softmax, test_split,test_predict_probability, test_nll_gradient_c\n\n\n\nBackground\nIn class we derived the logistic regression model for making predictions on binary data. Recall the the prediction function for logistic regression can be written as:\n\\[f(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\\]\nThe estimated probability of \\(y=1\\) as: \\[p(y=1\\mid \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{x}^T\\mathbf{w})\\]\nAlso recall that the negative log-likelihood loss for logistic regression can be written as:\n\\[\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\log \\sigma\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\nand it’s gradient with respect to \\(\\mathbf{w}\\) is: \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\big(1 - \\sigma((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w})\\big) \\big(2 y_i - 1\\big)\\mathbf{x}_i\\]\nBelow is an implementation of logistic regression using the functions we derived in class. In this example, we’ve created a logistic regression class that encapsulates the weights along with all of the functions we need to train and make predictions with the model.\n\ndef linear_function(X, w):\n    # Returns a linear function of X (and adds bias)\n    X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n    return np.dot(X, w)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1 / (1 + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1,))\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (int array): A length N array of predictions in {0, 1}\n        '''\n        return (linear_function(X, self.weights) &gt; 0).astype(int)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): A length N vector of predicted class probabilities\n        '''\n        return sigmoid(linear_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        return np.mean(self.predict(X) == y)\n\n    def nll(self, X, y):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (int array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        return -np.sum(np.log(py))\n\n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n\n    def nll_and_grad(self, X, y):\n        '''\n        Compute both the NLL and it's gradient\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nLet’s take a look at how to use this class. The code below uses the scikit-learn library to load a simple example dataset. Here we have 2 classes (purple and yellow) and our goal will be to separate the two.\n\n# Load a dataset with sklearn\nX, y = make_blobs(n_samples=200, random_state=42, centers=2, cluster_std=3)\n\n# Show a plot of the data\nplt.scatter(X[:, 0], X[:, 1], c=y,  edgecolor=\"black\");\n\n\n\n\n\n\n\n\nWe can create a model using the LogisticRegression class, specifying the number of features (\\(d\\)):\n\nmodel = LogisticRegression(X.shape[1])\n\nWe can train the model using the gradient_descent function provided in the support code:\nNote: Use this learning rate and number of steps throughout the homework!\n\nlosses = gradient_descent(model, X, y, lr=1e-6, steps=2500, watch=False)\n\n# Uncomment to run with a live visualization\n# losses = gradient_descent(model, X, y, lr=1e-6, steps=500, image_shape=images[0].shape, watch=True)\n\nLoss 137.26, accuracy: 0.89:   0%|          | 0/2500 [00:00&lt;?, ?it/s]Loss 42.77, accuracy: 0.95: 100%|██████████| 2500/2500 [00:01&lt;00:00, 2373.00it/s]\n\n\nWe provide a built-in function to visualize the data and decision boundary\n\n# Show an image and the corresponding prediction\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nWe can also make predictions using the built-in methods. Here we’ll visualize which observations we predicted incorrectly:\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = np.where(prediction, probabilities, 1 - probabilities)\nplt.scatter(X[:, 0], X[:, 1], c=(1 - prediction == y), edgecolor='black', cmap='Reds')\nplt.title('Incorrect predictions');\n\n\n\n\n\n\n\n\n\n\nPart 1: Logistic regression\nWe’ll first evaluate the performance of the logistic regression model above.\n\nQ1: Train and test splits (5 points)\nWrite a function to split the provided dataset into a train set and a test set. The train set should include 70% of the observations and the test set should include the remaining 30%. The data should be randomly shuffled to make sure there is no bias in the ordering.\n\ndef split_data(X, y):\n    ## YOUR CODE HERE\n\n    return Xtrain, ytrain, Xtest, ytest\n\n# Test the function\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\ntest_split(X, y, Xtrain, ytrain, Xtest, ytest)\n\n\n\nQ2: Model evaluation (5 points)\nUsing the function you just wrote, train a new logistic regression model on just the training data. Evaluate the accuracy and loss of the trained model on both the training data and the test data.\n\n## YOUR CODE HERE\n\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\n\n\n\nPart 2: Alternative losses\nOur original goal for classification was simply to maximize the number of correct classifications we’d make. Using accuracy as a loss function looked something like this:\n\\[\\mathbf{Acc.}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\mathbb{I}\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w} \\geq 0 \\big)\\]\nWhich unfortunately wasn’t differentiable and therefore we couldn’t optimize it with gradient descent.\nThe maximum likelihood principal helped us derive a useful loss function for classification:\n\\[\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\log \\sigma\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\n(and had the additional benefit of letting us estimate probabilities). But as we saw with linear regression that we’re not limited to thinking about things from the probabilistic perspective. Now that we’ve seen what a reasonable loss function for classification looks like, we could try some variations with similar properties.\nLet’s consider the exponential loss:\n\\[\\mathbf{ExpLoss}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=\\sum_{i=1}^N \\exp\\big(-(2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\nNote that \\(\\exp(x) = e^x\\)\nPlotting this we see that just like negative log-likelihood, the loss monotonically increases as we get further from a correct prediction, which is what we’d like!\n\nyxw = np.linspace(-3, 3, 200)\nacc = np.where(yxw &gt; 0, 0., 1.)\nnll = -np.log(sigmoid(yxw))\nexp = np.exp(-yxw)\n\nplt.plot(yxw, acc, label='Acc. (0-1 loss)')\nplt.plot(yxw, nll, label='Neg. Log-lik.')\nplt.plot(yxw, exp, label='Exp.')\nplt.ylim((-0.2, 3))\nplt.legend();\n\n\n\n\n\n\n\n\n\nQ3: Exponential loss gradient (10 points)\nDerive the gradient of the exponential loss with respect to \\(\\mathbf{w}\\), the weight vector for the linear model.\nYOUR ANSWER HERE\n\\[\\nabla_{\\mathbf{w}} \\textbf{ExpLoss}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\nQ4: Exponential loss implementation (10 points)\nLet’s try using the exponential loss. Below is a sub-class of the LogisticRegression class above that replaces the negative log-likelihood loss with the exponential loss.\nComplete the nll_gradient method using the gradient you derived above.\n\nclass ExponentialRegression(LogisticRegression):\n  def nll(self, X, y):\n        '''\n        Compute the exponential loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (int array): A length N vector of labels.\n        Returns:\n            nll (float): The exponential loss\n        '''\n        xw = linear_function(X, self.weights)\n        return -np.sum(np.exp(-xw))\n\n  def nll_gradient(self, X, y):\n      '''\n      Compute the gradient of the exponential loss.\n\n      Args:\n          X (array): An N x d matrix of observations.\n          y (array): A length N vector of labels.\n      Returns:\n          grad (array): A length (d + 1) vector with the gradient\n      '''\n      # YOUR CODE HERE\n\n\n\nQ5: Exponential loss comparison (5 points)\nRepeat q2, training a new exponential-loss regression model on just the training data. Evaluate the accuracy and loss of the trained model on both the training data and the test data.\n\n## YOUR CODE HERE\n\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\nplot_boundary(model, X, y)\n\nWhat differences (if any) do you notice between this and the log-likelihood loss?\nYOUR ANSWER HERE\n\n\nQ6: Linear losses (5 points)\nNote that both the negative log-likelihood and exponential losses are strictly positive, and threrefore bounded below by 0. Why is having a lower bound a desirable property for a classification loss?\nFor instance, why not simply use a linear loss?\n\\[\\mathbf{Loss}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N (2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\]\nHint: If you’re unsure, you could try modifying the ExponentialRegression class to use a linear loss and see what happens! Deriving the gradient should be even simpler than for the exponential loss.\nYOUR ANSWER HERE\n\n\n\nPart 3: Multinomial logistic regression\nIn this part, we will look at implementing multinomial logistic regression. Recall that this model extends logistic regression to the cases where there may be more than 2 possible labels, so \\(y\\in\\{1,...,C\\}\\), where \\(C\\) is the number of classes (possible outputs).\nWe saw that rather than having a single weight vector, this model has a weight vector for each class, \\(\\mathbf{w}_1,...,\\mathbf{w}_C\\). We can view these together as the rows of a weight matrix \\(\\mathbf{W}\\): \\[\\mathbf{W} = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_C^T \\end{bmatrix}\\]\nWe saw that the prediction function for this model was: \\[f(\\mathbf{x}) = \\underset{c\\in \\{1,...,C\\}}{\\text{argmax}}\\ \\mathbf{x}^T\\mathbf{w}_c\\]\nThe probabilistic model was defined as: \\[\np(y_i=c \\mid \\mathbf{x}, \\mathbf{W}) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c=\\frac{e^{\\mathbf{x}^T\\mathbf{w}_c}}{\\sum_{j=1}^Ce^{\\mathbf{x}^T\\mathbf{w}_j}}\n\\]\nThe negative log-likelihood loss was defined as: \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nIn the next few questions we will create a modified version of our logistic regression class that supports multinomal logistic regression. The class definition is below. A few things to note:\n1: We will still assume y is an array of int in numpy. We can convert an array y to an array of int with y = y.astype(int) and back with y = y.astype(float)\n2: Remeber that numpy is 0-indexed, so our classes will actually be \\(0\\) to \\(C-1\\), (\\(y\\in \\{0,...,C-1\\}\\))\n2: We will assume our weight matrix is a \\(C \\times d\\) matrix as shown below\n\nclass MultinomialLogisticRegression(LogisticRegression):\n    def __init__(self, classes, dims):\n        '''\n        Args:\n            classes (int): C, the number of possible outputs\n            dims (int): d, the dimension of each input\n        '''\n        self.classes = classes\n        self.weights = np.zeros((classes, dims + 1,))\n\n\nQ7: Prediction (5 points)\nWrite a function to make a prediction using the multinomial logistic regression prediction rule above. (assume self is the MultinomialLogisticRegression object)\n\ndef multiclass_predict(self, X):\n    '''\n    Predict labels given a set of inputs.\n\n    Args:\n        X (array): An N x d matrix of observations.\n    Returns:\n        pred (int array): A length N array of predictions in {0,...,(C-1)}\n    '''\n    W = self.weights\n\n    ## YOUR CODE HERE\n    pred =\n\n    return pred\n\n## Test the function\ntest_predict(multiclass_predict)\n\n## Add it to our class\nMultinomialLogisticRegression.predict = multiclass_predict\n\n\n\nQ8: Softmax (5 points)\nImplement the softmax function. \\[\n\\text{softmax}(\\mathbf{x})_c = \\frac{e^{x_c}}{\\sum_{j=1}^Ce^{x_j}}, \\quad\n\\text{softmax}(\\mathbf{x}) = \\begin{bmatrix}\\frac{e^{x_1}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\frac{e^{x_2}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\vdots \\\\ \\frac{e^{x_C}}{\\sum_{j=1}^Ce^{x_j}} \\end{bmatrix}\n\\]\nYou function should accept inputs as either a length \\(C\\) vector or as an \\(N\\times C\\) matrix. If the input is a matrix, the softmax function should be applied to each row of the matrix.\nThen, use your softmax function to complete the predict_probability method for multinomial logistic regression.\n\ndef softmax(x):\n    '''\n    Apply the softmax function to a vector or matrix\n\n    Args:\n        X (array): An N x C matrix of transformed inputs (or a length C vector)\n    Returns:\n        probs (array):  An N x C matrix with the softmax function applied to each row\n    '''\n    ## YOUR CODE HERE\n\ndef multiclass_predict_probability(self, X):\n    '''\n    Predict the probability of each class given a set of inputs\n\n    Args:\n        X (array): An N x d matrix of observations.\n    Returns:\n        probs (array): A length N x d matrix of predicted class probabilities\n    '''\n    ## YOUR CODE HERE\n\n\ntest_softmax(softmax)\ntest_predict_probability(multiclass_predict_probability)\n\n\n\nQ9: Multinomial logistic regression NLL (10 points)\nImplement a function to compute the multinomial logistic regression negative log-likelihood. \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nHint: Recall that \\(y_i\\) is an integer, so \\(\\mathbf{w}_{j}\\) refers to the row of the weight matrix at index \\(y_i\\) (you could access this as W[y[i]]). It’s possible to answer this question without loops, but you may find it easier to loop over each possible class/observation.\n\ndef nll(self, X, y):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        nll (float): The NLL loss\n    '''\n    W = self.weights\n    ## YOUR CODE HERE\n\n    return nll\n\ntest_nll(nll)\nMultinomialLogisticRegression.nll = nll\n\n\n\nQ10: Gradient of NLL (10 points)\nDerive the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}_c\\), the weight vector for a single class.\nHint: Again note that \\(\\mathbf{w}_{y_i}\\) refers to the weight vector corresponding to the true class of observation \\(i\\), and so only depends on \\(\\mathbf{w}_c\\) if \\(y_i=c\\). This means that: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\begin{cases}\\mathbf{x}_i \\quad \\text{ if } y_i = c \\\\ 0 \\quad \\ \\text{ otherwise}  \\end{cases}\\] We can write this more compactly using an indicator function: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\mathbb{I}(y_i=c)\\ \\mathbf{x}_i \\]\nYOUR ANSWER HERE\n\\[\\nabla_{\\mathbf{w}_c} \\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\nQ11: Implementing the gradient (10 points)\nWrite a function that computes the gradient of the negative log-likelihood with repect to the weight vector for a given class, using the results of the derivation above.\n\ndef nll_gradient_c(W, X, y, c):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        W (array): The C x d weight matrix.\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n        c (int): The class to compute the gradient for\n    Returns:\n        grad (array): A length d vector representing the gradient with respect to w_c\n    '''\n    ## YOUR CODE HERE\n\n    return grad\n\ntest_nll_gradient_c(nll_gradient_c)\n\n\n\nQ12: Implementing the full gradient (10 points)\nUsing the function you just wrote, write a function to compute the full gradient with respect to the \\(C \\times d\\) weight matrix. Hint: The output should be a matrix!\n\ndef nll_gradient(self, X, y, c):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        grad (array): A C x d matrix representing the gradient with respect to W\n    '''\n    ## YOUR CODE HERE\n    W = self.weights\n\n    return grad\n\ntest_nll_grad(nll_gradient)\nMultinomialLogisticRegression.nll_gradient = nll_gradient\n\nNote if you are struggling with this problem, you can uncomment the following cell to get a valid gradient function based on your nll function. You can use this for testing to to complete the remaining questions.\n\n'''\ndef autograd_nll_gradient(self, X, y):\n    import autograd\n    def autograd_nll(W):\n        temp_model = MultinomialLogisticRegression(self.classes, X.shape[1])\n        temp_model.weights = W\n        return temp_model.nll(X, y)\n    return autograd.grad(autograd_nll)(self.weights)\nMultinomialLogisticRegression.nll_gradient = autograd_nll_gradient\n'''\n\nFinally, we will test out our multinomial logistic regression classifier on the MNIST dataset (https://en.wikipedia.org/wiki/MNIST_database), one of the most popular datasets in machine learning!\nWe’ll start by loading it as before. As we saw in class, before we can use logistic regression on image data, we first need to reshape it from a 3-dimensional array into a 2-dimensional matrix.\n\nimages, labels, label_names = get_dataset('mnist')\n\nimage_shape = images[0].shape                # Keep track of the original image shape\nX = images.reshape((images.shape[0], -1))    # Reshape into an N x d matrix X\ny = labels\nprint('Image shape: ', images.shape, ', X shape: ', X.shape)\n\n# Create the initial model\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\n\n\n\nQ13: Repeat question 2 using the MNIST dataset (5 points)\n\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\n\nmodel = ## YOUR CODE HERE\n\n## Note that we need to pass \"image_shape\" here to reshape our data to a vector\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-4, steps=2500, image_shape=image_shape, watch=False)\n\n## YOUR CODE HERE\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nHere we’ll show an image and the corresponding prediction made by the model.\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = probabilities[np.arange(probabilities.shape[0]), prediction]\n\n# Show an image and the corresponding prediction\nplt.imshow(X[0].reshape(image_shape), cmap='gray')\nprint('Prediction: %s, probability: %.3f' % (label_names[prediction[0]], probability_of_prediction[0]))\n\n\n\nQ14: Visualize the learned weights (10 points)\nThe Matplotlib function plt.imshow (or ax.imshow for subplots) will display a matrix as an image as shown above.\nReshape the weight vector for each of the 10 classes in your trained model into a \\(28 \\times 28\\) matrix (ignore the last, bias dimension for each). Then plot each weight vector using the imshow function.\nHint: Your weight matrix should be of size \\(10 \\times 785\\)\n\n## YOUR CODE HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/solutions-S4MH4K.html",
    "href": "assignments/homeworks/Homework 4/solutions-S4MH4K.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks (solutions)",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and start on an implementation of automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#overview",
    "href": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#overview",
    "title": "Homework 4: Automatic Differentiation and Neural Networks (solutions)",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and start on an implementation of automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-1-autograd",
    "href": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-1-autograd",
    "title": "Homework 4: Automatic Differentiation and Neural Networks (solutions)",
    "section": "Part 1: Autograd",
    "text": "Part 1: Autograd\nIn this homework we will be using a special version of Numpy from a package called Autograd. Assuming it is installed (pip install autograd), we can import it as follows:\n\nimport autograd.numpy as np\n\nThis special version of Numpy behaives exactly like normal numpy. We can create and do calculations with arrays just like we would before:\n\nx = np.array([3., 2., 1])\nprint('x:\\t', x)\nprint('x^2:\\t', x ** 2)\nprint('sum(x):\\t', np.sum(x))\n\nx:   [3. 2. 1.]\nx^2:     [9. 4. 1.]\nsum(x):  6.0\n\n\nHowever, Autograd also has a very important trick up its sleeve: it can take derivatives (and gradients) for us! This functionality can be accessed through the grad function. Let’s start by seeing it in action with a very simple example, where we know the correct answer. The square function and its derivative can be written as:\n\\(f(x) = x^2, \\quad f'(x) = 2x\\)\nThe following code uses Autograd to compute this derivative automatically:\n\nfrom autograd import grad\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0\n\n\nWe can start to see how grad operates. grad takes as input a function (e.g. \\(f(x)\\)) and returns a new function that computes the derivative of \\(f\\) at \\(x\\). (\\(f'(x)\\)). So:\n\\(\\text{grad}(f) \\longrightarrow f'\\)\n\nQ1: Trying out autograd\nDefine the following function in python:\n\\(f(x) = \\log(\\sin(x^3) + 3 x)\\)\nUse grad to compute the derivative of \\(f\\) at \\(1.5\\) (i.e. compute \\(f'(1.5)\\))\n\n\nAnswer\n\ndef f(x):\n    return np.log(np.sin(x ** 3) + 3 * x)\n\nanswer = grad(f)(1.5)\nprint(\"f'(1.5)=\", answer)\n\nf'(1.5)= -0.8356083737326538\n\n\nAs the name would imply, grad can more generally be used to compute the gradient of a function of the form \\(f(\\mathbf{x}): \\mathbb{R}^d\\rightarrow \\mathbb{R}\\). Remember that for a function that takes in a vector and outputs a scalar, the gradient is vector of all partial derivatives of the output with respect to each input. For example, consider a function that gives the square of the 2-norm of a vector:\n\\(f(\\mathbf{x}) = ||\\mathbf{x}||^2_2 = \\mathbf{x}^T\\mathbf{x} = \\sum_{i=1}^d x_i^2\\)\nThink about why these expressions are equivalent!\nAs we’ve seen, the gradient of this function can be written as:\n\\(\\nabla f(\\mathbf{x}) = 2\\mathbf{x} = \\begin{bmatrix}2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_d \\end{bmatrix}\\)\nLet’s see what Autograd gives us in this case:\n\n# Define a function\ndef f(x):\n    return np.sum(x ** 2)\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = np.array([1., 2., 3])\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nx:   [1. 2. 3.]\nf(x):    14.0\nf'(x):   [2. 4. 6.]\n\n\nWe see that the gradient has the same shape as the input. So the gradient function is of the form: \\(\\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\)\nThis makes sense as the gradient should have exactly one partial derivative for each entry in the input to the function. As discussed, this even extends beyond vectors! We could have a function that takes in any datastructure and computes the set of partial derivatives with respect to each entry.\n\n\nQ2: More complex autograd\nWrite a function that takes a list of vectors and computes the sum of the squared 2-norm for each vector. That is:\n\\(f([\\mathbf{a}, \\mathbf{b}, \\mathbf{c}...]) = ||\\mathbf{a}||^2 + ||\\mathbf{b}||^2 + ||\\mathbf{c}||^2+...\\)\nRecall from above how we can compute each term in this sum!\nThen use grad to compute the gradient of this function with respect to the given input.\n\n# Define a function\ndef f(x):\n    '''\n    Compute the sum of squared 2-norms for a list of vectors\n\n    Args:\n        x (list of arrays): A list of 1-dimensional arrays\n    Returns:\n        output (float): The result\n    '''\n    return np.sum([np.sum(xi ** 2) for xi in x])\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = [np.array([1., 2., 3]), np.array([7., 2.]), np.array([6.])]\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nx:   [array([1., 2., 3.]), array([7., 2.]), array([6.])]\nf(x):    103.0\nf'(x):   [array([2., 4., 6.]), array([14.,  4.]), array([12.])]\n\n\nA useful argument that we can give to grad is argnum. If our function takes more than one argument argnum lets us specify which one to take the gradient with respect to. For example, if we have the function:\n\\(f(x, y) = x^2y\\)\nThen:\n\\(f'_x(x,y)=2xy, \\quad f'_y(x, y)=x^2\\)\n\ndef f(x, y):\n    return x ** 2 * y\n\nprint('f(3, 5) = ', f(3., 5.))\n\ndf_dx = grad(f, argnum=0)(3., 5.)\ndf_dy = grad(f, argnum=1)(3., 5.)\n\nprint('df_dx = ', df_dx)\nprint('df_dy = ', df_dy)\n\nf(3, 5) =  45.0\ndf_dx =  30.0\ndf_dy =  9.0\n\n\nNow that we have everything we need to apply automatic differentiation to train a neural network!\nBefore we do that though, let’s try out our automatic differentiation for logistic regression. Below is a slight modification of LogisticRegression implementation we saw in the last homework.\n\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1, 1))\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1., mode='constant')\n        return np.dot(X, w)\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n\n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1., mode='constant')\n        return -np.sum(grad, axis=0)\n\n    def nll_and_grad_no_autodiff(self, X, y):\n        # Compute nll_and_grad without automatic diferentiation\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\n\nQ3: Logistic regression using autograd\nWrite the method nll_and_grad for the LogisticRegression class using the grad function from Autograd. Verify that it gives a similar answer to nll_and_grad_no_autodiff.\nHint: Note that the nll function can optionally take in the parameters. You can use this functionality and the argnum argument of grad in your answer. You can assume that self refers to the model object, so you can access the weights via self.weights\n\nfrom autograd import grad\n\ndef nll_and_grad(self, X, y):\n    loss = self.nll(X, y)\n    grads = grad(self.nll, argnum=2)(X, y, self.weights)\n    return loss, grads\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nThis implementation quite inefficient (we’ll fix this in the future!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 23.68, accuracy: 0.87: 100%|██████████| 250/250 [00:00&lt;00:00, 1734.69it/s]\n\n\nModel accuracy: 0.870"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-2-feature-transforms",
    "href": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-2-feature-transforms",
    "title": "Homework 4: Automatic Differentiation and Neural Networks (solutions)",
    "section": "Part 2: Feature transforms",
    "text": "Part 2: Feature transforms\nRecall that in class we dicussed feature transforms an easy way to get more expressive models, using our linear model tools. Here we’ll try applying some basic feature transforms to this problem and see if we can improve the performance.\n\nQ4: Quadratic feature transforms\nBelow we’ve started a sub-class of LogisticRegression that should first compute a transformed version of the input data by adding quadratic features. Only add the unary quadratic terms (\\(x_i^2\\)) not the cross terms (\\(x_i x_j\\)). For a single dimension the transform would look like: \\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ x_i^2 \\end{bmatrix}\\]\nIn general, the transform should look like:\n\\[\\textbf{Single observation: }\\phi(\\mathbf{x}) = \\begin{bmatrix}x_1 \\\\ \\vdots \\\\ x_d \\\\ x_1^2 \\\\ \\vdots \\\\ x_d^2 \\end{bmatrix}, \\quad \\textbf{Dataset: } \\phi(\\mathbf{X}) = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1d} & x_{11}^2 & \\dots & x_{1d}^2 \\\\ x_{21} & x_{22} & \\dots & x_{2d} & x_{21}^2 & \\dots & x_{2d}^2 \\\\  \\vdots & \\vdots & & \\vdots & \\vdots & & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nd} & x_{N1}^2 & \\dots & x_{Nd}^2 \\\\  \\end{bmatrix} \\]\n\n\nAnswer\n\nclass QuadraticRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        transformed_dims = dims * 2\n        super().__init__(transformed_dims)\n\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a quadratic feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        Xtransformed = np.hstack([X, X ** 2])\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n    \n\nHere we’ll try out our quadratic feature transform.\n\nX, y = make_moons(100, noise=0.1)\nmodel = QuadraticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 28.06, accuracy: 0.86: 100%|██████████| 250/250 [00:00&lt;00:00, 1651.19it/s]\n\n\nModel accuracy: 0.860\n\n\n\n\n\n\n\n\n\n\nQ5: Evaluating sin transforms\nRepeat question 4, but using a different transform, defined as:\n\\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ \\sin(10 x_i) \\end{bmatrix}\\]\n\n\n\nAnswer\n\nclass SineRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        super().__init__(dims * 2)\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a quadratic feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.hstack([X, np.sin(10 * X)])\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(X, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = SineRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=2500)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 24.89, accuracy: 0.86: 100%|██████████| 2500/2500 [00:01&lt;00:00, 1773.91it/s]\n\n\nModel accuracy: 0.860\n\n\n\n\n\n\n\n\n\n\nQ6: Comparing feature transforms\nBased on the results, would you use any feature transform for this problem? If so, which one?\n\n\n\nAnswer\nA basic feature transform does appear to help, but only slightly.\n\nQ7: Creating your own transform\nRepeat question 4, but define your own transform to try to get as close as you can to classifying all the points correctly.\nThis doesn’t need to be perfect for full credit, just try to improve on the examples.\n\\[\\phi(x_i) = ?\\]\n\n\n\nAnswer\n\nclass MyRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        super().__init__(dims * 4)\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a quadratic feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.hstack([X, np.sin(X), np.cos(X), X ** 2])\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(X, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = MyRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=2500)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 5.78, accuracy: 0.99: 100%|██████████| 2500/2500 [00:01&lt;00:00, 1865.93it/s]\n\n\nModel accuracy: 0.990"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-3-implementing-a-neural-network",
    "href": "assignments/homeworks/Homework 4/solutions-S4MH4K.html#part-3-implementing-a-neural-network",
    "title": "Homework 4: Automatic Differentiation and Neural Networks (solutions)",
    "section": "Part 3: Implementing a neural network",
    "text": "Part 3: Implementing a neural network\nNow let’s extend our model to be a neural network! We’ll create a neural network class that extends our logistic regression class. First we’ll setup the needed weight matrices.\n\nQ8: Initializing a neural network\nFill in the Neural Network __init__ method below. The method should take in the input data dimension and a list of integers specifying the size of each hidden layer (the number of neurons in each layer). The function should create a list of numpy arrays of the appropriate shapes for the weight matrices.\nFor example if dims is 2 and hidden_sizes is [4, 4], then self.weights should have 3 entries of shapes [(4x2), (4x4), (1x4)]. This network is shown below (may not show in colab).\n\n\nInput Layer ∈ ℝ²Hidden Layer ∈ ℝ⁴Hidden Layer ∈ ℝ⁴Output Layer ∈ ℝ¹\n\nIf you find it easier you could also define the weights in terms of \\(W^T\\) instead, in which case the shapes would be: [(2x4), (4x4), (4x1)]. You could also consider how to add a bias term at each layer as in logistic regression (but this isn’t nessecary for full credit).\nThe values in each array should be drawn from a normal distribution with standard deviation 1. You can create such a matrix in numpy using:\nnp.random.normal(scale=1., size=shape)\n\nAnswer\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        self.weights = [1. * np.random.normal(scale=1., size=(i + 1, o)) for (i, o) in zip([dims] + hidden_sizes, hidden_sizes + [1])]\n\ntest_nn_constructor(NeuralNetwork)\n\nPassed!\n\n\nRecall that for logistic regression the prediction function (before threholding or sigmoid) was \\(\\mathbf{X}\\mathbf{w}\\). We now want to implement the prediction function for our neural network class. This function should perform the appropriate feature transforms and multiply by the regression weights. For a neural network with a single hidden layer this will look like:\n\\(f(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{w}_0\\)\nUse the sigmoid activation function for this problem.\nFor multiple layers we can also think of this a a chain of feature transforms: \\[\\Phi_1 = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\] \\[\\Phi_2 = \\sigma(\\Phi_1 \\mathbf{W}_2^T)\\] \\[...\\] \\[\\Phi_l = \\sigma(\\Phi_{l-1} \\mathbf{W}_l^T)\\] \\[f(\\mathbf{X}) = \\Phi_l\\mathbf{w}_0\\] Where \\(\\Phi_i\\) is just the variable that represents the neurons at layer \\(i\\) (the result of the first \\(i\\) transforms applied to \\(\\mathbf{X}\\)).\n\nQ9: Prediction function\nImplement the prediction function as described above. Note that the prediction function should use the weights passed into the w argument rather than self.weights, this will make it easier to implement the next question.\nHint: Note that this function should not apply a final sigmoid or thresholding, instead it should be the equivalent of linear_function from the previous homework\n\n\n\nAnswer\n\ndef prediction_function(self, X, w):\n    '''\n    Get the result of our base function for prediction (i.e. x^t w)\n\n    Args:\n        X (array): An N x d matrix of observations.\n        w (list of arrays): A list of weight matrices\n    Returns:\n        pred (array): An N x 1 matrix of f(X).\n    '''\n    for wi in w[:-1]:\n        X = sigmoid(LogisticRegression.prediction_function(self, X, wi))\n    pred = LogisticRegression.prediction_function(self, X, w[-1])\n    return pred.reshape((-1, 1))\n\nNeuralNetwork.prediction_function = prediction_function\ntest_nn_prediction_function(NeuralNetwork)\n\nPassed!\n\n\n\nQ10: Neural network loss\nImplement an nll_and_grad method for the NeuralNetwork class using Autograd to compute the gradient with respect to each weight matrix.\nHint: If you use np.pad anywhere in your implementation, Autograd may complain if you don’t include the keyword argument mode='constant'\n\n\n\nAnswer\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    loss = self.nll(X, y, self.weights)\n    grads = grad(self.nll, argnum=2)(X, y, self.weights)\n    return loss, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 2.25, accuracy: 1.00: 100%|██████████| 250/250 [00:00&lt;00:00, 1131.38it/s]  \n\n\nModel accuracy: 1.000\n\n\n\n\n\n\n\n\n\n\nQ11: Comparison\nHow does the neural network compare to explicit feature transforms in this case? How would you expect it to compare on other datasets?\n\n\n\nAnswer\nThe neural network performed much better in this case, without needing to hand-design a transform!"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/submission.html",
    "href": "assignments/homeworks/Homework 5/submission.html",
    "title": "Homework 5: Automatic Differentiation",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%205/hw5_support.py\n\n# Run me first!\nfrom hw5_support import *\n\n\n\n\n\nQ1\n\nclass _add(AutogradValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _neg(AutogradValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(AutogradValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(AutogradValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _div(AutogradValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _exp(AutogradValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nclass _log(AutogradValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our ForwardValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\n\n\n\n\n\nQ2\n\ndef forward_pass(self, args):\n    # Clear forward_grads if it exists\n    self.forward_grads = {}\n    ## YOUR CODE HERE\n\n\n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nAutogradValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x * x\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\n\n\n\n\n\nQ3\n\ndef graph_print(a):\n    ## YOUR CODE HERE\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\n\n\n\n\n\nQ4\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n    local_grads = self.grads(*self.parent_values)\n\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\n\n\n\n\n\nQ5\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## YOUR CODE HERE\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\n\n\n\n\n\nQ6\n\ndef wrap_array(a):\n    ## YOUR CODE HERE\n\ndef unwrap_gradient(a):\n    ## YOUR CODE HERE\n\n\ntest_wrap_unwrap(wrap_array, unwrap_gradient, AutogradValue)\n\n\n\n\n\n\nQ7\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/main.html",
    "href": "assignments/homeworks/Homework 5/main.html",
    "title": "Homework 5: Automatic Differentiation",
    "section": "",
    "text": "In this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/main.html#overview",
    "href": "assignments/homeworks/Homework 5/main.html#overview",
    "title": "Homework 5: Automatic Differentiation",
    "section": "",
    "text": "In this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/main.html#part-1-forward-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 5/main.html#part-1-forward-mode-automatic-differentiation",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 1: Forward-mode automatic differentiation",
    "text": "Part 1: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        parent_values    (list): A list of raw values of each input (as floats)\n        forward_grads (dict): A dictionary mapping inputs to gradients\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.parent_values = [arg.value if isinstance(arg, AutogradValue) else arg for arg in args]\n        self.forward_grads = {}\n        self.value = self.forward_pass()\n        self.grad = 0. # Used later for reverse mode\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.parent_values)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n\nclass ForwardValue(AutogradValue):\n    '''\n    Subclass for forward-mode automatic differentiation. Initialized the forward_grads\n    dict to include this value.\n    '''\n\n    def __init__(self, *args):\n        super().__init__(*args)\n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ1: Defining operations (15 points)\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\nclass _add(AutogradValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _neg(AutogradValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(AutogradValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(AutogradValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _div(AutogradValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _exp(AutogradValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nclass _log(AutogradValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our ForwardValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\n\nQ2: Defining forward-mode autodiff (20 points)\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the forward_grads property of the operation such that: - forward_grads has an entry for every input that appears in forward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self, args):\n    # Clear forward_grads if it exists\n    self.forward_grads = {}\n    ## YOUR CODE HERE\n\n\n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nAutogradValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x * x\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/main.html#part-2-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 5/main.html#part-2-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 2: Reverse-mode automatic differentiation",
    "text": "Part 2: Reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, just like forward-mode automactic differentiation, it makes sense to define a class to represent the result of an operation.\nIn this case, we’ll reuse the AutogradValue class we defined above as the the base class. The set of properties will be the same, except that instead of keeping track of a forward_grads dictionary, we’ll keep track of a new grad property. - grad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\))\nRemember that this will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5).\nLet’s see how this will work in practice. If we want to take derivatives using reverse-mode, we will first define the inputs using AutogradValue.\na = AutogradValue(5)\nb = AutogradValue(2)\nAs before, we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\nL.backward()\ndL_da = a.grad\nAgain, we’ll be able to compute operations with non-AutogradValue numbers, but won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\nNow that we’ve seen what our final produce will look like, let’s define our AutogradValue class.\nLet’s confirm that we do keep the entire compuational graph for operations defined in this way.\n\nQ3: Computational graph (10 points)\nWrite a function graph_print that takes a single argument. If the argument is an AutogradValue (or one of its subclasses), print its value property and then call graph_print on each of its parents. If the argument is not an AutogradValue, just print it. The format of printing is not important.\nHint: You can use the built-in Python function isinstance to determine if something is an AutogradValue or one of its subclasses. e.g. isinstance(a, AutogradValue)\n\ndef graph_print(a):\n    ## YOUR CODE HERE\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\nThe function should print (it’s ok if the numbers or order aren’t exact):\n2.995732273553991\n20.0\n10.0\n5.0\n5.0\n5\n2.0\n2.0\nNow in order to do automatic differentiation, we need to define how to do the backward pass. We’ll start with the backward_step for a single operation.\n\n\nQ4: Backward pass (15 points)\nFill in the method backward_pass which computes a single step of the reverse pass through the computational graph (assume self is an AutogradValue instance). If backward_pass is called on a value c, the method should: - Assume that self.grad contains the derivaive of the final loss with respect to c (\\(\\frac{dL}{dc}\\)). - Check if each parent of c is an AutogradValue. If it is, update that parent’s grad property to account for c (e.g. for parent a, update the value of \\(\\frac{dL}{da}\\))\nFor example: if c represents the result of an addition so c = a + b, calling backward_pass on c will update the grad property of both a and b. (a.grad represents \\(\\frac{dL}{da}\\) and is initialized to 0).\nHint: grads will be one of the methods we wrote in the last homework (and shown above). Recall that if c has parents a and b then grads method will give \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\).\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n    local_grads = self.grads(*self.parent_values)\n\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\nFinally we need to define the backward method itself. We will call this on the loss value to find the derivatives of the loss with respect to each input. This means working our way backward through the sequence of operations. Remember that if c=a+b, then if c.grad is \\(\\frac{dL}{dc}\\), calling backward_pass on c will update \\(\\frac{dL}{da}\\) (a.grad) and \\(\\frac{dL}{db}\\) (b.grad).\nThe complication is that c may be used in multiple operations, so we can’t call backward_pass on c until we’ve called backward_pass on each child operation of c otherwise c.grad won’t have the correct value of \\(\\frac{dL}{dc}\\), as in this example:\nc = a + b\ng = c * 2\nh = c + 4\nL = g * h\n\nL.backward_pass() # Updates dL/dg and dL/dh\nh.backward_pass() # Updates dL/dc\n\n##WRONG ORDER\nc.backward_pass() # Incorrect because dL/dc hasn't accounted for dL/dg\ng.backward_pass()\n\n## CORRECT ORDER\ng.backward_pass() # Updates dL/dc\nc.backward_pass() # Updates dL/da and dL/db\n\n\nQ5: Backward method (20 points)\nFill in the backward method for AutogradValue. Your backward method should call backward_pass on each operation used to compute the loss (self is the loss value). Some important things to keep in mind: - backward_pass should only be called once on each operation - backward_pass must be called on every child of an operation before it can be called on the operation. - You should not try to call backward_pass on values that aren’t instances of AutogradValue, even though they might be stored in operation.parents\nHint: We discussed a simple approach to this problem in class! In general the problem we’re solving here is a topological sort. We won’t score efficiency in grading, but it still might be worth optimizing this function a bit.\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## YOUR CODE HERE\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\nIf we want to train a neural network using our automatic differentiation implementation, we’re going to want to be able to use numpy to do matrix operations. Fortunately, the our AutogradValue class is (mostly) compatible with numpy!\nWe can create arrays of AutogradValue and take derivatives as shown below:\n\na = np.asarray([AutogradValue(5), AutogradValue(2)])\nL = np.dot(a, a)\nL.backward()\nprint('Gradient for a', a[0].item().grad, a[1].item().grad)\n\nIt would be a bit tedious to define every AutogradValue array in this way, so let’s write some convinience functions to make doing automatic differentiation with numpy easier.\n\n\nQ6: Array support (10 points)\nComplete the following two functions wrap_array and unwrap_gradient.\nwrap_array should take a numpy array of floats and return a new array where every element has been made into an AutogradValue.\nunwrap_gradient should take a numpy array of AutogradValue and return a new array of floats, where every element is the extracted grad property of the corresponding element from the original array.\nBoth of these functions should work on 2-D arrays (matrices) at a minimum (but more general solutions that support 1 and/or &gt;2 dimensional arrays are also possible).\nHint: You can create an array from nested lists as np.asarray([[1, 2], [3, 4]]).\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    ## YOUR CODE HERE\n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    ## YOUR CODE HERE\n\n\ntest_wrap_unwrap(wrap_array, unwrap_gradient, AutogradValue)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/main.html#part-2-training-a-neural-network",
    "href": "assignments/homeworks/Homework 5/main.html#part-2-training-a-neural-network",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 2: Training a neural network",
    "text": "Part 2: Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks! Below is a (slightly modified) version of the neural network class we wrote for the last homework.\n\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if isinstance(a, AutogradValue) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + np.exp(-x))\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n\n\nQ7: Autograd for a neural network (10 points)\nImplement an nll_and_grad method for the NeuralNetwork class using your reverse-mode automatic differentiation implmentation to compute the gradient with respect to each weight matrix.\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/submission.html",
    "href": "assignments/homeworks/Homework 2/submission.html",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\n\n\n\n\nQ1\n\n# Test inputs\nx = np.array([1, -3, 5])\nw = np.array([-1, 2, 0.5, 2])\ny = -2.5\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## Validate the function\nassert y == linear_regression(x, w)\n\n\n\n\n\n\nQ2\n\n# Test inputs\nw = np.array([0.5, 2])\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## CODE TO PLOT THE FUNCTION HERE\nX =\ny = linear_regression(X, w)\n\n\n\n\n\n\n\nQ3\n\ndef mse_and_grad(w, X, y):\n    ### YOUR CODE HERE\n    return mse, grad_w\n\n\n\n\n\n\nQ4\n\ndef gradient_descent(value_and_grad, w0, lr, niter, *args):\n    # Get the inital loss\n    initial_loss, _ = value_and_grad(w0, *args)\n    losses = []\n\n    ### YOUR CODE HERE\n\n    return w, losses\n\n\ndata = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n# Uncomment if on Colab!\n# import urllib.request\n# link = 'https://gist.githubusercontent.com/gabehope/4df286bbd9a672ce7731d52afe3ca07e/raw/65026711d71affaafb9713ddf5b6ef29125ba0fb/auto.csv'\n# data = np.genfromtxt(urllib.request.urlopen(link), delimiter=',', missing_values=['?'], filling_values=[0])\n\n# MPG is the output value\ntarget = 'MPG'\ny = data[:, 0]\n\n# The other variables are inputs in the order listed\nfeatures = ['displacement', 'weight', 'acceleration', 'year']\nX = data[:, [2, 4, 5, 6]]\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\n\n\n\n\n\nQ5\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw, losses =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\n\n\n\nQ6\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\n\n\n\nQ7\n\nw0 = np.zeros((5,))\n\n### YOUR CODE HERE\nw, losses =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nDESCRIBE RESULTS HERE\n\n\n\n\n\nQ8\n\n### CODE TO SPLIT DATASET HERE\nXweight_train =\ny_train =\n\nXweight_test =\ny_test =\n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((2,))\nw, losses =\n\n### CODE TO EVALUATE MODEL HERE\nmse_train =\nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\n\n\n\n\n\nQ9\n\n### CODE TO SPLIT DATASET HERE\nX_train =\ny_train =\n\nX_test =\ny_test =\n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((5,))\nw, losses =\n\n### CODE TO EVALUATE MODEL HERE\nmse_train =\nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nDESCRIBE RESULTS HERE\n\n\n\n\n\nQ10\nYOUR ANSWER HERE \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\n\n\n\nQ11\nYOUR ANSWER HERE \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\n\n\n\nQ12\n\ndef nll_and_grad(w, X, y):\n    N = X.shape[0]\n    ### YOUR CODE HERE\n\n\n    return nll / N, grad_w / N\n\n\n\n\n\n\nQ13\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw_laplace, losses_laplace =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\n\n\n\nQ14\n\n### CODE FROM Q5 HERE\nw_mse, losses_mse =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nWRITTEN ANSWER HERE\n\n\n\n\n\nQ15\n\n# Example of deconstructing and reconstructing the parameter vector.\nw1, b = w\nwi = np.array([w1, b])\n\n### PLOTTING CODE FOR NLL HERE\nplt.figure(figsize=(6, 4))\n\n\n### PLOTTING CODE FOR MSE HERE\nplt.figure(figsize=(6, 4))\n\nIn the cells below, copy your code for Q5 and Q13. Try out different learning rates and and numbers of iterations. Observe what happens to the loss plot in each case.\n\n### COPY Q5 CODE HERE\n\n\n### COPY Q13 CODE HERE\n\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 9/submission.html",
    "href": "assignments/homeworks/Homework 9/submission.html",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%209/hw9_support.py\n\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\nfrom hw9_support import *\ndata_path = '/tmp/data'\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\n\n\n\nQ1\nYOUR ANSWER HERE\n\n\n\n\n\nQ2\nYOUR ANSWER HERE\n\n\n\n\n\nQ3\n\ndef conv1d(sequence, kernel):\n    kernel_size = kernel.shape[0]\n    sequence_length = sequence.shape[0]\n    output_length = ## YOUR CODE HERE\n\n    output = np.zeros((output_length,))\n    ## YOUR CODE HERE\n    \n    return output\n\nNow we’ll try out our convolution on a sequence of data! Below, we’ll create an arbitrary input sequence and apply a kernel to it using the convolution function we just wrote. If you’re curious, try changing the kernel and see how the result changes!\n\n# Create a domain to create our input\nx = np.linspace(-5, 5, 25)\n\n# Create an sequence\nsignal = np.sin(x * 1.5) + np.cos(x / 2) + np.cos(x / 1.3 + 2)\n\n# Create a kernel for our convolution\nkernel = np.array([-1, 1, -1])\n\n# Plot the input, kernel and the result of the convolution\nf, ax = plt.subplots(1, 3, figsize=(7, 2))\nax[0].plot(signal)\nax[0].set_title('Input')\nax[1].plot(kernel)\nax[1].set_title('Kernel')\nax[2].plot(conv1d(signal, kernel))\nax[2].set_title('Convolved')\n\n\n\n\n\n\nQ4\n\ndef conv1d_backward(sequence, kernel, dloss_doutput):\n    kernel_size = kernel.shape[0]\n    sequence_length = sequence.shape[0]\n    output_length = dloss_doutput.shape[0]\n\n    dloss_dsequence = np.zeros_like(sequence)\n    dloss_dkernel = np.zeros_like(kernel)\n\n    ## YOUR CODE HERE\n\n    return dloss_dsequence, dloss_dkernel\n\n\n\n\n\n\nQ5\n\ndef conv2d(image, kernel):\n    kernel_size = kernel.shape[0]\n    image_height, image_width = image.shape[0], image.shape[1]\n    output_height = # YOUR CODE HERE\n    output_width = # YOUR CODE HERE\n\n    output = np.zeros((output_height, output_width))\n    ## YOUR CODE HERE\n\n    return output\n\nLet’s try out our conv2d function on an image. As we’ve used in previous homeworks, we can use PyTorch to load a variety of real datasets. For image datasets, these are available in the torchvision library. We can download the MNIST dataset of number images that we’ve used before with the following code:\n\nimport torchvision\ndata = torchvision.datasets.MNIST(data_path,       # Specify where to store the data\n                                  download=True,   # Whether to download the data if we don't have it\n                                  train=True       # Download the training set (False will download the validation set)\n                                  )\nprint(data[0])\n\nWe see that in the above if we take an observation from this dataset we get a tuple of an image and a corresponding label. The image is given as an object from the Pillow library (PIL).\n\ndata[0][0]\n\nWe can convert Pillow images to torch tensors using a torchvision.transforms.ToTensor object, or we can pass such an object directly to the dataset class to transform our data automatically.\n\n# Create a transform object\ntransform = torchvision.transforms.ToTensor()\n\n# Apply the transform to the first image in the dataset (ignoring the label)\nimage = transform(data[0][0])\nprint('Converted image type:', type(image))\n\n# Give the transform directly to the MNIST object\ndata = torchvision.datasets.MNIST(data_path, transform=transform)\nprint('Automatically converted image type:', type(data[0][0]))\nprint('Image shape:', data[0][0].shape)\n\nIf we look at the shape of an image, we see that it has height and width dimensions, but also an extra dimension. This is the color channel dimension. Since these are greyscale images with only a single color channel we’ll get rid of it for now.\n\n# Take just the height and width dimensions of our image\nimage = data[0][0][0]\nimage.shape\n\nFianlly let’s apply a few different kernels to the image and visualize the results.\n\n# Create an edge detection kernel\nkernel = np.array([[ 1,  1,  1],\n                   [ 0,  0,  0],\n                   [-1, -1, -1]])\n\n# Create the axes for our plots\nf, ax = plt.subplots(2, 4, figsize=(8, 4))\nax[0, 0].imshow(image, cmap='Greys_r')\nax[0, 0].set_title('Image')\n\n# Apply our convolution and plot the result\noutput = conv2d(image, kernel)\nax[0, 1].imshow(output, cmap='Greys_r')\nax[0, 1].set_title('Vertical edges')\nax[1, 1].imshow(kernel, cmap='Greys_r')\n\n# Apply our transposed convolution and plot the result\noutput = conv2d(image, kernel.T)\nax[0, 2].imshow(output, cmap='Greys_r')\nax[0, 2].set_title('Horizontal edges')\nax[1, 2].imshow(kernel.T, cmap='Greys_r')\n\n# Apply a kernel of all 1s to blur the image\noutput = conv2d(image, np.ones_like(kernel))\nax[0, 3].imshow(output, cmap='Greys_r')\nax[0, 3].set_title('Blur')\nax[1, 3].imshow(np.ones_like(kernel), cmap='Greys_r')\n\n\n\n\n\n\nQ6\n\ndef conv2d(image, kernel, padding=0):\n    kernel_size = kernel.shape[0]\n    image_height, image_width = image.shape[0], image.shape[1]\n    output_height = # YOUR CODE HERE\n    output_width = # YOUR CODE HERE\n\n    output = np.zeros((output_height, output_width))\n    ## YOUR CODE HERE\n\n    return output\n\nLet’s visualize the same convolution with and without padding.\n\n# Create an edge detection kernel\nkernel = np.array([[ 1,  1,  1],\n                   [ 0,  0,  0],\n                   [-1, -1, -1]])\n\n# Take just the height and width dimensions of our image\nimage = data[0][0][0]\n\n# Create the axes for our plots\nf, ax = plt.subplots(1, 3,)\nax[0].imshow(image, cmap='Greys_r')\nax[0].set_title('Image')\n\n# Apply our convolution with no padding and plot the result\noutput_0 = conv2d(image, kernel, padding=0)\nax[1].imshow(output_0, cmap='Greys_r')\nax[1].set_title('Padding=0')\n\n# Apply our convolution with a padding of 10 and plot the result\noutput_10 = conv2d(image, kernel, padding=10)\nax[2].imshow(output_10, cmap='Greys_r')\nax[2].set_title('Padding=10')\n\nWhile it is convinient to think of images as being matrices, as we’ve seen, color images actually have 3 values at each location! A red value, a green value as a blue value as shown below. We call these the color channels.\n\nimport PIL # Pillow\n# Load an image\nimage = np.array(PIL.Image.open('astronaut.jpg'))[..., :3]\n\n# If you're in Colab, you can use the commented line below to load the same image.\n#image = (skimage.transform.resize(skimage.data.astronaut(), (128, 128, 3)) * 255).astype(int)\n\n# Plot the color image\nf, ax = plt.subplots(1, 4, figsize=(8, 3))\nax[0].imshow(image)\nax[0].set_title('Image')\n\n# Plot each color channel separately\nax[1].imshow(image[..., 0], cmap='Greys_r')\nax[1].set_title('Red channel')\nax[2].imshow(image[..., 1], cmap='Greys_r')\nax[2].set_title('Green channel')\nax[3].imshow(image[..., 2], cmap='Greys_r')\nax[3].set_title('Blue channel')\n\n\n\n\n\n\nQ7\n\ndef conv2d(image, kernel, padding=0):\n    kernel_size = kernel.shape[-1]\n    channels, image_height, image_width = image.shape[0], image.shape[1], image.shape[2]\n    output_height = # YOUR CODE HERE\n    output_width = # YOUR CODE HERE\n\n    output = np.zeros((output_height, output_width))\n\n    return output\n\nLet’s try applying using our convolution function on a color image! Below we’ll load an image using the Python Pillow library and use our function to compute a convolution, using an edge detection kernel.\n\nimport PIL # Pillow\n\n# Create an edge detection kernel\nkernel = np.array([[ 1,  1,  1],\n                   [ 0,  0,  0],\n                   [-1, -1, -1]])\n# Repeat it for the red, green and blue channels\nkernel_vertical = np.stack([kernel, kernel, kernel])\n# Create a transposed version as well\nkernel_horizontal = np.stack([kernel.T, kernel.T, kernel.T])\n\n# Load an image and convert it to a numpy array\nimage = np.array(PIL.Image.open('astronaut.jpg'))[..., :3]\n\n# Create the axes for our plots\nf, ax = plt.subplots(1, 4, figsize=(8, 3))\nax[0].imshow(image)\n\n# Convert our image from (height x width x channels) to (channels x height x width)\nimage = image.transpose(2, 0, 1)\n\n# Apply our convolution and plot the result\noutput_vertical = conv2d(image, kernel_vertical)\nax[1].imshow(output_vertical, cmap='Greys_r')\n\n# Apply our transposed convolution and plot the result\noutput_horizontal = conv2d(image, kernel_horizontal)\nax[2].imshow(output_horizontal, cmap='Greys_r')\n\n# Apply a averaging (blur) kernel\noutput_mean = conv2d(image, np.ones_like(kernel_horizontal))\nax[3].imshow(output_mean, cmap='Greys_r')\n\n\n\n\n\n\nQ8\n\ndef conv2d(image, kernel, padding=0):\n    kernel_size = kernel.shape[-1]\n    output_channels = kernel.shape[0]\n    N, channels, image_height, image_width = image.shape[0], image.shape[1], image.shape[2], image.shape[3]\n    output_height = # YOUR CODE HERE\n    output_width = # YOUR CODE HERE\n\n    output = np.zeros((N, output_channels, output_height, output_width))\n    ## YOUR CODE HERE\n\n    return output\n\nPyTorch provides a convinient way to load batches of images from a dataset via the DataLoader class. The dataloader will automatically group images and labels into tensors for us!\n\nfrom torch.utils.data import DataLoader\n\nloader = DataLoader(data,            # The dataset\n                    batch_size=8,    # The batch size\n                    shuffle=True,    # Tell PyTorch to randomize the order of the data\n                    )\n\nfor batch in loader:\n    images, labels = batch\n    print('Image batch shape:', images.shape)\n    print('Label batch shape:', labels.shape)\n    break\n\nNow we can try applying 3 kernels to a batch of data simultaniously.\n\n# Create an edge detection kernel\nkernel = np.array([[ 1,  1,  1],\n                   [ 0,  0,  0],\n                   [-1, -1, -1]])\n# Repeat it for the red, green and blue channels\nkernel_vertical = np.stack([kernel])\n# Create a transposed version as well\nkernel_horizontal = np.stack([kernel.T])\n# Create a blur kernel\nkernel_blur = np.ones_like(kernel_horizontal)\n\n# Put all 3 kernels together into a single array\nkernel = np.stack([kernel_vertical, kernel_horizontal, kernel_blur])\noutput = conv2d(images, kernel)\n\n# Create the axes for our plots\nf, ax = plt.subplots(1, 5, figsize=(10, 3))\nax[0].imshow(images[0][0], cmap='Greys_r')\nax[0].set_title('Image')\n\n# Plot the result of the first kernel\nax[1].imshow(output[0][0], cmap='Greys_r')\nax[1].set_title('Kernel 1')\n\n# Plot the result of the second kernel\nax[2].imshow(output[0][1], cmap='Greys_r')\nax[2].set_title('Kernel 2')\n\n# Plot the result of the third kernel\nax[3].imshow(output[0][2], cmap='Greys_r')\nax[3].set_title('Kernel 3')\n\n# Plot the result of all three kernels as the rgb channels of an image\nfull_output = output[0].transpose(1, 2, 0)\nfull_output = full_output - full_output.min()\nfull_output = full_output / full_output.max()\nax[4].imshow(full_output)\nax[4].set_title('All kernels')\n\n\n\n\n\n\nQ9\n\ndef maxpool1d(sequence, pool_size=3, stride=1):\n    sequence_length = sequence.shape[0]\n    output_length = # YOUR CODE HERE\n\n    output = np.ones((output_length,)) * -np.inf\n    \n    ## YOUR CODE HERE\n\n    return output\n\n\n\n\n\n\nQ10\n\nmodel = nn.Sequential(\n    ## YOUR CODE HERE\n)\n\nrun_model(data_path, model)\n\n\n\n\n\n\nQ11\n\n# Create the axes for our plots\nf, ax = plt.subplots(2, 6, figsize=(12, 4))\n\n# We're using a nn.Sequential model, so we can access the first layer as follows\nlayer = model[0]\n\n\n## YOUR CODE HERE\n\n\n\n\n\n\nQ12\n\nimproved_model = nn.Sequential(\n    ## YOUR CODE HERE\n)\n\nrun_model(data_path, improved_model)\n\n\nencoder = model\n\n\n\n\n\n\nQ13\n\ndecoder = nn.Sequential(\n    ## YOUR CODE HERE\n)\n\nFor convinience, we’ll create an autoencoder model that lets us combine the encoder and decoder in to one object.\n\nclass Autoencoder(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, X):\n        return self.decoder(self.encoder(X))\n    \nae_model = Autoencoder(encoder, decoder)\n\n\n\n\n\n\nQ14\n\ndef autoencoder_output_and_mseloss(model, X,  y):\n    '''\n    Inputs:\n        model: nn.Module, an autoencoder model.\n        X: tensor (float), an N x C x H x W tensor of images\n        y: tensor (float), an N x classes tensor of labels (unused)\n\n    Outputs:\n        output: tensor (float), an N x C x H x W tensor of reconstructed images.\n        loss: float, the mean squared error loss between the input and reconstructions.\n    '''\n    \n    ## YOUR CODE HERE\n    return output, loss\n\n\ndef autoencoder_output_and_maeloss(model, X,  y):\n    '''\n    Inputs:\n        model: nn.Module, an autoencoder model.\n        X: tensor (float), an N x C x H x W tensor of images\n        y: tensor (float), an N x classes tensor of labels (unused)\n\n    Outputs:\n        output: tensor (float), an N x C x H x W tensor of reconstructed images.\n        loss: float, the mean squared error loss between the input and reconstructions.\n    '''\n    \n    ## YOUR CODE HERE\n    return output, loss\n\n\nget_output_and_loss = autoencoder_output_and_maeloss# MSE or MAE\nrun_model(data_path, ae_model, learning_rate=0.003, get_output_and_loss=get_output_and_loss)\n\n\noutput = ae_model(images)\n\n# Convert to numpy\noutput = output.detach().numpy()\n\n# Create the axes for our plots\nf, ax = plt.subplots(4, 2, figsize=(4, 8))\nfor r in range(4):\n    ax[r, 0].imshow(images[r][0], cmap='Greys_r')\n    ax[r, 0].set_title('Image')\n    ax[r, 0].axis('off')\n    ax[r, 1].imshow(output[r][0], cmap='Greys_r')\n    ax[r, 1].set_title('Reconstruction')\n    ax[r, 1].axis('off')\n\n\n\n\n\n\nQ15\nYOUR ANSWER HERE\n\n\n\n\n\nQ16\n\nencoder = nn.Sequential(\n    ## YOUR CODE HERE                              \n)\n\ndecoder = nn.Sequential(\n    ## YOUR CODE HERE\n)\n\nae_model = Autoencoder(encoder, decoder)\nrun_model(data_path, ae_model, learning_rate=0.003, get_output_and_loss=autoencoder_output_and_maeloss)\n\n\noutput = ae_model(images)\n\n# Convert to numpy\noutput = output.detach().numpy()\n\n# Create the axes for our plots\nf, ax = plt.subplots(4, 2, figsize=(4, 8))\nfor r in range(4):\n    ax[r, 0].imshow(images[r][0], cmap='Greys_r')\n    ax[r, 0].set_title('Image')\n    ax[r, 0].axis('off')\n    ax[r, 1].imshow(output[r][0], cmap='Greys_r')\n    ax[r, 1].set_title('Reconstruction')\n    ax[r, 1].axis('off')\n\n\n\n\n\n\nQ17\n\nimage_0 = images[2, 0] # Select image 0 and remove unused channel dimension\nimage_1 = images[1, 0] # Same for second image\n\nf, ax = plt.subplots(1, 10, figsize=(15, 1.5))\nfor i, t in enumerate(np.linspace(0, 1, 10)):\n    # Perform the interpolation and show each intermediate result.\n    \n    image_t = ## YOUR CODE HERE\n    ax[i].imshow(image_t, cmap='Greys_r')\n\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 9/main.html",
    "href": "assignments/homeworks/Homework 9/main.html",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "For this homework and for the final project, you may find it useful to run your code with access to a sufficient GPU, which may allow your code to run faster (we will talk about why later in the course). If you do not have access to a powerful GPU on your personal computer (e.g. if you primarily use a laptop), then there are 2 options you may consider for using a remotely hosted GPU.\nNote that some laptops may actually run this code faster than the course server, so you may want to try it first on your laptop regardless\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/3e574b9d225004ff1a179136c29ef4d5/raw/288949bfc3b768b7603fe4decafbcd589c9a72d5/hw9_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw9_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\nfrom hw9_support import *\ndata_path = '/tmp/data'\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\nWe have a GPU server available for this course that you all should have access to. (If you are not a Mudd student we may need to get you setup with a Mudd CS account). The server name is teapot.cs.hmc.edu.\nYou can login to the server via a terminal using your hmc username and password:\nssh &lt;USERNAME&gt;@teapot.ssh.hmc.edu\nThen run the command:\nsource /cs/cs152/venv/bin/activate\nto activate the course Python enviornment, followed by:\njupyter lab --no-browser\nto start a Jupyter server (if you want to keep a server running you can use tmux). At the end of the Jupyter startup output you should see a line like this:\n\n\n\nimage.png\n\n\nThis tells us the port and password we need to access the server remotely. In order to access the server we’ll start an ssh tunnel. Open a new terminal window and run the command:\nssh -L 9000:localhost:&lt;PORT&gt; &lt;USERNAME&gt;@teapot.cs.hmc.edu\nWhere &lt;PORT&gt; is the port output from JupyterLab above (8888 in the example image). 9000 is a local network port for your compute to access the server. If 9000 is in use, you can change the number to something different. Once the ssh tunnel is running you can access the notebook server by navigating to http://localhost:9000/lab in a web browser.\nYou can also setup VSCode to connect to this server. At the top right of the window click the kernel menu:\n\n\n\nimage.png\n\n\nYou should see the following popup:\n\n\n\nimage.png\n\n\nClick Select another kernel, then Existing Jupyter Server and paste the address from above:\n\n\n\nimage.png\n\n\nPaste the token from the Jupyter output when prompted for a password. If given multiple kernel options, select Python3. You should now be running the notebook code remotely!\n\n\n\nIf you are unable to get the course server to work, another option is to use Google’s Colab service which provides a simple way to run GPU-accelerated Jupyter notebooks on the web.\nTo start, go to: https://colab.research.google.com/\n\n\n\nimage.png\n\n\nOnce you open the notebook, you’ll want to add a GPU. To do this navigate to runtime-&gt;change runtime type in the top menu.\nIn the popup menu select T4 GPU and click save.\n\n\n\nimage.png\n\n\nNow you should be able to run the notebook! Once you’ve completed the assignment, you can download the notebook to submit it as usual."
  },
  {
    "objectID": "assignments/homeworks/Homework 9/main.html#option-1-use-the-course-gpu-server",
    "href": "assignments/homeworks/Homework 9/main.html#option-1-use-the-course-gpu-server",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "We have a GPU server available for this course that you all should have access to. (If you are not a Mudd student we may need to get you setup with a Mudd CS account). The server name is teapot.cs.hmc.edu.\nYou can login to the server via a terminal using your hmc username and password:\nssh &lt;USERNAME&gt;@teapot.ssh.hmc.edu\nThen run the command:\nsource /cs/cs152/venv/bin/activate\nto activate the course Python enviornment, followed by:\njupyter lab --no-browser\nto start a Jupyter server (if you want to keep a server running you can use tmux). At the end of the Jupyter startup output you should see a line like this:\n\n\n\nimage.png\n\n\nThis tells us the port and password we need to access the server remotely. In order to access the server we’ll start an ssh tunnel. Open a new terminal window and run the command:\nssh -L 9000:localhost:&lt;PORT&gt; &lt;USERNAME&gt;@teapot.cs.hmc.edu\nWhere &lt;PORT&gt; is the port output from JupyterLab above (8888 in the example image). 9000 is a local network port for your compute to access the server. If 9000 is in use, you can change the number to something different. Once the ssh tunnel is running you can access the notebook server by navigating to http://localhost:9000/lab in a web browser.\nYou can also setup VSCode to connect to this server. At the top right of the window click the kernel menu:\n\n\n\nimage.png\n\n\nYou should see the following popup:\n\n\n\nimage.png\n\n\nClick Select another kernel, then Existing Jupyter Server and paste the address from above:\n\n\n\nimage.png\n\n\nPaste the token from the Jupyter output when prompted for a password. If given multiple kernel options, select Python3. You should now be running the notebook code remotely!"
  },
  {
    "objectID": "assignments/homeworks/Homework 9/main.html#option-2-google-colab",
    "href": "assignments/homeworks/Homework 9/main.html#option-2-google-colab",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "If you are unable to get the course server to work, another option is to use Google’s Colab service which provides a simple way to run GPU-accelerated Jupyter notebooks on the web.\nTo start, go to: https://colab.research.google.com/\n\n\n\nimage.png\n\n\nOnce you open the notebook, you’ll want to add a GPU. To do this navigate to runtime-&gt;change runtime type in the top menu.\nIn the popup menu select T4 GPU and click save.\n\n\n\nimage.png\n\n\nNow you should be able to run the notebook! Once you’ve completed the assignment, you can download the notebook to submit it as usual."
  },
  {
    "objectID": "assignments/homeworks/Homework 7/solutions-TOLGQV.html",
    "href": "assignments/homeworks/Homework 7/solutions-TOLGQV.html",
    "title": "Homework 7: PyTorch",
    "section": "",
    "text": "Now that we’ve successfully built our own tool for automatic differentiation and neural networks, let’s look at an industry-standard tool for accomplishing the same tasks: PyTorch.\nThroughout this homework to may find it helpful to refer to the PyTorch documentation, as well as the lecture notebook on Pytorch.\nWe saw in class that we can create a function with parameters in PyTorch using the torch.nn module that we’ll import as just nn. We can do this by creating a subclass of nn.Module and defining the parameters with nn.Parameter.\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/4d66c02805cb1a8b1b1f6043f08c5929/raw/14332b6d752fe1c7420647a2fe7eeb587cd767ef/hw6_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw7_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\nimport torch\nfrom torch import nn\nfrom hw7_support import *\n\n\nclass LinearZeros(nn.Module):\n    '''\n    A PyTorch module representing a linear/affine function with weights W and bias b:\n        f(X) = XW + b\n    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n\n    This version of the Linear module initializes the parameters to 0.\n    '''\n    def __init__(self, in_dimensions, out_dimensions):\n        # Call the nn.Module __init__ function\n        super().__init__()\n\n        # Create parameters that we can fit with gradient descent.\n        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n        # This assumes X is 2-dimensional (a matrix)!\n        return torch.matmul(x, self.weights) + self.bias\n\nWe can create a 1-dimensional linear function by creating a LinearZeros object, specifying that both the input and output dimensions should be 1. The method model.parameters() will give us access to all the weights we can fit with gradient descent.\n\nmodel = LinearZeros(1, 1)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[0.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nWe can also call this model just like any other function.\n\n# Create 4 1-dimensional inputs\nx = torch.ones((4, 1))\n\nmodel(x)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;AddBackward0&gt;)\n\n\nLet’s start by creating a simple dataset to use for the next few problems. We’ll use a regression dataset similar to the one we saw in class. In this case, I’ve provied data already split into training and validation sets.\n\n# Create the training inputs and labels\nx = torch.rand(200, 1) * 10 - 5.\ny = x ** 2 / 2 + torch.sin(x * 5) - 5\n\n# Create the validation inputs and labels\nxvalid = torch.rand(200, 1) * 10 - 5.\nyvalid = xvalid ** 2 / 2 + torch.sin(xvalid * 5 + torch.pi) - 5\n\nplotRegression(x, y, xvalid, yvalid)\n\n\n\n\n\n\n\n\nWe can make predictions for our data using the model we just definied:\n\npredictions = model(x)\npredictions[:5]\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;SliceBackward0&gt;)\n\n\nHowever if we plot the prediction function, we’ll see that it isn’t very good as we haven’t optimized the parameters yet:\n\nplotRegression(x, y, xvalid, yvalid, model=model)\n\n\n\n\n\n\n\n\nThe first thing we’ll need to optimize our model is a loss function. As we saw in class, the convention in PyTorch is to separate the loss from the model, so we’ll write a simple function that takes in predictions and labels, returning the mean squared error loss.\n\n\nComplete the mse_loss function below. The function should compute the same MSE loss we’ve seen in previous homeworks, but using PyTorch operations.\n\\[\\textbf{Loss}(\\mathbf{a}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N(a_i - y_i)^2\\]\nHint: As we see above, our linear module returns a column-vector (predictions is 2-dimensional), but y is just a vector (y is 1-dimensional). Make sure to account for this!\n\n\n\n\ndef mse_loss(prediction, labels):\n    return torch.mean((prediction.reshape((-1,)) - labels.reshape((-1,))) ** 2)\n\n\n# Test to check\ntorch.manual_seed(0)\nassert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)\n\nWith our loss in hand, we can run gradient descent to optimize our model’s parameters. This time, we’ll use the torch.optim module, which includes many useful variations of gradient descent.\n\n\n\nComplete the gradient descent function below. The function should: - Create an optim.SGD optimizer for the model’s parameters with the specified learning rate - At each step: - Compute the model output and loss (loss_func) on the training data - Compute the gradients of the loss with respect to the model parameters - Take a gradient descent step - Reset the parameter gradients to 0 - Compute the validation loss\n\n\n\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)\n\n100%|██████████| 1/1 [00:00&lt;00:00, 27.20it/s]\n\n\nPassed!\n\n\n\n\n\n\nmodel = LinearZeros(1, 1)\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:00&lt;00:00, 10880.02it/s]\n\n\n\n\n\n\n\n\n\nNow that we have a function to train a PyTorch model, we can try something bigger and more exciting! Let’s train a neural network.\n\n\n\nCreate a PyTorch model for a neural network with the following specification: - The network should have 4 hidden layers, each with 20 neurons - The network should take 1-dimensional inputs as above - Each layer should use the LinearZeros module we just wrote - Each linear layer should be followed by a ReLU activation (except the output), use the nn.ReLU() module.\nHint: Remember that you can use the nn.Sequential class to easily compose a sequence of functions in PyTorch.\n\n\n\n\nmodel = nn.Sequential(\n            LinearZeros(1, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 1),\n            )\n\n# Test the model build\ntest_build(model, LinearZeros, dropout_type=None, type='zeros')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3014.51it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened when you attempted to train the model above? Why did this happen? Give a short 1-2 sentence answer.\n\n\n\nNothing happened because we initialized all weights to 0.\nLet’s try modifying our Linear module with a different strategy for initialization.\n\n\n\nModify the LinearZeros implementation from above to initialize the weights and bias parameters from a standard normal distribution \\(w,b \\sim \\mathcal{N}(0, 1)\\). Then modify your model from Q6 to use this new module.\nHint: You may find the torch.randn function useful here. You might also find that the model doesn’t train! We’ll address this in the next question.\n\n\n\n\nclass LinearNormal(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.weights = nn.Parameter(torch.randn(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.randn(out_dimensions))\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n    \nmodel = nn.Sequential(\n            LinearNormal(1, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 1),\n            )\n\n# Test the model build and LinearKaiming\ntest_normal(LinearNormal)\ntest_build(model, LinearNormal, dropout_type=None, type='normal')\n\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3333.41it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nIn the previous question you might have found that gradient descent didn’t work. This could suggest that our learning rate is set wrong. Think about a strategy that you might use to find an appropriate learning rate for fitting this model and try it out below. Then explain the strategy that you used. Is there any way you could improve this strategy to make finding a learning rate quicker?\n\n\n\n\n# Modify this code to choose a good learning rate\nmodel = nn.Sequential(\n            LinearNormal(1, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 1),\n            )\n\nlr = 0.00001\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3079.02it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nWe saw in class that a common, useful approach for initializing neural networks is to use a Kaiming normal initialization. In this approach we draw each initial weight from a normal distribution where the standard deviation is scaled by the square root of the number of input dimensions to the layer. If \\(\\mathbf{W} \\in \\mathbb{R}^{d\\times e}\\) then: \\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\mathbf{W}: d \\times e\\] \\[b_j = 0 \\quad \\mathbf{b}: e\\] We’ll initialize the biases to \\(0\\). Below, implement a linear module using the Kaiming normal initialization, then repeat Q5 using the LinearKaiming class and the learning rate you chose in Q8. If needed, adjust the learning rate until your model almost perfectly fits the training data.\n\n\n\n\nclass LinearKaiming(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.weights = nn.Parameter(torch.randn(in_dimensions, out_dimensions) / np.sqrt(in_dimensions))\n        self.bias =nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n    \nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\n\n# Test the model build and LinearKaiming\ntest_kaiming(LinearKaiming)\ntest_build(model, LinearKaiming, dropout_type=None, type='normal')\n\nlr = 0.01\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3045.19it/s]\n\n\n\n\n\n\n\n\n\nIf all went well so far, we should find that our model fits our data well, but perhaps a little bit too well. Let’s try out some of the strategies we’ve seen to reduce overfitting, starting with early stopping.\n\n\n\nModify your gradient descent algorithm to implment a basic form of early stopping: stop gradient descent as soon as the validation loss increases from the previous iteration. Test this approach with the same model from Q9.\n\n\n\n\ndef gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n        if len(valid_losses) &gt; 1 and valid_losses[-2] &lt; valid_losses[-1]:\n            break\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.01\nlosses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n  1%|          | 26/5000 [00:00&lt;00:02, 2084.48it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nDid this approach work as intended? Why or why not? Think about how you might improve this approach and explain any ideas you have in 1-2 sentences.\n\n\n\nNo, it stopped too early.\n\n\n\nModify your early stopping gradient descent so that it always runs for at least 50 iterations. Then after 50 iterations stop if at any point the validation loss is larger than the average validation loss for the previous 50 iterations.\n\n\n\n\ndef gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n        if len(valid_losses) &gt; 50 and np.mean(valid_losses[-50:-1]) &lt; valid_losses[-1]:\n            break\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.003\nlosses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n  2%|▏         | 105/5000 [00:00&lt;00:02, 2299.35it/s]\n\n\n\n\n\n\n\n\n\nNow let’s try out L1 regualrization! We will consider a scaled version of L1 regularization, where for a \\(d \\times e\\) weight matrix \\(\\mathbf{W}\\) we will define the L1 loss as: \\[\\textbf{Loss}_{L1}(\\mathbf{W})= \\frac{\\lambda}{d e}\\sum_{i=1}^d\\sum_{j=1}^e |w_{ij}| \\quad \\mathbf{W}: d \\times e\\] Here \\(\\lambda\\) is a value that we can choose to control how much weight we put on our L1 loss (we’ll call it l1_weight below).\n\n\n\nModify your original gradient descent algorithm from Q4 (no early stopping) to add the L1 loss for each parameter in the model to the loss.\nHint: Recall that we can access every parameter in the model using the model.parameters() method. In this question you do not need to worry about distinguishing between weights and biases, you can apply L1 regularization to biases as well if it simplifies your approach. Your validation loss should not include the regularization terms.\n\n\n\n\nfrom torch import optim\n\ndef gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        losses.append(loss.detach().numpy()) \n\n        l1_loss = 0\n        for p in model.parameters():\n            l1_loss = l1_loss + torch.mean(torch.abs(p))\n        loss = loss + l1_weight * l1_loss        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)\n\n100%|██████████| 1/1 [00:00&lt;00:00, 328.09it/s]\n\n\nPassed!\n\n\n\n\n\n\n\n\nApply gradient_descent_l1 as in previous problems. Find an appropriate setting of l1_weight that minimizes the validation loss.\nHint: How you go about choosing l1_weight is up to you! Your validation loss should be lower than the validation loss without regularization.\n\n\n\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.003\nl1_weight = 1.\nlosses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:02&lt;00:00, 1984.48it/s]\n\n\n\n\n\n\n\n\n\nFinally let’s try out dropout regularization. We will implement dropout as its own module, so we can think of it as a function that transforms a vector or matix into a vector or matrix of the same shape with elements randomly set to \\(0\\). In this case we can write the dropout function as: \\[\\text{Dropout}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix},\\ d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\nHere \\(\\odot\\) denotes element-wise multiplication (so \\(\\mathbf{D}\\) and \\(\\mathbf{X}\\) are the same shape), \\(r\\) is the dropout rate so \\(p(d_{ij}=0)=r\\).\nAt evaluation time, we do not want to randomly drop elements. Instead we will scale \\(\\mathbf{X}\\) by \\((1-r)\\): \\[\\text{Dropout}_{\\text{eval}}(\\mathbf{X}, r) = (1-r)\\mathbf{X}\\]\n\n\n\nComplete the implementation of the Dropout module below.\nHint: The built-in training property of an nn.Module instance specifies if our model is in training mode or evaluation mode. By default models are in training mode (training == True), but we can set a model to evaluation mode by calling model.eval(). Then we can use model.train() to set it back to training mode.\nYou may find the function torch.rand_like() helpful for this problem. You might also find it helpful to know that you can convert and boolean tensor X into a float tensor by calling X.float() (True becomes 1., False becomes 0.)\n\n\n\n\nclass Dropout(nn.Module):\n    def __init__(self, rate=0.01):\n        # Rate specifies the dropout rate (r)\n        super().__init__()\n        self.rate = rate\n\n    def forward(self, x):\n        if self.training:\n            return x * (torch.rand_like(x) &gt; self.rate).float()\n        else:\n            return x * (1 - self.rate)\n        \ntest_dropout(Dropout)\n\nPassed!\n\n\n\n\n\nModify your gradient_descent function to put the model into train mode before calculating the training loss and into eval mode before calculating the validation loss. Then create a model based on your network from Q9, but this time add a Dropout layer before each LinearKaiming layer. You can use the default dropout rate of 0.01 or try something different! Verify that dropout gives different results to previous approaches.\n\n\n\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        model.train()\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        model.eval()\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            Dropout(),\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 1),\n            )\n\n# Test our model build\ntest_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n\nlr = 0.003\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\n\n\n100%|██████████| 5000/5000 [00:02&lt;00:00, 1946.09it/s]"
  },
  {
    "objectID": "assignments/homeworks/Homework 7/solutions-TOLGQV.html#part-1-introduction-to-pytorch",
    "href": "assignments/homeworks/Homework 7/solutions-TOLGQV.html#part-1-introduction-to-pytorch",
    "title": "Homework 7: PyTorch",
    "section": "",
    "text": "Now that we’ve successfully built our own tool for automatic differentiation and neural networks, let’s look at an industry-standard tool for accomplishing the same tasks: PyTorch.\nThroughout this homework to may find it helpful to refer to the PyTorch documentation, as well as the lecture notebook on Pytorch.\nWe saw in class that we can create a function with parameters in PyTorch using the torch.nn module that we’ll import as just nn. We can do this by creating a subclass of nn.Module and defining the parameters with nn.Parameter.\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/4d66c02805cb1a8b1b1f6043f08c5929/raw/14332b6d752fe1c7420647a2fe7eeb587cd767ef/hw6_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw7_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\nimport torch\nfrom torch import nn\nfrom hw7_support import *\n\n\nclass LinearZeros(nn.Module):\n    '''\n    A PyTorch module representing a linear/affine function with weights W and bias b:\n        f(X) = XW + b\n    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n\n    This version of the Linear module initializes the parameters to 0.\n    '''\n    def __init__(self, in_dimensions, out_dimensions):\n        # Call the nn.Module __init__ function\n        super().__init__()\n\n        # Create parameters that we can fit with gradient descent.\n        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n        # This assumes X is 2-dimensional (a matrix)!\n        return torch.matmul(x, self.weights) + self.bias\n\nWe can create a 1-dimensional linear function by creating a LinearZeros object, specifying that both the input and output dimensions should be 1. The method model.parameters() will give us access to all the weights we can fit with gradient descent.\n\nmodel = LinearZeros(1, 1)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[0.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nWe can also call this model just like any other function.\n\n# Create 4 1-dimensional inputs\nx = torch.ones((4, 1))\n\nmodel(x)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;AddBackward0&gt;)\n\n\nLet’s start by creating a simple dataset to use for the next few problems. We’ll use a regression dataset similar to the one we saw in class. In this case, I’ve provied data already split into training and validation sets.\n\n# Create the training inputs and labels\nx = torch.rand(200, 1) * 10 - 5.\ny = x ** 2 / 2 + torch.sin(x * 5) - 5\n\n# Create the validation inputs and labels\nxvalid = torch.rand(200, 1) * 10 - 5.\nyvalid = xvalid ** 2 / 2 + torch.sin(xvalid * 5 + torch.pi) - 5\n\nplotRegression(x, y, xvalid, yvalid)\n\n\n\n\n\n\n\n\nWe can make predictions for our data using the model we just definied:\n\npredictions = model(x)\npredictions[:5]\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;SliceBackward0&gt;)\n\n\nHowever if we plot the prediction function, we’ll see that it isn’t very good as we haven’t optimized the parameters yet:\n\nplotRegression(x, y, xvalid, yvalid, model=model)\n\n\n\n\n\n\n\n\nThe first thing we’ll need to optimize our model is a loss function. As we saw in class, the convention in PyTorch is to separate the loss from the model, so we’ll write a simple function that takes in predictions and labels, returning the mean squared error loss.\n\n\nComplete the mse_loss function below. The function should compute the same MSE loss we’ve seen in previous homeworks, but using PyTorch operations.\n\\[\\textbf{Loss}(\\mathbf{a}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N(a_i - y_i)^2\\]\nHint: As we see above, our linear module returns a column-vector (predictions is 2-dimensional), but y is just a vector (y is 1-dimensional). Make sure to account for this!\n\n\n\n\ndef mse_loss(prediction, labels):\n    return torch.mean((prediction.reshape((-1,)) - labels.reshape((-1,))) ** 2)\n\n\n# Test to check\ntorch.manual_seed(0)\nassert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)\n\nWith our loss in hand, we can run gradient descent to optimize our model’s parameters. This time, we’ll use the torch.optim module, which includes many useful variations of gradient descent.\n\n\n\nComplete the gradient descent function below. The function should: - Create an optim.SGD optimizer for the model’s parameters with the specified learning rate - At each step: - Compute the model output and loss (loss_func) on the training data - Compute the gradients of the loss with respect to the model parameters - Take a gradient descent step - Reset the parameter gradients to 0 - Compute the validation loss\n\n\n\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)\n\n100%|██████████| 1/1 [00:00&lt;00:00, 27.20it/s]\n\n\nPassed!\n\n\n\n\n\n\nmodel = LinearZeros(1, 1)\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:00&lt;00:00, 10880.02it/s]\n\n\n\n\n\n\n\n\n\nNow that we have a function to train a PyTorch model, we can try something bigger and more exciting! Let’s train a neural network.\n\n\n\nCreate a PyTorch model for a neural network with the following specification: - The network should have 4 hidden layers, each with 20 neurons - The network should take 1-dimensional inputs as above - Each layer should use the LinearZeros module we just wrote - Each linear layer should be followed by a ReLU activation (except the output), use the nn.ReLU() module.\nHint: Remember that you can use the nn.Sequential class to easily compose a sequence of functions in PyTorch.\n\n\n\n\nmodel = nn.Sequential(\n            LinearZeros(1, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 20),\n            nn.ReLU(),\n            LinearZeros(20, 1),\n            )\n\n# Test the model build\ntest_build(model, LinearZeros, dropout_type=None, type='zeros')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3014.51it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened when you attempted to train the model above? Why did this happen? Give a short 1-2 sentence answer.\n\n\n\nNothing happened because we initialized all weights to 0.\nLet’s try modifying our Linear module with a different strategy for initialization.\n\n\n\nModify the LinearZeros implementation from above to initialize the weights and bias parameters from a standard normal distribution \\(w,b \\sim \\mathcal{N}(0, 1)\\). Then modify your model from Q6 to use this new module.\nHint: You may find the torch.randn function useful here. You might also find that the model doesn’t train! We’ll address this in the next question.\n\n\n\n\nclass LinearNormal(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.weights = nn.Parameter(torch.randn(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.randn(out_dimensions))\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n    \nmodel = nn.Sequential(\n            LinearNormal(1, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 1),\n            )\n\n# Test the model build and LinearKaiming\ntest_normal(LinearNormal)\ntest_build(model, LinearNormal, dropout_type=None, type='normal')\n\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3333.41it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nIn the previous question you might have found that gradient descent didn’t work. This could suggest that our learning rate is set wrong. Think about a strategy that you might use to find an appropriate learning rate for fitting this model and try it out below. Then explain the strategy that you used. Is there any way you could improve this strategy to make finding a learning rate quicker?\n\n\n\n\n# Modify this code to choose a good learning rate\nmodel = nn.Sequential(\n            LinearNormal(1, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 20),\n            nn.ReLU(),\n            LinearNormal(20, 1),\n            )\n\nlr = 0.00001\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3079.02it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nWe saw in class that a common, useful approach for initializing neural networks is to use a Kaiming normal initialization. In this approach we draw each initial weight from a normal distribution where the standard deviation is scaled by the square root of the number of input dimensions to the layer. If \\(\\mathbf{W} \\in \\mathbb{R}^{d\\times e}\\) then: \\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\mathbf{W}: d \\times e\\] \\[b_j = 0 \\quad \\mathbf{b}: e\\] We’ll initialize the biases to \\(0\\). Below, implement a linear module using the Kaiming normal initialization, then repeat Q5 using the LinearKaiming class and the learning rate you chose in Q8. If needed, adjust the learning rate until your model almost perfectly fits the training data.\n\n\n\n\nclass LinearKaiming(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.weights = nn.Parameter(torch.randn(in_dimensions, out_dimensions) / np.sqrt(in_dimensions))\n        self.bias =nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n    \nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\n\n# Test the model build and LinearKaiming\ntest_kaiming(LinearKaiming)\ntest_build(model, LinearKaiming, dropout_type=None, type='normal')\n\nlr = 0.01\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\nPassed!\n\n\n100%|██████████| 5000/5000 [00:01&lt;00:00, 3045.19it/s]\n\n\n\n\n\n\n\n\n\nIf all went well so far, we should find that our model fits our data well, but perhaps a little bit too well. Let’s try out some of the strategies we’ve seen to reduce overfitting, starting with early stopping.\n\n\n\nModify your gradient descent algorithm to implment a basic form of early stopping: stop gradient descent as soon as the validation loss increases from the previous iteration. Test this approach with the same model from Q9.\n\n\n\n\ndef gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n        if len(valid_losses) &gt; 1 and valid_losses[-2] &lt; valid_losses[-1]:\n            break\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.01\nlosses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n  1%|          | 26/5000 [00:00&lt;00:02, 2084.48it/s]\n\n\n\n\n\n\n\n\n\n\n\n\nDid this approach work as intended? Why or why not? Think about how you might improve this approach and explain any ideas you have in 1-2 sentences.\n\n\n\nNo, it stopped too early.\n\n\n\nModify your early stopping gradient descent so that it always runs for at least 50 iterations. Then after 50 iterations stop if at any point the validation loss is larger than the average validation loss for the previous 50 iterations.\n\n\n\n\ndef gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n        if len(valid_losses) &gt; 50 and np.mean(valid_losses[-50:-1]) &lt; valid_losses[-1]:\n            break\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.003\nlosses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n  2%|▏         | 105/5000 [00:00&lt;00:02, 2299.35it/s]\n\n\n\n\n\n\n\n\n\nNow let’s try out L1 regualrization! We will consider a scaled version of L1 regularization, where for a \\(d \\times e\\) weight matrix \\(\\mathbf{W}\\) we will define the L1 loss as: \\[\\textbf{Loss}_{L1}(\\mathbf{W})= \\frac{\\lambda}{d e}\\sum_{i=1}^d\\sum_{j=1}^e |w_{ij}| \\quad \\mathbf{W}: d \\times e\\] Here \\(\\lambda\\) is a value that we can choose to control how much weight we put on our L1 loss (we’ll call it l1_weight below).\n\n\n\nModify your original gradient descent algorithm from Q4 (no early stopping) to add the L1 loss for each parameter in the model to the loss.\nHint: Recall that we can access every parameter in the model using the model.parameters() method. In this question you do not need to worry about distinguishing between weights and biases, you can apply L1 regularization to biases as well if it simplifies your approach. Your validation loss should not include the regularization terms.\n\n\n\n\nfrom torch import optim\n\ndef gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        output = model(x)\n        loss = loss_func(output, y)\n        losses.append(loss.detach().numpy()) \n\n        l1_loss = 0\n        for p in model.parameters():\n            l1_loss = l1_loss + torch.mean(torch.abs(p))\n        loss = loss + l1_weight * l1_loss        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        valid_loss = loss_func(model(xvalid), yvalid)\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)\n\n100%|██████████| 1/1 [00:00&lt;00:00, 328.09it/s]\n\n\nPassed!\n\n\n\n\n\n\n\n\nApply gradient_descent_l1 as in previous problems. Find an appropriate setting of l1_weight that minimizes the validation loss.\nHint: How you go about choosing l1_weight is up to you! Your validation loss should be lower than the validation loss without regularization.\n\n\n\n\nmodel = nn.Sequential(\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            LinearKaiming(20, 1),\n            )\nlr = 0.003\nl1_weight = 1.\nlosses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n100%|██████████| 5000/5000 [00:02&lt;00:00, 1984.48it/s]\n\n\n\n\n\n\n\n\n\nFinally let’s try out dropout regularization. We will implement dropout as its own module, so we can think of it as a function that transforms a vector or matix into a vector or matrix of the same shape with elements randomly set to \\(0\\). In this case we can write the dropout function as: \\[\\text{Dropout}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix},\\ d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\nHere \\(\\odot\\) denotes element-wise multiplication (so \\(\\mathbf{D}\\) and \\(\\mathbf{X}\\) are the same shape), \\(r\\) is the dropout rate so \\(p(d_{ij}=0)=r\\).\nAt evaluation time, we do not want to randomly drop elements. Instead we will scale \\(\\mathbf{X}\\) by \\((1-r)\\): \\[\\text{Dropout}_{\\text{eval}}(\\mathbf{X}, r) = (1-r)\\mathbf{X}\\]\n\n\n\nComplete the implementation of the Dropout module below.\nHint: The built-in training property of an nn.Module instance specifies if our model is in training mode or evaluation mode. By default models are in training mode (training == True), but we can set a model to evaluation mode by calling model.eval(). Then we can use model.train() to set it back to training mode.\nYou may find the function torch.rand_like() helpful for this problem. You might also find it helpful to know that you can convert and boolean tensor X into a float tensor by calling X.float() (True becomes 1., False becomes 0.)\n\n\n\n\nclass Dropout(nn.Module):\n    def __init__(self, rate=0.01):\n        # Rate specifies the dropout rate (r)\n        super().__init__()\n        self.rate = rate\n\n    def forward(self, x):\n        if self.training:\n            return x * (torch.rand_like(x) &gt; self.rate).float()\n        else:\n            return x * (1 - self.rate)\n        \ntest_dropout(Dropout)\n\nPassed!\n\n\n\n\n\nModify your gradient_descent function to put the model into train mode before calculating the training loss and into eval mode before calculating the validation loss. Then create a model based on your network from Q9, but this time add a Dropout layer before each LinearKaiming layer. You can use the default dropout rate of 0.01 or try something different! Verify that dropout gives different results to previous approaches.\n\n\n\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = optim.SGD(model.parameters(), lr=lr)\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        model.train()\n        output = model(x)\n        loss = loss_func(output, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        model.eval()\n        valid_loss = loss_func(model(xvalid), yvalid)\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = nn.Sequential(\n            Dropout(),\n            LinearKaiming(1, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 20),\n            nn.ReLU(),\n            Dropout(),\n            LinearKaiming(20, 1),\n            )\n\n# Test our model build\ntest_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n\nlr = 0.003\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nPassed!\n\n\n100%|██████████| 5000/5000 [00:02&lt;00:00, 1946.09it/s]"
  },
  {
    "objectID": "assignments/homeworks/Homework 10/submission.html",
    "href": "assignments/homeworks/Homework 10/submission.html",
    "title": "Homework 10: Language models",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n# Uncomment for Colab\n# !yes | pip uninstall torch\n# !yes | pip uninstall torchtext\n# !yes | pip install torch==2.3.0\n# !yes | pip install torchtext==0.18\n# !wget https://cs152.github.io/assignments/homeworks/Homework%2010/hw10_support.py\n\n# Run me to get the data (should be included!)\n#!wget https://gist.githubusercontent.com/gabehope/286a065f3b7cc081af5f3e8d71502e63/raw/d31a233d8ade78ac5cbd8ecfa45f184017812c52/dataset.txt\n\nThis cell make take some time to run.\nIf you have issues running this cell on your own computer it may be an issue with the torch & torchtext versions, see here.\n\nfrom hw10_support import *\n\n\ntrain_data, test_data = torch.utils.data.random_split(data, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=lambda x: x)\nvalid_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=lambda x: x)\n\n\n\n\n\nQ1\n\ndef convertToText(x, vocab):\n    # YOUR CODE HERE\n    pass\n\n# Convert the first batch of validation data here\nx, y = next(iter(valid_loader))\ntext = convertToText(x, data.eng_vocab)\nprint(text)\n\n\nprint('Input 0: ', convertToText(x, data.eng_vocab)[0])\nprint('Target 0: ', convertToText(y, data.eng_vocab)[0])\n\n\n\n\n\n\nQ2\n\nclass Embedding(nn.Module):\n  def __init__(self, embedding_dimension):\n      super().__init__() # Needed for PyTorch!\n\n      # YOUR CODE HERE\n      self.embedding_matrix =\n\n  def forward(self, x):\n      # YOUR CODE HERE\n\n# Test output shape\nx, y = next(iter(valid_loader))\nassert Embedding(64)(x).shape == torch.Size([256, 26, 64])\n\n\n\n\n\n\nQ3\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n\nclass RNNGenerator(nn.Module):\n  def __init__(self, vocab_size=1000, dimension=128):\n    super().__init__()\n    self.embedding = Embedding(dimension)\n    self.block1 = RNN(dimension, dimension)\n    self.block2 = RNN(dimension, dimension)\n    self.block3 = RNN(dimension, dimension)\n    self.output = nn.Linear(dimension, vocab_size)\n\n  def forward(self, x):\n    x = self.embedding(x)\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    return self.output(x)\n\nmodel = RNNGenerator()\n\n\n\n\n\n\nQ4\n\ndef softmax(x):\n    # Compute the softmax for each entry in a tensor\n    ex = torch.exp(x)\n    sum_ex = torch.sum(ex, dim=-1, keepdims=True)\n    return ex / sum_ex\n\ndef autoregressive_loss(f, y):\n      # YOUR CODE HERE\n\n\n\n\n\n\nQ5\n\ndef autoregressive_loss(f, y):\n      # YOUR CODE HERE\n\n\n\n\n\n\nQ6\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Do model creation here so that the model is recreated each time the cell is run\nmodel = model.to(device)\nmodel.train()\n\n# Create the optimizer, just like we have with the built-in optimizer\nopt = torch.optim.Adam(model.parameters(), 0.001)\n\n# Information for plots\ntrain_losses = []\n\nfor iteration, (train_X, train_Y) in enumerate(tqdm.tqdm(train_loader)):\n    # Grab the batch of data and send it to the correct device\n    train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n    # Compute the output, loss, and gradient and take a step of gradient descent\n    # YOUR CODE HERE\n\n\n    loss =\n    train_losses.append(loss.item())\n\n    if iteration &gt; 100:\n      break\n\n\n# Plot the loss over the first 100 iterations\nplt.plot(train_losses)\nplt.title('Loss vs. Iterations')\n\n\n\n\n\n\nQ7\nYOUR ANSWER HERE\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n        # Add any additional sub-modules here\n\n    def forward(self, x):\n        ''' Computes the forward pass of an RNN\n\n        Inputs:\n            x: tensor (float), An N x L x D tensor of input data\n\n        Returns:\n            h: tensor (float), An N x L x H tensor of transformed features\n        '''\n        # YOUR CODE HERE\n\n# Create a model\nmodel = RNNGenerator()\n\n\n# YOUR CODE HERE\n\n\nimport torch\ndef sample_categorical(probs):\n  assert torch.all(torch.isclose(p.sum(dim=-1), torch.tensor(1.)))\n  return torch.distributions.Categorical(probs=probs).sample()\n\n# 4 x 3 matrix of probabilities (each row sums to 1.)\np = torch.tensor([[0.3, 0.2, 0.5],\n                  [0.0, 0.9, 0.1],\n                  [0.9, 0.0, 0.1],\n                  [0.3, 0.3, 0.4]])\n\n# Length 4 vector of samples\nprint(sample_categorical(p))\n\n# 2 x 2 x 3 matrix of probabilities (each final dimension sums to 1.)\np = torch.tensor([\n                  [\n                    [0.3, 0.2, 0.5],\n                    [0.0, 0.9, 0.1]],\n                  [\n                    [0.9, 0.0, 0.1],\n                    [0.3, 0.3, 0.4]\n                  ]\n                  ])\n\n# 2x2 matrix of samples\nprint(sample_categorical(p))\n\n\n\n\n\n\nQ8\n\ndef sample(model, data, batch_size=1, max_length=50):\n  model.eval()\n\n  # Start with an N x 1 matrix where each entry is just the &lt;start&gt; token.\n  # After the first iteration this should be N x 2, then N x 3 ... until N x L.\n  sample = torch.ones((batch_size, 1)).int().to(device)\n  # YOUR CODE HERE\n\n  return output\n\n\n# Test sampling\nsample_sentence = sample(model, data)\nprint('Tokens:', sample_sentence)\nprint('Text:', convertToText(sample_sentence, data.eng_vocab))\n\n\n\n\n\n\nQ9\n\nclass Attention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n\n\n\n\n\nQ10\n\nclass MaskedAttention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n\n\n\n\n\nQ11\n\nclass MaskedMultiheadAttention(nn.Module):\n    def __init__(self, input_size, hidden_size, num_heads=1):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size // num_heads\n        self.num_heads = num_heads\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n\n\n\n\n\nQ12\nYOUR ANSWER HERE\nThere are no more questions in this homework, but if you’d like to try out training an actual language model using the code you wrote, feel free to experiment with the implementation below!\n\nepsilon = 1e-7\nclass LayerNorm(nn.Module):\n    '''\n        The same LayerNorm implementation we saw before.\n    '''\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        xmean = x.mean(dim=(-1, -2), keepdims=True)\n        xvar = x.var(dim=(-1, -2), keepdims=True)\n        return (x - xmean) / torch.sqrt(xvar + epsilon)\n\n\nclass PositionalEncoding(nn.Module):\n    '''\n        A layer to add positional encodings to the input.\n    '''\n    def forward(self, x):\n        pos = torch.arange(x.shape[-2]).unsqueeze(1)\n        i = torch.arange(x.shape[-1] // 2).unsqueeze(0)\n        embedding = torch.zeros_like(x)\n        embedding[..., ::2] = torch.sin(pos / 10000. ** (2 * i / x.shape[-1]))\n        embedding[..., 1::2] = torch.cos(pos / 10000. ** (2 * i / x.shape[-1]))\n        return x + embedding\n\nclass TransformerBlock(nn.Module):\n    '''\n        A block of a transformer decoder.\n    '''\n    def __init__(self, input_size, hidden_size, num_heads=8):\n        super().__init__()\n        self.attention = MaskedMultiheadAttention(input_size, hidden_size, num_heads)\n        self.linear1 = nn.Linear(hidden_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, hidden_size)\n        self.activation = nn.ReLU()\n        self.ln1 = LayerNorm()\n        self.ln2 = LayerNorm()\n\n    def forward(self, x):\n        x = self.ln1(self.attention(x) + x)\n        x = self.ln2(self.linear2(self.activation(self.linear1(x))) + x)\n        return x\n\nclass TransformerGenerator(nn.Module):\n  '''\n      A full transformer decoder model.\n  '''\n  def __init__(self, vocab_size=1000, dimension=128, num_heads=8):\n    super().__init__()\n    self.embedding = Embedding(dimension)\n    self.positional_encoding = PositionalEncoding()\n    self.block1 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n    self.block2 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n    self.block3 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n    self.output = nn.Linear(dimension, vocab_size)\n\n  def forward(self, x):\n    x = self.embedding(x)\n    x = self.positional_encoding(x)\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    return self.output(x)\n\n\n\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\nfrom fastprogress.fastprogress import master_bar, progress_bar\nimport matplotlib.pyplot as plt\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using '{device}' device.\")\n\n# Mini-Batch SGD hyperparameters\nbatch_size = 256\nnum_epochs = 10\nlearning_rate = 0.001\n\nfrom torch.optim import Adam\n\ndef gradient_descent(model, train_loader, valid_loader, optimizer=Adam, learning_rate=0.001, criterion=nn.CrossEntropyLoss(), num_epochs=10, batch_size=256):\n\n    # Do model creation here so that the model is recreated each time the cell is run\n    model = model.to(device)\n    model.train()\n\n    t = 0\n    # Create the optimizer, just like we have with the built-in optimizer\n    opt = optimizer(model.parameters(), learning_rate)\n\n    # A master bar for fancy output progress\n    mb = master_bar(range(num_epochs))\n\n    # Information for plots\n    mb.names = [\"Train Loss\", \"Valid Loss\"]\n    train_losses = []\n    valid_losses = []\n\n    for epoch in mb:\n\n        #\n        # Training\n        #\n        model.train()\n\n        train_N = len(train_loader.dataset)\n        num_train_batches = len(train_loader)\n        train_dataiterator = iter(train_loader)\n\n        train_loss_mean = 0\n\n        for batch in progress_bar(range(num_train_batches), parent=mb):\n\n            # Grab the batch of data and send it to the correct device\n            train_X, train_Y = next(train_dataiterator)\n            train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n\n            # Compute the output\n            train_output = model(train_X)\n\n            # Compute loss\n            train_loss = criterion(train_output, train_Y)\n\n            num_in_batch = len(train_Y)\n            tloss = train_loss.item() * num_in_batch / train_N\n            train_loss_mean += tloss\n            train_losses.append(train_loss.item())\n\n            # Compute gradient\n            model.zero_grad()\n            train_loss.backward()\n\n            # Take a step of gradient descent\n            t += 1\n            with torch.no_grad():\n                opt.step()\n\n        #\n        # Validation\n        #\n        model.eval()\n\n        valid_N = len(valid_loader.dataset)\n        num_valid_batches = len(valid_loader)\n\n        valid_loss_mean = 0\n        valid_correct = 0\n        valid_total = 0\n\n        with torch.no_grad():\n\n            # valid_loader is probably just one large batch, so not using progress bar\n            for valid_X, valid_Y in valid_loader:\n\n                valid_X, valid_Y = valid_X.to(device), valid_Y.to(device)\n\n                valid_output = model(valid_X)\n\n                valid_loss = criterion(valid_output, valid_Y)\n\n                num_in_batch = len(valid_Y)\n                vloss = valid_loss.item() * num_in_batch / valid_N\n                valid_loss_mean += vloss\n                valid_losses.append(valid_loss.item())\n\n                # Convert network output into predictions (one-hot -&gt; number)\n                predictions = valid_output.argmax(-1)\n\n                # Sum up total number that were correct\n                valid_correct += (predictions == valid_Y).type(torch.float).sum().item()\n                valid_total += torch.ones_like(predictions).type(torch.float).sum().item()\n\n        valid_accuracy = 100 * (valid_correct / valid_total)\n\n        # Report information\n        tloss = f\"Train Loss = {train_loss_mean:.4f}\"\n        vloss = f\"Valid Loss = {valid_loss_mean:.4f}\"\n        vaccu = f\"Valid Accuracy = {(valid_accuracy):&gt;0.1f}%\"\n        mb.write(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\n        # Update plot data\n        max_loss = max(max(train_losses), max(valid_losses))\n        min_loss = min(min(train_losses), min(valid_losses))\n\n        x_margin = 0.2\n        x_bounds = [0 - x_margin, num_epochs + x_margin]\n\n        y_margin = 0.1\n        y_bounds = [min_loss - y_margin, max_loss + y_margin]\n\n        valid_Xaxis = torch.linspace(0, epoch + 1, len(train_losses))\n        valid_xaxis = torch.linspace(1, epoch + 1, len(valid_losses))\n        graph_data = [[valid_Xaxis, train_losses], [valid_xaxis, valid_losses]]\n\n        mb.update_graph(graph_data, x_bounds, y_bounds)\n\n    print(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\n\n# Test out the model!\nmodel = TransformerGenerator()\ngradient_descent(model, train_loader, valid_loader, criterion=autoregressive_loss)"
  },
  {
    "objectID": "assignments/homeworks/Homework 10/main.html",
    "href": "assignments/homeworks/Homework 10/main.html",
    "title": "Homework 10: Language models",
    "section": "",
    "text": "# Uncomment for Colab\n# !yes | pip uninstall torch\n# !yes | pip uninstall torchtext\n# !yes | pip install torch==2.3.0\n# !yes | pip install torchtext==0.18\n\n# Run me to get the data (should be included!)\n#!wget https://gist.githubusercontent.com/gabehope/286a065f3b7cc081af5f3e8d71502e63/raw/d31a233d8ade78ac5cbd8ecfa45f184017812c52/dataset.txt"
  },
  {
    "objectID": "assignments/homeworks/Homework 10/main.html#part-1-language-modeling",
    "href": "assignments/homeworks/Homework 10/main.html#part-1-language-modeling",
    "title": "Homework 10: Language models",
    "section": "Part 1: Language Modeling",
    "text": "Part 1: Language Modeling\nIn the support code we’ve setup a PyTorch dataset of sentences. As we discussed in class, our neural networks can’t directly work with text, so our dataset has been tokenized using a sentence-piece tokenizer (a variation of the byte-pair tokenizer we discussed in class). This assigns short sequences of characters (such as words) to individual integer ids (0-999 in this assignment). It also includes several special tokens:\n\n&lt;start&gt;: Indicates the start of an sentence.\n&lt;stop&gt;: Indicates the end of an sentence.\n&lt;pad&gt;: Indicates blank space after a sentence.\n&lt;unk&gt;: Indicates an unknown token.\n\nWe can see that when we print an observation in our dataset, it’s represented as a list token ids.\n\nx, y = data[0]\nprint(x)\n\nFor convinence, the “target” y is simply the same observation shifted by one token. This will make it easier to implement our next word prediction language model.\n\nprint(y)\n\nAs we’ve used in previous homeworks, PyTorch provides a convinient object for generating batches of data for training called a DataLoader. The DataLoader will handle selecting observations to use at each step. We’ll create a loader for both our training and vaildation data, specifying a batch size of 64. We’ll also tell the loader for our training data to randomly shuffle the data (you can ignore the collate_fn argument`).\n\ntrain_data, test_data = torch.utils.data.random_split(data, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=lambda x: x)\nvalid_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=lambda x: x)\n\nWe can iterate through a DataLoader to get batches of data. Notice that our batch of data has been grouped into a single Tensor object. Because sentences may have different lengths, the size of the tensor will be determined by the longest sentence in the batch, while shorter sentences will have &lt;pad&gt; tokens added to the end.\n\nfor x, y in train_loader:\n  print(x)\n  break\n\nOur data also contains a vocab object that defines our mapping from string tokens to ids. This is called eng_vocab in our dataset. We can get an ordered list of the tokens by calling itos() method of the vocab object.\n\nvocab = data.eng_vocab\nprint(vocab.get_itos())\n\n\nQ1 (10 points)\nFor our language model to be useful, we’ll need to be able to translate batches of data back into English text. Complete the function below which takes a tensor of token ids, as shown above, along with a vocab object and returns a list of strings. Each entry should be the text corresponding to a single observation in the batch (a row of the tensor). Test your function on the first batch from valid_loader.\nHint: While it’s not nessecary for full credit, an ideal implementation would ignore the special characters defined above which aren’t a part of the text.\n\ndef convertToText(x, vocab):\n    '''\n    Converts a batch of token ids into text.\n\n    Inputs:\n      x (tensor of ints): An N x L int tensor of N sentences with L tokens each.\n      vocab (vocabulary object)\n\n    Returns:\n      text (list of strings): A length N list of translated strings\n    '''\n    # YOUR CODE HERE\n    pass\n\n# Convert the first batch of validation data here\nx, y = next(iter(valid_loader))\ntext = convertToText(x, data.eng_vocab)\nprint(text)\n\nNow we can verify that our targets are indeed just our input senteces shifted by one.\n\nprint('Input 0: ', convertToText(x, data.eng_vocab)[0])\nprint('Target 0: ', convertToText(y, data.eng_vocab)[0])\n\nAs discussed in class, words don’t have an inherent ordering as implied by their token ids. Instead of using our token ids as features directly, we’ll learn a word embedding. That is, we’ll represent each word with a unique random vector and then allow our gradient descent to update these vectors to better represent each word as we train our model.\nNote that we can also think of as representing each word with a one-hot vector just we would with multi-class labels! Multiplying a one-hot vector with a (weight) matrix is equivalent to selecting a row of that matrix. Therefore a word embedding can be thought of as a combination of one-hot encoding each word and applying a linear layer. That said, it’s far more efficient to just select rows directly.\n\n\n\nebeddings.png\n\n\n\n\nQ2 (10 points)\nComplete the following implementation of a word embedding PyTorch layer. The forward method should take as input an \\(N \\times L\\) tensor of integers corresponding to a batch of sentences represented by token ids in the range 0 to 1000 and return an \\(N \\times L \\times D\\) tensor replacing each integer entry with the corresponding row of the embdedding matrix. The __init__ method should take the embedding dimension as input. That is, the length of the vector being used to represent each word.\nHint: You’ll want to use the nn.Parameter class for the embedding matrix, just as we did for the weight matricies for our own version of the Linear layer. Make sure to initialize the entries of this matrix randomly! For forward you should not need any loops. Try using the input matrix to index the embedding matrix\n\nclass Embedding(nn.Module):\n  def __init__(self, embedding_dimension):\n      super().__init__() # Needed for PyTorch!\n\n      # YOUR CODE HERE (Create a random 1000 x D matrix)\n      self.embedding_matrix =\n\n  def forward(self, x):\n      # YOUR CODE HERE\n\n# Test output shape\nx, y = next(iter(valid_loader))\nassert Embedding(64)(x).shape == torch.Size([256, 26, 64])\n\nOur goal is ultimately to create a language model. To do so we’ll need a neural network layer that can take as input sequences of different lengths. One such layer that we’ve seen is a Recurrent Neural Network Layer. Let’s refresh our memory on what this looks like. We’ll let \\(\\mathbf{x}_i\\) refer to the vector representing ith word in our input. Our layer will transform our featues so that after the layer we’ll have a new representation for word \\(i\\): \\(\\mathbf{\\phi}_i\\). A recurrent layer defines \\(\\phi_i\\) recursively as:\n\\[\\phi_i = \\text{ReLU}(\\phi_{i-1}^T \\mathbf{W}_\\phi + \\mathbf{x}_i^T \\mathbf{W}_x + \\mathbf{b})\\]\nHere we’ll used the ReLU activation function, but this could just as easily be any other activation. For simplicity, we’ll assume that when computing the representation \\(\\phi_{0}\\) we can pretend the previous value was 0. That is, we’ll assume: \\[\\phi_{-1}=\\mathbf{0}\\]\nNotice that at every location we’ll use the same parameters and these parameters will define a linear function.\n\n\nQ3 (10 points)\nComplete the implementation of an RNN layer below, using the definition above.\nHint: You can assume that forward is always given a batch of inputs of size N. The formula above is for a single input. x[n, i] will give us the (length \\(D\\)) representation for the \\(i^{th}\\) word in sentence \\(n\\), while x[:, i] will give us an \\(N \\times D\\) matrix of the representation of the \\(i^{th}\\) word in every sentence. Because each word’s new representation depends on the previous word’s new representation, you’ll need to loop over every word position explicitly.\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x):\n        ''' Computes the forward pass of an RNN\n\n        Inputs:\n            x: tensor (float), An N x L x D tensor of input data\n\n        Returns:\n            h: tensor (float), An N x L x H tensor of transformed features\n        '''\n        # YOUR CODE HERE\n\nAs with any neural network layer represented as a PyTorch module, we can compose several RNN layers together to make a more complex network.\n\nclass RNNGenerator(nn.Module):\n  def __init__(self, vocab_size=1000, dimension=128):\n    super().__init__()\n    self.embedding = Embedding(dimension)\n    self.block1 = RNN(dimension, dimension)\n    self.block2 = RNN(dimension, dimension)\n    self.block3 = RNN(dimension, dimension)\n    self.output = nn.Linear(dimension, vocab_size)\n\n  def forward(self, x):\n    x = self.embedding(x)\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    return self.output(x)\n\nmodel = RNNGenerator()\n\nYou can see that the final layer of this network is a linear function that outputs our final prediction. This linear function is applied at each word separately, so the output for a given word \\(i\\) is computed as:\n\\[f(\\mathbf{x})_i=\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0\\]\nWe can apply this model to a batch of data and see that it gives use 1000 outputs for each word in each sentece. That is the output size is \\(N \\times L \\times 1000\\).\n\nprint(model(next(iter(train_loader))[0]).shape)\n\nAs we saw, each target \\(y_i\\) is simply the next word in the sentence, so \\(y_i =x_{i+1}\\). This is our autoregressive language modelling framework or next-word prediction. Since we have 1000 possible tokens (words), we essentially need to make a prediction for each target of one of 1000 classes. We’ll use our 1000 dimensional output at each word to estimate the probability of each possible next word. Recall that we can use the Softmax function to map an arbitrary vector to a positive vector that sums to 1. \\[p(y_i = c | \\mathbf{x}_{0}, \\mathbf{x}_{i}) = \\text{Softmax}(\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0)_c\\] This says that the probability that \\(y_i\\) is some token \\(c\\) is modelled as the \\(c^{th}\\) output of the softmax function.\nWith this in mind we can now define our negative log-likelihood loss for a given word as: \\[\\text{NLL}(y_i, \\mathbf{x}, \\mathbf{W}) = -\\log p(y_i | \\mathbf{x}_{0}, \\mathbf{x}_{i}) = -\\log \\text{Softmax}(\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0)_{y_i}\\]\nWe want to calculate this loss over each of the \\(L\\) words in each of our \\(N\\) sentences, so we should be taking the softmax over the last dimension of the input (of size 1000).\n\n\nQ4 (10 points)\nComplete the method below to compute the negative log-likelihood for a batch of sentences given the output of the network and the labels. Note that the output of the network will be of size \\(N \\times L \\times 1000\\), as shown above while the targets (\\(y\\)), will be a matrix of token ids of size \\(N \\times L\\) (again each token id is in the range [0-999]). The output should be an \\(N \\times L\\) matrix of float representing the negative log-likelihood loss for each predicted word.\nHint: an appropriate softmax function has been provided for you!\n\ndef softmax(x):\n    # Compute the softmax for each entry in a tensor\n    ex = torch.exp(x)\n    sum_ex = torch.sum(ex, dim=-1, keepdims=True)\n    return ex / sum_ex\n\ndef autoregressive_loss(f, y):\n    ''' The loss for each word in a batch of predictions.\n\n        Inputs:\n            f: tensor (float), An N x L x 1000 tensor network outputs\n            y: tensor (int), An N x L tensor of true token ids in the range [0-999]\n\n        Returns:\n            loss: tensor (float), An N x L tensor of losses\n        '''\n      # YOUR CODE HERE\n\nFor our final loss we’ll need a single number, in this case we’ll take the average NLL over every word in every sentence. In the simplest case this would look like: \\[ \\text{Loss}(\\mathbf{y}, \\mathbf{X}, \\mathbf{W}) = \\frac{1}{N\\cdot L} \\sum_{n=1}^{N}\\sum_{i=1}^{L} \\text{NLL}(y_{ni}, \\mathbf{x}_{ni}, \\mathbf{W})\\]\nHowever, this isn’t quite right! Remember that our actual sentences can be different lengths and that shorter sentences are lengthened with extra &lt;pad&gt; tokens to be length \\(L\\). For example if our longest sentence has 8 words, then \\(L=8\\) and we need to transform:\n&lt;start&gt; I love purple cats &lt;stop&gt; -&gt; &lt;start&gt; I love purple cats &lt;stop&gt;  &lt;pad&gt; &lt;pad&gt;\nSince &lt;pad&gt; tokens don’t correspond to actual words in a sentence, we don’t want to try to predict them and therefore we’ll want to exclude words where \\(y_i\\) is &lt;pad&gt;. In our setup &lt;pad&gt; is represented by a token id of 0. So our loss should actually be:\n\\[ \\text{Loss}(\\mathbf{y}, \\mathbf{X}, \\mathbf{W}) = \\frac{1}{\\sum_{n=1}^{N}\\sum_{i=1}^{L} \\mathbb{I}(y_{ni} &gt; 0)} \\sum_{n=1}^{N}\\sum_{i=1}^{L} \\mathbb{I}(y_{ni} &gt; 0) \\text{NLL}(y_{ni}, \\mathbf{x}_{ni}, \\mathbf{W})\\]\nHere \\(\\mathbb{I}(\\cdot)\\) is the indicator function so: \\[ \\mathbb{I}(y_{ni} &gt; 0) = \\begin{cases} 1 \\text{ if }y_{ni} &gt; 0 \\\\ 0 \\text{ if }y_{ni} = 0\\end{cases}\\]\n\n\nQ5 (5 points)\nModify your autoregressive_loss function to take the mean loss over all words where \\(y_{ni}&gt;0\\).\nHint: torch.where may come in handy here\n\ndef autoregressive_loss(f, y):\n    ''' The mean loss for each word in a batch of predictions.\n\n        Inputs:\n            f: tensor (float), An N x L x 1000 tensor network outputs\n            y: tensor (int), An N x L tensor of true token ids in the range [0-999]\n\n        Returns:\n            loss: (float) The averge loss\n        '''\n      # YOUR CODE HERE\n\nOk, we’re finally ready to do some training!\n\n\nQ6 (10 points)\nComplete the train loop below. At each iteration, make sure to compute the model output and the loss using the autoregressive_loss function you just wrote. Then do any nessecary steps for gradient descent using the provided optimizer.\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Do model creation here so that the model is recreated each time the cell is run\nmodel = model.to(device)\nmodel.train()\n\n# Create the optimizer, just like we have with the built-in optimizer\nopt = torch.optim.Adam(model.parameters(), 0.001)\n\n# Information for plots\ntrain_losses = []\n\nfor iteration, (train_X, train_Y) in enumerate(tqdm.tqdm(train_loader)):\n    # Grab the batch of data and send it to the correct device\n    train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n    # Compute the output, loss, and gradient and take a step of gradient descent\n    # YOUR CODE HERE\n\n\n    loss =\n    train_losses.append(loss.item())\n\n    if iteration &gt; 100:\n      break\n\n\n# Plot the loss over the first 100 iterations\nplt.plot(train_losses)\nplt.title('Loss vs. Iterations')\n\n\n\nQ7 (5 points)\nYou might notice that the plotted loss above has pretty poor behaivior! This could be due to vanishing or exploding gradients. Briefly explain, why RNNs might be especially prone to this problem and how you might address it. Then show how you might implement this approach within your RNN layer.\nYOUR ANSWER HERE\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n        # Add any additional sub-modules here\n\n    def forward(self, x):\n        ''' Computes the forward pass of an RNN\n\n        Inputs:\n            x: tensor (float), An N x L x D tensor of input data\n\n        Returns:\n            h: tensor (float), An N x L x H tensor of transformed features\n        '''\n        # YOUR CODE HERE\n\n# Create a model\nmodel = RNNGenerator()\n\nTry out your implementation by copying your training loop from above (this does not need to actually improve on Q6 for full credit).\n\n# YOUR CODE HERE\n\nIf we want to make use of our language model, we’ll need a way to actually generate text from it. Recall from class that we’ll need to do this one token at a time. We know that any text will always start with our designated &lt;start&gt; token, which has token id 1 in our vocabulary. Therefore we can start generating a sentence by using our model to sample the next word given &lt;start&gt;.\nTo sample a word we’ll use our model to predict a probability distribution over every possible next token and sample from that distribution. For example we might have the following sequence of samples:\n\\[\\text{I} \\sim p(y_1| \\text{&lt;start&gt;})\\] \\[\\text{love} \\sim p(y_2| \\text{&lt;start&gt;}, \\text{I})\\] \\[\\text{purple} \\sim p(y_3| \\text{&lt;start&gt;}, \\text{I}, \\text{love})\\] \\[\\text{cats} \\sim p(y_4| \\text{&lt;start&gt;}, \\text{I}, \\text{love})\\] \\[\\text{&lt;stop&gt;} \\sim p(y_4| \\text{&lt;start&gt;}, \\text{I}, \\text{love}, \\text{purple})\\]\nThe following function will take a tensor of size \\(N \\times ... \\times C\\), where all entries are non-negative and the entries along the last dimension sum to 1 (therefore forming a valid categorical distribution). It returns a sample tensor of ints of size \\(N\\times ...\\), sampling each entry from the corresponding input distribution.\n\nimport torch\ndef sample_categorical(probs):\n  assert torch.all(torch.isclose(p.sum(dim=-1), torch.tensor(1.)))\n  return torch.distributions.Categorical(probs=probs).sample()\n\n# 4 x 3 matrix of probabilities (each row sums to 1.)\np = torch.tensor([[0.3, 0.2, 0.5],\n                  [0.0, 0.9, 0.1],\n                  [0.9, 0.0, 0.1],\n                  [0.3, 0.3, 0.4]])\n\n# Length 4 vector of samples\nprint(sample_categorical(p))\n\n# 2 x 2 x 3 matrix of probabilities (each final dimension sums to 1.)\np = torch.tensor([\n                  [\n                    [0.3, 0.2, 0.5],\n                    [0.0, 0.9, 0.1]],\n                  [\n                    [0.9, 0.0, 0.1],\n                    [0.3, 0.3, 0.4]\n                  ]\n                  ])\n\n# 2x2 matrix of samples\nprint(sample_categorical(p))\n\n\n\nQ8 (10 points)\nComplete the function below to sample a batch of sentences given a trained model. The function should return a matrix of size \\(N \\times L\\), where \\(N\\) is the given batch size and \\(L\\) is the given maximum sentence length.\nHint: Remember that you’ll need to sample sequentially, one word at a time in each sentence, so you should have a loop that runs \\(L\\) times. Also remember that the model outputs a prediction for every word in a sentence, but at each step you only need the prediction for the last word that has yet to be seen.\n\ndef sample(model, data, batch_size=1, max_length=50):\n  model.eval()\n\n  # Start with an N x 1 matrix where each entry is just the &lt;start&gt; token.\n  # After the first iteration this should be N x 2, then N x 3 ... until N x L.\n  sample = torch.ones((batch_size, 1)).int().to(device)\n  # YOUR CODE HERE\n\n  return output\n\n\n# Test sampling\nsample_sentence = sample(model, data)\nprint('Tokens:', sample_sentence)\nprint('Text:', convertToText(sample_sentence, data.eng_vocab))\n\nNow recall that RNNs actually aren’t ideal for language modeling. In recent years they’ve mostly been replaced by attention layers. A scaled dot-product attention layer is defined by the formula: \\[\\text{Attention}(Q, K, V) = \\text{Softmax}\\bigg(\\frac{QK^T}{\\sqrt{h}} \\bigg)V\\]\nIn the above formula, \\(Q\\), \\(K\\) and \\(V\\) are all assumed to be \\(L \\times h\\) matrices given by affine functions of the input: \\[Q = X W_Q + b_Q\\] \\[K = X W_K + b_K\\] \\[V = X W_V + b_V\\]\n\n\nQ9 (10 points)\nComplete the following implementation of a (single-headed) attention layer. The forward method should assume a batched input of shape \\(N \\times L \\times d\\), so the attention equation above should be applied for each observation yielding an \\(N \\times L \\times h\\) output.\nHint: you can use t.transpose(-1, -2) to transpose the last two dimensions of a tensor, e.g. to turn an \\(N \\times L \\times h\\) tensor into an \\(N \\times h \\times L\\) tensor\n\nclass Attention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n        # YOUR CODE HERE\n\nIn order to do autoregressive generation, we need to make sure that future words don’t influence past words. As we saw in class we can accomplish this by masking our attention matrix before applying the softmax function:\n\\[\\text{MaskedAttention}(Q, K, V) = \\text{Softmax}\\bigg( \\text{Mask} \\bigg( \\frac{QK^T}{\\sqrt{h}} \\bigg) \\bigg)V\\]\nOur masking function will work as follows: \\[\\text{Mask}(M)_{ij} = \\begin{cases} -\\infty \\text{ if } i &lt; j \\\\ M_{ij} \\text{ if } i \\geq j\\end{cases}\\] After the softmax operation entries set to \\(-\\infty\\) will become \\(0\\). Luckily PyTorch provides us with a useful function called torch.tril that can help us: \\[\\text{TriL}(M)_{ij} = \\begin{cases} 0\\  \\ \\ \\  \\text{ if } i &lt; j \\\\ M_{ij} \\text{ if } i \\geq j\\end{cases}\\]\n\n\nQ10 (10 points)\nComplete the following implementation of masked attention. Using your previous attention implementation as a starting point.\n\nclass MaskedAttention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n        # YOUR CODE HERE\n\nFinally the last addition we’ll make to our attention layer (for now) is to implement a Multi-headed attention layer. In this case our layer will take an additional argument num_heads that specifies the number of attention heads to use.\nRecall that for multi-headed attention we’ll compute \\(Q\\), \\(K\\) and \\(V\\) the same way as before, but this time before computing the attention forumla as above, we’ll split each into num_heads chunks along the last dimension. That is, if \\(Q\\) is of shape \\(N \\times L \\times h\\), and num_heads is 8, we’ll create 8 new query matricies \\(Q_1...Q_8\\), each of size \\(N \\times L \\times \\frac{h}{8}\\).\nWe’ll then compute num_heads different attention outputs, where the output for head i is: \\[\\text{Head}_i = \\text{Softmax}\\bigg( \\text{Mask} \\bigg( \\frac{Q_iK_i^T}{\\sqrt{h/8}} \\bigg) \\bigg)V_i\\] Each head will similarly return an output of size \\(N \\times L \\times \\frac{h}{8}\\), and we can then use torch.cat(heads, dim=-1) to recombine them into a final output tensor of size \\(N \\times L \\times h\\).\n\n\nQ11 (10 points)\nComplete the implementation of MaskedMultiheadedAttention below, using the formula above.\n\nclass MaskedMultiheadAttention(nn.Module):\n    def __init__(self, input_size, hidden_size, num_heads=1):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size // num_heads\n        self.num_heads = num_heads\n\n    def forward(self, x):\n      '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n        # YOUR CODE HERE\n\n\n\nQ12 (5 points)\nExplain, in your own words, the potential advantages of attention-based models over RNN-based models for the language modelling problem.\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/submission.html",
    "href": "assignments/homeworks/Homework 1/submission.html",
    "title": "Homework 1: Introduction to Numpy",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n\nPython setup\n\n# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\n\n\n\n\nQ1\nWRITE ANSWER HERE\n\n\n\n\n\nQ2\n\n# Fill answers here\nA =\nx =\nb =\n\nprint(b)\n\n\n\n\n\n\nQ3\n\n# Fill answer here (A is the same matrix from above)\nb =\nx =\n\n\n\n\n\n\nQ4\n\n# Fill in function below\ndef step(x_guess, A, b, omega=0.1):\n\n    return new_x_guess\n\nx_guess = np.zeros(3)\nfor i in range(100):\n    x_guess = step(x_guess, A, b)\n\nprint(x_guess, x)\n\n\n\n\n\n\nQ5\n\n# Fill in function below\ndef error(x_guess, A, b):\n\n    return err\n\n# Add code to plot the error over time\n\nx_guess = np.zeros(3)\nfor step in range(100):\n\n    x_guess = step(x_guess, A, b)\n\n\n\n\n\n\n\nQ6\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1}= \\]\nYOU MAY ADD WORK HERE\n\n\n\n\n\nQ7\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}}= \\]\n\n\n\n\n\nQ8\nWRITE YOUR ANSWER HERE\n\n\n\n\n\nQ9\n\n# Fill in code here\nx_col =\nx_row =\n\n\n\n\n\n\nQ10\n\nones = np.ones((3, 3))\nx = np.array([1, -2, 1])\n\n\n# Fill in code here\n\nones OPERATION x.reshape( SHAPE )\n\n\n\n\n\n\nQ11\n\n# Fill code here\n\nX =\nprint(X)\n\n\n\n\n\n\nQ12\n\ntheta = np.linspace(0, 2 * np.pi, 20) # Generates 20 evenly-spaced numbers between 0 and 2π\n\n# Fill in your code here\ncircle =\n\n\n\n\n\n\nQ13\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\n\n\n\n\n\n\nQ14\n\n# Fill your code here\ntransformed_circle =\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\n\n\n\n\n\n\nQ15\n\n# Fill your code here\nb = np.array([-0.5, 1.2, 0])\ntransformed_circle =\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\n# Fill your code here\n\n\n\n\n\n\nQ16\n\nimport sklearn.datasets as datasets\ndataset = datasets.load_iris()\nfeatures = dataset['data']\ntargets = dataset['target']\nfeature_names = dataset['feature_names']\ntarget_names = dataset['target_names']\n\n# Write any code to determine the number of observations here\n\n\n# Fill your code here\n\nplt.figure(figsize=(4, 4))"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/solutions-M7GY1X.html",
    "href": "assignments/homeworks/Homework 6/solutions-M7GY1X.html",
    "title": "Homework 6: Vectorization (solutions)",
    "section": "",
    "text": "In this homework we will update a our reverse-mode automatic differentiation library to use vectorized operations. It should make it a lot faster!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw6_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw6_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#overview",
    "href": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#overview",
    "title": "Homework 6: Vectorization (solutions)",
    "section": "",
    "text": "In this homework we will update a our reverse-mode automatic differentiation library to use vectorized operations. It should make it a lot faster!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw6_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw6_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#part-0-setting-up-automatic-differentiation",
    "href": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#part-0-setting-up-automatic-differentiation",
    "title": "Homework 6: Vectorization (solutions)",
    "section": "Part 0: Setting up automatic differentiation",
    "text": "Part 0: Setting up automatic differentiation\nHere we’ll re-use our automatic differentiation library from the previous homework as our starting point for this assignment.\nIn the marked cells below, copy the corresponding answers from homework 5. You may use either your own answers or published solutions.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        parent_values    (list): A list of raw values of each input (as floats)\n        forward_grads (dict): A dictionary mapping inputs to gradients\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.parent_values = [arg.value if isinstance(arg, AutogradValue) else arg for arg in args]\n        self.forward_grads = {}\n        self.value = self.forward_pass()\n        self.grad = 0. # Used later for reverse mode\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.parent_values)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n\nDefining operations\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\nclass _add(AutogradValue):\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n    \n    def grads(self, a, b):\n        return 1., -1.\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n    \nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n    \n    def grads(self, a, b):\n        return b, a\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n    \n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n    \nclass _exp(AutogradValue):\n    def func(self, a):\n        return math.exp(a)\n    \n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return math.log(a)\n    \n    def grads(self, a):\n        return (1 / a,)\n\n\n\nBackward pass\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef backward_pass(self):\n    local_grads = self.grads(*self.parent_values)\n\n    # Loop through pairs of parents and their corresponding grads\n    for node, grad in zip(self.parents, local_grads):\n        # Update the gradient of each AutogradValue parent\n        if isinstance(node, AutogradValue):\n            node.grad += self.grad * grad\n\nAutogradValue.backward_pass = backward_pass\n\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n    queue = [self]\n    order = []\n\n    # Additionally keep track of the visit counts for each node\n    counts = {}\n    while len(queue) &gt; 0:\n        node = queue.pop()\n        \n        # Rather than removing nodes from the order [slow, O(N)], \n        # just mark that it has been visited again [O(1)]\n        if isinstance(node, AutogradValue):\n            if node in counts:\n                counts[node] += 1\n            else:\n                counts[node] = 1\n\n            order.append(node)\n            queue.extend(node.parents)\n    \n    # Go through the order, but only call backward pass once we're at\n    # the last vist for a given node\n    for node in order:\n        counts[node] -= 1\n        if counts[node] == 0:\n            node.backward_pass()\n\nAutogradValue.backward = backward\n\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#training-a-neural-network",
    "href": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#training-a-neural-network",
    "title": "Homework 6: Vectorization (solutions)",
    "section": "Training a neural network",
    "text": "Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks!\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if isinstance(a, AutogradValue) or isinstance(b, AutogradValue) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + np.exp(-x))\n\ndef log(x):\n    # Computes the sigmoid function\n    return x.log() if isinstance(x, AutogradValue) else np.log(x)\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid(xw * (2 * y - 1))\n        nll = -(log(py))\n        return nll.sum()\n\n\nAutograd for a neural network\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef element_map(f, a):\n    '''\n    Creates a new array the same shape as a, with a function f applied to each element.\n\n    Args:\n        a (function): The function to apply\n        a (array): The array to map\n    Returns:\n        g (array): An array g, such that g[i,j] = f(a[i,j])\n    '''\n\n    # Store the original shape\n    shape = a.shape\n    \n    # Create a 1-d array with the same elements using flatten()\n    # then iterate through applying f to each element\n    flat_wrapped = np.asarray([f(ai) for ai in a.flatten()])\n\n    # Reshape back to the original shape\n    return flat_wrapped.reshape(shape)\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    return element_map(AutogradValue, a)\n    \n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    return element_map(lambda ai: ai.grad, a)\n\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    # Wrap the array we want to differentiate with respect to (weights)\n    w = [wrap_array(wi) for wi in self.weights]\n\n    # Run the NLL function and call backward to populate the gradients\n    nll = self.nll(X, y, w)\n    nll.backward()\n\n    # Get both the nll value and graident\n    return nll.value, [unwrap_gradient(wi) for wi in w]\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 3.60, accuracy: 0.99: 100%|██████████| 250/250 [00:12&lt;00:00, 20.36it/s]  \n\n\nModel accuracy: 0.990"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#part-1-vectorizing-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 6/solutions-M7GY1X.html#part-1-vectorizing-reverse-mode-automatic-differentiation",
    "title": "Homework 6: Vectorization (solutions)",
    "section": "Part 1: Vectorizing Reverse-mode automatic differentiation",
    "text": "Part 1: Vectorizing Reverse-mode automatic differentiation\nWe might notice that our reverse-mode automatic differentiation implementation is quite slow! The main reason for this is that our implementation operates on individual numbers (scalars) rather than entire arrays. This means that for a big operation like a matrix multiplication, an AutogradValue object needs to be tracked for each of the \\(O(n^3)\\) individual operations! Even worse, it also means that internally Numpy can’t use the very fast C and C++ implementations it has for array operations on type float, our array elements are now objects so it has to fall back on slow Python-loop based implementations.\nIdeally we’d like our AutogradValue objects to operate at the level of array operations, rather than scalar operations. This would circumvent these problems as we could represent an entire matrix multiplication with a single AutogradValue. In order to do this efficiently, we’ll need to make use of the Vector-Jacobian Product idea that we discussed in class. Let’s review the concept here.\nRecall that in backward_pass for a node c we assume that we have the gradient (derivative) of the loss with respect to c: \\(\\frac{dL}{d\\mathbf{c}}\\) and we need to update the gradients for the parents (say a and b) as:\n\\[\\frac{dL}{da} = \\frac{dL}{dc} \\frac{dc}{da}, \\quad \\frac{dL}{dc} = \\frac{dL}{dc} \\frac{dc}{db}\\]\nWhen \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\) are vectors the derivates \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) and \\(\\frac{d\\mathbf{c}}{d\\mathbf{b}}\\) are Jacobian matrices with possibly many entries and our updates become vector-Jacobian products:\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T, \\quad \\frac{dL}{d\\mathbf{b}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{b}}\\bigg)^T\\]\n\nQ1\nIn this case, let’s assume that \\(\\mathbf{a}\\) is a length \\(n\\) vector and \\(\\mathbf{c}\\) is a length \\(m\\) vector. So we would say that: \\[\\mathbf{a} \\in \\mathbb{R}^n, \\quad \\mathbf{c} \\in \\mathbb{R}^m\\]\nRemember that our loss, \\(L\\), is generally a scalar (\\(L\\in \\mathbb{R}\\)). Based on this, what is the shape of each term in the equation below?\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T\\]\nYour answer should be as matrix/vector dimensions e.g. \\((n \\times m)\\)\n\n\nAnswer\n\\[\\frac{dL}{d\\mathbf{a}} = (n)\\] \\[\\frac{dL}{d\\mathbf{c}} = (m)\\] \\[\\frac{d\\mathbf{c}}{d\\mathbf{a}} = (m \\times n)\\]\n\n\nElement-wise operations\nWe often don’t need to actually construct the Jacobians fully to compute these vector-Jacobian products, as is the case for element-wise operations. As long as we can compute the correct values for \\(\\frac{dL}{d\\mathbf{a}}\\), we’re good! For example if \\[\\mathbf{c} = \\mathbf{a}^2, \\quad \\mathbf{c} = \\begin{bmatrix} a_1^2 \\\\ a_2^2 \\\\ a_3^2 \\\\ \\vdots \\end{bmatrix}\\]\nWe can easily see that we can just update the derivate for each element of \\(\\mathbf{a}\\) independently. \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix} = 2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\]\nIf we want to be more formal we can note that technically, the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is diagonal (\\(\\frac{\\partial c_i}{\\partial a_j}\\) is only nonzeros for \\(i=j\\)). Therefore we can write the Vector-Jacobian Product as:\n\\[\\frac{dL}{d\\mathbf{a}}^T = \\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}  = \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 2 a_1 & 0 & 0 & \\dots \\\\0  & 2 a_2 & 0 & \\dots \\\\ 0 & 0 & 2 a_3 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix}^T = \\bigg(2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\bigg)^T\\]\nFor the case of addition, things are even simpler! If: \\[\\mathbf{c} = \\mathbf{a} + \\mathbf{b}\\]\nWe can again see that we can just update the derivative for each element of \\(\\mathbf{a}\\) independently, but this time each local derivative (\\(\\frac{dc_i}{da_i}\\)) is just \\(1\\), so \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 1 \\\\  \\frac{dL}{dc_2} \\cdot 1 \\\\  \\frac{dL}{dc_3} \\cdot 1 \\\\ \\vdots  \\end{bmatrix} = \\frac{dL}{d\\mathbf{c}}\\]\nIn this case the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is simply the identity matrix, so: \\[\\frac{dL}{d\\mathbf{a}}^T =  \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 1 & 0 & 0 & \\dots \\\\0  & 1 & 0 & \\dots \\\\ 0 & 0 & 1 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}= \\frac{dL}{d\\mathbf{c}}^T \\mathbf{I} = \\frac{dL}{d\\mathbf{c}}^T\\]\n\n\nQ2\nAssume that we have the following formula for \\(\\mathbf{a}\\): \\[\\mathbf{a}= \\exp \\big( \\mathbf{A} \\mathbf{w} \\big) + \\mathbf{w}^2\\] Where \\(\\mathbf{A}\\) is a constant \\(n \\times n\\) matrix. Given the gradient of \\(L\\) with respect to \\(\\mathbf{a}\\): \\(\\frac{dL}{d\\mathbf{a}}\\), what is the gradient of \\(L\\) with respect to \\(\\mathbf{w}\\) (\\(\\frac{dL}{d\\mathbf{w}}\\)) in terms of: \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{w}\\)?\nHint: You do not need to write a formula for the Jacobian (\\(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\)). As we see above, many VJPs can be written without definining the Jacobian explicitly (e.g. for element-wise functions). You can use \\(\\odot\\) (\\odot) to denote an element-wise product between vectors: \\[ \\mathbf{a} \\odot \\mathbf{b} = \\begin{bmatrix}\na_1 b_1 \\\\\na_2 b_3 \\\\\n\\vdots \\\\\na_d b_d \\\\\n\\end{bmatrix}\n\\]\n\n\nAnswer\nHere we’ll start by writing out the vector-Jacobian product we’re looking for: \\[\\frac{dL}{d\\mathbf{w}} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d\\mathbf{a}}{d\\mathbf{w}} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d}{d\\mathbf{w}}\\bigg( \\exp \\big( \\mathbf{A} \\mathbf{w} \\big) + \\mathbf{w}^2\\bigg)\\] Using the addition rule, we can distribute the derivative: \\[=\\frac{dL}{d\\mathbf{a}}^T\\frac{d}{d\\mathbf{w}}\\bigg( \\exp \\big( \\mathbf{A} \\mathbf{w} \\big)\\bigg) + \\frac{dL}{d\\mathbf{a}}^T\\frac{d}{d\\mathbf{w}}\\bigg(\\mathbf{w}^2\\bigg)\\]\nFor simplicity, let’s substitute \\(\\mathbf{b} = \\mathbf{A}\\mathbf{w}\\) for now, so we can apply the chain rule \\[=\\frac{dL}{d\\mathbf{a}}^T\\frac{d}{d\\mathbf{b}}\\bigg( \\exp \\big( \\mathbf{b} \\big)\\bigg)\\frac{d\\mathbf{b}}{d\\mathbf{w}} + \\frac{dL}{d\\mathbf{a}}^T\\frac{d}{d\\mathbf{w}}\\bigg(\\mathbf{w}^2\\bigg)\\]\nWe see that \\(\\exp(w)\\) and \\(w^2\\) are both element-wise operations, so we can use the rule we learned in class:\n\\[  = \\bigg(\\frac{dL}{d\\mathbf{a}} \\odot \\exp(d\\mathbf{b})\\bigg)^T \\frac{d\\mathbf{b}}{d\\mathbf{w}} + 2 \\bigg( \\frac{dL}{d\\mathbf{a}}  \\odot \\mathbf{w} \\bigg)\\]\nFinally we know that \\(\\mathbf{b} = \\mathbf{A}\\mathbf{w}\\), therefore \\(\\frac{d\\mathbf{b}}{d\\mathbf{w}} = \\mathbf{A}\\)\n\\[ \\frac{dL}{d\\mathbf{w}}  = \\bigg(\\frac{dL}{d\\mathbf{a}} \\odot \\exp(\\mathbf{A}\\mathbf{w})\\bigg)^T \\mathbf{A} + 2 \\bigg( \\frac{dL}{d\\mathbf{a}}  \\odot \\mathbf{w} \\bigg)\\]\n\n\nQ3\nLet’s replace our operation implementations above with ones that compute Vector-Jacobian products. We’ll start with element-wise operations. Complete the vjp function for each operation below. Unlike the grads methods we implemented before which computed the derivative of the output with respect to each input: \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\) (if applicable), each vjp method should directly compute the gradient of the loss with respect to each input: \\(\\frac{dL}{d\\mathbf{a}}\\) and \\(\\frac{dL}{d\\mathbf{b}}\\), assuming the grad argument provides the gradient of the loss with respect to the output: \\(\\frac{dL}{d\\mathbf{c}}\\).\nHint: For binary operations (+,-,*,/), you do not need to account for broadcasting. That is, you can assume that a, b and c are always the same shape! We’ve started you off with a few examples to base your answers on.\n\nclass _add(AutogradValue):\n    # An example representing the addition operation.\n    def func(self, a, b):\n        '''\n        Computes the result of the operation (a + b). Assumes a and b are the same shape.\n\n        Args:\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            c (array of float): The result c = a + b\n        '''\n        return a + b\n\n    def vjp(self, grad, a, b):\n        '''\n        Computes dL/da and dL/db given dL/dc.\n\n        Args:\n            grad (array of float): The gradient of the loss with respect to the output (dL/dc)\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            grads (tuple of arrays): A tuple containing the gradients dL/da and dL/db\n        '''\n        return grad, grad\n\nclass _square(AutogradValue):\n    # Another example class implementing c = a^2\n    def func(self, a):\n        return a ** 2\n\n    def vjp(self, grad, a):\n        return (2 * a * grad,)\n\nclass _pad(AutogradValue):\n    # An implementation for padding with a column of 1s.\n    def func(self, a):\n        return np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\n    def vjp(self, grad, a):\n        return (grad[:, :-1],)\n\n\n\nAnswer\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n    \n    def vjp(self, grad, a, b):\n        return grad, -grad\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n    \n    def vjp(self, grad, a):\n        return (-grad,)\n    \nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n    \n    def vjp(self, grad, a, b):\n        return b * grad, a * grad\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n    \n    def vjp(self, grad, a, b):\n        return grad / b, grad * (-a / (b * b))\n    \nclass _exp(AutogradValue):\n    def func(self, a):\n        return np.exp(a)\n    \n    def vjp(self,grad,  a):\n        return (grad * np.exp(a),)\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return np.log(a)\n    \n    def vjp(self, grad, a):\n        return (grad / a,)\n\ntest_vjp(_neg, '_neg', )\ntest_vjp(_exp, '_exp', true_func=anp.exp)\ntest_vjp(_log, '_log', true_func=anp.log)\ntest_vjp(_sub, '_sub', True)\ntest_vjp(_mul, '_mul', True)\ntest_vjp(_div, '_div', True)\n\nPassed _neg!\nPassed _exp!\nPassed _log!\nPassed _sub!\nPassed _mul!\nPassed _div!\n\n\n\n\nQ4\nConsider the operation defined by np.sum, that takes the sum over all elements of a matrix or vector, producing a scalar:\n\\[c  = \\sum_{i=1}^n a_i\\]\nWrite a vjp method for this operation that computes: \\(\\frac{dL}{d\\mathbf{a}}\\) given \\(\\frac{dL}{dc}\\).\nHint: Note that \\(L\\), \\(c\\) and \\(\\frac{dL}{dc}\\) are all scalars, so for any entry \\(i\\) of our output we can simply apply the chain rule and compute \\(\\frac{dL}{da_i} = \\frac{dL}{dc} \\frac{dc}{da_i}\\). As the equation above for \\(c\\) given \\(\\mathbf{a}\\) is a sum, \\(\\frac{dc}{da_i}\\) should be simple!\n\n\nAnswer\n\nclass _sum(AutogradValue):\n    def func(self, a):\n        return np.sum(a)\n    \n    def vjp(self, grad, a):\n        return (grad * np.ones_like(a),)\n\ntest_vjp(_sum, '_sum', true_func=anp.sum, issum=True)\n\nPassed _sum!\n\n\n\n\nMatrix multiplication\nFor the next few problems, it may be useful to refer to this diagram of matrix multiplication.\n\n\n\nimage.png\n\n\nThe last important operation we’ll need a vjp method for in order to use our vectorized AutogradValue class for a neural network is matrix multiplication. Let’s consider the operation:\n\\[\\mathbf{C} = \\mathbf{A}\\mathbf{B}\\]\nWhere \\(\\mathbf{A}\\) is an \\(N\\times h\\) matrix, \\(\\mathbf{B}\\) is a \\(h \\times d\\) matrix and \\(\\mathbf{C}\\) is an \\(N\\times d\\) matrix.\nRecall that for vjp want to compute \\(\\frac{dL}{d\\mathbf{A}}\\) (and \\(\\frac{dL}{d\\mathbf{B}}\\) ) given \\(\\frac{dL}{d\\mathbf{C}}\\). We can compute a given entry \\(i,j\\) of \\(\\frac{dL}{d\\mathbf{A}}\\) by applying the chain rule using each element of \\(\\mathbf{C}\\):\n\\[\\frac{dL}{dA_{ij}} = \\sum_{k=1}^N \\sum_{l=1}^d \\frac{dL}{dC_{kl}}\\frac{dC_{kl}}{dA_{ij}}\\]\nHowever, each entry of \\(\\mathbf{C}\\) only depends on a single row of \\(\\mathbf{A}\\) and a single column of \\(\\mathbf{B}\\), thus for most \\(i,j,k,l\\), \\(\\frac{dC_{kl}}{dA_{ij}}=0\\).\n\nQ5\nUsing this observation, simplify the expression for \\(\\frac{dL}{dA_{ij}}\\) above. (The derivative of the loss with respect to the entry of \\(\\mathbf{A}\\) at row \\(i\\), column \\(j\\)).\nHint: Your answer should have a similar form, but should only have a single summation and a subset of the indices \\(i,j,k,l\\).\n\n\nAnswer\n\\[\\frac{dL}{dA_{ij}} = \\sum_{l=1}^d \\frac{dL}{dC_{il}}\\frac{dC_{il}}{dA_{ij}}\\]\n\n\nQ6\nRecalling the definition of matrix-multiplication, give a simple expression for \\(\\frac{dC_{il}}{dA_{ij}}\\), then substitue it into your expression for \\(\\frac{dL}{dA_{ij}}\\).\n\n\nAnswer\n\\[\\frac{dC_{il}}{dA_{ij}}=B_{jl} , \\quad\\frac{dL}{dA_{ij}} = \\frac{dL}{dC_{il}}B_{jl}\\]\n\n\nQ7\nUsing your expression in Q13, write an expression for \\(\\frac{dL}{d\\mathbf{A}}\\) as a matrix multiplication between two of the 3 given matrices: \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\), \\(\\mathbf{B}\\). Make sure to inlude any nessecary transposes.\nHint: Recall that \\(\\frac{dL}{d\\mathbf{C}}\\) is the same shape as \\(\\mathbf{C}\\) (\\(N\\times d\\)), \\(\\mathbf{A}\\) has shape \\(N \\times h\\) and \\(\\mathbf{B}\\) has shape \\(h \\times d\\).\n\n\nAnswer\n\\[\\frac{dL}{d\\mathbf{A}}= \\frac{dL}{d\\mathbf{C}}\\mathbf{B}^T\\]\n\n\nQ8\nWrite the corresponding formula for \\(\\frac{dL}{d\\mathbf{B}}\\).\nHint: You can use the fact that \\(C^T = B^T A^T\\) and that \\(\\frac{dL}{d\\mathbf{C}^T} = (\\frac{dL}{d\\mathbf{C}})^T\\)\n\n\nAnswer\n\\[\\frac{dL}{d\\mathbf{B}}=\\frac{dL}{d\\mathbf{C}}^T\\mathbf{A}\\]\n\n\nQ9\nUsing the expressions you derived in Q14 and Q15, implement the vjp function for the matmul operation to compute \\(\\frac{dL}{d\\mathbf{A}}\\) and \\(\\frac{dL}{d\\mathbf{B}}\\) given \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\).\n\n\nAnswer\n\nclass _matmul(AutogradValue):\n    def func(self, a, b):\n        return np.matmul(a, b)\n\n    def vjp(self, grad, a, b):\n        return np.dot(grad, b.T), np.dot(grad.T, a).T\n\ntest_vjp(_matmul, '_matmul', binary=True, true_func=anp.matmul)\n\nPassed _matmul!\n\n\nNow that we’ve written the vjp versions of our operators, we’ll update our AutogradValue class to use them!\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.vjp = lambda self, g, a: (1.,)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.pad = lambda a: _pad(a)\nAutogradValue.sum = lambda a: _sum(a)\nAutogradValue.matmul = lambda a, b: _matmul(a, b)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nAs a final step, we need to update our backward_pass method to use our new vjp method instead of relying on grads.\n\n\nQ10\nUpdate your backward_pass method to use vjp instead of grads.\nHint: Recall that vjp directly computes \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\frac{dL}{d\\mathbf{b}}\\), whereas grads computed \\(\\frac{dc}{da}\\), \\(\\frac{dc}{db}\\)\n\n\nAnswer\n\ndef backward_pass(self):\n    local_vjps = self.vjp(self.grad, *self.parent_values)\n    # Loop through pairs of parents and their corresponding grads\n    for node, vjp in zip(self.parents, local_vjps):\n        # Update the gradient of each AutogradValue parent\n        if isinstance(node, AutogradValue):\n            node.grad += vjp\n\nAutogradValue.backward_pass = backward_pass\n\n\n\nQ11\nFinally update the nll_and_grad function for our NeuralNetwork class to use our shiny new vectorized reverse-mode implementation.\nHint: We should no longer need to use our wrap_array and unwrap_gradient functions, as AutogradValue objects can now contain arrays!\n\n\nAnswer\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    w = [AutogradValue(wi) for wi in self.weights]\n    nll = self.nll(X, y, w)\n    nll.backward()\n    return nll.value, [wi.grad for wi in w]\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe should be able to run it with a much larger network now!\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [25, 25])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 2.37, accuracy: 1.00: 100%|██████████| 250/250 [00:00&lt;00:00, 1332.97it/s]\n\n\nModel accuracy: 1.000"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/submission.html",
    "href": "assignments/homeworks/Homework 8/submission.html",
    "title": "Homework 8: Optimization and Normalization",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\ndata_path = '/cs/cs152/data'\n\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%208/hw8_support.py\n\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\nfrom hw8_support import *\n\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using '{device}' device.\")\n\n# Model hyperparameters\nneurons_per_hidden_layer = [20] * 2\n\n# Mini-Batch SGD hyperparameters\nbatch_size = 256\nnum_epochs = 10\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\n\n\n# Load the example dataset (Fashion MNIST)\ntrain_loader, valid_loader = get_fmnist_data_loaders(data_path, batch_size)\n\nprint(\"Training dataset shape   :\", train_loader.dataset.data.shape)\nprint(\"Validation dataset shape :\", valid_loader.dataset.data.shape)\n\n\n# Let's plot a few images as an example\nnum_to_show = 8\nimages = train_loader.dataset.data[:num_to_show]\ntargets = train_loader.dataset.targets[:num_to_show]\nlabels = [train_loader.dataset.classes[t] for t in targets]\nfig, axes = plt.subplots(1, num_to_show)\n\nfor axis, image, label in zip(axes, images, labels):\n    axis.imshow(image.squeeze(), cmap=\"Greys\")\n    axis.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n    axis.set_xticks([])\n    axis.set_yticks([])\n    axis.set_title(f\"{label}\")\n\n\n# Run the initial model\nrun_model()\n\n\n\n\n\nQ1\n\\[E\\left[L^{(100)}\\right] = \\mathbf{?}\\]\n\n\n\n\n\nQ2\n\\[\\text{Var}\\left[L^{(100)}\\right] = \\mathbf{?}\\]\n\n\n\n\n\nQ3\n\nclass MomentumOptimizer(SGDOptimizer):\n    # Gradient descent with momentum\n    def __init__(self, parameters, lr=0.01, mu=0.9):\n        self.lr = lr\n        self.mu = mu\n        self.parameters = list(parameters)\n        self.velocity = [torch.zeros_like(param) for param in self.parameters]\n\n    def step(self):\n        for ind, parameter in enumerate(self.parameters):\n            self.velocity[ind] = # YOUR CODE HERE\n            update = # YOUR CODE HERE\n            parameter -= update\n\n\n\n\n\n\nQ4\nYOUR ANSWER HERE\n\nrun_model(optimizer=MomentumOptimizer)\n\n\n\n\n\n\nQ5\n\nepsilon = 1e-7\nclass RMSPropOptimizer(SGDOptimizer):\n    # RMSProp Optimizer\n    def __init__(self, parameters, lr=0.01, beta=0.9):\n        self.lr = lr\n        self.beta = beta\n        self.parameters = list(parameters)\n        # YOUR CODE HERE\n\n    def step(self):\n        # Take a step of gradient descent\n        for ind, parameter in enumerate(self.parameters):\n            # YOUR CODE HERE\n            update = # YOUR CODE HERE\n            parameter -= update\n\n\n\n\n\n\nQ6\n\nrun_model(optimizer=RMSPropOptimizer)\n\n\n\n\n\n\nQ7\n\nepsilon = 1e-7\nclass AdamOptimizer(SGDOptimizer):\n    # Adam optimizer\n    def __init__(self, parameters, lr=0.01, beta1=0.9, beta2=0.99):\n        self.lr = lr\n        self.beta1 = beta1\n        self.beta2 = beta2\n\n        self.parameters = list(parameters)\n        # YOUR CODE HERE\n\n    def step(self):\n        for ind, parameter in enumerate(self.parameters):\n            # YOUR CODE HERE\n            update = # YOUR CODE HERE\n            parameter -= update\n\n\n\n\n\n\nQ8\n\nrun_model(optimizer=AdamOptimizer)\n\n\n\n\n\n\nQ9\nYOUR ANSWER HERE\n\nrun_model(number_of_hidden_layers=20)\n\n\n\n\n\n\nQ10\n\nepsilon = 1e-7\nclass LayerNorm(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n# Replace our Layer class with one that includes layer normalization\nclass LayerNormLayer(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.linear = nn.Linear(in_dimensions, out_dimensions)\n        self.layer_norm = LayerNorm()\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = self.layer_norm(x)\n        x = self.activation(x)\n        return x\n\n\n\n\n\n\nQ11\nYOUR ANSWER HERE\n\nrun_model(number_of_hidden_layers=20, layer_type=LayerNormLayer)\n\n\n\n\n\n\nQ12\n\nepsilon = 1e-7\nclass BatchNorm(nn.Module):\n    def __init__(self, dimensions, beta=0.9):\n        super().__init__()\n        self.beta=beta\n        self.running_mean = torch.zeros((1, dimensions))\n        self.running_var = torch.ones((1, dimensions))\n\n    def forward(self, x):\n        # Needed for GPU compatibility\n        self.running_mean = self.running_mean.to(x.device)\n        self.running_var = self.running_var.to(x.device)\n\n        if self.training:\n            # YOUR CODE HERE\n        else:\n            # YOUR CODE HERE\n\nclass BatchNormLayer(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.linear = nn.Linear(in_dimensions, out_dimensions)\n        self.layer_norm = BatchNorm(out_dimensions)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = self.layer_norm(x)\n        x = self.activation(x)\n        return x\n\n\n\n\n\n\nQ13\nYOUR ANSWER HERE\n\nrun_model(number_of_hidden_layers=20, layer_type=BatchNormLayer)\n\n\n\n\n\n\nQ14\n\nclass ResidualLayer(nn.Module):\n    def __init__(self, dimensions, *args):\n        super().__init__()\n        self.linear = nn.Linear(dimensions, dimensions)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        # YOUR CODE HERE\n\n\n\n\n\n\nQ15\n\nrun_model(number_of_hidden_layers=20, layer_type=ResidualLayer)\n\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html",
    "href": "assignments/homeworks/Homework 8/main.html",
    "title": "Homework 8: Optimization and Normalization",
    "section": "",
    "text": "For this homework and for the final project, you may find it useful to run your code with access to a sufficient GPU, which may allow your code to run faster (we will talk about why later in the course). If you do not have access to a powerful GPU on your personal computer (e.g. if you primarily use a laptop), then there are 2 options you may consider for using a remotely hosted GPU.\nNote that some laptops may actually run this code faster than the course server, so you may want to try it first on your laptop regardless\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\ndata_path = '/cs/cs152/data'"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#option-1-use-the-course-gpu-server",
    "href": "assignments/homeworks/Homework 8/main.html#option-1-use-the-course-gpu-server",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Option 1: Use the course GPU server",
    "text": "Option 1: Use the course GPU server\nWe have a GPU server available for this course that you all should have access to. (If you are not a Mudd student we may need to get you setup with a Mudd CS account). The server name is teapot.cs.hmc.edu.\nYou can login to the server via a terminal using your hmc username and password:\nssh &lt;USERNAME&gt;@teapot.ssh.hmc.edu\nThen run the command:\nsource /cs/cs152/venv/bin/activate\nto activate the course Python enviornment, followed by:\njupyter lab --no-browser\nto start a Jupyter server (if you want to keep a server running you can use tmux). At the end of the Jupyter startup output you should see a line like this:\n\n\n\nimage.png\n\n\nThis tells us the port and password we need to access the server remotely. In order to access the server we’ll start an ssh tunnel. Open a new terminal window and run the command:\nssh -L 9000:localhost:&lt;PORT&gt; &lt;USERNAME&gt;@teapot.cs.hmc.edu\nWhere &lt;PORT&gt; is the port output from JupyterLab above (8888 in the example image). 9000 is a local network port for your compute to access the server. If 9000 is in use, you can change the number to something different. Once the ssh tunnel is running you can access the notebook server by navigating to http://localhost:9000/lab in a web browser.\nYou can also setup VSCode to connect to this server. At the top right of the window click the kernel menu:\n\n\n\nimage.png\n\n\nYou should see the following popup:\n\n\n\nimage.png\n\n\nClick Select another kernel, then Existing Jupyter Server and paste the address from above:\n\n\n\nimage.png\n\n\nPaste the token from the Jupyter output when prompted for a password. If given multiple kernel options, select Python3. You should now be running the notebook code remotely!"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#option-2-google-colab",
    "href": "assignments/homeworks/Homework 8/main.html#option-2-google-colab",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Option 2: Google Colab",
    "text": "Option 2: Google Colab\nIf you are unable to get the course server to work, another option is to use Google’s Colab service which provides a simple way to run GPU-accelerated Jupyter notebooks on the web.\nTo start, go to: https://colab.research.google.com/\n\n\n\nimage.png\n\n\nOnce you open the notebook, you’ll want to add a GPU. To do this navigate to runtime-&gt;change runtime type in the top menu.\nIn the popup menu select T4 GPU and click save.\n\n\n\nimage.png\n\n\nNow you should be able to run the notebook! Once you’ve completed the assignment, you can download the notebook to submit it as usual."
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#set-hyperparameters",
    "href": "assignments/homeworks/Homework 8/main.html#set-hyperparameters",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Set Hyperparameters",
    "text": "Set Hyperparameters\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\nfrom torchsummary import summary\n\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import Compose, Normalize, ToTensor\n\nfrom fastprogress.fastprogress import master_bar, progress_bar\n\nimport matplotlib.pyplot as plt\n\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using '{device}' device.\")\n\n# Model hyperparameters\nneurons_per_hidden_layer = [20] * 2\n\n# Mini-Batch SGD hyperparameters\nbatch_size = 256\nnum_epochs = 10\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\n\nUsing 'cpu' device."
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#prepare-the-dataset",
    "href": "assignments/homeworks/Homework 8/main.html#prepare-the-dataset",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Prepare the Dataset",
    "text": "Prepare the Dataset\n\ndef get_fmnist_data_loaders(path, batch_size, valid_batch_size=0):\n    # Computing normalization constants for Fashion-MNIST (commented out since we only need to do this once)\n    # train_loader, valid_loader = get_fmnist_data_loaders(data_path, 0)\n    # X, _ = next(iter(train_loader))\n    # s, m = torch.std_mean(X)\n\n\n    # Data specific transforms\n    data_mean = (0.2860,)\n    data_std = (0.3530,)\n    xforms = Compose([ToTensor(), Normalize(data_mean, data_std)])\n\n    # Training data loader\n    train_dataset = FashionMNIST(root=path, train=True, download=True, transform=xforms)\n\n    # Set the batch size to N if batch_size is 0\n    tbs = len(train_dataset) if batch_size == 0 else batch_size\n    train_loader = DataLoader(train_dataset, batch_size=tbs, shuffle=True)\n\n    # Validation data loader\n    valid_dataset = FashionMNIST(root=path, train=False, download=True, transform=xforms)\n\n    # Set the batch size to N if batch_size is 0\n    vbs = len(valid_dataset) if valid_batch_size == 0 else valid_batch_size\n    valid_loader = DataLoader(valid_dataset, batch_size=vbs, shuffle=True)\n\n    return train_loader, valid_loader\n\n\n# Load the example dataset (Fashion MNIST)\ntrain_loader, valid_loader = get_fmnist_data_loaders(data_path, batch_size)\n\nprint(\"Training dataset shape   :\", train_loader.dataset.data.shape)\nprint(\"Validation dataset shape :\", valid_loader.dataset.data.shape)\n\nTraining dataset shape   : torch.Size([60000, 28, 28])\nValidation dataset shape : torch.Size([10000, 28, 28])\n\n\n\n# Let's plot a few images as an example\nnum_to_show = 8\nimages = train_loader.dataset.data[:num_to_show]\ntargets = train_loader.dataset.targets[:num_to_show]\nlabels = [train_loader.dataset.classes[t] for t in targets]\n\nfig, axes = plt.subplots(1, num_to_show)\n\nfor axis, image, label in zip(axes, images, labels):\n    axis.imshow(image.squeeze(), cmap=\"Greys\")\n    axis.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n    axis.set_xticks([])\n    axis.set_yticks([])\n    axis.set_title(f\"{label}\")"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#create-a-neural-network",
    "href": "assignments/homeworks/Homework 8/main.html#create-a-neural-network",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Create a Neural Network",
    "text": "Create a Neural Network\n\nclass Layer(nn.Module):\n    # This class will represent a basic neural network layer with a linear function\n    # and an activation (in this case ReLU)\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.linear = nn.Linear(in_dimensions, out_dimensions)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = self.activation(x)\n        return x\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self, layer_sizes, layer_class=Layer):\n        super(NeuralNetwork, self).__init__()\n\n        # The first \"layer\" just rearranges the Nx28x28 input into Nx784\n        first_layer = nn.Flatten()\n\n        # The hidden layers include:\n        # 1. a linear component (computing Z) and\n        # 2. a non-linear comonent (computing A)\n        hidden_layers = [\n            (layer_class(nlminus1, nl) if nlminus1 == nl else Layer(nlminus1, nl))\n            for nl, nlminus1 in zip(layer_sizes[1:-1], layer_sizes)\n        ]\n\n        # The output layer must be Linear without an activation. See:\n        #   https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n        output_layer = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n\n        # Group all layers into the sequential container\n        all_layers = [first_layer] + hidden_layers + [output_layer]\n        self.layers = nn.Sequential(*all_layers)\n\n    def forward(self, X):\n        return self.layers(X)"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#implement-an-optimizer",
    "href": "assignments/homeworks/Homework 8/main.html#implement-an-optimizer",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Implement an Optimizer",
    "text": "Implement an Optimizer\n\nclass SGDOptimizer:\n    def __init__(self, parameters, lr=0.01):\n        # Set the learning rate\n        self.lr = lr\n        # Store the set of parameters that we'll be optimizing\n        self.parameters = list(parameters)\n\n    def step(self):\n        # Take a step of gradient descent\n        for ind, parameter in enumerate(self.parameters):\n            # Compute the update to the parameter\n            update = self.lr * parameter.grad\n\n            # Update the parameter: w &lt;- w - lr * grad\n            parameter -= update"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/main.html#train-classifier",
    "href": "assignments/homeworks/Homework 8/main.html#train-classifier",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Train Classifier",
    "text": "Train Classifier\n\n# Here we'll define a function to train and evaluate a neural network with a specified architecture\n# using a specified optimizer.\ndef run_model(optimizer=SGDOptimizer,\n              layer_type=Layer,\n              number_of_hidden_layers=2,\n              neurons_per_hidden_layer=20,\n              learning_rate=0.001):\n\n    # Get the dataset\n    train_loader, valid_loader = get_fmnist_data_loaders(data_path, batch_size)\n\n    # The input layer size depends on the dataset\n    nx = train_loader.dataset.data.shape[1:].numel()\n\n    # The output layer size depends on the dataset\n    ny = len(train_loader.dataset.classes)\n\n    # Preprend the input and append the output layer sizes\n    layer_sizes = [nx] + [neurons_per_hidden_layer] * number_of_hidden_layers + [ny]\n\n    # Do model creation here so that the model is recreated each time the cell is run\n    model = NeuralNetwork(layer_sizes, layer_type).to(device)\n\n    t = 0\n    # Create the optimizer, just like we have with the built-in optimizer\n    opt = optimizer(model.parameters(), learning_rate)\n\n    # A master bar for fancy output progress\n    mb = master_bar(range(num_epochs))\n\n    # Information for plots\n    mb.names = [\"Train Loss\", \"Valid Loss\"]\n    train_losses = []\n    valid_losses = []\n\n    for epoch in mb:\n\n        #\n        # Training\n        #\n        model.train()\n\n        train_N = len(train_loader.dataset)\n        num_train_batches = len(train_loader)\n        train_dataiterator = iter(train_loader)\n\n        train_loss_mean = 0\n\n        for batch in progress_bar(range(num_train_batches), parent=mb):\n\n            # Grab the batch of data and send it to the correct device\n            train_X, train_Y = next(train_dataiterator)\n            train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n            # Compute the output\n            train_output = model(train_X)\n\n            # Compute loss\n            train_loss = criterion(train_output, train_Y)\n\n            num_in_batch = len(train_X)\n            tloss = train_loss.item() * num_in_batch / train_N\n            train_loss_mean += tloss\n            train_losses.append(train_loss.item())\n\n            # Compute gradient\n            model.zero_grad()\n            train_loss.backward()\n\n            # Take a step of gradient descent\n            t += 1\n            with torch.no_grad():\n                opt.step()\n\n        #\n        # Validation\n        #\n        model.eval()\n\n        valid_N = len(valid_loader.dataset)\n        num_valid_batches = len(valid_loader)\n\n        valid_loss_mean = 0\n        valid_correct = 0\n\n        with torch.no_grad():\n\n            # valid_loader is probably just one large batch, so not using progress bar\n            for valid_X, valid_Y in valid_loader:\n\n                valid_X, valid_Y = valid_X.to(device), valid_Y.to(device)\n\n                valid_output = model(valid_X)\n\n                valid_loss = criterion(valid_output, valid_Y)\n\n                num_in_batch = len(valid_X)\n                vloss = valid_loss.item() * num_in_batch / valid_N\n                valid_loss_mean += vloss\n                valid_losses.append(valid_loss.item())\n\n                # Convert network output into predictions (one-hot -&gt; number)\n                predictions = valid_output.argmax(1)\n\n                # Sum up total number that were correct\n                valid_correct += (predictions == valid_Y).type(torch.float).sum().item()\n\n        valid_accuracy = 100 * (valid_correct / valid_N)\n\n        # Report information\n        tloss = f\"Train Loss = {train_loss_mean:.4f}\"\n        vloss = f\"Valid Loss = {valid_loss_mean:.4f}\"\n        vaccu = f\"Valid Accuracy = {(valid_accuracy):&gt;0.1f}%\"\n        mb.write(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\n        # Update plot data\n        max_loss = max(max(train_losses), max(valid_losses))\n        min_loss = min(min(train_losses), min(valid_losses))\n\n        x_margin = 0.2\n        x_bounds = [0 - x_margin, num_epochs + x_margin]\n\n        y_margin = 0.1\n        y_bounds = [min_loss - y_margin, max_loss + y_margin]\n\n        valid_Xaxis = torch.linspace(0, epoch + 1, len(train_losses))\n        valid_xaxis = torch.linspace(1, epoch + 1, len(valid_losses))\n        graph_data = [[valid_Xaxis, train_losses], [valid_xaxis, valid_losses]]\n\n        mb.update_graph(graph_data, x_bounds, y_bounds)\n\n    print(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\nrun_model()\n\n\n\n\n\n[ 1/10] Train Loss = 2.2851; Valid Loss = 2.2532; Valid Accuracy = 18.2%[ 2/10] Train Loss = 2.2051; Valid Loss = 2.1532; Valid Accuracy = 21.5%[ 3/10] Train Loss = 2.0912; Valid Loss = 2.0296; Valid Accuracy = 32.8%[ 4/10] Train Loss = 1.9543; Valid Loss = 1.8825; Valid Accuracy = 41.3%[ 5/10] Train Loss = 1.7954; Valid Loss = 1.7177; Valid Accuracy = 49.8%[ 6/10] Train Loss = 1.6275; Valid Loss = 1.5526; Valid Accuracy = 52.7%[ 7/10] Train Loss = 1.4671; Valid Loss = 1.4015; Valid Accuracy = 57.6%[ 8/10] Train Loss = 1.3261; Valid Loss = 1.2732; Valid Accuracy = 60.8%[ 9/10] Train Loss = 1.2093; Valid Loss = 1.1696; Valid Accuracy = 63.0%[10/10] Train Loss = 1.1161; Valid Loss = 1.0881; Valid Accuracy = 65.9%\n\n\n\n\n\n\n\n\n\n[10/10] Train Loss = 1.1161; Valid Loss = 1.0881; Valid Accuracy = 65.9%"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/main.html",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/main.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#overview",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#overview",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Overview",
    "text": "Overview\nIn this homework we will build a tiny automatic differentiation, matrix and neural network library from scratch!\n\n# Run me first!\nfrom hw4_support import *\n\n\nPython features\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-1-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-1-reverse-mode-automatic-differentiation",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 1: Reverse-mode automatic differentiation",
    "text": "Part 1: Reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - parents: The parent operations (a and b) - grad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\)) - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called AutogradValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using AutogradValue.\na = AutogradValue(5)\nb = AutogradValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\nL.backward()\ndL_da = a.grad\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\nNow that we’ve seen what our final produce will look like, let’s define our AutogradValue class.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        args    (list): A list of raw values of each input (as floats)\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.args = [arg.value if isinstance(arg, AutogradValue) else arg for arg in self.parents]\n        self.grad = 0.\n        self.value = self.forward_pass()\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n    \n    def forward_pass(self):\n        # Calls func to compute the value of this operation \n        return self.func(*self.args)\n    \n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n \n\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing AutogradValue\n\nQ1\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\n\nclass _add(AutogradValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n    \nclass _neg(AutogradValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(AutogradValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(AutogradValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _div(AutogradValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n    \nclass _exp(AutogradValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nclass _log(AutogradValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(AutogradValue)\n\nLet confirm that we do keep the entire compuational graph for operations defined in this way.\n\n\nQ2\nWrite a function graph_print that takes a single argument. If the argument is an AutogradValue (or one of its subclasses), print its value property and then call graph_print on each of its parents. If the argument is not an AutogradValue, just print it. The format of printing is not important.\nHint: You can use the built-in Python function isinstance to determine if something is an AutogradValue or one of its subclasses. e.g. isinstance(a, AutogradValue)\n\ndef graph_print(a):\n    ## YOUR CODE HERE\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\nThe function should print (it’s ok if the numbers or order aren’t exact):\n2.995732273553991\n20.0\n10.0\n5.0\n5.0\n5\n2.0\n2.0\nNow in order to do automatic differentiation, we need to define how to do the backward pass. We’ll start with the backward_step for a single operation.\n\n\nQ3\nFill in the method backward_pass which computes a single step of the reverse pass through the computational graph (assume self is an AutogradValue instance). If backward_pass is called on a value c, the method should: - Assume that self.grad contains the derivaive of the final loss with respect to c (\\(\\frac{dL}{dc}\\)). - Check if each parent of c is an AutogradValue. If it is, update that parent’s grad property to account for c (e.g. for parent a, update the value of \\(\\frac{dL}{da}\\))\nFor example: if c represents the result of an addition so c = a + b, calling backward_pass on c will update the grad property of both a and b. (a.grad represents \\(\\frac{dL}{da}\\) and is initialized to 0).\nHint: grads will be one of the methods we wrote in Q1. Recall that if c has parents a and b then grads method will give \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\).\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\nFinally we need to define the backward method itself. We will call this on the loss value to find the derivatives of the loss with respect to each input. This means working our way backward through the sequence of operations. Remember that if c=a+b, then if c.grad is \\(\\frac{dL}{dc}\\), calling backward_pass on c will update \\(\\frac{dL}{da}\\) (a.grad) and \\(\\frac{dL}{db}\\) (b.grad).\nThe complication is that c may be used in multiple operations, so we can’t call backward_pass on c until we’ve called backward_pass on each child operation of c otherwise c.grad won’t have the correct value of \\(\\frac{dL}{dc}\\), as in this example:\nc = a + b\ng = c * 2\nh = c + 4\nL = g * h\n\nL.backward_pass() # Updates dL/dg and dL/dh\nh.backward_pass() # Updates dL/dc\n\n##WRONG ORDER\nc.backward_pass() # Incorrect because dL/dc hasn't accounted for dL/dg\ng.backward_pass()\n\n## CORRECT ORDER\ng.backward_pass() # Updates dL/dc\nc.backward_pass() # Updates dL/da and dL/db\n\n\nQ4\nFill in the backward method for AutogradValue. Your backward method should call backward_pass on each operation used to compute the loss (self is the loss value). Some important things to keep in mind: - backward_pass should only be called once on each operation - backward_pass must be called on every child of an operation before it can be called on the operation. - You should not try to call backward_pass on values that aren’t instances of AutogradValue, even though this might be stored in operation.parents\nHint: The efficiency of this method will have a large impact on the running time of later problems! We won’t score efficiency in grading, but it still might be worth optimizing this function a bit.\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n    \n    ## YOUR CODE HERE\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\nIf we want to train a neural network using our automatic differentiation implementation, we’re going to want to be able to use numpy to do matrix operations. Fortunately, the our AutogradValue class is (mostly) compatible with numpy!\nWe can create arrays of AutogradValue and take derivatives as shown below:\n\na = np.array([AutogradValue(5), AutogradValue(2)])\nL = np.dot(a, a)\nL.backward()\nprint('Gradient for a', a[0].grad, a[1].grad)\n\nIt would be a bit tedious to define every AutogradValue array in this way, so let’s write some convinience functions to make doing automatic differentiation with numpy easier.\n\n\nQ5\nComplete the following two functions wrap_array and unwrap_gradient.\nwrap_array should take a numpy array of floats and return a new array where every element has been made into an AutogradValue.\nunwrap_gradient should take a numpy array of AutogradValue and return a new array of floats, where every element is the extracted grad property of the corresponding element from the original array.\nHint: You can create an array from nested lists as shown above.\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    ## YOUR CODE HERE\n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    ## YOUR CODE HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-2-implementing-a-neural-network",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-2-implementing-a-neural-network",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 2: Implementing a neural network",
    "text": "Part 2: Implementing a neural network\nNow that we have everything we need to apply our automatic differentiation to train a neural network!\nBefore we do that though, let’s try out our automatic differentiation for logistic regression. Below is a slight modification of LogisticRegression implementation we saw in the last homework.\n\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1, 1))\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(X, w)\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): A length N vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n    \n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): A length N vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n    \n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        xw = self.prediction_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n    \n    def nll_and_grad_no_autodiff(self, X, y):\n        # Compute nll_and_grad without automatic diferentiation\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nQ6\nWrite the method nll_and_grad for the LogisticRegression class using the automatic differentiation tools we built above. Verify that it gives a similar answer to nll_and_grad_no_autodiff.\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nOur automatic differentiation is very inefficient (we’ll fix this in the next homework!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nNow let’s extend our model to be a neural network! We’ll create a neural network class that extends our logistic regression class. First we’ll setup the needed weight matrices.\n\n\nQ7\nFill in the Neural Network __init__ method below. The method should take in the input data dimension and a list of integers specifying the size of each hidden layer (the number of neurons in each layer). The function should create a list of numpy arrays of the appropriate shapes for the weight matrices.\nFor example if dims is 2 and hidden_sizes is [4, 4], then self.weights should have 3 entries of shapes [(4x2), (4x4), (4,)]. This network is shown below.\n\n\nInput Layer ∈ ℝ²Hidden Layer ∈ ℝ⁴Hidden Layer ∈ ℝ⁴Output Layer ∈ ℝ¹\n\nIf you find it easier you could also define the weights in terms of \\(W^T\\) instead, in which case the shapes would be: [(2x4), (4x4), (4,)].\nThe values in each array should be drawn from a normal distribution with standard deviation 0.01. You can create such a matrix in numpy using:\nnp.random.normal(scale=0.01, size=shape)\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        ## YOUR CODE HERE\n        self.weights = \n\nRecall that for logistic regression the prediction function (before threholding or sigmoid) was \\(\\mathbf{X}\\mathbf{w}\\). We now want to implement the prediction function for our neural network class. This function should perform the appropriate feature transforms and multiply by the regression weights. For a neural network with a single hidden layer this will look like:\n\\(f(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{w}_0\\)\nUse the sigmoid activation function for this problem.\nFor multiple layers we can also think of this a a chain of feature transforms: \\[\\Phi_1 = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\] \\[\\Phi_2 = \\sigma(\\Phi_1 \\mathbf{W}_2^T)\\] \\[...\\] \\[\\Phi_l = \\sigma(\\Phi_{l-1} \\mathbf{W}_l^T)\\] \\[f(\\mathbf{X}) = \\Phi_l\\mathbf{w}_0\\] Where \\(\\Phi_i\\) is just the variable that represents the neurons at layer \\(i\\) (the result of the first \\(i\\) transforms applied to \\(\\mathbf{X}\\)).\n\nQ8\nImplement the prediction function as described above. Note that the prediction function should use the weights passed into the w argument rather than self.weights, this will make it easier to implement the next question.\n\ndef prediction_function(self, X, w):\n    '''\n    Get the result of our base function for prediction (i.e. x^t w)\n\n    Args:\n        X (array): An N x d matrix of observations.\n        w (list of arrays): A list of weight matrices\n    Returns:\n        pred (array): An N x 1 matrix of f(X).\n    '''\n    ## YOUR CODE HERE\n\n\nNeuralNetwork.prediction_function = prediction_function\n\n\n\nQ9\nImplement an nll_and_grad method for the NeuralNetwork class using your automatic differentiation implmentation to compute the gradient with respect to each weight matrix.\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nPart 4: Forward-mode automatic differentiation\nLet’s now try out the other type of automatic differentiation that we learned about: forward-mode. To do this we’ll create a subclass of our AutogradValue class called ForwardValue.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. For example, in the code below the g object needs to store both \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\).\na = ForwardValue(5)\nb = ForwardValue(2)\nc = a + b\ng = c * 2\nOur ForwardValue class will maintain a dict called forward_grads that maps each original input object to the derivative of the current value with respect to that input (so g will have a dict with keys that are the a and b objects).\nIn the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\n\nclass ForwardValue(AutogradValue):\n    def __init__(self, *args):\n        super().__init__(*args)\n        self.forward_grads = {self: 1}\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\nQ10\nImplement the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\n\ndef forward_pass(self):\n    # Clear forward_grads if it exists\n    self.forward_grads = {} \n    ## YOUR CODE HERE\n    \n\n    # Make sure to still return the operation's value\n    return self.func(*self.args)\n\n# Overwrite the AutogradValue method so that operators still work\nAutogradValue.forward_pass = forward_pass\n\nWe can now take derivates of functions much like with our reverse-mode implementation!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nL = -log(5 *b + a)\nprint(L.forward_grads[a], L.forward_grads[b])\n\n\n\nQ11\nComplete the ForwardModeNeuralNetwork class that inherits from NeuralNetwork by implementing nll_and_grad to use the forward-mode implementation you just wrote!\n\nclass ForwardModeNeuralNetwork(NeuralNetwork):\n    def nll_and_grad(self, X, y):\n        ## YOUR CODE HERE\n\nWe can again test it on our tiny dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = ForwardModeNeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nQ12\nBased on what we’ve learned and your experience here, why would we choose forward or reverse-mode automatic differentiation?\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-4-forward-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/main.html#part-4-forward-mode-automatic-differentiation",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 4: Forward-mode automatic differentiation",
    "text": "Part 4: Forward-mode automatic differentiation\nLet’s now try out the other type of automatic differentiation that we learned about: forward-mode. To do this we’ll create a subclass of our AutogradValue class called ForwardValue.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. For example, in the code below the g object needs to store both \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\).\na = ForwardValue(5)\nb = ForwardValue(2)\nc = a + b\ng = c * 2\nOur ForwardValue class will maintain a dict called forward_grads that maps each original input object to the derivative of the current value with respect to that input (so g will have a dict with keys that are the a and b objects).\nIn the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\n\nclass ForwardValue(AutogradValue):\n    def __init__(self, *args):\n        super().__init__(*args)\n        self.forward_grads = {self: 1}\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\nQ10\nImplement the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\n\ndef forward_pass(self):\n    # Clear forward_grads if it exists\n    self.forward_grads = {} \n    ## YOUR CODE HERE\n    \n\n    # Make sure to still return the operation's value\n    return self.func(*self.args)\n\n# Overwrite the AutogradValue method so that operators still work\nAutogradValue.forward_pass = forward_pass\n\nWe can now take derivates of functions much like with our reverse-mode implementation!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nL = -log(5 *b + a)\nprint(L.forward_grads[a], L.forward_grads[b])\n\n\n\nQ11\nComplete the ForwardModeNeuralNetwork class that inherits from NeuralNetwork by implementing nll_and_grad to use the forward-mode implementation you just wrote!\n\nclass ForwardModeNeuralNetwork(NeuralNetwork):\n    def nll_and_grad(self, X, y):\n        ## YOUR CODE HERE\n\nWe can again test it on our tiny dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = ForwardModeNeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nQ12\nBased on what we’ve learned and your experience here, why would we choose forward or reverse-mode automatic differentiation?\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/main.html",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/main.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and start on an implementation of automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/main.html#overview",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/main.html#overview",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and start on an implementation of automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-1-autograd",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-1-autograd",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 1: Autograd",
    "text": "Part 1: Autograd\nIn this homework we will be using a special version of Numpy from a package called Autograd. Assuming it is installed (pip install autograd), we can import it as follows:\n\nimport autograd.numpy as np\n\nThis special version of Numpy behaives exactly like normal numpy. We can create and do calculations with arrays just like we would before:\n\nx = np.array([3., 2., 1])\nprint('x:\\t', x)\nprint('x^2:\\t', x ** 2)\nprint('sum(x):\\t', np.sum(x))\n\nHowever, Autograd also has a very important trick up its sleeve: it can take derivatives (and gradients) for us! This functionality can be accessed through the grad function. Let’s start by seeing it in action with a very simple example, where we know the correct answer. The square function and its derivative can be written as:\n\\(f(x) = x^2, \\quad f'(x) = 2x\\)\nThe following code uses Autograd to compute this derivative automatically:\n\nfrom autograd import grad\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nWe can start to see how grad operates. grad takes as input a function (e.g. \\(f(x)\\)) and returns a new function that computes the derivative of \\(f\\) at \\(x\\). (\\(f'(x)\\)). So:\n\\(\\text{grad}(f) \\longrightarrow f'\\)\n\nQ1\nDefine the following function in python:\n\\(f(x) = \\log(\\sin(x^3) + 3 x)\\)\nUse grad to compute the derivative of \\(f\\) at \\(1.5\\) (i.e. compute \\(f'(1.5)\\))\n\n## YOUR CODE HERE\n\n\nanswer = \nprint(\"f'(1.5)=\", answer)\n\nAs the name would imply, grad can more generally be used to compute the gradient of a function of the form \\(f(\\mathbf{x}): \\mathbb{R}^d\\rightarrow \\mathbb{R}\\). Remember that for a function that takes in a vector and outputs a scalar, the gradient is vector of all partial derivatives of the output with respect to each input. For example, consider a function that gives the square of the 2-norm of a vector:\n\\(f(\\mathbf{x}) = ||\\mathbf{x}||^2_2 = \\mathbf{x}^T\\mathbf{x} = \\sum_{i=1}^d x_i^2\\)\nThink about why these expressions are equivalent!\nAs we’ve seen, the gradient of this function can be written as:\n\\(\\nabla f(\\mathbf{x}) = 2\\mathbf{x} = \\begin{bmatrix}2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_d \\end{bmatrix}\\)\nLet’s see what Autograd gives us in this case:\n\n# Define a function\ndef f(x):\n    return np.sum(x ** 2)\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = np.array([1., 2., 3])\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nWe see that the gradient has the same shape as the input. So the gradient function is of the form: \\(\\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\)\nThis makes sense as the gradient should have exactly one partial derivative for each entry in the input to the function. As discussed, this even extends beyond vectors! We could have a function that takes in any datastructure and computes the set of partial derivatives with respect to each entry.\n\n\nQ2\nWrite a function that takes a list of vectors and computes the sum of the squared 2-norm for each vector. That is:\n\\(f([\\mathbf{a}, \\mathbf{b}, \\mathbf{c}...]) = ||\\mathbf{a}||^2 + ||\\mathbf{b}||^2 + ||\\mathbf{c}||^2+...\\)\nRecall from above how we can compute each term in this sum!\nThen use grad to compute the gradient of this function with respect to the given input.\n\n# Define a function\ndef f(x):\n    '''\n    Compute the sum of squared 2-norms for a list of vectors\n\n    Args:\n        x (list of arrays): A list of 1-dimensional arrays\n    Returns:\n        output (float): The result\n    '''\n    ## YOUR CODE HERE\n    s = 0.\n    for xi in x:\n        s += np.dot(xi, xi)\n    return s\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = [np.array([1., 2., 3]), np.array([7., 2.]), np.array([6.])]\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nA useful argument that we can give to grad is argnum. If our function takes more than one argument argnum lets us specify which one to take the gradient with respect to. For example, if we have the function:\n\\(f(x, y) = x^2y\\)\nThen:\n\\(f'_x(x,y)=2xy, \\quad f'_y(x, y)=x^2\\)\n\ndef f(x, y):\n    return x ** 2 * y\n\nprint('f(3, 5) = ', f(3., 5.))\n\ndf_dx = grad(f, argnum=0)(3., 5.)\ndf_dy = grad(f, argnum=1)(3., 5.)\n\nprint('df_dx = ', df_dx)\nprint('df_dy = ', df_dy)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-2-implementing-a-neural-network",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-2-implementing-a-neural-network",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 2: Implementing a neural network",
    "text": "Part 2: Implementing a neural network\nNow that we have everything we need to apply automatic differentiation to train a neural network!\nBefore we do that though, let’s try out our automatic differentiation for logistic regression. Below is a slight modification of LogisticRegression implementation we saw in the last homework.\n\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1, 1))\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1., mode='constant')\n        return np.dot(X, w)\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n    \n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n    \n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n    \n    def nll_and_grad_no_autodiff(self, X, y):\n        # Compute nll_and_grad without automatic diferentiation\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nQ3\nWrite the method nll_and_grad for the LogisticRegression class using the grad function from Autograd. Verify that it gives a similar answer to nll_and_grad_no_autodiff.\nHint: Note that the nll function can optionally take in the parameters. You can use this functionality and the argnum argument of grad in your answer. You can assume that self refers to the model object, so you can access the weights via self.weights\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads = \n    return loss, grads\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nThis implementation quite inefficient (we’ll fix this in the future!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nNow let’s extend our model to be a neural network! We’ll create a neural network class that extends our logistic regression class. First we’ll setup the needed weight matrices.\n\n\nQ4\nFill in the Neural Network __init__ method below. The method should take in the input data dimension and a list of integers specifying the size of each hidden layer (the number of neurons in each layer). The function should create a list of numpy arrays of the appropriate shapes for the weight matrices.\nFor example if dims is 2 and hidden_sizes is [4, 4], then self.weights should have 3 entries of shapes [(4x2), (4x4), (1x4)]. This network is shown below.\n\n\nInput Layer ∈ ℝ²Hidden Layer ∈ ℝ⁴Hidden Layer ∈ ℝ⁴Output Layer ∈ ℝ¹\n\nIf you find it easier you could also define the weights in terms of \\(W^T\\) instead, in which case the shapes would be: [(2x4), (4x4), (4x1)]. You could also consider how to add a bias term at each layer as in logistic regression (but this isn’t nessecary for full credit).\nThe values in each array should be drawn from a normal distribution with standard deviation 1. You can create such a matrix in numpy using:\nnp.random.normal(scale=1., size=shape)\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        ## YOUR CODE HERE\n        self.weights = \n\ntest_nn_constructor(NeuralNetwork)\n\nRecall that for logistic regression the prediction function (before threholding or sigmoid) was \\(\\mathbf{X}\\mathbf{w}\\). We now want to implement the prediction function for our neural network class. This function should perform the appropriate feature transforms and multiply by the regression weights. For a neural network with a single hidden layer this will look like:\n\\(f(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{w}_0\\)\nUse the sigmoid activation function for this problem.\nFor multiple layers we can also think of this a a chain of feature transforms: \\[\\Phi_1 = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\] \\[\\Phi_2 = \\sigma(\\Phi_1 \\mathbf{W}_2^T)\\] \\[...\\] \\[\\Phi_l = \\sigma(\\Phi_{l-1} \\mathbf{W}_l^T)\\] \\[f(\\mathbf{X}) = \\Phi_l\\mathbf{w}_0\\] Where \\(\\Phi_i\\) is just the variable that represents the neurons at layer \\(i\\) (the result of the first \\(i\\) transforms applied to \\(\\mathbf{X}\\)).\n\nQ5\nImplement the prediction function as described above. Note that the prediction function should use the weights passed into the w argument rather than self.weights, this will make it easier to implement the next question.\nHint: Note that this function should not apply a final sigmoid or thresholding, instead it should be the equivalent of linear_function from the previous homework\n\ndef prediction_function(self, X, w):\n    '''\n    Get the result of our base function for prediction (i.e. x^t w)\n\n    Args:\n        X (array): An N x d matrix of observations.\n        w (list of arrays): A list of weight matrices\n    Returns:\n        pred (array): An N x 1 matrix of f(X).\n    '''\n    ## YOUR CODE HERE\n\n    return pred.reshape((-1, 1))\n\nNeuralNetwork.prediction_function = prediction_function\ntest_nn_prediction_function(NeuralNetwork)\n\n\n\nQ6\nImplement an nll_and_grad method for the NeuralNetwork class using Autograd to compute the gradient with respect to each weight matrix.\nHint: If you use np.pad anywhere in your implementation, Autograd may complain if you don’t include the keyword argument mode='constant'\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads = \n    return loss, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nPart 3: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass ForwardValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parent_values    (list): A list of raw values of each input (as floats)\n        value   (float): The value of the result of this operation\n        forward_grads (dict): A dictionary mapping inputs to gradients\n    '''\n\n    def __init__(self, *args):\n        self.parent_values = [arg.value if isinstance(arg, ForwardValue) else arg for arg in args]\n        self.value = self.forward_pass(args)\n        \n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n        \n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n    \n    def forward_pass(self, args):\n        # Calls func to compute the value of this operation \n        self.forward_grads = {}\n        return self.func(*self.parent_values)\n    \n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n \n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ7\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\nclass _add(ForwardValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n    \nclass _neg(ForwardValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(ForwardValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(ForwardValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _div(ForwardValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n    \nclass _exp(ForwardValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nclass _log(ForwardValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, ForwardValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, ForwardValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nForwardValue.exp = lambda a: _exp(a)\nForwardValue.log = lambda a: _log(a)\nForwardValue.__add__ = lambda a, b: _add(a, b)\nForwardValue.__radd__ = lambda a, b: _add(b, a)\nForwardValue.__sub__ = lambda a, b: _sub(a, b)\nForwardValue.__rsub__ = lambda a, b: _sub(b, a)\nForwardValue.__neg__ = lambda a: _neg(a)\nForwardValue.__mul__ = lambda a, b: _mul(a, b)\nForwardValue.__rmul__ = lambda a, b: _mul(b, a)\nForwardValue.__truediv__ = lambda a, b: _div(a, b)\nForwardValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\n\nQ8\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self, args):\n    # Clear forward_grads if it exists\n    self.forward_grads = {} \n    ## YOUR CODE HERE\n    \n\n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nForwardValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nIn the next homework, we’ll combine our forward-mode AD implementation with our neural network class. Then we’ll look at how to do automatic-differentiation more efficiently with reverse-mode AD."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-3-forward-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/main.html#part-3-forward-mode-automatic-differentiation",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 3: Forward-mode automatic differentiation",
    "text": "Part 3: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass ForwardValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parent_values    (list): A list of raw values of each input (as floats)\n        value   (float): The value of the result of this operation\n        forward_grads (dict): A dictionary mapping inputs to gradients\n    '''\n\n    def __init__(self, *args):\n        self.parent_values = [arg.value if isinstance(arg, ForwardValue) else arg for arg in args]\n        self.value = self.forward_pass(args)\n        \n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n        \n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n    \n    def forward_pass(self, args):\n        # Calls func to compute the value of this operation \n        self.forward_grads = {}\n        return self.func(*self.parent_values)\n    \n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n \n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ7\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\nclass _add(ForwardValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n    \nclass _neg(ForwardValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(ForwardValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(ForwardValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n\nclass _div(ForwardValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n    \n    def grads(self, a, b):\n        # Your code here\n    \nclass _exp(ForwardValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nclass _log(ForwardValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n    \n    def grads(self, a):\n        # Your code here\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, ForwardValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, ForwardValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nForwardValue.exp = lambda a: _exp(a)\nForwardValue.log = lambda a: _log(a)\nForwardValue.__add__ = lambda a, b: _add(a, b)\nForwardValue.__radd__ = lambda a, b: _add(b, a)\nForwardValue.__sub__ = lambda a, b: _sub(a, b)\nForwardValue.__rsub__ = lambda a, b: _sub(b, a)\nForwardValue.__neg__ = lambda a: _neg(a)\nForwardValue.__mul__ = lambda a, b: _mul(a, b)\nForwardValue.__rmul__ = lambda a, b: _mul(b, a)\nForwardValue.__truediv__ = lambda a, b: _div(a, b)\nForwardValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\n\nQ8\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self, args):\n    # Clear forward_grads if it exists\n    self.forward_grads = {} \n    ## YOUR CODE HERE\n    \n\n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nForwardValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nIn the next homework, we’ll combine our forward-mode AD implementation with our neural network class. Then we’ll look at how to do automatic-differentiation more efficiently with reverse-mode AD."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/main.html",
    "href": "assignments/homeworks-sp24/homework1-background/main.html",
    "title": "Homework 1: Introduction to Numpy",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/main.html#part-1-numpy-basics",
    "href": "assignments/homeworks-sp24/homework1-background/main.html#part-1-numpy-basics",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 1: Numpy basics",
    "text": "Part 1: Numpy basics\nAs discussed in class, a square matrix \\(A\\) defines a linear mapping: \\(\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\). Given a vector \\(\\textbf{x}\\), we can find the corresponding output of this mapping \\(\\textbf{b}\\) using matrix-vector multiplication: \\(\\textbf{b}=A \\textbf{x}\\). We can write an example matrix-multiplication using matrix notation as:\n\\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}\n= \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix}\n\\]\nQ1: Perform this matrix-vector multiplication by hand and write the answer in the cell below.\nWRITE ANSWER HERE\nQ2: In the code cell below, create the matrix \\(A\\) and the vector \\(\\textbf{x}\\) shown above, using Numpy. Then use the np.dot function to find the output of the mapping \\(\\textbf{b} = A\\textbf{x}\\). Verify that the answer matches what you derived above.\n\n# Fill answers here\nA = \nx =\nb =\n\nprint(b)\n\nOften we will have access to the transformed vector \\(\\textbf{b}\\) and need to find the orginal vector \\(\\textbf{x}\\). To do this we need to solve the system of linear equations \\(A\\textbf{x}=\\textbf{b}\\) for \\(\\textbf{x}\\). \\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix} = \\begin{bmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{bmatrix}\n\\]\nQ3: Find the missing \\(\\textbf{x}\\) in the equation above using the np.linalg.solve function and verify that \\(A\\textbf{x}=\\textbf{b}\\).\n\n# Fill answer here (A is the same matrix from above)\nb = \nx = \n\nIn linear algebra you may have learned how to solve a system of linear equations using Gaussian elimination. Here we will implement an alternative approach known as Richardson iteration. In this method we start with an inital guess for the solution: \\(\\textbf{x}^{(0)}\\), then we will iteratively update this guess until the solution is reached. Given a matrix \\(A\\), a target \\(\\textbf{b}\\) and a current guess \\(\\textbf{x}^{(k)}\\), we can compute the Richardson update as:\n\\[\\textbf{x}^{(k+1)} \\leftarrow \\textbf{x}^{(k)} + \\omega \\left(\\textbf{b} - A\\textbf{x}^{(k)}\\right)\\]\nHere \\(\\omega\\) is a constant that we can choose to adjust the algorithm. We will set \\(\\omega = 0.1\\).\nQ4: Fill in the Richardson iteration function below and apply it to the system of linear equations from above using 100 updates. Verify that if gives a similar answer to np.linalg.solve.\n\n# Fill in function below\ndef richardson_iter(x_guess, A, b, omega=0.1):\n    \n    return new_x_guess\n\nx_guess = np.zeros(3)\nfor i in range(100):\n    x_guess = richardson_iter(x_guess, A, b)\n\nprint(x_guess, x)\n\nRecall that the length of a vector is given by it’s two-norm, which is defined as: \\[\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.\\]\nCorrespondingly, the (Euclidian) distance between two points \\(\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n\\) can be written as \\(\\|\\mathbf{a} - \\mathbf{b}\\|_2\\). As a convenient measure of error for our Richardson iteration algorithm, we will use the squared Euclidean distance. For a guess \\(\\mathbf{x}^{(k)}\\) we will compute the error \\(e^{(k)}\\) as: \\[e^{(k)} = \\|A\\mathbf{x}^{(k)} - \\mathbf{b}\\|_2^2\\]\nIn expanded form, this would be written as: \\[e^{(k)} = \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\nQ5: Write a function to compute the error of a given guess. Then run Richardson iteration again for 100 steps, computing the error at each step. Finally create a plot of the error for each step (error vs. step).\nHint: recall that basic operations in numpy (addition, subtraction, powers) are performed element-wise.\n\\[\\mathbf{c} = \\mathbf{A}\\mathbf{x}\\]\n\\[||c-b||^2_2\\]\n\\[\\sum_{i=1}^N (c_i - b_i)^2\\]\n$$c_i = {j=1}^n A{ij}x_j\n\n# Fill in function below\ndef error(x_guess, A, b):\n\n    return err\n\n# Add code to plot the error over time\n\nx_guess = np.zeros(3)\nfor step in range(100):\n\n    x_guess = richardson_iter(x_guess, A, b)\n\n    \n\nQ6: Derive the partial derivative of the error with respect to a single entry of \\(\\mathbf{x}^{(k)}\\) (without loss of generality, we will say \\(x^{(k)}_1\\)). Work in the expanded form as in the equation above, writing your answer in the markdown cell below.\nHint: You may find it helpful to refer to the latex equation cheatsheet on the course website. You may show intermediate steps here or as handwritten work as a separate file in the repository. The final answer should be filled in here.\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1}= \\]\nYOU MAY ADD WORK HERE\nIn practice, we will likely want to compute the derivative with respect to all entries of \\(\\mathbf{x}\\): \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}} = \\begin{bmatrix}\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1} \\\\\n\\vdots \\\\\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_n}\n\\end{bmatrix}\\]\nQ7: Using the formula you just derived, write the formula for the vector of all partial derivatives in the compact matrix/vector notation (e.g. \\(A\\mathbf{x}=\\mathbf{b}\\)).\nEDIT THIS CELL WITH YOUR ANSWER\n\\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}}= \\]\nQ8: In 1-2 sentences describe how this answer relates to the Richardson iteration algorithm above. We will discuss this more in class!\nWRITE YOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/main.html#part-2-working-with-batches-of-vectors",
    "href": "assignments/homeworks-sp24/homework1-background/main.html#part-2-working-with-batches-of-vectors",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 2: Working with batches of vectors",
    "text": "Part 2: Working with batches of vectors\nRecall that a vector can also be seen as either an \\(n \\times 1\\) matrix (column vector) or a \\(1 \\times n\\) matrix (row vector).\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nNote that we use the same notation for both as they refer to the same concept (a vector). The difference becomes relevant when we consider matrix-vector multiplication. We can write matrix-vector multiplication in two ways: \\[\\text{Matrix-vector: }A\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}A^T= \\mathbf{b}\\] In matrix-vector multiplication we treat \\(\\textbf{x}\\) as a column vector (\\(n \\times 1\\) matrix), while in vector-matrix multiplication we treat it as a row vector (\\(n \\times 1\\) matrix). Transposing \\(A\\) for left multiplication ensures that the two forms give the same answer.\nQ9: Using the previously defined \\(\\mathbf{x}\\), create an explicit column vector and row vector. Then using the previously defined \\(A\\), verify that the matrix-vector and vector-matrix multiplications shown above do produce the same resultant vector \\(\\mathbf{b}\\).\nHint: Recall that np.dot is also used for matrix-matrix multiplication.\n\n# Fill in code here\nx_col =\nx_row = \n\nThroughout this course we will typically use row vectors and vector-matrix multiplication, as this is more conventional in neural-network literature. The concept of row and column vectors becomes handy when transforming collections of vectors.\nRecall that a matrix can be seen as a collection of vectors. In numpy we can create a matrix from a list of (1- dimensional) vectors using the np.stack function. This function assumes that the vectors are row vectors creating the matrix as follows: \\[\\begin{bmatrix}\n3 & 1 & -2\n\\end{bmatrix},\\ \\begin{bmatrix}\n4 & 5 & 3\n\\end{bmatrix},\\ \\begin{bmatrix}\n-2 & -1 & 5\n\\end{bmatrix}\\quad \\overset{\\text{np.stack}}{\\longrightarrow} \\begin{bmatrix}\n3 & 1 & -2 \\\\\n4 & 5 & 3 \\\\\n-2 & -1 & 5\n\\end{bmatrix} \\]\nWe will call this matrix \\(X\\) to denote that it is a collection of vectors, rather than a single vector (\\(\\mathbf{x}\\)).\nQ10: Create this matrix in numpy using th np.stack function.\n\n# Fill code here\n\nX = \nprint(X)\n\nWhen taken together as a matrix in this way, we can apply the linear mapping \\(A\\) to all vectors using matrix-matrix multiplication: \\[B=XA^T\\]\nLet’s put this into practice with a visual example.\nQ11: Create a \\(20 \\times 3\\) matrix, circle, in numpy of the following form\n\\[ \\begin{bmatrix} \\sin(\\theta_1) & \\cos(\\theta_1)  & 1 \\\\\n\\sin(\\theta_2) & \\cos(\\theta_2)  & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\theta_{20}) & \\cos(\\theta_{20})  & 1 \\\\\n\\end{bmatrix}\\] Where \\(\\theta_1...\\theta_{20}\\) are evenly spaced between \\(0\\) and \\(2\\pi\\).\n\ntheta = np.linspace(0, 2 * np.pi, 20) # Generates 20 evenly-spaced numbers between 0 and 2π\n\n# Fill in your code here\ncircle = \n\nThe code we just wrote creates a matrix corresponding to a collection of \\(20\\) row vectors of length 3. Each vector represents a point on the unit circle where the first entry is the x-coordinate, the second entry is the y-coordinate and the third entry is always \\(1\\): \\[ \\begin{bmatrix} x & y & 1 \\end{bmatrix}\\]\nQ12: Plot the set of 20 points in circle using the plt.plot function. Use only the x and y coordinates, ignoring the column of 1s.\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\n\nQ13: Transform all the vectors in circle with the matrix \\(A\\) using a single call to np.dot. Then plot the original set of points in black and the transformed points in red using the plt.plot function.\nYou might also consider why we added the extra column of 1s! We will discuss the answer to that in class.\n\n# Fill your code here\ntransformed_circle = \n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/main.html#part-3-loading-and-visualizing-data",
    "href": "assignments/homeworks-sp24/homework1-background/main.html#part-3-loading-and-visualizing-data",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 3: Loading and visualizing data",
    "text": "Part 3: Loading and visualizing data\nFor most of this class we will be working with real-world data. A very well-known dataset in statistics is the Iris flower dataset collected by Edgar Anderson in 1929. The dataset consists of measurments of iris flowers. Each flower has 4 collected measurements: sepal length, sepal width, petal length, petal width, as well as a classification into one of 3 species: Iris setosa, Iris versicolor and Iris virginica. We will return to this dataset in the next homework.\nWe can load this dataset as Numpy objects using the Scikit-Learn library. Below we’ve extrated 4 relevant arrays: - features: a \\(150 \\times 4\\) matrix which has one row per observed flower and one column per measurement. - targets: a length \\(150\\) array that specifies the species of each flower as a number 0-2. - feature_names: a list of strings with the name of each measurement. - target_names: a list of strings with the name of each species.\nIn this homework, we will only visualize this dataset, which is typically a good first step in working with a new type of data. To get a convenient summary of the data we will create what is called a scatterplot matrix. This is a grid of plots where each plot contains a scatter plot with different features on the x and y axes. Because there are 4 features (measurements) in this data, we will create a 4-by-4 matrix to plot each pair of features.\nQ14: Fill in the code to create a scatterplot matrix for the Iris dataset below. - Each row of the matrix should use a different feature for the y-axis and each column should use a different feature for the x-axis. The plots on the diagonal where x and y would be the same feature can be ignored. - The x and y axis of each sub-plot should be labeled with the appropriate feature names. - The points in each scatterplot should be colored by the species label of that flower. Include a legend in at least 1 sub-plot.\nHint: The linked Wikipedia article shows an example of a scatterplot matrix for this dataset, feel free to use it as reference!\n\nimport sklearn.datasets as datasets\ndataset = datasets.load_iris()\nfeatures = dataset['data']\ntargets = dataset['target']\nfeature_names = dataset['feature_names']\ntarget_names = dataset['target_names']\n\n# Fill in the code below\nfig, ax = plt.subplots(4, 4, figsize=(12, 12))\nfor i in range(4):\n    for j in range(4):\n        # Skip sub-plots on the diagonal\n        if i == j: \n            continue\n\n        # Add subplot code here"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/main.html",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/main.html",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-1-linear-regression",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-1-linear-regression",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\nLet’s begin by reviewing the context of linear regression.\nRecall that the linear regression model makes predictions of the following form:\n\\[f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} + b\\]\nOr if we consdier the augmented representation:\n\\[\\mathbf{x} \\rightarrow \\begin{bmatrix}\\mathbf{x} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\\\ 1 \\end{bmatrix},\\quad \\mathbf{w} \\rightarrow \\begin{bmatrix}\\mathbf{w} \\\\ b \\end{bmatrix} = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_d \\\\ b \\end{bmatrix}\\] Then we can use the more convenient linear form: \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\]\nQ1: Write a function that takes in an input \\((\\mathbf{x})\\) and a set of weights \\((\\mathbf{w})\\) and makes a prediction using the function above. Your implementation should assume that the bias \\((b)\\) is included in the weights \\((\\mathbf{w})\\) and thus should augment the input to account for this (or separate \\(b\\) from \\(\\mathbf{w}\\)).\n\n# Test inputs\nx = np.array([1, -3, 5])\nw = np.array([-1, 2, 0.5, 2])\ny = -2.5\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## Validate the function\nassert y == linear_regression(x, w)\n\nAs discussed in class, we can compactly refer to an entire dataset of inputs and outputs using the notation \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) respectively. Our convention will be that row \\(i\\) of \\(\\mathbf{X}\\) will correspond to the \\(i^{th}\\) observed input \\(\\mathbf{x}_i\\), while the corresponding entry \\(y_i\\) of \\(\\mathbf{y}\\) is the observed output. In other words \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) are defined as: \\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}, \\quad\n                \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nWith this notation, we can make predictions for an entire set of inputs as: \\[f(\\mathbf{X}) = \\mathbf{X}\\mathbf{w}\\] Where the output is now a vector of predictions. We see that each entry corresponds to the prediction for input \\(\\mathbf{x}_i\\): \\[f(\\mathbf{X})_i = \\mathbf{x}_i^T\\mathbf{w} = f(\\mathbf{x}_i)\\]\nQ2: Modify (if needed) your linear regression prediction function to accept a set of inputs as matrix as described above and return a vector of predictions. Once again you should not assume the data includes the extra bias dimension. Then plot the prediction function given by the provided weights on the range \\([0, 5]\\). Recall that np.linspace(a, b, n) produces a vector of n equally spaced numbers between a and b.\n\n# Test inputs\nw = np.array([0.5, 2])\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## CODE TO PLOT THE FUNCTION HERE\nX = \ny = linear_regression(X, w)\n\n\nRecall that ordinary least squares finds the parameter \\(\\mathbf{w}\\) that minimizes the mean of squared error between the true outputs \\(\\mathbf{y}\\) and predictions. \\[\\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2\\]\nObserve that this is the same formula as the error we used for evaluating Richardson iteration in the last homework, we’ve simply renamed the variables from \\((\\mathbf{A}, \\mathbf{x}, \\mathbf{b})\\) to \\((\\mathbf{X}, \\mathbf{w}, \\mathbf{y})\\)! (We’ve also added the constant \\(\\frac{1}{N}\\), but this doesn’t change the optimal \\(\\mathbf{w}\\))\nWe’ve now seen 3 equivalent ways to write the same formula. From most compact to least compact these are: \\[\\textbf{1: } \\frac{1}{N} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 \\quad \\textbf{2: } \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2 \\quad \\textbf{3: } \\frac{1}{N} \\sum_{i=1}^n \\left(\\sum_{j=1}^n X_{ij}w_j - y_i\\right)^2\\]\nQ3: Using the gradient formula we derived in class, write a function that returns both the mean squared error and the gradient of the error with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\). Hint: don’t forget to augment X when computing the gradient!\n\ndef mse_and_grad(w, X, y):\n    ### YOUR CODE HERE\n    return mse, grad_w\n\nRecall that we can use the gradient descent algorithm to find the input that minimizes a function, using the corresponding gradient function.\nGiven an initial guess of the optimal input, \\(\\mathbf{w}^{(0)}\\), gradient descent uses the following update to improve the guess: \\[\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}),\\] where \\(\\alpha\\) is the learning rate or step size.\nQ4: Write a function to perform gradient descent. The function should take as input: - value_and_grad: A function that produces the output and gradient of the function to optimize (e.g. the mse_and_grad) - w0: An inital guess \\(\\mathbf{w}^{(0)}\\) - lr: The learning rate \\((\\alpha)\\) - niter: The number of updates to perform - *args: Any additional argumets to pass to value_and_grad (e.g. X and y)\nThe function should return: - w: The final guess - losses: A list (or array) that tracks the value of the function at each update\n\ndef gradient_descent(value_and_grad, w0, lr, niter, *args):\n    # Get the inital loss\n    initial_loss, _ = value_and_grad(w0, *args)\n    losses = []\n\n    ### YOUR CODE HERE\n\n    return w, losses"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-2-applications-to-real-data",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-2-applications-to-real-data",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 2: Applications to real data",
    "text": "Part 2: Applications to real data\nNow that we’ve setup a full implementation of linear regression, let’s test it on a real dataset. We’ll use the MPG dataset that we saw in class. The following code will load the data and rescale it.\n\ndata = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n\n# MPG is the output value\ntarget = 'MPG'\ny = data[:, 0]\n\n# The other variables are inputs in the order listed\nfeatures = ['displacement', 'weight', 'acceleration', 'year']\nX = data[:, [2, 4, 5, 6]]\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\nLet’s start by fitting a model that just uses the feature weight.\nQ5: Use the gradient_descent and mse_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 0.1. Plot the loss (MSE) as a function of the number of updates.\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw, losses = \n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nQ6: Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\).\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nQ7: Repeat Q5 using all 4 features and compare the final loss to the final loss using only weight as an input. Describe any differences you observe.\n\nw0 = np.zeros((5,))\n\n### YOUR CODE HERE\nw, losses = \n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nDESCRIBE RESULTS HERE\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\nQ8: Split the MPG dataset into training and test datasets. Use 70% of the observations for training and 30% for test. Then repeat Q5 to fit a linear regression model on just the training dataset using only the weight feature (you don’t need to plot the loss for this question). Report the final loss (MSE) on the training dataset and on the test dataset.\n\n### CODE TO SPLIT DATASET HERE\nXweight_train = \ny_train = \n\nXweight_test = \ny_test = \n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((2,))\nw, losses = \n\n### CODE TO EVALUATE MODEL HERE\nmse_train = \nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nQ9: Repeat Q8 using the all 4 features. Compare the results to the model using only weight.\n\n### CODE TO SPLIT DATASET HERE\nX_train = \ny_train = \n\nX_test = \ny_test = \n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((5,))\nw, losses = \n\n### CODE TO EVALUATE MODEL HERE\nmse_train = \nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nDESCRIBE RESULTS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-3-maximum-likelihood-training",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/main.html#part-3-maximum-likelihood-training",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 3: Maximum Likelihood Training",
    "text": "Part 3: Maximum Likelihood Training\n\nBackground:\nWe saw in lecture that we can view linear regression as the following probibalistic model: \\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\] Where \\(\\mathcal{N}(\\mu, \\sigma)\\) is the Normal distribution, which has the following probability density function: \\[\np(y\\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\] We saw that a reasonable way to choose the optimal \\(\\mathbf{w}\\) is to maximize the likelihood of our observed dataset, which is equivalent to minimizing the negative log likelihood: \\[\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) =\n\\underset{\\mathbf{w}}{\\text{argmin}} -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\frac{1}{2\\sigma^2}\\sum_{i=1}^N  (y_i -\\mathbf{x}_i^T\\mathbf{w})^2 + C\n\\] Where \\(C\\) is a constant: \\(C = N \\log \\sigma \\sqrt{2\\pi}\\). We further saw that this is equivalent to minimizing the mean squared error for any choice of \\(\\sigma\\).\n\n\nLaplace Maximum Likelihood Estimation\nA natural question about the above model is: why choose the Normal distribution? In principal, we could define a linear model using any distribution over the real numbers \\(\\mathbb{R}\\). Let’s explore an alternative choice: the Laplace distribution (Wiki). The Laplace distribution \\(L(\\mu, a)\\) has the following PDF:\n\\[p(y\\mid \\mu, a) = \\frac{1}{2a} \\exp\\bigg(- \\frac{|y-\\mu|}{a} \\bigg) \\]\nAs for the normal distribution \\(\\mu\\) is the mean, while \\(a\\) defines the “width” of the distribution (analogous to variance for the Normal). We can compare the two distributions visually:\n\ny = np.linspace(-3, 3, 200)\nmu, sigma2_or_a = 0, 1\np_y_normal = (1 / np.sqrt(sigma2_or_a * 2 * np.pi)) * np.exp(- (0.5 / sigma2_or_a) * (y - mu) ** 2)\np_y_laplace = (1 / (2 * sigma2_or_a)) * np.exp(- (1 / sigma2_or_a) * np.abs(y - mu))\n\nplt.figure(figsize=(4,3))\nplt.plot(y, p_y_normal, label=r\"Normal PDF\")\nplt.plot(y, p_y_laplace, label=r\"Laplace PDF\")\nplt.xlabel('$y$')\nplt.ylabel('$p(y)$')\nplt.legend()\npass\n\n\n\n\n\n\n\n\nLet’s now consider the Laplace version of our probabilistic linear model: \\[\ny_i \\sim L\\big(\\mathbf{x}_i^T \\mathbf{w},\\ a\\big)\n\\] Recall that the negative log-likelihood is defined as: \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, a)\\]\nQ10: Write out the negative log-likelihood for this model in terms of \\(\\mathbf{w}, a, \\mathbf{X}, y\\) using the Laplace PDF shown above.\nYOUR ANSWER HERE \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = \\]\nNote that if we drop the constants, we would call this loss the sum absolute error.\nQ11: Find the gradient with respect to \\(\\mathbf{w}\\) of the negative log-likelihood for this model. Hint: remember that the gradient is the vector of partial derivatives!\nYou should use the following definition of the derivative of the absolute value \\(|\\cdot |\\) operator: \\[\\frac{d}{dx}|x| = sign(x), \\quad sign(x) = \\begin{cases} +1 \\quad \\text{ if  } x &gt; 0 \\\\ -1 \\quad \\text{ if  } x &lt; 0 \\\\ \\ \\ \\ 0 \\quad \\text{ if  } x = 0 \\end{cases}\\] (Technically \\(\\frac{d}{dx}|x|\\) is undefined at \\(x=0\\), but it is convinient to assume \\(\\frac{d}{dx}|0|=0\\) in practice.)\nYOUR ANSWER HERE \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) = \\]\nQ12: Using the formula you just derived, write a function that returns both the negative log-likelihood and the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) (assume that \\(a=1\\)). We’ll divide both outputs by \\(N\\) to make our results more comparable to MSE. Hint: np.sign will compute the sign function descibed above.\n\ndef nll_and_grad(w, X, y):\n    N = X.shape[0]\n    ### YOUR CODE HERE\n\n    \n    return nll / N, grad_w / N\n\nQ13: Use the gradient_descent and nll_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 1.0. Plot the loss (NLL) as a function of the number of updates. Use the full dataset as in Q5 and note the change in learning rate!\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw_laplace, losses_laplace = \n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nQ14: Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\). Finally, copy your code from Q5 to once again find the optimal \\(\\mathbf{w}\\) using the MSE loss and plot this function on the same plot in a different color. Describe any differences you see between the two models\n\n### CODE FROM Q5 HERE\nw_mse, losses_mse = \n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nWRITTEN ANSWER HERE\nQ15: Using the parameters that you just found, plot the Laplace NLL loss as a function of the first entry in w (w1 below), holding the other (the bias) constant. Plot this loss on the range \\([-10, 0]\\). Then, in a separate cell, plot the MSE loss as a function of the first entry in w on the same range.\n\n# Example of deconstructing and reconstructing the parameter vector.\nw1, b = w\nwi = np.array([w1, b])\n\n### PLOTTING CODE FOR NLL HERE\nplt.figure(figsize=(6, 4))\n\n\n### PLOTTING CODE FOR MSE HERE\nplt.figure(figsize=(6, 4))\n\nIn the cells below, copy your code for Q5 and Q13. Try out different learning rates and and numbers of iterations. Observe what happens to the loss plot in each case.\n\n### COPY Q5 CODE HERE\n\n\n### COPY Q13 CODE HERE\n\nQ16: Based on what you’ve obsevered above and in the previous questions, why might you choose the Normal distribution or the Laplace distribution for linear regression? What effect does the learning rate have (what happens if it’s set too high or too low)?\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main.html",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main.html",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#overview",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#overview",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Overview",
    "text": "Overview\nIn this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\nimport numpy as np\n\n\nPython features\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-1-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-1-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 1: Reverse-mode automatic differentiation",
    "text": "Part 1: Reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - parents: The parent operations (a and b) - grad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\)) - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called AutogradValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using AutogradValue.\na = AutogradValue(5)\nb = AutogradValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\nL.backward()\ndL_da = a.grad\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\nNow that we’ve seen what our final produce will look like, let’s define our AutogradValue class.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        args    (list): A list of raw values of each input (as floats)\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.args = [arg.value if isinstance(arg, AutogradValue) else arg for arg in self.parents]\n        self.grad = 0.\n        self.value = self.forward_pass()\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.args)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n\n\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing AutogradValue. These subclasses will look the same as the ones we wrote for our forward-mode automatic differentiation in the last homework.\n\nclass _add(AutogradValue):\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def grads(self, a, b):\n        return 1., -1.\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def grads(self, a, b):\n        return b, a\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return math.exp(a)\n\n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return math.log(a)\n\n    def grads(self, a):\n        return (1 / a,)\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\ndef exp(a):\n    return a.exp() if isinstance(a, AutogradValue) else np.exp(a)\ndef log(a):\n    return a.log() if isinstance(a, AutogradValue) else np.log(a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(AutogradValue)\n\nLet’s confirm that we do keep the entire compuational graph for operations defined in this way.\n\nQ1\nWrite a function graph_print that takes a single argument. If the argument is an AutogradValue (or one of its subclasses), print its value property and then call graph_print on each of its parents. If the argument is not an AutogradValue, just print it. The format of printing is not important.\nHint: You can use the built-in Python function isinstance to determine if something is an AutogradValue or one of its subclasses. e.g. isinstance(a, AutogradValue)\n\ndef graph_print(a):\n    ## YOUR CODE HERE\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\nThe function should print (it’s ok if the numbers or order aren’t exact):\n2.995732273553991\n20.0\n10.0\n5.0\n5.0\n5\n2.0\n2.0\nNow in order to do automatic differentiation, we need to define how to do the backward pass. We’ll start with the backward_step for a single operation.\n\n\nQ2\nFill in the method backward_pass which computes a single step of the reverse pass through the computational graph (assume self is an AutogradValue instance). If backward_pass is called on a value c, the method should: - Assume that self.grad contains the derivaive of the final loss with respect to c (\\(\\frac{dL}{dc}\\)). - Check if each parent of c is an AutogradValue. If it is, update that parent’s grad property to account for c (e.g. for parent a, update the value of \\(\\frac{dL}{da}\\))\nFor example: if c represents the result of an addition so c = a + b, calling backward_pass on c will update the grad property of both a and b. (a.grad represents \\(\\frac{dL}{da}\\) and is initialized to 0).\nHint: grads will be one of the methods we wrote in the last homework (and shown above). Recall that if c has parents a and b then grads method will give \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\).\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n    local_grads = self.grads(*self.args)\n\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\nFinally we need to define the backward method itself. We will call this on the loss value to find the derivatives of the loss with respect to each input. This means working our way backward through the sequence of operations. Remember that if c=a+b, then if c.grad is \\(\\frac{dL}{dc}\\), calling backward_pass on c will update \\(\\frac{dL}{da}\\) (a.grad) and \\(\\frac{dL}{db}\\) (b.grad).\nThe complication is that c may be used in multiple operations, so we can’t call backward_pass on c until we’ve called backward_pass on each child operation of c otherwise c.grad won’t have the correct value of \\(\\frac{dL}{dc}\\), as in this example:\nc = a + b\ng = c * 2\nh = c + 4\nL = g * h\n\nL.backward_pass() # Updates dL/dg and dL/dh\nh.backward_pass() # Updates dL/dc\n\n##WRONG ORDER\nc.backward_pass() # Incorrect because dL/dc hasn't accounted for dL/dg\ng.backward_pass()\n\n## CORRECT ORDER\ng.backward_pass() # Updates dL/dc\nc.backward_pass() # Updates dL/da and dL/db\n\n\nQ3\nFill in the backward method for AutogradValue. Your backward method should call backward_pass on each operation used to compute the loss (self is the loss value). Some important things to keep in mind: - backward_pass should only be called once on each operation - backward_pass must be called on every child of an operation before it can be called on the operation. - You should not try to call backward_pass on values that aren’t instances of AutogradValue, even though they might be stored in operation.parents\nHint: We discussed a simple approach to this problem in class! We won’t score efficiency in grading, but it still might be worth optimizing this function a bit.\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## YOUR CODE HERE\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\nIf we want to train a neural network using our automatic differentiation implementation, we’re going to want to be able to use numpy to do matrix operations. Fortunately, the our AutogradValue class is (mostly) compatible with numpy!\nWe can create arrays of AutogradValue and take derivatives as shown below:\n\na = np.array([AutogradValue(5), AutogradValue(2)])\nL = np.dot(a, a)\nL.backward()\nprint('Gradient for a', a[0].grad, a[1].grad)\n\nIt would be a bit tedious to define every AutogradValue array in this way, so let’s write some convinience functions to make doing automatic differentiation with numpy easier.\n\n\nQ4\nComplete the following two functions wrap_array and unwrap_gradient.\nwrap_array should take a numpy array of floats and return a new array where every element has been made into an AutogradValue.\nunwrap_gradient should take a numpy array of AutogradValue and return a new array of floats, where every element is the extracted grad property of the corresponding element from the original array.\nBoth of these functions should work on 2-D arrays (matrices) at a minimum (but more general solutions that support 1 and/or &gt;2 dimensional arrays are also possible).\nHint: You can create an array from nested lists as np.array([[1, 2], [3, 4]]).\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    ## YOUR CODE HERE\n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    ## YOUR CODE HERE\n\n\ntest_wrap_unwrap(wrap_array, unwrap_gradient, AutogradValue)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-2-training-a-neural-network",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-2-training-a-neural-network",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 2: Training a neural network",
    "text": "Part 2: Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks! Below is a (slightly modified) version of the neural network class we wrote for the last homework.\n\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if (isinstance(a, AutogradValue) or isinstance(b, AutogradValue)) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(a, AutogradValue) else 1. / (1. + exp(-x))\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(log(py)).sum()\n\n\nQ5\nImplement an nll_and_grad method for the NeuralNetwork class using your reverse-mode automatic differentiation implmentation to compute the gradient with respect to each weight matrix.\nHint: You’ll need to use the wrap_array and unwrap_gradients functions you wrote above. You should use the built-in nll method to compute the loss.\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-3-vectorizing-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main.html#part-3-vectorizing-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 3: Vectorizing Reverse-mode automatic differentiation",
    "text": "Part 3: Vectorizing Reverse-mode automatic differentiation\nWe might notice that our reverse-mode automatic differentiation implementation is quite slow! The main reason for this is that our implementation operates on individual numbers (scalars) rather than entire arrays. This means that for a big operation like a matrix multiplication, an AutogradValue object needs to be tracked for each of the \\(O(n^3)\\) individual operations! Even worse, it also means that internally Numpy can’t use the very fast C and C++ implementations it has for array operations on type float, our array elements are now objects so it has to fall back on slow Python-loop based implementations.\nIdeally we’d like our AutogradValue objects to operate at the level of array operations, rather than scalar operations. This would circumvent these problems as we could represent an entire matrix multiplication with a single AutogradValue. In order to do this efficiently, we’ll need to make use of the Vector-Jacobian Product idea that we discussed in class. Let’s review the concept here.\nRecall that in backward_pass for a node c we assume that we have the gradient (derivative) of the loss with respect to c: \\(\\frac{dL}{d\\mathbf{c}}\\) and we need to update the gradients for the parents (say a and b) as:\n\\[\\frac{dL}{da} = \\frac{dL}{dc} \\frac{dc}{da}, \\quad \\frac{dL}{dc} = \\frac{dL}{dc} \\frac{dc}{db}\\]\nWhen \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\) are vectors the derivates \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) and \\(\\frac{d\\mathbf{c}}{d\\mathbf{b}}\\) are Jacobian matrices with possibly many entries and our updates become vector-Jacobian products:\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T, \\quad \\frac{dL}{d\\mathbf{b}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{b}}\\bigg)^T\\]\nHowever we often don’t need to actually construct the Jacobians fully to compute these products, as is the case for element-wise operations. As long as we can compute the correct values for \\(\\frac{dL}{d\\mathbf{a}}\\), we’re good! For example if \\[\\mathbf{c} = \\mathbf{a}^2, \\quad \\mathbf{c} = \\begin{bmatrix} a_1^2 \\\\ a_2^2 \\\\ a_3^2 \\\\ \\vdots \\end{bmatrix}\\]\nWe can easily see that we can just update the derivate for each element of \\(\\mathbf{a}\\) independently. \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix} = 2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\]\nIf we want to be more formal we can note that technically, the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is diagonal (\\(\\frac{\\partial c_i}{\\partial a_j}\\) is only nonzeros for \\(i=j\\)). Therefore we can write the Vector-Jacobian Product as:\n\\[\\frac{dL}{d\\mathbf{a}}^T = \\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}  = \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 2 a_1 & 0 & 0 & \\dots \\\\0  & 2 a_2 & 0 & \\dots \\\\ 0 & 0 & 2 a_3 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix}^T = \\bigg(2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\bigg)^T\\]\nFor the case of addition, things are even simpler! If: \\[\\mathbf{c} = \\mathbf{a} + \\mathbf{b}\\]\nWe can again see that we can just update the derivative for each element of \\(\\mathbf{a}\\) independently, but this time each local derivative (\\(\\frac{dc_i}{da_i}\\)) is just \\(1\\), so \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 1 \\\\  \\frac{dL}{dc_2} \\cdot 1 \\\\  \\frac{dL}{dc_3} \\cdot 1 \\\\ \\vdots  \\end{bmatrix} = \\frac{dL}{d\\mathbf{c}}\\]\nIn this case the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is simply the identity matrix, so: \\[\\frac{dL}{d\\mathbf{a}}^T =  \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 1 & 0 & 0 & \\dots \\\\0  & 1 & 0 & \\dots \\\\ 0 & 0 & 1 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}= \\frac{dL}{d\\mathbf{c}}^T \\mathbf{I} = \\frac{dL}{d\\mathbf{c}}^T\\]\n\nQ6\nLet’s replace our operation implementations above with ones that compute Vector-Jacobian products. We’ll start with element-wise operations. Complete the vjp function for each operation below. Unlike the grads methods we implemented before which computed the derivative of the output with respect to each input: \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\) (if applicable), each vjp method should directly compute the gradient of the loss with respect to each input: \\(\\frac{dL}{d\\mathbf{a}}\\) and \\(\\frac{dL}{d\\mathbf{b}}\\), assuming the grad argument provides the gradient of the loss with respect to the output: \\(\\frac{dL}{d\\mathbf{c}}\\).\nHint: For binary operations (+,-,*,/), you do not need to account for broadcasting. That is, you can assume that a, b and c are always the same shape! We’ve started you off with a few examples to base your answers on.\n\nclass _add(AutogradValue):\n    # An example representing the addition operation.\n    def func(self, a, b):\n        '''\n        Computes the result of the operation (a + b). Assumes a and b are the same shape.\n\n        Args:\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            c (array of float): The result c = a + b\n        '''\n        return a + b\n\n    def vjp(self, grad, a, b):\n        '''\n        Computes dL/da and dL/db given dL/dc.\n\n        Args:\n            grad (array of float): The gradient of the loss with respect to the output (dL/dc)\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            grads (tuple of arrays): A tuple containing the gradients dL/da and dL/db\n        '''\n        return grad, grad\n\nclass _square(AutogradValue):\n    # Another example class implementing c = a^2\n    def func(self, a):\n        return a ** 2\n\n    def vjp(self, grad, a):\n        return (2 * a * grad,)\n\nclass _pad(AutogradValue):\n    # An implementation for padding with a column of 1s.\n    def func(self, a):\n        return np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\n    def vjp(self, grad, a):\n        return (grad[:, :-1],)\n\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return np.exp(a)\n\n    def vjp(self,grad,  a):\n        # YOUR CODE HERE\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return np.log(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_neg, '_neg', )\ntest_vjp(_exp, '_exp', true_func=anp.exp)\ntest_vjp(_log, '_log', true_func=anp.log)\ntest_vjp(_sub, '_sub', True)\ntest_vjp(_mul, '_mul', True)\ntest_vjp(_div, '_div', True)\n\n\n\nQ7\nConsider the operation defined by np.sum, that takes the sum over all elements of a matrix or vector, producing a scalar:\n\\[c  = \\sum_{i=1}^n a_i\\]\nWrite a vjp method for this operation that computes: \\(\\frac{dL}{d\\mathbf{a}}\\) given \\(\\frac{dL}{dc}\\).\nHint: Note that \\(L\\), \\(c\\) and \\(\\frac{dL}{dc}\\) are all scalars, so for any entry \\(i\\) of our output we can simply apply the chain rule and compute \\(\\frac{dL}{da_i} = \\frac{dL}{dc} \\frac{dc}{da_i}\\). As the equation above for \\(c\\) given \\(\\mathbf{a}\\) is a sum, \\(\\frac{dc}{da_i}\\) should be simple!\n\nclass _sum(AutogradValue):\n    def func(self, a):\n        return np.sum(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_sum, '_sum', true_func=anp.sum, issum=True)\n\n\n\nMatrix multiplication\nFor the next few problems, it may be useful to refer to this diagram of matrix multiplication.\n\n\n\nimage.png\n\n\nThe last important operation we’ll need a vjp method for in order to use our vectorized AutogradValue class for a neural network is matrix multiplication. Let’s consider the operation:\n\\[\\mathbf{C} = \\mathbf{A}\\mathbf{B}\\]\nWhere \\(\\mathbf{A}\\) is an \\(N\\times h\\) matrix, \\(\\mathbf{B}\\) is a \\(h \\times d\\) matrix and \\(\\mathbf{C}\\) is an \\(N\\times d\\) matrix.\nRecall that for vjp want to compute \\(\\frac{dL}{d\\mathbf{A}}\\) (and \\(\\frac{dL}{d\\mathbf{B}}\\) ) given \\(\\frac{dL}{d\\mathbf{C}}\\). We can compute a given entry \\(i,j\\) of \\(\\frac{dL}{d\\mathbf{A}}\\) by applying the chain rule using each element of \\(\\mathbf{C}\\):\n\\[\\frac{dL}{dA_{ij}} = \\sum_{k=1}^N \\sum_{l=1}^d \\frac{dL}{dC_{kl}}\\frac{dC_{kl}}{dA_{ij}}\\]\nHowever, each entry of \\(\\mathbf{C}\\) only depends on a single row of \\(\\mathbf{A}\\) and a single column of \\(\\mathbf{B}\\), thus for most \\(i,j,k,l\\), \\(\\frac{dC_{kl}}{dA_{ij}}=0\\).\n\nQ8\nUsing this observation, simplify the expression for \\(\\frac{dL}{dA_{ij}}\\) above. (The derivative of the loss with respect to the entry of \\(\\mathbf{A}\\) at row \\(i\\), column \\(j\\)).\nHint: Your answer should have a similar form, but should only have a single summation and a subset of the indices \\(i,j,k,l\\).\n\\[\\frac{dL}{dA_{ij}} = \\]\n\n\nQ9\nRecalling the definition of matrix-multiplication, give a simple expression for \\(\\frac{dC_{il}}{dA_{ij}}\\), then substitue it into your expression for \\(\\frac{dL}{dA_{ij}}\\).\n\\[\\frac{dC_{il}}{dA_{ij}}= , \\quad\\frac{dL}{dA_{ij}} = \\]\n\n\nQ10\nUsing your expression in Q13, write an expression for \\(\\frac{dL}{d\\mathbf{A}}\\) as a matrix multiplication between two of the 3 given matrices: \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\), \\(\\mathbf{B}\\). Make sure to inlude any nessecary transposes.\nHint: Recall that \\(\\frac{dL}{d\\mathbf{C}}\\) is the same shape as \\(\\mathbf{C}\\) (\\(N\\times d\\)), \\(\\mathbf{A}\\) has shape \\(N \\times h\\) and \\(\\mathbf{B}\\) has shape \\(h \\times d\\).\n\\[\\frac{dL}{d\\mathbf{A}}= \\]\n\n\nQ11\nWrite the corresponding formula for \\(\\frac{dL}{d\\mathbf{B}}\\).\nHint: You can use the fact that \\(C^T = B^T A^T\\) and that \\(\\frac{dL}{d\\mathbf{C}^T} = (\\frac{dL}{d\\mathbf{C}})^T\\)\n\\[\\frac{dL}{d\\mathbf{B}}=\\]\n\n\nQ12\nUsing the expressions you derived in Q14 and Q15, implement the vjp function for the matmul operation to compute \\(\\frac{dL}{d\\mathbf{A}}\\) and \\(\\frac{dL}{d\\mathbf{B}}\\) given \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\).\n\nclass _matmul(AutogradValue):\n    def func(self, a, b):\n        return np.matmul(a, b)\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\ntest_vjp(_matmul, '_matmul', binary=True, true_func=anp.matmul)\n\nNow that we’ve written the vjp versions of our operators, we’ll update our AutogradValue class to use them!\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.vjp = lambda self, grad, a: (1.,)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.pad = lambda a: _pad(a)\nAutogradValue.sum = lambda a: _sum(a)\nAutogradValue.matmul = lambda a, b: _matmul(a, b)\nAutogradValue.rmatmul = lambda a, b: _matmul(b, a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nAs a final step, we need to update our backward_pass method to use our new vjp method instead of relying on grads.\n\n\nQ13\nUpdate your backward_pass method to use vjp instead of grads.\nHint: Recall that vjp directly computes \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\frac{dL}{d\\mathbf{b}}\\), whereas grads computed \\(\\frac{dc}{da}\\), \\(\\frac{dc}{db}\\)\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n\n\n\nAutogradValue.backward_pass = backward_pass\n\n\n\nQ14\nFinally update the nll_and_grad function for our NeuralNetwork class to use our shiny new vectorized reverse-mode implementation.\nHint: We should no longer need to use our wrap_array and unwrap_gradient functions, as AutogradValue objects can now contain arrays!\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe should be able to run it with a much larger network now!\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [25, 25])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/final-project/outline.html",
    "href": "assignments/final-project/outline.html",
    "title": "Final project",
    "section": "",
    "text": "The first step for the project will be to form a group and participate in a discussion about the potential ethical issues that arise when applying machine learning models in the real world. For this stage you should:\n\nForm a group of 2-4 students and choose a cool team name. If you would like help finding a group, please email me! If you would like to work individually, you must get prior approval from the professor.\nComplete the ethics and AI assignment as a group."
  },
  {
    "objectID": "assignments/final-project/outline.html#ethics-discussion-due-wednesday-28-1159pm",
    "href": "assignments/final-project/outline.html#ethics-discussion-due-wednesday-28-1159pm",
    "title": "Final project",
    "section": "",
    "text": "The first step for the project will be to form a group and participate in a discussion about the potential ethical issues that arise when applying machine learning models in the real world. For this stage you should:\n\nForm a group of 2-4 students and choose a cool team name. If you would like help finding a group, please email me! If you would like to work individually, you must get prior approval from the professor.\nComplete the ethics and AI assignment as a group."
  },
  {
    "objectID": "assignments/final-project/outline.html#proposal-due-thursday-44-1159pm",
    "href": "assignments/final-project/outline.html#proposal-due-thursday-44-1159pm",
    "title": "Final project",
    "section": "Proposal (Due Thursday 4/4 11:59pm)",
    "text": "Proposal (Due Thursday 4/4 11:59pm)\nThe next step for the project will be to formally propose a project topic, for this milestone you should:\n\nChoose a project topic. You may choose a topic from the list below or you may propose your own topic.\nWith your team, write a short (up to 1 page) proposal for your project and submit it on gradescope. Your proposal should include:\nThe names of the team members\nA one paragraph high-level description of the goal(s) of the project (e.g. object detection in images, classifying text data, etc.), how this goal could be useful in real-world applications and why this topic interests you.\nA one paragraph description of how you intend to approach this problem and any challenges you forsee. This should include identifying datasets that you might use, identifying at least one referance (academic paper or website) for a technique you intend to try.\nA one paragraph description of how you will evaluate success for your application."
  },
  {
    "objectID": "assignments/final-project/outline.html#check-in-due-monday-422-1159pm",
    "href": "assignments/final-project/outline.html#check-in-due-monday-422-1159pm",
    "title": "Final project",
    "section": "Check-in (Due Monday 4/22 11:59pm)",
    "text": "Check-in (Due Monday 4/22 11:59pm)\nAs a progress report you and your team will submit a short (1 page) summery of progress on Gradescope. This summary will include:\n\nA high-level description of any updates you have made to the goals of your project.\nA description of what methods you have tried and any preliminary results.\nA timeline for finishing the remaining goals of your project.\nA brief description of the contributions made by each team member."
  },
  {
    "objectID": "assignments/final-project/outline.html#final-deliverables-due-53-1159pm",
    "href": "assignments/final-project/outline.html#final-deliverables-due-53-1159pm",
    "title": "Final project",
    "section": "Final deliverables (Due 5/3, 11:59pm)",
    "text": "Final deliverables (Due 5/3, 11:59pm)\nPlease see the final project template here, which includes instructions and guidelines for what to submit. Submissions will be through gradescope.\nRubric: link\nOverleaf template: link"
  },
  {
    "objectID": "assignments/final-project/outline.html#course-server",
    "href": "assignments/final-project/outline.html#course-server",
    "title": "Final project",
    "section": "Course server",
    "text": "Course server\nThere is a GPU server allocated to this class at teapot.cs.hmc.edu. Please follow the instructions in homework 6 or 7 to setup a Jupyter session for project work.\nData directory If you are working with a large dataset on the server, please do not save it to your home directory as this may cause you to exceed your account’s allocated limit. Instead, please create a sub-directory of /cs/cs152/shared for your project and save your data there."
  },
  {
    "objectID": "assignments/final-project/outline.html#examples-from-previous-semesters",
    "href": "assignments/final-project/outline.html#examples-from-previous-semesters",
    "title": "Final project",
    "section": "Examples from previous semesters",
    "text": "Examples from previous semesters\nHere are examples of great projects kindly shared by students from previous semesters. Note that these may be longer than what is expected for a perfect grade. 4-6 pages should be sufficient.\n\nExplainable Transfer Learning for CNNs and Transformers\nRecurrent Neural Network Variants for Generating Opinion Distributions"
  },
  {
    "objectID": "assignments/final-project/outline.html#possible-projects",
    "href": "assignments/final-project/outline.html#possible-projects",
    "title": "Final project",
    "section": "Possible projects",
    "text": "Possible projects\n\nNeural style transfer\nLink: https://arxiv.org/pdf/1508.06576.pdf\nSummary: Style transfer is the process of taking an existing image and applying an artistic style to it, such as making a photograph look like a painting or a drawing (check out the examples in the linked paper!). This can be accomplished with neural networks. For this project you could: implement the neural style transfer algorithm, evaluate it with different kinds of images and compare it to other methods for restyling images.\nSuggested datasets: Any artistic images you’d like!\n\n\nSemi-supervised learning with MixMatch\nLink: https://arxiv.org/pdf/1905.02249.pdf\nSummary: Semi-supervised learning is the problem of learning when we don’t have all the labels for our training data. MixMatch is a state-of-the-art approach for semi-supervised image classification. In this project you could: implement the Mix-Match algorithm, compare the different versions of it discussed in the paper and evaluate it on several different datasets. You could also test it on your own proposed semi-supervised learning task.\nSuggested datasets: Street view house numbers, CIFAR-10, STL-10\n\n\nAudio generation and classification with WaveNet\nLink: https://arxiv.org/pdf/1609.03499.pdf\nSummary: WaveNet is at network that forms the basis for many text-to-speech systems (think Alexa or Siri) it also allows for classifying audio. For this project you could: implement WaveNet, train it to generate speech (or other audio like music!) and evaluate it compared to existing tools for generation. You could also try to use it to classify speech or music.\nSuggested datasets: Spoken digits, Speech commands, Crema-D, GTZAN\n\n\nU-Nets for segmentation, depth-prediction, colorization or super-resolution\nLink: https://arxiv.org/pdf/1505.04597.pdf\nSummary: U-Nets are a very flexible type of neural network used for many computer vision tasks. They were originally introduced for segmenting different parts of medical images, but can used for everything from colorizing images to upscaling images to predicting depth in am image. For this project you could: implement the U-Net architecture, train a U-Net on one or more of the above tasks and evaluate its performance.\nSuggested datasets: Oxford flowers ImageNet, NYU Depth\n\n\nObject detection with YOLO\nIntroduction: https://pyimagesearch.com/2022/04/11/understanding-a-real-time-object-detection-network-you-only-look-once-yolov1/\nOriginal paper: https://arxiv.org/pdf/1506.02640v5.pdf\nSummary: Object detection is the task of locating objects within an image. This is a step more difficult than just classifying images, but is very useful in practice. For this project you could: implement the YOLO object detection model, test different variations of the model and evaluate it on new data.\nSuggested datasets: VOC, Wider face, Kitti\n\n\nImage generation with Generative Adversarial Networks\nIntroduction: https://developers.google.com/machine-learning/gan\nOriginal paper: https://arxiv.org/pdf/1406.2661.pdf\nSummary: Generative adversarial networks (GANs for short) are an effective way to generate realistic looking images using neural networks. They have caused a considerable amount of excitement and concern for their performance in generating realistic images of humans. For this project you could: implement a generative adversarial network, explore reasonable ways to evaluate the performance of GANs and dive into the ethical implications.\nSuggested datasets: MNIST, Omniglot, CIFAR-10, FFHQ\n\n\nImage classification with visual transformers\nLink: https://arxiv.org/pdf/2010.11929.pdf\nSummary: Transformer-based neural networks have transformed the field of natural language processing in recent years, as evidenced by the performance of models such as ChatGPT. There is growing evidence that they are also extremely useful for classifying images. For this project you might: implement the visual transformer architecture, compare it to convolutional neural network based architecture for image classification and visualize features to understand the differences in the approaches. You might also consider applying it to your own dataset.\nSuggested datasets: Oxford flowers, CIFAR-10, ImageNet\n\n\nText generation or classification with GPT\nLink: https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\nSummary: Large language models, such at GPT-3 and GPT-4 have gained a lot of attention recently, as their performance in generating plausible text is (debatably) approaching human levels. The GPT model is used by Chat-GPT and many other applications to model language. For this project you could implement and train your own version of the original (GPT-1) model, compare it against available tools such as Chat-GPT and explore how to distinguish generated text from real human writing.\nSuggested datasets: Amazon reviews IMDB reviews\n\n\nOther possible projects:\n\nMachine learning with differential privacy\nhttps://arxiv.org/pdf/1607.00133.pdf\n\n\nGraph neural networks\nhttps://arxiv.org/pdf/1810.00826.pdf"
  },
  {
    "objectID": "lecture10-normalization/slides.html",
    "href": "lecture10-normalization/slides.html",
    "title": "Initialization",
    "section": "",
    "text": "Can we combine adaptive scaling and momentum?"
  },
  {
    "objectID": "lecture10-normalization/slides.html#adam",
    "href": "lecture10-normalization/slides.html#adam",
    "title": "Initialization",
    "section": "",
    "text": "Can we combine adaptive scaling and momentum?"
  },
  {
    "objectID": "lecture10-normalization/slides.html#adam-1",
    "href": "lecture10-normalization/slides.html#adam-1",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta_1 \\mathbf{v}^{(k)} + (1-\\beta_1) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\] Update scaling\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta_2 \\mathbf{s}^{(k)} + (1-\\beta_2) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\] Update weights\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\mathbf{v}^{(k+1)}\n}{\\sqrt{\\mathbf{s}^{(k+1)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#adam-2",
    "href": "lecture10-normalization/slides.html#adam-2",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nUpdate velocity\n\\[ \\mathbf{v}^{(k+1)} \\longleftarrow \\beta_1 \\mathbf{v}^{(k)} + (1-\\beta_1) \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\] Update scaling\\[ \\mathbf{s}^{(k+1)} \\longleftarrow \\beta_2 \\mathbf{s}^{(k)} + (1-\\beta_2) (\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y}))^2\\]\nModified weight update:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\frac{\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)}\n}{\\sqrt{\\frac{\\mathbf{s}^{(k+1)}}{(1-\\beta_2^k)} + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#adam-3",
    "href": "lecture10-normalization/slides.html#adam-3",
    "title": "Initialization",
    "section": "Adam",
    "text": "Adam\nAt step 0:\n\\[\\mathbf{v}^{(0)} = \\mathbf{0}, \\quad \\mathbf{s}^{(0)} = \\mathbf{0}\\] \\[\\frac{\\mathbf{v}^{(k+1)}}{(1-\\beta_1^k)} = \\frac{\\beta_1 \\mathbf{0} + (1-\\beta_1)\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})}{(1-\\beta_1^1)} = \\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#summary-of-gradient-descent-issues",
    "href": "lecture10-normalization/slides.html#summary-of-gradient-descent-issues",
    "title": "Initialization",
    "section": "Summary of gradient descent issues",
    "text": "Summary of gradient descent issues\nUpdates are too slow\n\nStochastic/minibatch gradient descent\n\nSGD gradients are very noisy (high variance)\n\nIncrease batch size, use momentum\n\nStuck at saddle points or shallow optima\n\nUse momentum\n\nInconsistant scaling of the gradient\n\nUse RMSProp scaling"
  },
  {
    "objectID": "lecture10-normalization/slides.html#exponential-moving-average-ema",
    "href": "lecture10-normalization/slides.html#exponential-moving-average-ema",
    "title": "Initialization",
    "section": "Exponential moving average (EMA)",
    "text": "Exponential moving average (EMA)"
  },
  {
    "objectID": "lecture10-normalization/slides.html#exponential-moving-average-ema-1",
    "href": "lecture10-normalization/slides.html#exponential-moving-average-ema-1",
    "title": "Initialization",
    "section": "Exponential moving average (EMA)",
    "text": "Exponential moving average (EMA)"
  },
  {
    "objectID": "lecture10-normalization/slides.html#exponential-moving-average-ema-2",
    "href": "lecture10-normalization/slides.html#exponential-moving-average-ema-2",
    "title": "Initialization",
    "section": "Exponential moving average (EMA)",
    "text": "Exponential moving average (EMA)"
  },
  {
    "objectID": "lecture10-normalization/slides.html#exponential-moving-average-ema-3",
    "href": "lecture10-normalization/slides.html#exponential-moving-average-ema-3",
    "title": "Initialization",
    "section": "Exponential moving average (EMA)",
    "text": "Exponential moving average (EMA)"
  },
  {
    "objectID": "lecture10-normalization/slides.html#exponential-moving-average-ema-4",
    "href": "lecture10-normalization/slides.html#exponential-moving-average-ema-4",
    "title": "Initialization",
    "section": "Exponential moving average (EMA)",
    "text": "Exponential moving average (EMA)"
  },
  {
    "objectID": "lecture10-normalization/slides.html#data-normalization",
    "href": "lecture10-normalization/slides.html#data-normalization",
    "title": "Initialization",
    "section": "Data normalization",
    "text": "Data normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#data-normalization-1",
    "href": "lecture10-normalization/slides.html#data-normalization-1",
    "title": "Initialization",
    "section": "Data normalization",
    "text": "Data normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#data-normalization-2",
    "href": "lecture10-normalization/slides.html#data-normalization-2",
    "title": "Initialization",
    "section": "Data normalization",
    "text": "Data normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#data-normalization-3",
    "href": "lecture10-normalization/slides.html#data-normalization-3",
    "title": "Initialization",
    "section": "Data normalization",
    "text": "Data normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#data-normalization-4",
    "href": "lecture10-normalization/slides.html#data-normalization-4",
    "title": "Initialization",
    "section": "Data normalization",
    "text": "Data normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients",
    "href": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients",
    "title": "Initialization",
    "section": "Vanishing and exploding gradients",
    "text": "Vanishing and exploding gradients"
  },
  {
    "objectID": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients-1",
    "href": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients-1",
    "title": "Initialization",
    "section": "Vanishing and exploding gradients",
    "text": "Vanishing and exploding gradients"
  },
  {
    "objectID": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients-2",
    "href": "lecture10-normalization/slides.html#vanishing-and-exploding-gradients-2",
    "title": "Initialization",
    "section": "Vanishing and exploding gradients",
    "text": "Vanishing and exploding gradients"
  },
  {
    "objectID": "lecture10-normalization/slides.html#gradient-clipping",
    "href": "lecture10-normalization/slides.html#gradient-clipping",
    "title": "Initialization",
    "section": "Gradient clipping",
    "text": "Gradient clipping"
  },
  {
    "objectID": "lecture10-normalization/slides.html#gradient-clipping-1",
    "href": "lecture10-normalization/slides.html#gradient-clipping-1",
    "title": "Initialization",
    "section": "Gradient clipping",
    "text": "Gradient clipping\nExplicitly clip the gradient to prevent it form becoming too large.\n\\[\\textbf{clip}_{\\text{value}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{bmatrix} \\min(\\max(x_1, -\\epsilon), \\epsilon) \\\\ \\min(\\max(x_2, - \\epsilon), \\epsilon) \\\\ \\vdots \\end{bmatrix}\\]\n\\[\\textbf{clip}_{\\text{norm}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{cases}\n\\frac{\\epsilon\\mathbf{x} }{\\| \\mathbf{x} \\|_2} \\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 &gt; \\epsilon \\\\\n\\mathbf{x} \\  \\quad\\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 \\leq \\epsilon\n\\end{cases}\\]\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha\\ \\textbf{clip}\\big(\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\big)\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#gradient-clipping-2",
    "href": "lecture10-normalization/slides.html#gradient-clipping-2",
    "title": "Initialization",
    "section": "Gradient clipping",
    "text": "Gradient clipping"
  },
  {
    "objectID": "lecture10-normalization/slides.html#batch-normalization",
    "href": "lecture10-normalization/slides.html#batch-normalization",
    "title": "Initialization",
    "section": "Batch normalization",
    "text": "Batch normalization\nNormalize over the batch:\n\\[\\text{BatchNorm}(x) = \\frac{ x - \\mathbb{E}[x]}{\\sqrt{\\text{Var}[x] + \\epsilon}}\\]\nTraining time: \\[\\text{Batch: } \\{x_1, x_2,...,x_B\\}\\] \\[\\mathbb{E}[x] \\approx \\bar{x} = \\frac{1}{B}\\sum_{i=1}^{B} x_i\\quad \\text{(sample mean)}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#batch-normalization-1",
    "href": "lecture10-normalization/slides.html#batch-normalization-1",
    "title": "Initialization",
    "section": "Batch normalization",
    "text": "Batch normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#batch-normalization-2",
    "href": "lecture10-normalization/slides.html#batch-normalization-2",
    "title": "Initialization",
    "section": "Batch normalization",
    "text": "Batch normalization"
  },
  {
    "objectID": "lecture10-normalization/slides.html#batch-normalization-3",
    "href": "lecture10-normalization/slides.html#batch-normalization-3",
    "title": "Initialization",
    "section": "Batch normalization",
    "text": "Batch normalization\nBiased estimator: \\[\\text{Var}[x] \\approx s^2 = \\frac{1}{B}\\sum_{i=1}^{B} \\bigg(x_i - \\bigg(\\frac{1}{B}\\sum_{i=1}^{B} x_i\\bigg)\\bigg)^2\\quad \\text{(sample var.)}\\] Unbiased estimator: \\[\\text{Var}[x] \\approx  s^2 = \\frac{1}{B-1}\\sum_{i=1}^{B} \\bigg(x_i - \\bigg(\\frac{1}{B}\\sum_{i=1}^{B} x_i\\bigg)\\bigg)^2\\quad \\text{(sample var.)}\\]\n\\[\\underset{\\text{train}}{\\text{BatchNorm}}(x) = \\frac{ x - \\bar{x}}{\\sqrt{s^2 + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#batch-normalization-4",
    "href": "lecture10-normalization/slides.html#batch-normalization-4",
    "title": "Initialization",
    "section": "Batch normalization",
    "text": "Batch normalization\nRunning estimate: \\[\\bar{\\mu}^{(k+1)} \\longleftarrow \\beta \\bar{\\mu}^{(k)} + (1-\\beta) \\bar{x}^{(k)}\\] \\[\\bar{\\sigma}^{2(k+1)} \\longleftarrow \\beta \\bar{\\sigma}^{2(k)} + (1-\\beta) s^{2(k)}\\]\n\\[\\underset{\\text{test}}{\\text{BatchNorm}}(x) = \\frac{ x - \\bar{\\mu}}{\\sqrt{\\bar{\\sigma}^2 + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#layer-normalization",
    "href": "lecture10-normalization/slides.html#layer-normalization",
    "title": "Initialization",
    "section": "Layer normalization",
    "text": "Layer normalization\nNormalize over the layer:\n\\[\\text{LayerNorm}(\\mathbf{x}) = \\frac{\\mathbf{x} - \\bar{x}}{\\sqrt{s^2 + \\epsilon}}, \\quad \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_d\\end{bmatrix}\\]\nTraining & test time: \\[\\bar{x} = \\frac{1}{d}\\sum_{i=1}^{d} x_i\\quad \\text{(output mean)}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#layer-normalization-1",
    "href": "lecture10-normalization/slides.html#layer-normalization-1",
    "title": "Initialization",
    "section": "Layer normalization",
    "text": "Layer normalization\nBiased estimator: \\[s^2 = \\frac{1}{d}\\sum_{i=1}^{d} \\bigg(x_i - \\bigg(\\frac{1}{d}\\sum_{i=1}^{d} x_i\\bigg)\\bigg)^2\\quad \\text{(output var.)}\\] Unbiased estimator: \\[s^2 = \\frac{1}{d-1}\\sum_{i=1}^{d} \\bigg(x_i - \\bigg(\\frac{1}{d}\\sum_{i=1}^{d} x_i\\bigg)\\bigg)^2\\quad \\text{(output var.)}\\]"
  },
  {
    "objectID": "lecture10-normalization/slides.html#scaled-normalization",
    "href": "lecture10-normalization/slides.html#scaled-normalization",
    "title": "Initialization",
    "section": "Scaled normalization",
    "text": "Scaled normalization\n\\[\\text{BatchNorm}(x) = \\frac{ x - \\mathbb{E}[x]}{\\sqrt{\\text{Var}[x] + \\epsilon}} \\gamma + \\kappa\\] \\[\\text{LayerNorm}(\\mathbf{x}) = \\frac{\\mathbf{x} - \\bar{x}}{\\sqrt{s^2 + \\epsilon}} \\gamma + \\kappa\\]"
  },
  {
    "objectID": "misc/hw1-hint.html",
    "href": "misc/hw1-hint.html",
    "title": "Hint for homework 1: Q7",
    "section": "",
    "text": "For this question we are interested in simplifying an expression into matrix/vector notation. In order to do this it may be first helpful to think about how we went the other direction: matrix/vector notation to expanded notation.\nRecall that a dot product between two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), can be written explicitly from its definition as:\n\\[\n\\mathbf{x}^T\\mathbf{y} = \\sum_{i=1}^n x_iy_i\n\\]\nTherefore if we see something like the summation on the right in an expression, we can replace it with the more compact dot product notation.\nIf we have the expression \\(\\mathbf{A} \\mathbf{x}\\), where \\(\\mathbf{A}\\) is a matrix and \\(\\mathbf{x}\\) is a vector, we know that the result of this multiplication will be a vector. Let’s call this vector \\(\\mathbf{c}\\), so that \\(\\mathbf{A}\\mathbf{x}=\\mathbf{c}\\).\nWe know from the definition of matrix-multiplication that each element of \\(\\mathbf{c}\\) can be written as the following summation:\n\\[\nc_i = \\sum_{j=1}^n A_{ij}x_j\n\\]\nTherefore, if we saw such a summation in an expression, we could temporarily replace it with \\(c_i\\), knowing that we defined \\(\\mathbf{c}\\) as \\(\\mathbf{c}=\\mathbf{A}\\mathbf{x}\\). Try doing this as the first step in the homework, then try repeating this idea until you have something that you can write compactly in matrix/vector notation.\nWhen writing you final answer make sure to write the final expression in terms of the original variables \\((\\mathbf{A}, \\mathbf{x}, \\mathbf{b})\\). E.g. if you substituted \\(\\mathbf{c}\\) for \\(\\mathbf{A}\\mathbf{x}\\), make sure to substitute it back in the answer."
  },
  {
    "objectID": "misc/grading.html",
    "href": "misc/grading.html",
    "title": "Hint for homework 1: Q7",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nform_inputs = [\n  Inputs.range([0, 255], {step: 1, label: \"r\"}),\n  Inputs.range([0, 255], {step: 1, label: \"g\"}),\n  Inputs.range([0, 255], {step: 1, label: \"b\"})\n]\n\n\n\n\n\n\n\nviewof rgb = Inputs.form(form_inputs)\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof replay = Inputs.button(\"Replay\")\n\n\n\n\n\n\n\nprogress = {\n  replay;\n  console.log(form_inputs)\n  if (replay &gt; 0){\n    form_inputs.push(Inputs.range([0, 255], {step: 1, label: \"r\"}));\n    (viewof rgb).dispatchEvent(new Event(\"input\", {bubbles: true}))\n    //document.getElementById('notebook').src = \"https://nytimes.com\";}\n  }\n}"
  },
  {
    "objectID": "misc/hw2-hint.html",
    "href": "misc/hw2-hint.html",
    "title": "Hints for homework 2",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "misc/hw2-hint.html#question-1-2",
    "href": "misc/hw2-hint.html#question-1-2",
    "title": "Hints for homework 2",
    "section": "Question 1 & 2",
    "text": "Question 1 & 2\nThere are multiple ways to add a column of ones to a matrix in numpy. \\[\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d}  \\\\\n                \\vdots & \\vdots & \\ddots  & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} \\\\  \n                \\end{bmatrix} \\longrightarrow \\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix}\\]\n\n## Example 4x4 matrix\nX = np.zeros((4,4))\nX\n\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])\n\n\n\n## Using np.concatenate\nones = np.ones((X.shape[0], 1))\nXaug = np.concatenate([X, ones], axis=1)\nXaug\n\narray([[0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.]])\n\n\n\n## Using np.pad\nXaug = np.pad(X, [(0,0), (0,1)], constant_values=1.)\nXaug\n\narray([[0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.]])\n\n\nWe could also use pad to add a 1 to a one-dimensional vector:\n\n## Example vector\nx = np.zeros((4,))\nxaug = np.pad(x, [(0,1)], constant_values=1.)\nprint(x)\nprint(xaug)\n\n[0. 0. 0. 0.]\n[0. 0. 0. 0. 1.]"
  },
  {
    "objectID": "misc/hw2-hint.html#question-2",
    "href": "misc/hw2-hint.html#question-2",
    "title": "Hints for homework 2",
    "section": "Question 2",
    "text": "Question 2\nIn order to plot a function with MatPlotLib, we need to provide the np.plot function with a set of inputs and outputs. For example, let’s say we want to plot the function \\[f(x) = \\sin(x)\\] for inputs between \\(0\\) and \\(10\\) (we say we want to plot \\(\\sin(x)\\) on the range \\([0,10]\\)). We first need a set of inputs between \\(0\\) and \\(10\\). The np.linspace(a, b, n) function will give us n equally-spaced values between a and b. We can use this to define the inputs to our function.\n\nx = np.linspace(0, 10, 100)\n\nThen, we can compute the corresponding set of outputs:\n\ny = np.sin(x)\n\nFinally we can plot these values to np.plot, which will “connect-the-dots” to make a smooth plot.\n\nplt.plot(x, y)\n\n\n\n\n\n\n\n\nWe can see more clearly what np.plot is doing if we lower the number of inputs that we use to plot our function and add markers at each point:\n\nx = np.linspace(0, 10, 10)\ny = np.sin(x)\nplt.plot(x, y, marker='o')\n\n\n\n\n\n\n\n\nThe prediction function for linear regression takes in vectors and outputs scalars: \\[f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w}\\] We saw that we can rewrite the prediction function to make predictions for an entire set of inputs: \\[f(\\mathbf{X})=\\mathbf{X}\\mathbf{w}\\] Where \\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}\\] If our data only has a single feature (as in the Q2 ), then this becomes: \\[\nf(\\mathbf{X}) =\\mathbf{X}\\mathbf{w}=\n\\begin{bmatrix} X_{11} &  1 \\\\\n                X_{21} &  1 \\\\\n                \\vdots & \\vdots  \\\\\n                X_{N1} &  1 \\\\  \n                \\end{bmatrix} \\cdot \\begin{bmatrix} w_{1} \\\\\n                b\n                \\end{bmatrix} \\]\nIn numpy, consider converting a range of inputs into a data matrix like the one above:\n\nx = np.linspace(0, 5, 6) # Get range of inputs\nX = x[:, None]             # Convert vector into an Nx1 matrix\n# Add a column of 1s\nXaug = np.pad(X, [(0,0), (0,1)], constant_values=1.)\nprint(Xaug)\n\n[[0. 1.]\n [1. 1.]\n [2. 1.]\n [3. 1.]\n [4. 1.]\n [5. 1.]]\n\n\nThis gives us something we can pass into our prediction function."
  },
  {
    "objectID": "misc/hw2-hint.html#question-8",
    "href": "misc/hw2-hint.html#question-8",
    "title": "Hints for homework 2",
    "section": "Question 8",
    "text": "Question 8\nIf we want to split a matrix by its rows in numpy as follow:\n\\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} \\\\\nX_{21} & X_{22} \\\\\nX_{31} & X_{32} \\\\\nX_{41} & X_{42} \\\\\nX_{51} & X_{52} \\\\\n                \\end{bmatrix}\\longrightarrow \\begin{bmatrix} X_{11} & X_{12} \\\\\nX_{21} & X_{22} \\\\\nX_{31} & X_{32} \\\\\n\\end{bmatrix}, \\quad\n\\begin{bmatrix}\nX_{41} & X_{42} \\\\\nX_{51} & X_{52} \\\\\n                \\end{bmatrix}\\]\nWe can use the index operator [] as follows:\n\nX = np.random.randint(10, size=(5,2))\nprint(X)\n\n[[9 7]\n [2 0]\n [7 7]\n [4 1]\n [4 9]]\n\n\n\nprint(X[:3]) # Get first 3 rows\n\n[[9 7]\n [2 0]\n [7 7]]\n\n\n\nprint(X[3:]) # Get the rest of the rows\n\n[[4 1]\n [4 9]]"
  },
  {
    "objectID": "lecture10-normalization/notes.html",
    "href": "lecture10-normalization/notes.html",
    "title": "Lecture 10: Normalization",
    "section": "",
    "text": "In previous lectures we discussed what can happen if we make a neural network too wide, meaning that there are many neurons a each layer. We saw that as long as we are careful in how we initialize the parameters, we can prevent any issues that might arrive. Now we’ll consider what happens if we make our network too deep, that is we’ll increase the number of layers. Modern neural networks can have up to 100’s of layers, so it’s important to make sure that gradient descent will work well even in this extreme case.\nJust like before we’ll analyze the scale of the gradient to make sure that we’re not going to take any extreme steps as we go that might cause our learning to stall or even diverge. This time we’ll be a little less formal and only take a look at a high level view of what happens to the gradient as the number of layers increases, as the specifics can vary quite a bit from network to network.\nRecall that our neural network feature transform can be written as a composition of feature transform functions, one for each of the \\(\\ell\\) layers.\n\\[\\phi(\\mathbf{x}) = \\phi_\\ell(\\phi_{\\ell-1}(\\phi_{\\ell-2}(...\\phi_1(\\mathbf{x})...)))\\]\nIn practice each layer will be a linear transformation followed by an activation function like the \\(\\text{relu}(\\cdot)\\) or \\(\\sigma (\\cdot)\\) function.\n\\[\\phi(\\mathbf{x}) = \\text{relu}(\\text{relu}(\\text{relu}(...\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1...)^T\\mathbf{W}_{\\ell-1} + \\mathbf{b}_{\\ell-1})^T\\mathbf{W}_\\ell + \\mathbf{b}_\\ell)\\]\nWe’ll then generally make a prediction using a linear function this output and compute a loss by comparing this prediction to a true label using a metric like mean squared error:\n\\[f(\\mathbf{x}) = \\phi(\\mathbf{x})^T\\mathbf{w}_0 + b_0\\]\n\\[\n\\text{Loss}(\\mathbf{x}, y) = (f(\\mathbf{x}) - y)^2\n\\]\nWe can write our neural network loss as a series of operations:\n\\[\n\\Phi_1 = \\sigma(\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\Phi_2 = \\sigma(\\Phi_1^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\vdots\n\\]\n\\[\n\\Phi_\\ell = \\sigma(\\Phi_{\\ell-1}^T\\mathbf{W}_\\ell + \\mathbf{b}_\\ell)\n\\]\n\\[\n\\mathbf{f} = \\Phi_{\\ell-1}^T\\mathbf{W}_0 + \\mathbf{b}_0\n\\]\n\\[\n\\mathbf{L} = \\text{Loss}(\\mathbf{f}, y)\n\\] Now let’s consider the gradient of the loss with respect to \\(\\mathbf{W}_1\\) , the first set of weights used in the network. We can write this gradient using the chain rule as:\n\\[\\frac{d\\mathbf{L}}{d\\mathbf{W}_1}=\\frac{d\\mathbf{L}}{d\\Phi_\\ell}\\frac{d\\Phi_{\\ell}}{d\\Phi_{\\ell-1}}...\\frac{d\\Phi_2}{d\\Phi_1}\\frac{d\\Phi_1}{d\\mathbf{W}_1}\\]\nFor the sake of simplicity, we’ll consider the 1-dimensional case, so all our variables are scalars rather than vectors/matrices (\\(\\mathbf{W}_1\\) becomes \\(w_1\\), \\(\\mathbf{x}\\) becomes \\(x\\)). In this case we can rewrite this using a product and expanding \\(\\frac{d\\Phi_1}{dw_1}\\).\n\\[\\frac{d\\Phi_1}{dw_1}=x\\sigma'(xw_1 + b_1)\\] \\[\\frac{d\\mathbf{L}}{dw_1}=x\\sigma'(xw_1 + b_1)\\frac{d\\mathbf{L}}{d\\Phi_\\ell}\\prod_{i=2}^{\\ell}\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\]\n\\[\nw_1, x, \\frac{d\\Phi_0}{d\\Phi_1},... \\in \\mathbb{R}\n\\]\nFinally we can consider how this gradient grows/shrinks as we increase the number of layers. We don’t know exactly what the gradient of each layer will be, but given our initialization it’s reasonable to assume that they’re all relatively consistent. For example if we use a linear (no) activation the gradient we simply get:\\[\n\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}= \\frac{d}{d\\Phi_{i-1}}(\\Phi_{i-1}w_i + b_i)=  w_i, \\quad\n\\]We’ll use \\(M\\) to denote the approximate magnitude of each term in the product:\n\\[\\bigg|\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\bigg| \\approx M, \\forall i\\]\nNow it becomes clear that the scale of the gradient grows/shrinks exponentially with the number of layers \\((\\ell)\\)!\n\\[\\bigg|\\frac{dL}{dw_1}\\bigg| = |x| \\prod_{i=2}^{\\ell}\\bigg| \\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\bigg|... \\approx |x|\\big(\\textcolor{red}{M^L}\\big)...\\]\nTherefore we have two concerning possibilities: if \\(M\\) is larger than \\(1\\), our gradient could become extremely large. We call this an exploding gradient:\n\\[\\textbf{If: } M &gt; 1 \\longrightarrow \\frac{dL}{dw_1} &gt;&gt; 1\\]\nIf \\(M\\) is smaller than 1, our gradient could be very small. We call this a vanishing gradient:\n\\[\\textbf{If: } M &lt; 1 \\longrightarrow \\frac{df}{dw_L} \\approx 0\\]\nConcretely if we have a 100 layer network and \\(M=1.5\\) then \\(\\frac{d\\mathbf{L}}{dw_1}\\approx 4\\times10^{17}\\). If \\(M=0.75\\), then \\(\\frac{d\\mathbf{L}}{dw_1}\\approx 3\\times10^{-13}\\). Only in the case where \\(M\\approx 1\\) do we have a stable gradient scale.\nIt’s tempting to think we could just initialize our weights carefully such that \\(M\\approx 1\\) or change our learning rate to counteract this scale. Unfortunately, once we start updating our network weights with gradient descent, \\(M\\) could change and we could easily move from one regime to another. Geometrically, this problem corresponds to a loss function that has both very steep slopes and very flat plateaus.\n\n\n\nLet’s start by looking at a very simple method to address the exploding gradient problem. Instead of scaling the gradient by a fixed amount, we’ll set a cap \\((\\epsilon)\\) on the size of step that we can take. If gradient exceeds that maximum step, we’ll simply try to re-scale it to the desired length. We call this approach gradient clipping. We’ll define two slightly different operations to clip a vector to a given length. If our gradient is actually a matrix or a collection of vectors/matrices, we could always flatten all the individual partial derivatives into one big, long vector to apply the clipping operation.\nWe’ll call our first approach clip-by-value. In this case, we will simply limit the value of any individual entry in our vector to be no more than \\(\\epsilon\\) and no less than \\(-\\epsilon\\). We can write this mathematically as:\n\\[\\textbf{clip}_{\\text{value}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{bmatrix} \\min(\\max(x_1, -\\epsilon), \\epsilon) \\\\ \\min(\\max(x_2, - \\epsilon), \\epsilon) \\\\ \\vdots \\end{bmatrix}\\]\nGeometrically, this corresponds to restricting \\(\\mathbf{x}\\) to a box centered at the origin.\nFor our second approach, rather than considering each dimension individually, we’ll restrict the overall length (magnitude) of the vector, while maintaining the direction. Remember that we define the length of a vector by its 2-norm: \\(||\\mathbf{x}||_2 = \\sqrt{\\sum_{i=1}^d x_i^2}\\), therefore we call this approach clip-by-norm. If we want to re-scale our vector to have length \\(\\epsilon\\) we simply need to divide each entry by \\(||\\mathbf{x}||_2\\) and multiply by \\(\\epsilon\\), therefore our clipping operation will look like:\n\\[\\textbf{clip}_{\\text{norm}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{cases}\n\\frac{\\epsilon\\mathbf{x} }{\\| \\mathbf{x} \\|_2} \\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 &gt; \\epsilon \\\\\n\\mathbf{x} \\  \\quad\\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 \\leq \\epsilon\n\\end{cases}\\]\nApplying either of these clipping operations within gradient descent would look like this:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha\\ \\textbf{clip}\\big(\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\big)\\]\nAs a final note, we don’t want to re-scale gradients smaller than length \\(\\epsilon\\) to be larger, because ultimately our gradient should have length 0 at the optimum. This means we may need an alternative way to handle vanishing gradients. We’ll come back to this!"
  },
  {
    "objectID": "lecture10-normalization/notes.html#vanishing-and-exploding-gradients",
    "href": "lecture10-normalization/notes.html#vanishing-and-exploding-gradients",
    "title": "Lecture 10: Normalization",
    "section": "",
    "text": "In previous lectures we discussed what can happen if we make a neural network too wide, meaning that there are many neurons a each layer. We saw that as long as we are careful in how we initialize the parameters, we can prevent any issues that might arrive. Now we’ll consider what happens if we make our network too deep, that is we’ll increase the number of layers. Modern neural networks can have up to 100’s of layers, so it’s important to make sure that gradient descent will work well even in this extreme case.\nJust like before we’ll analyze the scale of the gradient to make sure that we’re not going to take any extreme steps as we go that might cause our learning to stall or even diverge. This time we’ll be a little less formal and only take a look at a high level view of what happens to the gradient as the number of layers increases, as the specifics can vary quite a bit from network to network.\nRecall that our neural network feature transform can be written as a composition of feature transform functions, one for each of the \\(\\ell\\) layers.\n\\[\\phi(\\mathbf{x}) = \\phi_\\ell(\\phi_{\\ell-1}(\\phi_{\\ell-2}(...\\phi_1(\\mathbf{x})...)))\\]\nIn practice each layer will be a linear transformation followed by an activation function like the \\(\\text{relu}(\\cdot)\\) or \\(\\sigma (\\cdot)\\) function.\n\\[\\phi(\\mathbf{x}) = \\text{relu}(\\text{relu}(\\text{relu}(...\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1...)^T\\mathbf{W}_{\\ell-1} + \\mathbf{b}_{\\ell-1})^T\\mathbf{W}_\\ell + \\mathbf{b}_\\ell)\\]\nWe’ll then generally make a prediction using a linear function this output and compute a loss by comparing this prediction to a true label using a metric like mean squared error:\n\\[f(\\mathbf{x}) = \\phi(\\mathbf{x})^T\\mathbf{w}_0 + b_0\\]\n\\[\n\\text{Loss}(\\mathbf{x}, y) = (f(\\mathbf{x}) - y)^2\n\\]\nWe can write our neural network loss as a series of operations:\n\\[\n\\Phi_1 = \\sigma(\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\Phi_2 = \\sigma(\\Phi_1^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\vdots\n\\]\n\\[\n\\Phi_\\ell = \\sigma(\\Phi_{\\ell-1}^T\\mathbf{W}_\\ell + \\mathbf{b}_\\ell)\n\\]\n\\[\n\\mathbf{f} = \\Phi_{\\ell-1}^T\\mathbf{W}_0 + \\mathbf{b}_0\n\\]\n\\[\n\\mathbf{L} = \\text{Loss}(\\mathbf{f}, y)\n\\] Now let’s consider the gradient of the loss with respect to \\(\\mathbf{W}_1\\) , the first set of weights used in the network. We can write this gradient using the chain rule as:\n\\[\\frac{d\\mathbf{L}}{d\\mathbf{W}_1}=\\frac{d\\mathbf{L}}{d\\Phi_\\ell}\\frac{d\\Phi_{\\ell}}{d\\Phi_{\\ell-1}}...\\frac{d\\Phi_2}{d\\Phi_1}\\frac{d\\Phi_1}{d\\mathbf{W}_1}\\]\nFor the sake of simplicity, we’ll consider the 1-dimensional case, so all our variables are scalars rather than vectors/matrices (\\(\\mathbf{W}_1\\) becomes \\(w_1\\), \\(\\mathbf{x}\\) becomes \\(x\\)). In this case we can rewrite this using a product and expanding \\(\\frac{d\\Phi_1}{dw_1}\\).\n\\[\\frac{d\\Phi_1}{dw_1}=x\\sigma'(xw_1 + b_1)\\] \\[\\frac{d\\mathbf{L}}{dw_1}=x\\sigma'(xw_1 + b_1)\\frac{d\\mathbf{L}}{d\\Phi_\\ell}\\prod_{i=2}^{\\ell}\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\]\n\\[\nw_1, x, \\frac{d\\Phi_0}{d\\Phi_1},... \\in \\mathbb{R}\n\\]\nFinally we can consider how this gradient grows/shrinks as we increase the number of layers. We don’t know exactly what the gradient of each layer will be, but given our initialization it’s reasonable to assume that they’re all relatively consistent. For example if we use a linear (no) activation the gradient we simply get:\\[\n\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}= \\frac{d}{d\\Phi_{i-1}}(\\Phi_{i-1}w_i + b_i)=  w_i, \\quad\n\\]We’ll use \\(M\\) to denote the approximate magnitude of each term in the product:\n\\[\\bigg|\\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\bigg| \\approx M, \\forall i\\]\nNow it becomes clear that the scale of the gradient grows/shrinks exponentially with the number of layers \\((\\ell)\\)!\n\\[\\bigg|\\frac{dL}{dw_1}\\bigg| = |x| \\prod_{i=2}^{\\ell}\\bigg| \\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\bigg|... \\approx |x|\\big(\\textcolor{red}{M^L}\\big)...\\]\nTherefore we have two concerning possibilities: if \\(M\\) is larger than \\(1\\), our gradient could become extremely large. We call this an exploding gradient:\n\\[\\textbf{If: } M &gt; 1 \\longrightarrow \\frac{dL}{dw_1} &gt;&gt; 1\\]\nIf \\(M\\) is smaller than 1, our gradient could be very small. We call this a vanishing gradient:\n\\[\\textbf{If: } M &lt; 1 \\longrightarrow \\frac{df}{dw_L} \\approx 0\\]\nConcretely if we have a 100 layer network and \\(M=1.5\\) then \\(\\frac{d\\mathbf{L}}{dw_1}\\approx 4\\times10^{17}\\). If \\(M=0.75\\), then \\(\\frac{d\\mathbf{L}}{dw_1}\\approx 3\\times10^{-13}\\). Only in the case where \\(M\\approx 1\\) do we have a stable gradient scale.\nIt’s tempting to think we could just initialize our weights carefully such that \\(M\\approx 1\\) or change our learning rate to counteract this scale. Unfortunately, once we start updating our network weights with gradient descent, \\(M\\) could change and we could easily move from one regime to another. Geometrically, this problem corresponds to a loss function that has both very steep slopes and very flat plateaus."
  },
  {
    "objectID": "lecture10-normalization/notes.html#gradient-clipping",
    "href": "lecture10-normalization/notes.html#gradient-clipping",
    "title": "Lecture 10: Normalization",
    "section": "",
    "text": "Let’s start by looking at a very simple method to address the exploding gradient problem. Instead of scaling the gradient by a fixed amount, we’ll set a cap \\((\\epsilon)\\) on the size of step that we can take. If gradient exceeds that maximum step, we’ll simply try to re-scale it to the desired length. We call this approach gradient clipping. We’ll define two slightly different operations to clip a vector to a given length. If our gradient is actually a matrix or a collection of vectors/matrices, we could always flatten all the individual partial derivatives into one big, long vector to apply the clipping operation.\nWe’ll call our first approach clip-by-value. In this case, we will simply limit the value of any individual entry in our vector to be no more than \\(\\epsilon\\) and no less than \\(-\\epsilon\\). We can write this mathematically as:\n\\[\\textbf{clip}_{\\text{value}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{bmatrix} \\min(\\max(x_1, -\\epsilon), \\epsilon) \\\\ \\min(\\max(x_2, - \\epsilon), \\epsilon) \\\\ \\vdots \\end{bmatrix}\\]\nGeometrically, this corresponds to restricting \\(\\mathbf{x}\\) to a box centered at the origin.\nFor our second approach, rather than considering each dimension individually, we’ll restrict the overall length (magnitude) of the vector, while maintaining the direction. Remember that we define the length of a vector by its 2-norm: \\(||\\mathbf{x}||_2 = \\sqrt{\\sum_{i=1}^d x_i^2}\\), therefore we call this approach clip-by-norm. If we want to re-scale our vector to have length \\(\\epsilon\\) we simply need to divide each entry by \\(||\\mathbf{x}||_2\\) and multiply by \\(\\epsilon\\), therefore our clipping operation will look like:\n\\[\\textbf{clip}_{\\text{norm}}\\big(\\mathbf{x}, \\epsilon\\big) = \\begin{cases}\n\\frac{\\epsilon\\mathbf{x} }{\\| \\mathbf{x} \\|_2} \\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 &gt; \\epsilon \\\\\n\\mathbf{x} \\  \\quad\\quad & \\textbf{if: } \\|\\mathbf{x}\\|_2 \\leq \\epsilon\n\\end{cases}\\]\nApplying either of these clipping operations within gradient descent would look like this:\n\\[ \\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha\\ \\textbf{clip}\\big(\\nabla_{\\mathbf{w}} \\textbf{Loss}(\\mathbf{w}^{(k)}, \\mathbf{X}, \\mathbf{y})\\big)\\]\nAs a final note, we don’t want to re-scale gradients smaller than length \\(\\epsilon\\) to be larger, because ultimately our gradient should have length 0 at the optimum. This means we may need an alternative way to handle vanishing gradients. We’ll come back to this!"
  },
  {
    "objectID": "lecture10-normalization/notes.html#input-scaling",
    "href": "lecture10-normalization/notes.html#input-scaling",
    "title": "Lecture 10: Normalization",
    "section": "Input scaling",
    "text": "Input scaling\nReturning to our analysis of the gradient magnitude above we see that there’s another term that affects the scale of our gradient, \\(|x|\\), the scale of our input features!\n\\[\\bigg|\\frac{dL}{dw_1}\\bigg| = |x| \\prod_{i=2}^{\\ell}\\bigg| \\frac{d\\Phi_{i}}{d\\Phi_{i-1}}\\bigg|... \\approx |x|\\big(\\textcolor{red}{M^L}\\big)...\\]\nUnlike the initial values of our parameters, we don’t choose our data, so there’s nothing that prevents the scale of \\(x\\) itself from being very large or very small. Ideally we’d like a predictable scale for our data so that we can set things our learning rate more easily.\nMoreover, as we saw in our discussion of RMSProp optimization mismatch in scale between dimensions can also cause optimization issues even if the difference is not exponentially large! This is quite common in practice; in our initial fuel economy example we saw that each car had weight measurements in the range of 1000-4000lbs and acceleration measurements in the range of 5-10sec. While RMSProp can help, it would be ideal if we could re-scale our data to eliminate these differences before we even start running gradient descent."
  },
  {
    "objectID": "lecture10-normalization/notes.html#input-centering",
    "href": "lecture10-normalization/notes.html#input-centering",
    "title": "Lecture 10: Normalization",
    "section": "Input centering",
    "text": "Input centering\nBefore we get to how to re-scale our data, let’s consider one other way that an unexpected data distribution could break the assumptions that we used when designing a neural network. When we first introduced a neural network feature transform, we showed that in order for it to give us an improvement over a linear model, we needed to introduce non-linear activation functions into the network.\n\\[\n\\phi(x) = {\\color{red}\\sigma}(\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\nIn order for these activation to be useful however, our inputs need to be centered around \\(0\\). If we plot our common choices for activation functions we can see why.\nStarting with the \\(\\text{relu}\\) function, we see that if all observed inputs are positive, then the function is linear over the entire range of inputs. Conversely, if all observed inputs are negative, we’re even worse off; we’ll never get outputs other than \\(0\\)! It’s only when our data spans both positive and negative values that our prediction function will look non-linear.\nFor the sigmoid function, \\(\\sigma(\\cdot)\\), we have a similar story. In this case, if all observations are much larger than \\(0\\), the function will always output 1. That is: \\(\\sigma(x)\\approx 1 \\text{ if }x &gt;&gt; 0\\ \\forall x\\), while if all the observations are far below \\(0\\), the function will output \\(0\\); \\(\\sigma(x)\\approx 0 \\text{ if }x &lt;&lt; 0\\ \\forall x\\). In this case we also see that the variance of the data matters; if all the data is too close to \\(0\\), the function again looks linear; \\(\\sigma(x)\\approx x \\text{ if }|x| &lt;&lt; 1\\ \\forall x\\)."
  },
  {
    "objectID": "lecture10-normalization/notes.html#input-normalization",
    "href": "lecture10-normalization/notes.html#input-normalization",
    "title": "Lecture 10: Normalization",
    "section": "Input normalization",
    "text": "Input normalization\nUltimately we’ve seen that we’d like our data to be centered around \\(0\\) and to have a predictable scale. One way to say this more formally is that we want the mean (expectation) of our data to be \\(0\\) and the variance of our data to be a known constant, usually \\(1\\). So we’d like:\n\\[\n\\mathbb{E}[x]=0, \\quad \\text{Var}[x]=1\n\\]\nA simple way to achieve this is to normalize our data. That is, for every observation we’ll apply a transformation that subtracts the mean and divides by the square root of the variance.\n\\[\n\\text{Norm}(x) = \\frac{x-\\mathbb{E}[x]}{\\sqrt{\\text{Var}[x]}}\n\\]\nBy definition the expectation of this transformed value is \\(0\\) and the variance is \\(1\\)!\n\\[\n\\mathbb{E}[\\text{Norm}(x)]= \\mathbb{E}\\bigg[ \\frac{x-\\mathbb{E}[x]}{\\sqrt{\\text{Var}[x]}} \\bigg]=\\frac{\\mathbb{E}\\big[ x-\\mathbb{E}[x] \\big]}{\\sqrt{\\text{Var}[x]}}=\\frac{\\mathbb{E}[x]-\\mathbb{E}[x]}{\\sqrt{\\text{Var}[x]}}=0\n\\]\n\\[\n\\text{Var}[\\text{Norm}(x)]= \\text{Var}\\bigg[ \\frac{x-\\mathbb{E}[x]}{\\sqrt{\\text{Var}[x]}} \\bigg]=\\frac{\\text{Var}\\big[ x-\\mathbb{E}[x] \\big]}{(\\sqrt{\\text{Var}[x]})^2}=\\frac{\\text{Var}[x]-0}{\\text{Var}[x]}=1\n\\]\nNote that in this case, we’ve framed things in terms of scalar inputs \\(x\\). If our inputs are vectors, \\(\\mathbf{x}\\), we’ll just do the same thing for each dimension.\n\\[\n\\text{Norm}(\\mathbf{x}) = \\begin{bmatrix} \\frac{x_1-\\mathbb{E}[x_1]}{\\sqrt{\\text{Var}[x_1]}} \\\\ \\frac{x_2-\\mathbb{E}[x_2]}{\\sqrt{\\text{Var}[x_2]}} \\\\ \\vdots \\end{bmatrix} = \\frac{\\mathbf{x}-\\mathbb{E}[\\mathbf{x}]}{\\sqrt{\\text{Var}[\\mathbf{x}]}}\n\\]\nIn this case we’ll train \\(\\mathbb{E}[\\mathbf{x}]\\) and \\(\\text{Var}[\\mathbf{x}]\\) as the element-wise mean and variance."
  },
  {
    "objectID": "lecture10-normalization/notes.html#estimating-data-statistics",
    "href": "lecture10-normalization/notes.html#estimating-data-statistics",
    "title": "Lecture 10: Normalization",
    "section": "Estimating data statistics",
    "text": "Estimating data statistics\nUnfortunately, we don’t know the true mean and variance of the data, as our training data doesn’t likely doesn’t encompass all the data in the world. So we’ll typically we’ll estimate the mean and variance using what we have.\nRecall that sample mean, \\(\\mathbf{\\bar{x}}\\), gives us the optimal estimate of the expectation for a given sample of values. In this case we can compute the sample mean over our dataset.\n\\[\\text{Dataset: } \\{\\mathbf{x}_1, \\mathbf{x}_2,...,\\mathbf{x}_N\\}\\]\n\\[\\mathbb{E}[\\mathbf{x}] \\approx \\bar{\\mathbf{x}} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{x}_i\\quad \\text{(sample mean)}\\]\nSimilarly, the sample variance, \\(\\mathbf{s}^2\\) can be used as a good estimate of the true variance. There are actually two common ways to compute the sample variance. The biased estimator:\n\\[\\text{Var}[\\mathbf{x}] \\approx \\mathbf{s}^2 = \\frac{1}{N}\\sum_{i=1}^{N} \\bigg(\\mathbf{x}_i - \\bigg(\\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{x}_i\\bigg)\\bigg)^2\\quad \\text{(biased sample var.)}\\]\nand the unbiased estimator:\n\\[\\text{Var}[\\mathbf{x}] \\approx \\mathbf{s}^2 = \\frac{1}{N-1}\\sum_{i=1}^{N} \\bigg(\\mathbf{x}_i - \\bigg(\\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{x}_i\\bigg)\\bigg)^2\\quad \\text{(sample var.)}\\]\nThe differences between these two versions aren’t too important for our purposes, so we’ll leave that discussion for a statistics course. Both are commonly used in neural network applications and usually perform basically identically in practice.\nNow we can re-define our normalization operation to use this sample mean and variance:\n\\[\\text{Norm}(x) = \\frac{ x - \\bar{x}}{\\sqrt{s^2}}\\]"
  },
  {
    "objectID": "lecture10-normalization/notes.html#batch-normalization",
    "href": "lecture10-normalization/notes.html#batch-normalization",
    "title": "Lecture 10: Normalization",
    "section": "Batch normalization",
    "text": "Batch normalization\nIn some cases, if may not be practical to compute the estimates of the mean and variance over the entire dataset ahead of time (e.g. if we’re streaming date from an external source). In this case we can apply batch normalization. In this case the operation we perform will look almost exactly like our normalization operation, but we’ll compute the statistics over the current batch that we’re using for stochastic gradient descent.\n\\[\n\\text{BatchNorm}(x) = \\frac{ x - \\bar{x}}{\\sqrt{s^2 + \\epsilon}}\n\\] \\[\\text{Batch: } \\{\\mathbf{x}_1, \\mathbf{x}_2,...,\\mathbf{x}_B\\}\\] \\[\\mathbb{E}[\\mathbf{x}] \\approx \\bar{\\mathbf{x}} = \\frac{1}{B}\\sum_{i=1}^{B} \\mathbf{x}_i\\quad \\text{(sample mean)}\\] \\[\\text{Var}[\\mathbf{x}] \\approx  \\mathbf{s}^2 = \\frac{1}{B-1}\\sum_{i=1}^{B} \\bigg(\\mathbf{x}_i - \\bigg(\\frac{1}{B}\\sum_{i=1}^{B} \\mathbf{x}_i\\bigg)\\bigg)^2\\quad \\text{(sample var.)}\\]\nIn this case we’ll also in include a small constant \\(\\epsilon &lt;&lt; 1\\) in the denominator of the transform, just as we did in RMSProp to prevent division by \\(0\\) if we happen to sample a batch with \\(0\\) variance."
  },
  {
    "objectID": "lecture10-normalization/notes.html#distribution-shift",
    "href": "lecture10-normalization/notes.html#distribution-shift",
    "title": "Lecture 10: Normalization",
    "section": "Distribution shift",
    "text": "Distribution shift\nYou might notice that even if we transform our data to have \\(\\mathbb{E}[\\mathbf{x}]=0\\) and \\(\\text{Var}[\\mathbf{x}]=1\\), once our data goes through several layers:\n\\[\n\\Phi_1 = \\sigma(\\mathbf{x}^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\Phi_2 = \\sigma(\\Phi_1^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\vdots\n\\]\n\\[\n\\Phi_i = \\sigma(\\Phi_{i-1}^T\\mathbf{W}_i + \\mathbf{b}_i)\n\\]\nthis may no longer hold. That is, we may find that \\(\\mathbb{E}[\\Phi_{i}]\\neq 0\\), \\(\\text{Var}[\\Phi_{i}]\\neq 1\\). Again, we could carefully tune our initialization to avoid this at first, but once we start changing the weights in gradient descent, we could quickly drift away, particularly if the number of layers is large. This means that layer \\(i+1\\) may run into exactly the same issues we identified above.\n\\[\n\\Phi_{i+1} = \\sigma(\\Phi_{i}^T\\mathbf{W}_{i+1} + \\mathbf{b}_{i+1})\n\\]\nEven worse, we might find that not only does the distribution of \\(\\Phi_i\\) not have our desired mean and variance, its distribution could change dramatically every time we update the weights!\nRemember that at step \\(k\\) we’ll update the weights \\(\\mathbf{W}_{i+1}\\) according to the current input \\(\\Phi_i^{(k)}\\):\n\\[\n\\mathbf{W}_{i+1}^{(k+1)} \\longleftarrow \\mathbf{W}_{i+1}^{(k)} - \\alpha \\Phi_{i}^{(k)}\\sigma'(\\Phi_{i}^{(k)}\\mathbf{W}_{i+1} + \\mathbf{b}_{i+1})\n\\]\nBut since we’re also updating \\(\\{\\mathbf{W}_{1},\\mathbf{b}_1,...,\\mathbf{W}_{i},\\mathbf{b}_i \\}\\) at the same time, when we go to make a prediction, may find that the distribution of \\(\\Phi_{i}\\) has changed and our gradient step for \\(\\mathbf{W}_{i+1}\\) looks bad in hindsight. We call this problem distribution shift. Updating the weights sequentially might help avoid this issue, but would be very very slow. Instead we can use the normalization tool we just discussed to force the distribution of \\(\\Phi_{i}\\) to have the properties we want.\nIn other words, we can apply normalization at every layer!"
  },
  {
    "objectID": "lecture10-normalization/notes.html#batch-normalization-in-multiple-layers",
    "href": "lecture10-normalization/notes.html#batch-normalization-in-multiple-layers",
    "title": "Lecture 10: Normalization",
    "section": "Batch normalization in multiple layers",
    "text": "Batch normalization in multiple layers\nSince the distribution of \\(\\Phi_{i}\\) will change as we update the weights \\(\\{\\mathbf{W}_{1},\\mathbf{b}_1,...,\\mathbf{W}_{i},\\mathbf{b}_i \\}\\), we’ll need to continuously update our estimates of \\(\\mathbb{E}[\\Phi_i]\\) and \\(\\text{Var}[\\Phi_i]\\) as well. Meaning that if we’re using mini-batch stochastic gradient descent, we’ll also want to use batch-noramlization to avoid recomputing the mean and variance at each layer for the whole dataset at every step. With the addition of batch normalization operations (\\(BN(\\cdot)\\)), our network will now be computed as: \\[\n\\Phi_1 = \\sigma(BN(\\mathbf{X})^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\Phi_2 = \\sigma(BN(\\Phi_1)^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\vdots\n\\]\n\\[\n\\Phi_\\ell = \\sigma(BN(\\Phi_{\\ell-1})^T\\mathbf{W}_\\ell + \\mathbf{b}_\\ell)\n\\]\n\\[\n\\mathbf{f} = BN(\\Phi_{\\ell-1})^T\\mathbf{W}_0 + \\mathbf{b}_0\n\\]\n\\[\n\\mathbf{L} = \\text{Loss}(\\mathbf{f}, y)\n\\]"
  },
  {
    "objectID": "lecture10-normalization/notes.html#batch-normalization-at-test-time",
    "href": "lecture10-normalization/notes.html#batch-normalization-at-test-time",
    "title": "Lecture 10: Normalization",
    "section": "Batch normalization at test time",
    "text": "Batch normalization at test time\nSo far we’ve made an implicit assumption for batch normalization that the size of our batch is larger than one: \\(B&gt;1\\). If \\(B=1\\), we run into some issues with out mean and variance estimates: \\[\\bar{\\mathbf{x}}= \\frac{1}{1}\\sum_{i=1}^1 \\mathbf{x}_1 = \\mathbf{x}_1 \\longrightarrow \\mathbf{x}_1 - \\mathbf{\\bar{x}} = 0\\] \\[\\mathbf{s}^2= \\frac{1}{0}\\sum_{i=1}^1 (\\mathbf{x}_1 - \\mathbf{x}_1)^2= \\frac{0}{0}=\\mathbf{?}\\] \\[\\text{BatchNorm}(x) = \\frac{0}{\\sqrt{\\mathbf{?} + \\epsilon}}\\]\nEven if we to use the biased variance estimator, we’d still get a divide by 0 error in out batch norm calculation!\nThis isn’t too big a deal when we’re training our network; we can just always make sure out batch size is \\(&gt;1\\) if we’re using batch norm. The problem is that we want others to be able to use our network we can’t enforce that they must use a batch size of more than one. After all, in practice if I want to use a neural network to, for example, identify a species of flower in a photo, I shouldn’t need to give it 9 other photos of flowers just to make one prediction!\nEven if we could force users to give our network multiple examples, it could be difficult to enforce that the sample batch they chose was truely random. If the selection of the batch is biased, it could throw off the mean and variance estimates we need!\nThe solution often used in practice is to define batch normalization differently depending on whether we’re training the network or testing it on new data. At training time we can keep the same approarch from before.\nHowever, we’ll also keep track of a running average of the sample mean and sample variance that we observe at each step. We’ll use the same exponential moving average approach we\n\\[\\underset{\\text{train}}{\\text{BatchNorm}}(x) = \\frac{ x - \\bar{x}}{\\sqrt{s^2 + \\epsilon}}\\]\nRunning estimate: \\[\\bar{\\mu}^{(k+1)} \\longleftarrow \\beta \\bar{\\mu}^{(k)} + (1-\\beta) \\bar{x}^{(k)}\\] \\[\\bar{\\sigma}^{2(k+1)} \\longleftarrow \\beta \\bar{\\sigma}^{2(k)} + (1-\\beta) s^{2(k)}\\]\n\\[\\underset{\\text{test}}{\\text{BatchNorm}}(x) = \\frac{ x - \\bar{\\mu}}{\\sqrt{\\bar{\\sigma}^2 + \\epsilon}}\\]"
  },
  {
    "objectID": "lecture10-normalization/notes.html#layer-normalization",
    "href": "lecture10-normalization/notes.html#layer-normalization",
    "title": "Lecture 10: Normalization",
    "section": "Layer normalization",
    "text": "Layer normalization\nNormalize over the layer:\n\\[\\text{LayerNorm}(\\mathbf{x}) = \\frac{\\mathbf{x} - \\bar{x}}{\\sqrt{s^2 + \\epsilon}}, \\quad \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_d\\end{bmatrix}\\]\nTraining & test time: \\[\\bar{x} = \\frac{1}{d}\\sum_{i=1}^{d} x_i\\quad \\text{(output mean)}\\] Biased estimator: \\[s^2 = \\frac{1}{d}\\sum_{i=1}^{d} \\bigg(x_i - \\bigg(\\frac{1}{d}\\sum_{i=1}^{d} x_i\\bigg)\\bigg)^2\\quad \\text{(output var.)}\\] Unbiased estimator: \\[s^2 = \\frac{1}{d-1}\\sum_{i=1}^{d} \\bigg(x_i - \\bigg(\\frac{1}{d}\\sum_{i=1}^{d} x_i\\bigg)\\bigg)^2\\quad \\text{(output var.)}\\]"
  },
  {
    "objectID": "lecture10-normalization/notes.html#scaled-normalization",
    "href": "lecture10-normalization/notes.html#scaled-normalization",
    "title": "Lecture 10: Normalization",
    "section": "Scaled normalization",
    "text": "Scaled normalization\n\\[\\text{BatchNorm}(x) = \\frac{ x - \\mathbb{E}[x]}{\\sqrt{\\text{Var}[x] + \\epsilon}} \\gamma + \\kappa\\] \\[\\text{LayerNorm}(\\mathbf{x}) = \\frac{\\mathbf{x} - \\bar{x}}{\\sqrt{s^2 + \\epsilon}} \\gamma + \\kappa\\]"
  },
  {
    "objectID": "assignments/final-project/ethics.html",
    "href": "assignments/final-project/ethics.html",
    "title": "Ethics and AI Assignment",
    "section": "",
    "text": "In this assignment you will read and reflect on a fictional case study regarding the ethical implications of AI tools. While these cases are fictional, they are inspired by real issues. You may find yourself confronting similar scenerios in your future career, so it’s worth thinking about how to address ethical concerns now!\nFor your final project report, you will also be asked to discuss what real-world ethical concerns could arise from the types of tools you develop."
  },
  {
    "objectID": "assignments/final-project/ethics.html#due-wednesday-28-1159pm",
    "href": "assignments/final-project/ethics.html#due-wednesday-28-1159pm",
    "title": "Ethics and AI Assignment",
    "section": "",
    "text": "In this assignment you will read and reflect on a fictional case study regarding the ethical implications of AI tools. While these cases are fictional, they are inspired by real issues. You may find yourself confronting similar scenerios in your future career, so it’s worth thinking about how to address ethical concerns now!\nFor your final project report, you will also be asked to discuss what real-world ethical concerns could arise from the types of tools you develop."
  },
  {
    "objectID": "assignments/final-project/ethics.html#part-1-form-project-groups",
    "href": "assignments/final-project/ethics.html#part-1-form-project-groups",
    "title": "Ethics and AI Assignment",
    "section": "Part 1: Form project groups",
    "text": "Part 1: Form project groups\nForm a group of 2-4 students (ideally 3). This will also be your group for the final project. Create your group on Gradescope for the Ethics and AI assignment.\nThe writeups for this assignment should be done by the group members, however you are welcome (and encouraged) to involve anyone in the discussions!"
  },
  {
    "objectID": "assignments/final-project/ethics.html#part-2-choose-a-case-study",
    "href": "assignments/final-project/ethics.html#part-2-choose-a-case-study",
    "title": "Ethics and AI Assignment",
    "section": "Part 2: Choose a case study",
    "text": "Part 2: Choose a case study\nHere is a quick summary of the six available case studies provided by the Princeton Dialogues on AI and Ethics. Your group should choose one of them, based on the following descriptions.\n\nCase Study 1: Automated Healthcare App\nA team of medical researchers and computer scientists develop an app that utilizes artificial intelligence technologies to make diabetic care easier, more holistic and more accessible.\n\n\nCase Study 2: Dynamic Sound Identification\nAn R&D company develops an app that can identify information from sound. For example, personal information about those speaking, links to websites selling a product being advertised on television, encyclopedic entries about bird calls in the wild and other relevant resources.\n\n\nCase Study 3: Optimizing Schools\nA public high school contracts a data science company and gives them access to student behavioral data (attendance, purchases, library usage, movement on campus, etc.) so that they can predict which students are at-risk of dropping out.\n\n\nCase Study 4: Law Enforcement Chatbots\nA country’s federal law enforcement agency teams up with University researchers to develop a chatbot that could be used to identify cybercriminals.\n\n\nCase Study 5: Hiring By Machine\nA group of military veterans create a non-profit company that makes software for veterans transitioning back to civilian life. The company strongly believes in open-source and hiring veterans.\n\n\nCase Study 6: Public Sector Data Analytics\nA once-prosperous city contracts with a consulting group to use an algorithmic, data-driven approach to reduce crime."
  },
  {
    "objectID": "assignments/final-project/ethics.html#part-3-consider-possible-issues",
    "href": "assignments/final-project/ethics.html#part-3-consider-possible-issues",
    "title": "Ethics and AI Assignment",
    "section": "Part 3: Consider possible issues",
    "text": "Part 3: Consider possible issues\nBefore getting into reading the case study you chose, pause and think about what ethical issues might arise. Below are some common categories of ethical issues, several of which may apply to your chosen case. Choose 3 of these categories and, in the Gradscope assignment, list the categories you chose and explain (in 2-3 sentences) why, based on the case study description, your group felt these issues might be important for the case. (Note that there is not a wrong or right answer to this, just explain your reasoning)\n\nIssues with oversight and accountability\n\nWhich laws and regulations might be applicable to this project?\nHow is ethical accountability being achieved?\n\n\n\nIssues with data privacy and anonymity\n\nHow might the legal rights of organizations and individuals be impinged by our use of the data?\nHow might individuals’ privacy and anonymity be impinged via aggregation and linking of the data?\n\n\n\nIssues with data availability and validity\n\nHow do you know that the data is ethically available for its intended use?\nHow do you know that the data is valid for its intended use?\n\n\n\nIssues with model bias\n\nHow have we identified and minimized any bias in the data or in the model?\nHow was any potential modeler bias identified and then, if appropriate, mitigated?\n\n\n\nIssues with model transparency and interpretation\n\nHow transparent does the model need to be and how is that transparency achieved?\nWhat are likely misinterpretations of the results and what can be done to prevent those misinterpretations?\n\nThese issue categories are from Integrating Ethics within Machine Learning Courses | ACM Transactions on Computing Education by J. Saltz et al."
  },
  {
    "objectID": "assignments/final-project/ethics.html#part-4-read-and-discuss-your-case-study",
    "href": "assignments/final-project/ethics.html#part-4-read-and-discuss-your-case-study",
    "title": "Ethics and AI Assignment",
    "section": "Part 4: Read and discuss your case study",
    "text": "Part 4: Read and discuss your case study\nIn the case study you chose, you will find anywhere from three to seven discussion questions. Please read the case study individually, but pause at each discussion question and discuss them as a group. On Gradescope, summarize your group’s discussion for each question in 1-2 paragraphs.\nNow read through your chosen case study PDF. (It is okay to choose a new one if you decide you don’t like the one you’ve chosen after you’ve started reading it.)\nEach case study PDF includes a “Reflections & Discussion Questions” section near the end. You should read through these individually, and you can optionally choose to discuss them as a group. Note that you do not need to report on your discussions for this part of the case study PDFs.\nOnce you’ve completed this part you are finished with the Gradescope assignment!"
  },
  {
    "objectID": "assignments/final-project/ethics.html#part-5-in-class-discussion",
    "href": "assignments/final-project/ethics.html#part-5-in-class-discussion",
    "title": "Ethics and AI Assignment",
    "section": "Part 5: In-class discussion",
    "text": "Part 5: In-class discussion\nBe prepared to discuss your case in class. Depending on availble time, we may have an oppurtunity to discuss the cases in class."
  },
  {
    "objectID": "assignments/final-project/rubric.html",
    "href": "assignments/final-project/rubric.html",
    "title": "Final project rubric",
    "section": "",
    "text": "+1 Includes abstract\n+2 Summarizes goal of the project and method\n+1 Summarizes conclusions and results in 1-2 sentences\n+1 Clear and concise writing\n\n\n\n+5 Introduction to the goal of the project, why you are trying to solve it and how it could be used in practice.\n+5 Introduces at least 1-2 pieces of related work that form the basis for the project, including at least 1-2 sentences about what method/data each introduced and what they showed. Cites related work appropriately.\n\n\n\n+4 Clearly describes each dataset used and why it was chosen.\n+1 Provides citation and link to each dataset’s source.\n+4 Provides a summary of each dataset including the size, class distribution (if applicable), and format of each observation.\n+1 Clearly describes the training/validation/test split for each dataset.\n\n\n\n+10 Includes precise and correct mathematical formulations for the loss functions used and/or formulations and pseudocode for new algorithms introduced. If the method is an architecture (e.g. U-Nets or Vision transformers) this should be a precise discussion of how it differs from the networks we’ve used so far and what the relevant (hyper) parameters are.\n+10 Includes a clear description of the goals and intuition for the formulated approach. A student in this class should understand why the given formulation makes sense and how to replicate it.\n+5 Includes a clear description of the training procedure(s) you used. For example: how long did you train each model for, how did you choose the learning rate, batch size etc, how did you determine when to stop training? (It’s ok if some choices were made based on intution/prior experiences).\n+5 Includes a clear description of the network architectures used (e.g. how many layers, and additional layers such as normalization, dropout etc.) Explains why this architecture(s) were chosen.\n\n\n\n+10 Includes a clear quantitative and qualitative evaluation of the proposed method on test data. This should include defining the quantitative metrics used, at least one table or figure summarizing the best results achieved.\n+10 Includes at least one comparison or ablation study. This could be a comparison between substantially different model architectures, different possible losses or a comparison between the proposed method and a baseline.\n+5 Includes an insightful discussion of how to interpret the results and any recommendations. If the results did not live up to expectations, discuss what could have gone wrong and possible fixes.\n+5 Shows progress on training and validation data for the main (best) results. This could be a loss plot and/or plots of qualitative/quantitative evaluation over training.\n\n\n\n+5 Includes a well-written and concise summary of the conclusions and takeaways from this work.\n\n\n\n+5 Includes an discussion determining any possible ethical or societal impacts of this work. Be sure to identify any possible ways this approach could be misused and any biases in the results or data.\n+5 bonus Possible bonus points for a particularly in-depth discussion of impacts.\n\n\n\n+5 Includes clear code showing what was implemented as well as citations to code used.\n+5 bonus Possible bonus points for clearly documented code for reproducing all experiments."
  },
  {
    "objectID": "assignments/final-project/rubric.html#abstract-5-points",
    "href": "assignments/final-project/rubric.html#abstract-5-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+1 Includes abstract\n+2 Summarizes goal of the project and method\n+1 Summarizes conclusions and results in 1-2 sentences\n+1 Clear and concise writing"
  },
  {
    "objectID": "assignments/final-project/rubric.html#introduction-and-related-work-10-points",
    "href": "assignments/final-project/rubric.html#introduction-and-related-work-10-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+5 Introduction to the goal of the project, why you are trying to solve it and how it could be used in practice.\n+5 Introduces at least 1-2 pieces of related work that form the basis for the project, including at least 1-2 sentences about what method/data each introduced and what they showed. Cites related work appropriately."
  },
  {
    "objectID": "assignments/final-project/rubric.html#datasets-10-points",
    "href": "assignments/final-project/rubric.html#datasets-10-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+4 Clearly describes each dataset used and why it was chosen.\n+1 Provides citation and link to each dataset’s source.\n+4 Provides a summary of each dataset including the size, class distribution (if applicable), and format of each observation.\n+1 Clearly describes the training/validation/test split for each dataset."
  },
  {
    "objectID": "assignments/final-project/rubric.html#methods-30-points",
    "href": "assignments/final-project/rubric.html#methods-30-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+10 Includes precise and correct mathematical formulations for the loss functions used and/or formulations and pseudocode for new algorithms introduced. If the method is an architecture (e.g. U-Nets or Vision transformers) this should be a precise discussion of how it differs from the networks we’ve used so far and what the relevant (hyper) parameters are.\n+10 Includes a clear description of the goals and intuition for the formulated approach. A student in this class should understand why the given formulation makes sense and how to replicate it.\n+5 Includes a clear description of the training procedure(s) you used. For example: how long did you train each model for, how did you choose the learning rate, batch size etc, how did you determine when to stop training? (It’s ok if some choices were made based on intution/prior experiences).\n+5 Includes a clear description of the network architectures used (e.g. how many layers, and additional layers such as normalization, dropout etc.) Explains why this architecture(s) were chosen."
  },
  {
    "objectID": "assignments/final-project/rubric.html#results-30-points",
    "href": "assignments/final-project/rubric.html#results-30-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+10 Includes a clear quantitative and qualitative evaluation of the proposed method on test data. This should include defining the quantitative metrics used, at least one table or figure summarizing the best results achieved.\n+10 Includes at least one comparison or ablation study. This could be a comparison between substantially different model architectures, different possible losses or a comparison between the proposed method and a baseline.\n+5 Includes an insightful discussion of how to interpret the results and any recommendations. If the results did not live up to expectations, discuss what could have gone wrong and possible fixes.\n+5 Shows progress on training and validation data for the main (best) results. This could be a loss plot and/or plots of qualitative/quantitative evaluation over training."
  },
  {
    "objectID": "assignments/final-project/rubric.html#conclusion-5-points",
    "href": "assignments/final-project/rubric.html#conclusion-5-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+5 Includes a well-written and concise summary of the conclusions and takeaways from this work."
  },
  {
    "objectID": "assignments/final-project/rubric.html#impact-statement-5-points",
    "href": "assignments/final-project/rubric.html#impact-statement-5-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+5 Includes an discussion determining any possible ethical or societal impacts of this work. Be sure to identify any possible ways this approach could be misused and any biases in the results or data.\n+5 bonus Possible bonus points for a particularly in-depth discussion of impacts."
  },
  {
    "objectID": "assignments/final-project/rubric.html#code-5-points",
    "href": "assignments/final-project/rubric.html#code-5-points",
    "title": "Final project rubric",
    "section": "",
    "text": "+5 Includes clear code showing what was implemented as well as citations to code used.\n+5 bonus Possible bonus points for clearly documented code for reproducing all experiments."
  },
  {
    "objectID": "assignments/final-project/rubric.html#introduction-10-points",
    "href": "assignments/final-project/rubric.html#introduction-10-points",
    "title": "Final project rubric",
    "section": "Introduction (10 points)",
    "text": "Introduction (10 points)\n+5 Provides a clear outline of the problem to be solved\n+5 Gives clear and compelling reasons why this is an interesting problem and any societal implications"
  },
  {
    "objectID": "assignments/final-project/rubric.html#methods-20-points",
    "href": "assignments/final-project/rubric.html#methods-20-points",
    "title": "Final project rubric",
    "section": "Methods (20 points)",
    "text": "Methods (20 points)\n+5 Gives a clear overview of the datasets used.\n+10 Explains the technique that was studied with explanations for the most relevant formulas and/or algorithms.\n+5 Methods section is appropriately targeted towards the level of this class."
  },
  {
    "objectID": "assignments/final-project/rubric.html#results-10-points",
    "href": "assignments/final-project/rubric.html#results-10-points",
    "title": "Final project rubric",
    "section": "Results (10 points)",
    "text": "Results (10 points)\n+5 Highlights the main experimental results from the report.\n+5 Gives a clear summary of the takeaways from the experiments and recommendations for future users."
  },
  {
    "objectID": "assignments/final-project/rubric.html#presentation-10-points",
    "href": "assignments/final-project/rubric.html#presentation-10-points",
    "title": "Final project rubric",
    "section": "Presentation (10 points)",
    "text": "Presentation (10 points)\n+5 All group members contributed roughly equal time.\n+5 Visuals were clear, readable and reinforced the verbal discussion."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#overview",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#overview",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Overview",
    "text": "Overview\nIn this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\nimport numpy as np\n\n\nPython features\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-1-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-1-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 1: Reverse-mode automatic differentiation",
    "text": "Part 1: Reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - parents: The parent operations (a and b) - grad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\)) - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called AutogradValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using AutogradValue.\na = AutogradValue(5)\nb = AutogradValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\nL.backward()\ndL_da = a.grad\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\nNow that we’ve seen what our final produce will look like, let’s define our AutogradValue class.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        args    (list): A list of raw values of each input (as floats)\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.args = [arg.value if isinstance(arg, AutogradValue) else arg for arg in self.parents]\n        self.grad = 0.\n        self.value = self.forward_pass()\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.args)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n\n\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing AutogradValue. These subclasses will look the same as the ones we wrote for our forward-mode automatic differentiation in the last homework.\n\nclass _add(AutogradValue):\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def grads(self, a, b):\n        return 1., -1.\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def grads(self, a, b):\n        return b, a\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return math.exp(a)\n\n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return math.log(a)\n\n    def grads(self, a):\n        return (1 / a,)\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\ndef exp(a):\n    return a.exp() if isinstance(a, AutogradValue) else np.exp(a)\ndef log(a):\n    return a.log() if isinstance(a, AutogradValue) else np.log(a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(AutogradValue)\n\nLet’s confirm that we do keep the entire compuational graph for operations defined in this way.\n\nQ1\nWrite a function graph_print that takes a single argument. If the argument is an AutogradValue (or one of its subclasses), print its value property and then call graph_print on each of its parents. If the argument is not an AutogradValue, just print it. The format of printing is not important.\nHint: You can use the built-in Python function isinstance to determine if something is an AutogradValue or one of its subclasses. e.g. isinstance(a, AutogradValue)\n\ndef graph_print(a):\n    ## YOUR CODE HERE\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\nThe function should print (it’s ok if the numbers or order aren’t exact):\n2.995732273553991\n20.0\n10.0\n5.0\n5.0\n5\n2.0\n2.0\nNow in order to do automatic differentiation, we need to define how to do the backward pass. We’ll start with the backward_step for a single operation.\n\n\nQ2\nFill in the method backward_pass which computes a single step of the reverse pass through the computational graph (assume self is an AutogradValue instance). If backward_pass is called on a value c, the method should: - Assume that self.grad contains the derivaive of the final loss with respect to c (\\(\\frac{dL}{dc}\\)). - Check if each parent of c is an AutogradValue. If it is, update that parent’s grad property to account for c (e.g. for parent a, update the value of \\(\\frac{dL}{da}\\))\nFor example: if c represents the result of an addition so c = a + b, calling backward_pass on c will update the grad property of both a and b. (a.grad represents \\(\\frac{dL}{da}\\) and is initialized to 0).\nHint: grads will be one of the methods we wrote in the last homework (and shown above). Recall that if c has parents a and b then grads method will give \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\).\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n    local_grads = self.grads(*self.args)\n\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\nFinally we need to define the backward method itself. We will call this on the loss value to find the derivatives of the loss with respect to each input. This means working our way backward through the sequence of operations. Remember that if c=a+b, then if c.grad is \\(\\frac{dL}{dc}\\), calling backward_pass on c will update \\(\\frac{dL}{da}\\) (a.grad) and \\(\\frac{dL}{db}\\) (b.grad).\nThe complication is that c may be used in multiple operations, so we can’t call backward_pass on c until we’ve called backward_pass on each child operation of c otherwise c.grad won’t have the correct value of \\(\\frac{dL}{dc}\\), as in this example:\nc = a + b\ng = c * 2\nh = c + 4\nL = g * h\n\nL.backward_pass() # Updates dL/dg and dL/dh\nh.backward_pass() # Updates dL/dc\n\n##WRONG ORDER\nc.backward_pass() # Incorrect because dL/dc hasn't accounted for dL/dg\ng.backward_pass()\n\n## CORRECT ORDER\ng.backward_pass() # Updates dL/dc\nc.backward_pass() # Updates dL/da and dL/db\n\n\nQ3\nFill in the backward method for AutogradValue. Your backward method should call backward_pass on each operation used to compute the loss (self is the loss value). Some important things to keep in mind: - backward_pass should only be called once on each operation - backward_pass must be called on every child of an operation before it can be called on the operation. - You should not try to call backward_pass on values that aren’t instances of AutogradValue, even though they might be stored in operation.parents\nHint: We discussed a simple approach to this problem in class! We won’t score efficiency in grading, but it still might be worth optimizing this function a bit.\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## YOUR CODE HERE\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\nIf we want to train a neural network using our automatic differentiation implementation, we’re going to want to be able to use numpy to do matrix operations. Fortunately, the our AutogradValue class is (mostly) compatible with numpy!\nWe can create arrays of AutogradValue and take derivatives as shown below:\n\na = np.array([AutogradValue(5), AutogradValue(2)])\nL = np.dot(a, a)\nL.backward()\nprint('Gradient for a', a[0].grad, a[1].grad)\n\nIt would be a bit tedious to define every AutogradValue array in this way, so let’s write some convinience functions to make doing automatic differentiation with numpy easier.\n\n\nQ4\nComplete the following two functions wrap_array and unwrap_gradient.\nwrap_array should take a numpy array of floats and return a new array where every element has been made into an AutogradValue.\nunwrap_gradient should take a numpy array of AutogradValue and return a new array of floats, where every element is the extracted grad property of the corresponding element from the original array.\nBoth of these functions should work on 2-D arrays (matrices) at a minimum (but more general solutions that support 1 and/or &gt;2 dimensional arrays are also possible).\nHint: You can create an array from nested lists as np.array([[1, 2], [3, 4]]).\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    ## YOUR CODE HERE\n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    ## YOUR CODE HERE\n\n\ntest_wrap_unwrap(wrap_array, unwrap_gradient, AutogradValue)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-2-training-a-neural-network",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-2-training-a-neural-network",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 2: Training a neural network",
    "text": "Part 2: Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks! Below is a (slightly modified) version of the neural network class we wrote for the last homework.\n\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if (isinstance(a, AutogradValue) or isinstance(b, AutogradValue)) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + exp(-x))\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid(xw * (2 * y - 1))\n        return -(log(py)).sum()\n\n\nQ5\nImplement an nll_and_grad method for the NeuralNetwork class using your reverse-mode automatic differentiation implmentation to compute the gradient with respect to each weight matrix.\nHint: You’ll need to use the wrap_array and unwrap_gradients functions you wrote above. You should use the built-in nll method to compute the loss.\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-3-vectorizing-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework5-reverse-mode/main_updated.html#part-3-vectorizing-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Reverse-mode Automatic Differentiation",
    "section": "Part 3: Vectorizing Reverse-mode automatic differentiation",
    "text": "Part 3: Vectorizing Reverse-mode automatic differentiation\nWe might notice that our reverse-mode automatic differentiation implementation is quite slow! The main reason for this is that our implementation operates on individual numbers (scalars) rather than entire arrays. This means that for a big operation like a matrix multiplication, an AutogradValue object needs to be tracked for each of the \\(O(n^3)\\) individual operations! Even worse, it also means that internally Numpy can’t use the very fast C and C++ implementations it has for array operations on type float, our array elements are now objects so it has to fall back on slow Python-loop based implementations.\nIdeally we’d like our AutogradValue objects to operate at the level of array operations, rather than scalar operations. This would circumvent these problems as we could represent an entire matrix multiplication with a single AutogradValue. In order to do this efficiently, we’ll need to make use of the Vector-Jacobian Product idea that we discussed in class. Let’s review the concept here.\nRecall that in backward_pass for a node c we assume that we have the gradient (derivative) of the loss with respect to c: \\(\\frac{dL}{d\\mathbf{c}}\\) and we need to update the gradients for the parents (say a and b) as:\n\\[\\frac{dL}{da} = \\frac{dL}{dc} \\frac{dc}{da}, \\quad \\frac{dL}{dc} = \\frac{dL}{dc} \\frac{dc}{db}\\]\nWhen \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\) are vectors the derivates \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) and \\(\\frac{d\\mathbf{c}}{d\\mathbf{b}}\\) are Jacobian matrices with possibly many entries and our updates become vector-Jacobian products:\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T, \\quad \\frac{dL}{d\\mathbf{b}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{b}}\\bigg)^T\\]\nHowever we often don’t need to actually construct the Jacobians fully to compute these products, as is the case for element-wise operations. As long as we can compute the correct values for \\(\\frac{dL}{d\\mathbf{a}}\\), we’re good! For example if \\[\\mathbf{c} = \\mathbf{a}^2, \\quad \\mathbf{c} = \\begin{bmatrix} a_1^2 \\\\ a_2^2 \\\\ a_3^2 \\\\ \\vdots \\end{bmatrix}\\]\nWe can easily see that we can just update the derivate for each element of \\(\\mathbf{a}\\) independently. \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix} = 2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\]\nIf we want to be more formal we can note that technically, the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is diagonal (\\(\\frac{\\partial c_i}{\\partial a_j}\\) is only nonzeros for \\(i=j\\)). Therefore we can write the Vector-Jacobian Product as:\n\\[\\frac{dL}{d\\mathbf{a}}^T = \\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}  = \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 2 a_1 & 0 & 0 & \\dots \\\\0  & 2 a_2 & 0 & \\dots \\\\ 0 & 0 & 2 a_3 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix}^T = \\bigg(2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\bigg)^T\\]\nFor the case of addition, things are even simpler! If: \\[\\mathbf{c} = \\mathbf{a} + \\mathbf{b}\\]\nWe can again see that we can just update the derivative for each element of \\(\\mathbf{a}\\) independently, but this time each local derivative (\\(\\frac{dc_i}{da_i}\\)) is just \\(1\\), so \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 1 \\\\  \\frac{dL}{dc_2} \\cdot 1 \\\\  \\frac{dL}{dc_3} \\cdot 1 \\\\ \\vdots  \\end{bmatrix} = \\frac{dL}{d\\mathbf{c}}\\]\nIn this case the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is simply the identity matrix, so: \\[\\frac{dL}{d\\mathbf{a}}^T =  \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 1 & 0 & 0 & \\dots \\\\0  & 1 & 0 & \\dots \\\\ 0 & 0 & 1 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}= \\frac{dL}{d\\mathbf{c}}^T \\mathbf{I} = \\frac{dL}{d\\mathbf{c}}^T\\]\n\nQ6\nLet’s replace our operation implementations above with ones that compute Vector-Jacobian products. We’ll start with element-wise operations. Complete the vjp function for each operation below. Unlike the grads methods we implemented before which computed the derivative of the output with respect to each input: \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\) (if applicable), each vjp method should directly compute the gradient of the loss with respect to each input: \\(\\frac{dL}{d\\mathbf{a}}\\) and \\(\\frac{dL}{d\\mathbf{b}}\\), assuming the grad argument provides the gradient of the loss with respect to the output: \\(\\frac{dL}{d\\mathbf{c}}\\).\nHint: For binary operations (+,-,*,/), you do not need to account for broadcasting. That is, you can assume that a, b and c are always the same shape! We’ve started you off with a few examples to base your answers on.\n\nclass _add(AutogradValue):\n    # An example representing the addition operation.\n    def func(self, a, b):\n        '''\n        Computes the result of the operation (a + b). Assumes a and b are the same shape.\n\n        Args:\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            c (array of float): The result c = a + b\n        '''\n        return a + b\n\n    def vjp(self, grad, a, b):\n        '''\n        Computes dL/da and dL/db given dL/dc.\n\n        Args:\n            grad (array of float): The gradient of the loss with respect to the output (dL/dc)\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            grads (tuple of arrays): A tuple containing the gradients dL/da and dL/db\n        '''\n        return grad, grad\n\nclass _square(AutogradValue):\n    # Another example class implementing c = a^2\n    def func(self, a):\n        return a ** 2\n\n    def vjp(self, grad, a):\n        return (2 * a * grad,)\n\nclass _pad(AutogradValue):\n    # An implementation for padding with a column of 1s.\n    def func(self, a):\n        return np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\n    def vjp(self, grad, a):\n        return (grad[:, :-1],)\n\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return np.exp(a)\n\n    def vjp(self,grad,  a):\n        # YOUR CODE HERE\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return np.log(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_neg, '_neg', )\ntest_vjp(_exp, '_exp', true_func=anp.exp)\ntest_vjp(_log, '_log', true_func=anp.log)\ntest_vjp(_sub, '_sub', True)\ntest_vjp(_mul, '_mul', True)\ntest_vjp(_div, '_div', True)\n\n\n\nQ7\nConsider the operation defined by np.sum, that takes the sum over all elements of a matrix or vector, producing a scalar:\n\\[c  = \\sum_{i=1}^n a_i\\]\nWrite a vjp method for this operation that computes: \\(\\frac{dL}{d\\mathbf{a}}\\) given \\(\\frac{dL}{dc}\\).\nHint: Note that \\(L\\), \\(c\\) and \\(\\frac{dL}{dc}\\) are all scalars, so for any entry \\(i\\) of our output we can simply apply the chain rule and compute \\(\\frac{dL}{da_i} = \\frac{dL}{dc} \\frac{dc}{da_i}\\). As the equation above for \\(c\\) given \\(\\mathbf{a}\\) is a sum, \\(\\frac{dc}{da_i}\\) should be simple!\n\nclass _sum(AutogradValue):\n    def func(self, a):\n        return np.sum(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_sum, '_sum', true_func=anp.sum, issum=True)\n\n\n\nMatrix multiplication\nFor the next few problems, it may be useful to refer to this diagram of matrix multiplication.\n\n\n\nimage.png\n\n\nThe last important operation we’ll need a vjp method for in order to use our vectorized AutogradValue class for a neural network is matrix multiplication. Let’s consider the operation:\n\\[\\mathbf{C} = \\mathbf{A}\\mathbf{B}\\]\nWhere \\(\\mathbf{A}\\) is an \\(N\\times h\\) matrix, \\(\\mathbf{B}\\) is a \\(h \\times d\\) matrix and \\(\\mathbf{C}\\) is an \\(N\\times d\\) matrix.\nRecall that for vjp want to compute \\(\\frac{dL}{d\\mathbf{A}}\\) (and \\(\\frac{dL}{d\\mathbf{B}}\\) ) given \\(\\frac{dL}{d\\mathbf{C}}\\). We can compute a given entry \\(i,j\\) of \\(\\frac{dL}{d\\mathbf{A}}\\) by applying the chain rule using each element of \\(\\mathbf{C}\\):\n\\[\\frac{dL}{dA_{ij}} = \\sum_{k=1}^N \\sum_{l=1}^d \\frac{dL}{dC_{kl}}\\frac{dC_{kl}}{dA_{ij}}\\]\nHowever, each entry of \\(\\mathbf{C}\\) only depends on a single row of \\(\\mathbf{A}\\) and a single column of \\(\\mathbf{B}\\), thus for most \\(i,j,k,l\\), \\(\\frac{dC_{kl}}{dA_{ij}}=0\\).\n\nQ8\nUsing this observation, simplify the expression for \\(\\frac{dL}{dA_{ij}}\\) above. (The derivative of the loss with respect to the entry of \\(\\mathbf{A}\\) at row \\(i\\), column \\(j\\)).\nHint: Your answer should have a similar form, but should only have a single summation and a subset of the indices \\(i,j,k,l\\).\n\\[\\frac{dL}{dA_{ij}} = \\]\n\n\nQ9\nRecalling the definition of matrix-multiplication, give a simple expression for \\(\\frac{dC_{il}}{dA_{ij}}\\), then substitue it into your expression for \\(\\frac{dL}{dA_{ij}}\\).\n\\[\\frac{dC_{il}}{dA_{ij}}= , \\quad\\frac{dL}{dA_{ij}} = \\]\n\n\nQ10\nUsing your expression in Q13, write an expression for \\(\\frac{dL}{d\\mathbf{A}}\\) as a matrix multiplication between two of the 3 given matrices: \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\), \\(\\mathbf{B}\\). Make sure to inlude any nessecary transposes.\nHint: Recall that \\(\\frac{dL}{d\\mathbf{C}}\\) is the same shape as \\(\\mathbf{C}\\) (\\(N\\times d\\)), \\(\\mathbf{A}\\) has shape \\(N \\times h\\) and \\(\\mathbf{B}\\) has shape \\(h \\times d\\).\n\\[\\frac{dL}{d\\mathbf{A}}= \\]\n\n\nQ11\nWrite the corresponding formula for \\(\\frac{dL}{d\\mathbf{B}}\\).\nHint: You can use the fact that \\(C^T = B^T A^T\\) and that \\(\\frac{dL}{d\\mathbf{C}^T} = (\\frac{dL}{d\\mathbf{C}})^T\\)\n\\[\\frac{dL}{d\\mathbf{B}}=\\]\n\n\nQ12\nUsing the expressions you derived in Q14 and Q15, implement the vjp function for the matmul operation to compute \\(\\frac{dL}{d\\mathbf{A}}\\) and \\(\\frac{dL}{d\\mathbf{B}}\\) given \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\).\n\nclass _matmul(AutogradValue):\n    def func(self, a, b):\n        return np.matmul(a, b)\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\ntest_vjp(_matmul, '_matmul', binary=True, true_func=anp.matmul)\n\nNow that we’ve written the vjp versions of our operators, we’ll update our AutogradValue class to use them!\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.vjp = lambda self, grad, a: (1.,)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.pad = lambda a: _pad(a)\nAutogradValue.sum = lambda a: _sum(a)\nAutogradValue.matmul = lambda a, b: _matmul(a, b)\nAutogradValue.rmatmul = lambda a, b: _matmul(b, a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nAs a final step, we need to update our backward_pass method to use our new vjp method instead of relying on grads.\n\n\nQ13\nUpdate your backward_pass method to use vjp instead of grads.\nHint: Recall that vjp directly computes \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\frac{dL}{d\\mathbf{b}}\\), whereas grads computed \\(\\frac{dc}{da}\\), \\(\\frac{dc}{db}\\)\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n\n\n\nAutogradValue.backward_pass = backward_pass\n\n\n\nQ14\nFinally update the nll_and_grad function for our NeuralNetwork class to use our shiny new vectorized reverse-mode implementation.\nHint: We should no longer need to use our wrap_array and unwrap_gradient functions, as AutogradValue objects can now contain arrays!\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe should be able to run it with a much larger network now!\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [25, 25])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nIn this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-1-linear-regression",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-1-linear-regression",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\nLet’s begin by reviewing the context of linear regression.\nRecall that the linear regression model makes predictions of the following form:\n\\[f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} + b\\]\nOr if we consdier the augmented representation:\n\\[\\mathbf{x} \\rightarrow \\begin{bmatrix}\\mathbf{x} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\\\ 1 \\end{bmatrix},\\quad \\mathbf{w} \\rightarrow \\begin{bmatrix}\\mathbf{w} \\\\ b \\end{bmatrix} = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_d \\\\ b \\end{bmatrix}\\] The we can use the more convinient linear form: \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\]\nQ1: Write a function that takes in an input \\((\\mathbf{x})\\) and a set of weights \\((\\mathbf{w})\\) and makes a predicion using the function above. Your implementation should assume that the bias \\((b)\\) is included in the weights \\((\\mathbf{w})\\) and thus should augment the input to account for this.\n\n# Test inputs\nx = np.array([1, -3, 5])\nw = np.array([-1, 2, 0.5, 2])\ny = -2.5\n\ndef linear_regression(x, w):\n    x = np.pad(x, ((0, 1)), constant_values=1)\n    return np.dot(x, w)\n\n## Validate the function\nassert y == linear_regression(x, w)\n\nAs discussed in class, we can compactly refer to an entire dataset of inputs and outputs using the notation \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) respectively. Our convention will be that row \\(i\\) of \\(\\mathbf{X}\\) will correspond to the \\(i^{th}\\) observed input \\(\\mathbf{x}_i\\), while the corresponding entry \\(y_i\\) of \\(\\mathbf{y}\\) is the observed output. In other words \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) are defined as: \\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}, \\quad\n                \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nWith this notation, we can make predictions for an entire set of inputs as: \\[f(\\mathbf{X}) = \\mathbf{X}\\mathbf{w}\\] Where the output is now a vector of predictions. We see that each entry corresponds to the prediction for input \\(\\mathbf{x}_i\\): \\[f(\\mathbf{X})_i = \\mathbf{x}_i^T\\mathbf{w} = f(\\mathbf{x}_i)\\]\nQ2: Modify (if needed) your linear regression prediction function to accept a set of inputs as matrix as described above and return a vector of predictions. Once again you should not assume the data includes the extra bias dimension. Then plot the prediction function given by the provided weights on the range \\([0, 5]\\). Recall that np.linspace(a, b, n) produces a vector of n equally spaced numbers between a and b.\n\n# Test inputs\nw = np.array([0.5, 2])\n\ndef linear_regression(x, w):\n    # Account for the extra dimension in pad\n    x = np.pad(x, ((0, 0), (0, 1)), constant_values=1)\n    return np.dot(x, w)\n\nX = np.linspace(0, 5, 200).reshape((-1, 1))\ny = linear_regression(X, w)\nplt.plot(X.flatten(), y)\n\n\n\n\n\n\n\n\nRecall that ordinary least squares finds the parameter \\(\\mathbf{w}\\) that minimizes the sum of squared errors between the true outputs \\(\\mathbf{y}\\) and predictions. \\[\\min_{\\mathbf{w}} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2\\]\nObserve that this is the same formula as the error we used for evaluating Richardson iteration in the last homework, we’ve simply renamed the variables from \\((\\mathbf{A}, \\mathbf{x}, \\mathbf{b})\\) to \\((\\mathbf{X}, \\mathbf{w}, \\mathbf{y})\\)!\nWe’ve now seen 3 equivalent ways to write the same formula. From most compact to least compact these are: \\[\\textbf{1: }  \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 \\quad \\textbf{2: } \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2 \\quad \\textbf{3: } \\sum_{i=1}^n \\left(\\sum_{j=1}^n X_{ij}w_j - y_i\\right)^2\\]\nNote: Notation can be confusing. If you are having trouble following, don’t hesitate to ask for help!\nQ3: Using the gradient formula you derived in the last homework, write a function that returns both the mean squared error and the gradient of the error with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\). Hint: don’t forget about to augment X when computing the gradient!\n\ndef mse_and_grad(w, X, y):\n    error = linear_regression(X, w) - y\n    mse = np.mean(error ** 2)\n    grad_w = 2 * np.dot(error, np.pad(X, [(0,0), (0,1)], constant_values=1)) / X.shape[0]\n    return mse, grad_w\n\nRecall that we can use the gradient descent algorithm to find the input that minimizes a function, using the corresponding gradient function.\nGiven an initial guess of the optimal input, \\(\\mathbf{w}^{(0)}\\), gradient descent uses the following update to improve the guess: \\[\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}),\\] where \\(\\alpha\\) is the learning rate or step size.\nQ4: Write a function to perform gradient descent. The function should take as input: - value_and_grad: A function that produces the output and gradient of the function to optimize (e.g. the mse_and_grad) - w0: An inital guess \\(\\mathbf{w}^{(0)}\\) - lr: The learning rate \\((\\alpha)\\) - niter: The number of updates to perform - *args: Any additional argumets to pass to value_and_grad (e.g. X and y)\nThe function should return: - w: The final guess - losses: A list (or array) that tracks the value of the function at each update\n\ndef gradient_descent(value_and_grad, w0, lr, niter, *args):\n    # Get the inital loss\n    initial_loss, grad = value_and_grad(w0, *args)\n    losses = [initial_loss]\n    w = w0\n\n    for i in range(niter):\n        w = w - lr * grad\n        loss, grad = value_and_grad(w, *args)\n        losses.append(loss)\n    return w, losses"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-2-applications-to-real-data",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-2-applications-to-real-data",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 2: Applications to real data",
    "text": "Part 2: Applications to real data\nNow that we’ve setup a full implementation of linear regression, let’s test it on a real dataset. We’ll use the MPG dataset that we in class. The following code will load the data.\n\ndata = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n\n# MPG is the output value\ntarget = 'MPG'\ny = data[:, 0]\n\n# The other variables are in inputs in the order listed\nfeatures = ['displacement', 'weight', 'acceleration', 'year']\nX = data[:, [2, 4, 5, 6]]\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\nLet’s start by fitting a model that just uses the feature weight.\nQ5: Use the gradient_descent and mse_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 50 updates of gradient descent with a learning rate of 0.1. Plot the loss (MSE) as a function of the number of updates.\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n(w, losses) = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight, y)\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\nplt.plot(losses)\nprint(losses[-1])\n\n18.780939855850434\n\n\n\n\n\n\n\n\n\nQ6: Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]]\\).\n\nplt.figure(figsize=(8, 6))\nplt.scatter(Xweight.flatten(), y)\n\nx = np.linspace(-3, 3, 100).reshape((-1, 1))\nplt.plot(x.flatten(), linear_regression(x, w), c='r')\n\n\n\n\n\n\n\n\nQ7: Repeat Q5 using all 5 features and compare the final loss to the final loss using only weight as an input. Describe any differences you observe.\n\nw0 = np.zeros((5,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, X, y)\n\nplt.figure(figsize=(6, 4))\nplt.plot(losses)\nprint(losses[-1])\n\n12.013140556897708\n\n\n\n\n\n\n\n\n\nWe see that in both cases the loss converges very quickly, but with 5 features, the final loss is significantly smaller (12 vs 18)\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\nQ8: Split the MPG dataset into training and test datasets. Use 70% of the observations for training and 30% for test. Then repeat Q5 to fit a linear regression model on just the training dataset using only the weight feature (you don’t need to plot the loss for this question). Report the final loss (MSE) on the training dataset and on the test dataset.\n\nXweight_train = Xweight[:int(X.shape[0] * .7)]\ny_train = y[:int(X.shape[0] * .7)]\n\nXweight_test = Xweight[int(X.shape[0] * .7):]\ny_test = y[int(X.shape[0] * .7):]\n\nw0 = np.zeros((2,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight_train, y_train)\n\nmse_train, _ = mse_and_grad(w, Xweight_train, y_train)\nmse_test, _ = mse_and_grad(w, Xweight_test, y_test)\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nLoss on training data: 8.4172, loss on test data: 60.1368\n\n\nQ9: Repeat Q8 using the all 5 features. Compare the results to the model using only weight.\n\nX_train = X[:int(X.shape[0] * .7)]\ny_train = y[:int(X.shape[0] * .7)]\n\nX_test = X[int(X.shape[0] * .7):]\ny_test = y[int(X.shape[0] * .7):]\n\nw0 = np.zeros((5,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, X_train, y_train)\n\nmse_train, _ = mse_and_grad(w, X_train, y_train)\nmse_test, _ = mse_and_grad(w, X_test, y_test)\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nLoss on training data: 7.5947, loss on test data: 43.7603\n\n\nWe see that with all 5 features, both the training and the test loss are lower than with only weight!"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-3-maximum-likelihood-training",
    "href": "assignments/homeworks-sp24/homework2-linear-regression/solutions.html#part-3-maximum-likelihood-training",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 3: Maximum Likelihood Training",
    "text": "Part 3: Maximum Likelihood Training\n\nBackground:\nWe saw in lecture that we can view linear regression as the following probibalistic model: \\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\] Where \\(\\mathcal{N}(\\mu, \\sigma)\\) is the Normal distribution, which has the following probability density function: \\[\np(y\\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\] We saw that a reasonable way to choose the optimal \\(\\mathbf{w}\\) is to maximize the likelihood of our observed dataset, which is equivalent to minimizing the negative log likelihood: \\[\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) =\n\\underset{\\mathbf{w}}{\\text{argmin}} -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\frac{1}{2\\sigma^2}\\sum_{i=1}^N  (y_i -\\mathbf{x}_i^T\\mathbf{w})^2 + C\n\\] Where \\(C\\) is a constant: \\(C = N \\log \\sigma \\sqrt{2\\pi}\\). We further saw that this is equivalent to minimizing the mean squared error for any choice of \\(\\sigma\\).\n\n\nLaplace Maximum Likelihood Estimation\nA natural question about the above model is: why choose the Normal distribution? In principal, we could define a linear model using any distribution over the real numbers \\(\\mathbb{R}\\). Let’s explore an alternative choice: the Laplace distribution (Wiki). The Laplace distribution \\(L(\\mu, a)\\) has the following PDF:\n\\[p(y\\mid \\mu, a) = \\frac{1}{2a} \\exp\\bigg(- \\frac{|y-\\mu|}{a} \\bigg) \\]\nAs for the normal distribution \\(\\mu\\) is the mean, while \\(a\\) defines the “width” of the distribution (analogous to variance for the Normal). We can compare the two distributions visually:\n\ny = np.linspace(-3, 3, 200)\nmu, sigma2_or_a = 0, 1\np_y_normal = (1 / np.sqrt(sigma2_or_a * 2 * np.pi)) * np.exp(- (0.5 / sigma2_or_a) * (y - mu) ** 2)\np_y_laplace = (1 / (2 * sigma2_or_a)) * np.exp(- (1 / sigma2_or_a) * np.abs(y - mu))\n\nplt.figure(figsize=(4,3))\nplt.plot(y, p_y_normal, label=r\"Normal PDF\")\nplt.plot(y, p_y_laplace, label=r\"Laplace PDF\")\nplt.xlabel('$y$')\nplt.ylabel('$p(y)$')\nplt.legend()\npass\n\n\n\n\n\n\n\n\nLet’s now consider the Laplace version of our probabilistic linear model: \\[\ny_i \\sim L\\big(\\mathbf{x}_i^T \\mathbf{w},\\ a\\big)\n\\] In this case that the negative log-likelihood is defined as: \\[\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, a)\\]\nQ10: Write out the negative log-likelihood for this model in terms of \\(\\mathbf{w}, a, \\mathbf{X}, y\\) using the Laplace PDF shown above.\nWe can simply replace \\(p(y_i|\\mathbf{x}_i, a)\\) with the formula given above so we get: \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log \\frac{1}{2a} \\exp \\bigg(-\\frac{|y_i-\\mathbf{x}_i^T\\mathbf{w}|}{a}\\bigg)\\]\n\\[ = \\frac{1}{a}\\sum_{i=1}^N |y_i-\\mathbf{x}_i^T\\mathbf{w}| + N\\log 2a\\]\nNote that if we drop the constants, we would call this loss the sum absolute error.\nQ11: Find the gradient with respect to \\(\\mathbf{w}\\) of the negative log-likelihood for this model. Hint: remember that the gradient is the vector of partial derivatives, so you may use the approach we used to find this vector for the squared error function in the previous homework!\nYou should use the following definition of the derivative of the absolute value \\(|\\cdot |\\) operator: \\[\\frac{d}{dx}|x| = sign(x), \\quad sign(x) = \\begin{cases} +1 \\quad \\text{ if  } x &gt; 0 \\\\ -1 \\quad \\text{ if  } x &lt; 0 \\\\ \\ \\ \\ 0 \\quad \\text{ if  } x = 0 \\end{cases}\\] (Technically \\(\\frac{d}{dx}|x|\\) is undefined at \\(x=0\\), but it is convinient to assume \\(\\frac{d}{dx}|0|=0\\) in practice.)\n\\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) =  \\frac{d}{d\\mathbf{w}} \\frac{1}{a}\\sum_{i=1}^N |y_i-\\mathbf{x}_i^T\\mathbf{w}| + N\\log 2a\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N \\frac{d}{d\\mathbf{w}}|y_i-\\mathbf{x}_i^T\\mathbf{w}|\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N sign(y_i-\\mathbf{x}_i^T\\mathbf{w})\\frac{d}{d\\mathbf{w}}(y_i-\\mathbf{x}_i^T\\mathbf{w})\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N sign(y_i-\\mathbf{x}_i^T\\mathbf{w})\\mathbf{x}_i\\]\nQ12: Using the formula you just derived, write a function that returns both the negative log-likelihood and the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) (assume that \\(a=1\\)). To make our loss more comparable to MSE, we’ll divide both outputs by \\(N\\).\n\ndef nll_and_grad(w, X, y):\n    N = X.shape[0]\n    error = linear_regression(X, w) - y\n    mae = np.sum(np.abs(error))\n    nll = mae + np.log(2) \n    Xaug = np.pad(X, [(0, 0), (0, 1)], constant_values=1)\n    \n    grad_w = np.dot(np.sign(error), Xaug)\n    return nll / N, grad_w / N\n\nQ13: Use the gradient_descent and nll_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 50 updates of gradient descent with a learning rate of 1.. Plot the loss (NLL) as a function of the number of updates. Use the full dataset as in Q5.\n\nXweight = X[:, 1:2]\nw0 = np.zeros(2,)\n\n### YOUR CODE HERE\nw, losses = gradient_descent(nll_and_grad, w0, 0.1, 500, Xweight, y)\nwmse, mselosses = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight, y)\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\nplt.plot(losses, label='Laplace NLL')\nplt.plot(mselosses, label='Mean squared error')\nplt.legend()\nprint(losses[-1])\n\n3.262693397826824\n\n\n\n\n\n\n\n\n\nQ14: Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\). Describe any differences you see vs. the model you fit with MSE.\n\nplt.figure(figsize=(6, 4))\nplt.scatter(Xweight[:,0], y)\nplt.plot(np.linspace(-3, 3, 200), linear_regression(np.linspace(-3, 3, 200).reshape((-1, 1)), w), label='Laplace NLL weights')\nplt.plot(np.linspace(-3, 3, 200), linear_regression(np.linspace(-3, 3, 200).reshape((-1, 1)), wmse), label='MSE weights')\nplt.legend()\n\n\n\n\n\n\n\n\nQ15: Using the parameters that you just found, plot the Laplace NLL loss as a function of the first entry in w (w1 below), holding the other (the bias) constant. Then, using the same plot and parameters, plot the MSE loss as a function of the first entry in w.\n\n# Example of deconstructing and reconstructing the parameter vector.\nw1, b = w\nwi = np.array([w1, b])\n\nlosses = [nll_and_grad(np.array([wi, b]), Xweight, y)[0] for wi in np.linspace(-10, 0)]\nmse_losses = [mse_and_grad(np.array([wi, b]), Xweight, y)[0] for wi in np.linspace(-10, 0)]\n\nplt.figure(figsize=(6, 4))\nplt.plot(mse_losses, label='Mean squared error')\nplt.plot(losses, label='Laplace NLL')\n\nplt.legend()\nplt.ylabel('$w_1$')\nplt.xlabel('Loss')\n\nText(0.5, 0, 'Loss')\n\n\n\n\n\n\n\n\n\nIn the cells below, copy your code for Q5 and Q13. Try out different learning rates and and numbers of iterations. Observe what happens to the loss plot in each case.\nQ16: Based on what you’ve obsevered above and in the previous questions, why might you choose the Normal distribution or the Laplace distribution for linear regression?\nWe see that the MSE weights are more sensitive to outliers than the Laplace NLL weights."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/solutions.html",
    "href": "assignments/homeworks-sp24/homework1-background/solutions.html",
    "title": "Homework 1: Introduction to Numpy",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/solutions.html#part-1-numpy-basics",
    "href": "assignments/homeworks-sp24/homework1-background/solutions.html#part-1-numpy-basics",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 1: Numpy basics",
    "text": "Part 1: Numpy basics\nAs discussed in class, a square matrix \\(A\\) defines a linear mapping: \\(\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\). Given a vector \\(\\textbf{x}\\), we can find the corresponding output of this mapping \\(\\textbf{b}\\) using matrix-vector multiplication: \\(\\textbf{b}=A \\textbf{x}\\). We can write an example matrix-multiplication using matrix notation as:\n\\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}\n= \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix}\n\\]\nQ1: Perform this matrix-vector multiplication by hand and write the answer in the cell below.\n$$\n\\[\\begin{bmatrix}\n12 \\\\\n-3 \\\\\n0\n\\end{bmatrix}\\]\nQ2: In the code cell below, create the matrix \\(A\\) and the vector \\(\\textbf{x}\\) shown above, using Numpy. Then use the np.dot function to find the output of the mapping \\(\\textbf{b} = A\\textbf{x}\\). Verify that the answer matches what you derived above.\n\n# Fill answers here\nA = np.array([[4, -3, 2],\n              [6, 5, 1],\n              [-4, -1, 2]\n              ])\nx = np.array([1, -2, 1])\nb = np.dot(A, x)\n\nprint(b)\n\n[12 -3  0]\n\n\nOften we will have access to the transformed vector \\(\\textbf{b}\\) and need to find the orginal vector \\(\\textbf{x}\\). To do this we need to solve the system of linear equations \\(A\\textbf{x}=\\textbf{b}\\) for \\(\\textbf{x}\\). \\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix} = \\begin{bmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{bmatrix}\n\\]\nQ3: Find the missing \\(\\textbf{x}\\) in the equation above using the np.linalg.solve function and verify that \\(A\\textbf{x}=\\textbf{b}\\).\n\n# Fill answer here (A is the same matrix from above)\nb = np.array([2, -1, 3])\nx = np.linalg.solve(A, b)\nprint(b, np.dot(A, x))\n\n[ 2 -1  3] [ 2. -1.  3.]\n\n\nIn linear algebra you may have learned how to solve a system of linear equations using Gaussian elimination. Here we will implement an alternative approach known as Richardson iteration. In this method we start with an inital guess for the solution: \\(\\textbf{x}^{(0)}\\), then we will iteratively update this guess until the solution is reached. Given a matrix \\(A\\), a target \\(\\textbf{b}\\) and a current guess \\(\\textbf{x}^{(k)}\\), we can compute the Richardson update as:\n\\[\\textbf{x}^{(k+1)} \\leftarrow \\textbf{x}^{(k)} + \\omega \\left(\\textbf{b} - A\\textbf{x}^{(k)}\\right)\\]\nHere \\(\\omega\\) is a constant that we can choose to adjust the algorithm. We will set \\(\\omega = 0.1\\).\nQ4: Fill in the Richardson iteration function below and apply it to the system of linear equations from above using 100 updates. Verify that if gives a similar answer to np.linalg.solve.\n\n# Fill in function below\ndef richardson_iter(x_guess, A, b, omega=0.1):\n    new_x_guess = x_guess + omega * (b - np.dot(A, x_guess))\n    return new_x_guess\n\nx_guess = np.zeros(3)\nfor i in range(100):\n    x_guess = richardson_iter(x_guess, A, b)\n\nprint(x_guess, x)\n\n[-0.175 -0.2    1.05 ] [-0.175 -0.2    1.05 ]\n\n\nRecall that the length of a vector is given by it’s two-norm, which is defined as: \\[\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.\\]\nCorrespondingly, the (Euclidian) distance between two points \\(\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n\\) can be written as \\(\\|\\mathbf{a} - \\mathbf{b}\\|_2\\). As a convenient measure of error for our Richardson iteration algorithm, we will use the squared Euclidean distance. For a guess \\(\\mathbf{x}^{(k)}\\) we will compute the error \\(e^{(k)}\\) as: \\[e^{(k)} = \\|A\\mathbf{x}^{(k)} - \\mathbf{b}\\|_2^2\\]\nIn expanded form, this would be written as: \\[e^{(k)} = \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\nQ5: Write a function to compute the error of a given guess. Then run Richardson iteration again for 100 steps, computing the error at each step. Finally create a plot of the error for each step (error vs. step).\nHint: recall that basic operations in numpy (addition, subtraction, powers) are performed element-wise.\n\n# Fill in function below\ndef error(x_guess, A, b):\n    err = (np.dot(A, x_guess) - b) ** 2\n    err = err.sum()\n    return err\n\n# Add code to plot the error over time\nx_guess = np.zeros(3)\nall_errors = [error(x_guess, A, b)]\nfor step in range(100):\n    \n    x_guess = richardson_iter(x_guess, A, b)\n    all_errors.append(error(x_guess, A, b))\n\nplt.plot(all_errors)\n    \n\n\n\n\n\n\n\n\nQ6: Derive the partial derivative of the error with respect to a single entry of \\(\\mathbf{x}^{(k)}\\) (without loss of generality, we will say \\(x^{(k)}_1\\)). Work in the expanded form as in the equation above, writing your answer in the markdown cell below.\nHint: You may find it helpful to refer to the latex equation cheatsheet on the course website. You may show intermediate steps here or as handwritten work as a separate file in the repository. The final answer should be filled in here.\n\\[\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1}=  \\frac{\\partial}{\\partial x^{(k)}_1} \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\nApply sum and chain rules \\[=   2\\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right) \\frac{\\partial}{\\partial x^{(k)}_1}\\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)\\] Apply sum rule noting that \\(\\frac{\\partial}{\\partial x^{(k)}_1}A_{ij}x_{j} = 0\\) for \\(j\\neq 1\\).\n\\[=2\\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right) A_{i1}\\]\nIn practice, we will likely want to compute the derivative with respect to all entries of \\(\\mathbf{x}\\): \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}} = \\begin{bmatrix}\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1} \\\\\n\\vdots \\\\\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_n}\n\\end{bmatrix}\\]\nQ7: Using the formula you just derived, write the formula for the vector of all partial derivatives in the compact matrix/vector notation (e.g. \\(A\\mathbf{x}=\\mathbf{b}\\)).\n\\(\\sum_{j=1}^n A_{ij}x^{(k)}_j\\) of the \\(i^{th}\\) entry of the matrix-vector product \\(\\mathbf{A}\\mathbf{x}^{(k)}\\) \\[=2\\sum_{i=1}^n \\left( (\\mathbf{A}\\mathbf{x}^{(k)})_i - b_i\\right) A_{i1}\\]\nSimilarly subtracting \\(b_i\\) corresponds to vector subtraction with the vector \\(\\mathbf{b}\\) \\[=2\\sum_{i=1}^n \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)_i A_{i1}\\]\nFinally we’re left with the equivalent of a dot product for entry 1!\n\\[\\frac{\\partial e^{(k)}}{\\partial x_1^{(k)}}= 2 \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)^T \\mathbf{A}_{1}\\]\nIf we remove the index into \\(\\mathbf{A}\\), we get an expression for the gradient! \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}}= 2 \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)^T \\mathbf{A}\\]\nQ8: In 1-2 sentences describe how this answer relates to the Richardson iteration algorithm above. We will discuss this more in class!\nWe see that this gradient is almost equivalent to the update we made in our Richardson iteration, but scaled by \\(-2\\mathbf{A}\\)!"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/solutions.html#part-2-working-with-batches-of-vectors",
    "href": "assignments/homeworks-sp24/homework1-background/solutions.html#part-2-working-with-batches-of-vectors",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 2: Working with batches of vectors",
    "text": "Part 2: Working with batches of vectors\nRecall that a vector can also be seen as either an \\(n \\times 1\\) matrix (column vector) or a \\(1 \\times n\\) matrix (row vector).\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nNote that we use the same notation for both as they refer to the same concept (a vector). The difference becomes relevant when we consider matrix-vector multiplication. We can write matrix-vector multiplication in two ways: \\[\\text{Matrix-vector: }A\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}A^T= \\mathbf{b}\\] In matrix-vector multiplication we treat \\(\\textbf{x}\\) as a column vector (\\(n \\times 1\\) matrix), while in vector-matrix multiplication we treat it as a row vector (\\(n \\times 1\\) matrix). Transposing \\(A\\) for left multiplication ensures that the two forms give the same answer.\nQ9: Using the previously defined \\(\\mathbf{x}\\), create an explicit column vector and row vector. Then using the previously defined \\(A\\), verify that the matrix-vector and vector-matrix multiplications shown above do produce the same resultant vector \\(\\mathbf{b}\\).\nHint: Recall that np.dot is also used for matrix-matrix multiplication.\n\n# Fill in code here\nx_col = x[:, None] # Add new diminsion 1\nx_row = x[None, :] # Add new dimension 0\nprint(np.dot(A, x_col), np.dot(x_row, A.T))\n\n[[ 2.]\n [-1.]\n [ 3.]] [[ 2. -1.  3.]]\n\n\nThroughout this course we will typically use row vectors and vector-matrix multiplication, as this is more conventional in neural-network literature. The concept of row and column vectors becomes handy when transforming collections of vectors.\nRecall that a matrix can be seen as a collection of vectors. In numpy we can create a matrix from a list of (1- dimensional) vectors using the np.stack function. This function assumes that the vectors are row vectors creating the matrix as follows: \\[\\begin{bmatrix}\n3 & 1 & -2\n\\end{bmatrix},\\ \\begin{bmatrix}\n4 & 5 & 3\n\\end{bmatrix},\\ \\begin{bmatrix}\n-2 & -1 & 5\n\\end{bmatrix}\\quad \\overset{\\text{np.stack}}{\\longrightarrow} \\begin{bmatrix}\n3 & 1 & -2 \\\\\n4 & 5 & 3 \\\\\n-2 & -1 & 5\n\\end{bmatrix} \\]\nWe will call this matrix \\(X\\) to denote that it is a collection of vectors, rather than a single vector (\\(\\mathbf{x}\\)).\nQ10: Create this matrix in numpy using th np.stack function.\n\n\nX = np.stack([np.array([3, 1, -2]), \n              np.array([4, 5, 3]),\n              np.array([-2, -1, 5])])\nprint(X)\n\n[[ 3  1 -2]\n [ 4  5  3]\n [-2 -1  5]]\n\n\nWhen taken together as a matrix in this way, we can apply the linear mapping \\(A\\) to all vectors using matrix-matrix multiplication: \\[B=XA^T\\]\nLet’s put this into practice with a visual example.\nQ11: Create a \\(20 \\times 3\\) matrix, circle, in numpy of the following form\n\\[ \\begin{bmatrix} \\sin(\\theta_1) & \\cos(\\theta_1)  & 1 \\\\\n\\sin(\\theta_2) & \\cos(\\theta_2)  & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\theta_{20}) & \\cos(\\theta_{20})  & 1 \\\\\n\\end{bmatrix}\\] Where \\(\\theta_1...\\theta_{20}\\) are evenly spaced between \\(0\\) and \\(2\\pi\\).\n\ntheta = np.linspace(0, 2 * np.pi, 20) # Generates 20 evenly-spaced numbers between 0 and 2π\n\n# Fill in your code here\ncircle = np.stack([np.sin(theta), np.cos(theta), np.ones_like(theta)]).T\n\nThe code we just wrote creates a matrix corresponding to a collection of \\(20\\) row vectors of length 3. Each vector represents a point on the unit circle where the first entry is the x-coordinate, the second entry is the y-coordinate and the third entry is always \\(1\\): \\[ \\begin{bmatrix} x & y & 1 \\end{bmatrix}\\]\nQ12: Plot the set of 20 points in circle using the plt.plot function. Use only the x and y coordinates, ignoring the column of 1s.\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\n# Fill your code here\nplt.plot(circle[:, 0], circle[:, 1])\n\n\n\n\n\n\n\n\nQ13: Transform all the vectors in circle with the matrix \\(A\\) using a single call to np.dot. Then plot the original set of points in black and the transformed points in red using the plt.plot function.\nYou might also consider why we added the extra column of 1s! We will discuss the answer to that in class.\n\n# Fill your code here\ntransformed_circle = np.dot(circle, A)\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\n# Fill your code here\nplt.plot(circle[:, 0], circle[:, 1], c='k')\nplt.plot(transformed_circle[:, 0], transformed_circle[:, 1], c='r')"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework1-background/solutions.html#part-3-loading-and-visualizing-data",
    "href": "assignments/homeworks-sp24/homework1-background/solutions.html#part-3-loading-and-visualizing-data",
    "title": "Homework 1: Introduction to Numpy",
    "section": "Part 3: Loading and visualizing data",
    "text": "Part 3: Loading and visualizing data\nFor most of this class we will be working with real-world data. A very well-known dataset in statistics is the Iris flower dataset collected by Edgar Anderson in 1929. The dataset consists of measurments of iris flowers. Each flower has 4 collected measurements: sepal length, sepal width, petal length, petal width, as well as a classification into one of 3 species: Iris setosa, Iris versicolor and Iris virginica. We will return to this dataset in the next homework.\nWe can load this dataset as Numpy objects using the Scikit-Learn library. Below we’ve extrated 4 relevant arrays: - features: a \\(150 \\times 4\\) matrix which has one row per observed flower and one column per measurement. - targets: a length \\(150\\) array that specifies the species of each flower as a number 0-2. - feature_names: a list of strings with the name of each measurement. - target_names: a list of strings with the name of each species.\nIn this homework, we will only visualize this dataset, which is typically a good first step in working with a new type of data. To get a convenient summary of the data we will create what is called a scatterplot matrix. This is a grid of plots where each plot contains a scatter plot with different features on the x and y axes. Because there are 4 features (measurements) in this data, we will create a 4-by-4 matrix to plot each pair of features.\nQ14: Fill in the code to create a scatterplot matrix for the Iris dataset below. - Each row of the matrix should use a different feature for the y-axis and each column should use a different feature for the x-axis. The plots on the diagonal where x and y would be the same feature can be ignored. - The x and y axis of each sub-plot should be labeled with the appropriate feature names. - The points in each scatterplot should be colored by the species label of that flower. Include a legend in at least 1 sub-plot.\nHint: The linked Wikipedia article shows an example of a scatterplot matrix for this dataset, feel free to use it as reference!\n\nimport sklearn.datasets as datasets\ndataset = datasets.load_iris()\nfeatures = dataset['data']\ntargets = dataset['target']\nfeature_names = dataset['feature_names']\ntarget_names = dataset['target_names']\n\n# Fill in the code below\nfig, ax = plt.subplots(4, 4, figsize=(20, 20))\nfor i in range(4):\n    for j in range(4):\n        # Skip sub-plots on the diagonal\n        if i == j: \n            continue\n\n        # Add subplot code here\n        for c, name in enumerate(target_names): # Iterate through the different classes\n            # Plot only the features of examples in that class, label specifies the name for the legend\n            ax[i, j].scatter(features[targets == c, i], features[targets == c, j], label=name)\n        ax[i, j].legend() # Create the legend\n\n        # Set the axis labels\n        ax[i, j].set_xlabel(feature_names[i])\n        ax[i, j].set_ylabel(feature_names[j])"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "Please list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#overview",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#overview",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Overview",
    "text": "Overview\nIn this homework we will build a tiny neural network libarary from scratch and start on an implementation of automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\nPython features\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-1-autograd",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-1-autograd",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 1: Autograd",
    "text": "Part 1: Autograd\nIn this homework we will be using a special version of Numpy from a package called Autograd. Assuming it is installed (pip install autograd), we can import it as follows:\n\nimport autograd.numpy as np\n\nThis special version of Numpy behaives exactly like normal numpy. We can create and do calculations with arrays just like we would before:\n\nx = np.array([3., 2., 1])\nprint('x:\\t', x)\nprint('x^2:\\t', x ** 2)\nprint('sum(x):\\t', np.sum(x))\n\nx:   [3. 2. 1.]\nx^2:     [9. 4. 1.]\nsum(x):  6.0\n\n\nHowever, Autograd also has a very important trick up its sleeve: it can take derivatives (and gradients) for us! This functionality can be accessed through the grad function. Let’s start by seeing it in action with a very simple example, where we know the correct answer. The square function and its derivative can be written as:\n\\(f(x) = x^2, \\quad f'(x) = 2x\\)\nThe following code uses Autograd to compute this derivative automatically:\n\nfrom autograd import grad\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0\n\n\nWe can start to see how grad operates. grad takes as input a function (e.g. \\(f(x)\\)) and returns a new function that computes the derivative of \\(f\\) at \\(x\\). (\\(f'(x)\\)). So:\n\\(\\text{grad}(f) \\longrightarrow f'\\)\n\nQ1\nDefine the following function in python:\n\\(f(x) = \\log(\\sin(x^3) + 3 x)\\)\nUse grad to compute the derivative of \\(f\\) at \\(1.5\\) (i.e. compute \\(f'(1.5)\\))\n\ndef f(x):\n    return np.log(np.sin(x ** 3) + 2 * x)\n\nanswer = grad(f)(1.5)\nprint(\"f'(1.5)=\", answer)\n\nf'(1.5)= -1.6494948636364284\n\n\nAs the name would imply, grad can more generally be used to compute the gradient of a function of the form \\(f(\\mathbf{x}): \\mathbb{R}^d\\rightarrow \\mathbb{R}\\). Remember that for a function that takes in a vector and outputs a scalar, the gradient is vector of all partial derivatives of the output with respect to each input. For example, consider a function that gives the square of the 2-norm of a vector:\n\\(f(\\mathbf{x}) = ||\\mathbf{x}||^2_2 = \\mathbf{x}^T\\mathbf{x} = \\sum_{i=1}^d x_i^2\\)\nThink about why these expressions are equivalent!\nAs we’ve seen, the gradient of this function can be written as:\n\\(\\nabla f(\\mathbf{x}) = 2\\mathbf{x} = \\begin{bmatrix}2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_d \\end{bmatrix}\\)\nLet’s see what Autograd gives us in this case:\n\n# Define a function\ndef f(x):\n    return np.sum(x ** 2)\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = np.array([1., 2., 3])\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nx:   [1. 2. 3.]\nf(x):    14.0\nf'(x):   [2. 4. 6.]\n\n\nWe see that the gradient has the same shape as the input. So the gradient function is of the form: \\(\\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\)\nThis makes sense as the gradient should have exactly one partial derivative for each entry in the input to the function. As discussed, this even extends beyond vectors! We could have a function that takes in any datastructure and computes the set of partial derivatives with respect to each entry.\n\n\nQ2\nWrite a function that takes a list of vectors and computes the sum of the squared 2-norm for each vector. That is:\n\\(f([\\mathbf{a}, \\mathbf{b}, \\mathbf{c}...]) = ||\\mathbf{a}||^2 + ||\\mathbf{b}||^2 + ||\\mathbf{c}||^2+...\\)\nRecall from above how we can compute each term in this sum!\nThen use grad to compute the gradient of this function with respect to the given input.\n\n# Define a function\ndef f(x):\n    '''\n    Compute the sum of squared 2-norms for a list of vectors\n\n    Args:\n        x (list of arrays): A list of 1-dimensional arrays\n    Returns:\n        output (float): The result\n    '''\n    s = 0.\n    for xi in x:\n        s += np.dot(xi, xi)\n    return s\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = [np.array([1., 2., 3]), np.array([7., 2.]), np.array([6.])]\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nx:   [array([1., 2., 3.]), array([7., 2.]), array([6.])]\nf(x):    103.0\nf'(x):   [array([2., 4., 6.]), array([14.,  4.]), array([12.])]\n\n\nA useful argument that we can give to grad is argnum. If our function takes more than one argument argnum lets us specify which one to take the gradient with respect to. For example, if we have the function:\n\\(f(x, y) = x^2y\\)\nThen:\n\\(f'_x(x,y)=2xy, \\quad f'_y(x, y)=x^2\\)\n\ndef f(x, y):\n    return x ** 2 * y\n\nprint('f(3, 5) = ', f(3., 5.))\n\ndf_dx = grad(f, argnum=0)(3., 5.)\ndf_dy = grad(f, argnum=1)(3., 5.)\n\nprint('df_dx = ', df_dx)\nprint('df_dy = ', df_dy)\n\nf(3, 5) =  45.0\ndf_dx =  30.0\ndf_dy =  9.0"
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-2-implementing-a-neural-network",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-2-implementing-a-neural-network",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 2: Implementing a neural network",
    "text": "Part 2: Implementing a neural network\nNow that we have everything we need to apply automatic differentiation to train a neural network!\nBefore we do that though, let’s try out our automatic differentiation for logistic regression. Below is a slight modification of LogisticRegression implementation we saw in the last homework.\n\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1, 1))\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1., mode='constant')\n        return np.dot(X, w)\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n    \n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n    \n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n    \n    def nll_and_grad_no_autodiff(self, X, y):\n        # Compute nll_and_grad without automatic diferentiation\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nQ3\nWrite the method nll_and_grad for the LogisticRegression class using the grad function from Autograd. Verify that it gives a similar answer to nll_and_grad_no_autodiff.\nHint: Note that the nll function can optionally take in the parameters. You can use this functionality and the argnum argument of grad in your answer. You can assume that self refers to the model object, so you can access the weights via self.weights\n\ndef nll_and_grad(self, X, y):\n    loss = self.nll(X, y, self.weights)\n    grads = grad(self.nll, argnum=2)(X, y, self.weights)\n    return loss, grads\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nThis implementation quite inefficient (we’ll fix this in the future!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 25.74, accuracy: 0.88: 100%|██████████| 250/250 [00:00&lt;00:00, 1484.06it/s]\n\n\nModel accuracy: 0.880\n\n\n\n\n\n\n\n\n\nNow let’s extend our model to be a neural network! We’ll create a neural network class that extends our logistic regression class. First we’ll setup the needed weight matrices.\n\n\nQ4\nFill in the Neural Network __init__ method below. The method should take in the input data dimension and a list of integers specifying the size of each hidden layer (the number of neurons in each layer). The function should create a list of numpy arrays of the appropriate shapes for the weight matrices.\nFor example if dims is 2 and hidden_sizes is [4, 4], then self.weights should have 3 entries of shapes [(4x2), (4x4), (1x4)]. This network is shown below.\n\n\nInput Layer ∈ ℝ²Hidden Layer ∈ ℝ⁴Hidden Layer ∈ ℝ⁴Output Layer ∈ ℝ¹\n\nIf you find it easier you could also define the weights in terms of \\(W^T\\) instead, in which case the shapes would be: [(2x4), (4x4), (4x1)]. You could also consider how to add a bias term at each layer as in logistic regression (but this isn’t nessecary for full credit).\nThe values in each array should be drawn from a normal distribution with standard deviation 1. You can create such a matrix in numpy using:\nnp.random.normal(scale=1., size=shape)\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        self.weights = [1. * np.random.normal(scale=1., size=(i + 1, o)) for (i, o) in zip([dims] + hidden_sizes, hidden_sizes + [1])]\n\ntest_nn_constructor(NeuralNetwork)\n\nPassed!\n\n\nRecall that for logistic regression the prediction function (before threholding or sigmoid) was \\(\\mathbf{X}\\mathbf{w}\\). We now want to implement the prediction function for our neural network class. This function should perform the appropriate feature transforms and multiply by the regression weights. For a neural network with a single hidden layer this will look like:\n\\(f(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{w}_0\\)\nUse the sigmoid activation function for this problem.\nFor multiple layers we can also think of this a a chain of feature transforms: \\[\\Phi_1 = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\] \\[\\Phi_2 = \\sigma(\\Phi_1 \\mathbf{W}_2^T)\\] \\[...\\] \\[\\Phi_l = \\sigma(\\Phi_{l-1} \\mathbf{W}_l^T)\\] \\[f(\\mathbf{X}) = \\Phi_l\\mathbf{w}_0\\] Where \\(\\Phi_i\\) is just the variable that represents the neurons at layer \\(i\\) (the result of the first \\(i\\) transforms applied to \\(\\mathbf{X}\\)).\n\nQ5\nImplement the prediction function as described above. Note that the prediction function should use the weights passed into the w argument rather than self.weights, this will make it easier to implement the next question.\nHint: Note that this function should not apply a final sigmoid or thresholding, instead it should be the equivalent of linear_function from the previous homework\n\ndef prediction_function(self, X, w):\n    '''\n    Get the result of our base function for prediction (i.e. x^t w)\n\n    Args:\n        X (array): An N x d matrix of observations.\n        w (list of arrays): A list of weight matrices\n    Returns:\n        pred (array): An N x 1 matrix of f(X).\n    '''\n    for wi in w[:-1]:\n        X = sigmoid(LogisticRegression.prediction_function(self, X, wi))\n    pred = LogisticRegression.prediction_function(self, X, w[-1])\n    return pred.reshape((-1, 1))\n\nNeuralNetwork.prediction_function = prediction_function\ntest_nn_prediction_function(NeuralNetwork)\n\nPassed!\n\n\n\n\nQ6\nImplement an nll_and_grad method for the NeuralNetwork class using Autograd to compute the gradient with respect to each weight matrix.\nHint: If you use np.pad anywhere in your implementation, Autograd may complain if you don’t include the keyword argument mode='constant'\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    loss = self.nll(X, y, self.weights)\n    grads = grad(self.nll, argnum=2)(X, y, self.weights)\n    return loss, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 28.37, accuracy: 0.86: 100%|██████████| 250/250 [00:00&lt;00:00, 956.82it/s] \n\n\nModel accuracy: 0.860\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass ForwardValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parent_values    (list): A list of raw values of each input (as floats)\n        value   (float): The value of the result of this operation\n        forward_grads (dict): A dictionary mapping inputs to gradients\n    '''\n\n    def __init__(self, *args):\n        self.parent_values = [arg.value if isinstance(arg, ForwardValue) else arg for arg in args]\n        self.value = self.forward_pass(args)\n        \n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n        \n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n    \n    def forward_pass(self, args):\n        # Calls func to compute the value of this operation \n        self.forward_grads = {}\n        return self.func(*self.parent_values)\n    \n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n \n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ7\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\nclass _add(ForwardValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n    \nclass _neg(ForwardValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(ForwardValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        return a - b\n    \n    def grads(self, a, b):\n        return 1., -1.\n\nclass _mul(ForwardValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        return a * b\n    \n    def grads(self, a, b):\n        return b, a\n\nclass _div(ForwardValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        return a / b\n    \n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n    \nclass _exp(ForwardValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        return math.exp(a)\n    \n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(ForwardValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        return math.log(a)\n    \n    def grads(self, a):\n        return (1 / a,)\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, ForwardValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, ForwardValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nForwardValue.exp = lambda a: _exp(a)\nForwardValue.log = lambda a: _log(a)\nForwardValue.__add__ = lambda a, b: _add(a, b)\nForwardValue.__radd__ = lambda a, b: _add(b, a)\nForwardValue.__sub__ = lambda a, b: _sub(a, b)\nForwardValue.__rsub__ = lambda a, b: _sub(b, a)\nForwardValue.__neg__ = lambda a: _neg(a)\nForwardValue.__mul__ = lambda a, b: _mul(a, b)\nForwardValue.__rmul__ = lambda a, b: _mul(b, a)\nForwardValue.__truediv__ = lambda a, b: _div(a, b)\nForwardValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\n20\n0.6931471805599453\nPassed!\n\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\n\nQ8\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self, args):\n    self.forward_grads = {} \n    grads = None\n    for ind, node in enumerate(args):\n        if hasattr(node, 'forward_grads'):\n            if grads is None:\n                grads = self.grads(*self.parent_values)\n                self.forward_grads = {}\n                \n            for key, value in node.forward_grads.items():\n                if key not in self.forward_grads:\n                    self.forward_grads[key] = 0\n                self.forward_grads[key] += value * grads[ind]\n                \n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nForwardValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nPassed!\n\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\ndL/da = -0.067, dL/db = -0.333\n\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x * x\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0\n\n\nIn the next homework, we’ll combine our forward-mode AD implementation with our neural network class. Then we’ll look at how to do automatic-differentiation more efficiently with reverse-mode AD."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-3-forward-mode-automatic-differentiation",
    "href": "assignments/homeworks-sp24/homework4-neural-networks/solutions.html#part-3-forward-mode-automatic-differentiation",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 3: Forward-mode automatic differentiation",
    "text": "Part 3: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass ForwardValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parent_values    (list): A list of raw values of each input (as floats)\n        value   (float): The value of the result of this operation\n        forward_grads (dict): A dictionary mapping inputs to gradients\n    '''\n\n    def __init__(self, *args):\n        self.parent_values = [arg.value if isinstance(arg, ForwardValue) else arg for arg in args]\n        self.value = self.forward_pass(args)\n        \n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n        \n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n    \n    def forward_pass(self, args):\n        # Calls func to compute the value of this operation \n        self.forward_grads = {}\n        return self.func(*self.parent_values)\n    \n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n \n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ7\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\nclass _add(ForwardValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n    \nclass _neg(ForwardValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(ForwardValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        return a - b\n    \n    def grads(self, a, b):\n        return 1., -1.\n\nclass _mul(ForwardValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        return a * b\n    \n    def grads(self, a, b):\n        return b, a\n\nclass _div(ForwardValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        return a / b\n    \n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n    \nclass _exp(ForwardValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        return math.exp(a)\n    \n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(ForwardValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        return math.log(a)\n    \n    def grads(self, a):\n        return (1 / a,)\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, ForwardValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, ForwardValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it. \n# (You don't need to everything that's happening here to do the HW)\nForwardValue.exp = lambda a: _exp(a)\nForwardValue.log = lambda a: _log(a)\nForwardValue.__add__ = lambda a, b: _add(a, b)\nForwardValue.__radd__ = lambda a, b: _add(b, a)\nForwardValue.__sub__ = lambda a, b: _sub(a, b)\nForwardValue.__rsub__ = lambda a, b: _sub(b, a)\nForwardValue.__neg__ = lambda a: _neg(a)\nForwardValue.__mul__ = lambda a, b: _mul(a, b)\nForwardValue.__rmul__ = lambda a, b: _mul(b, a)\nForwardValue.__truediv__ = lambda a, b: _div(a, b)\nForwardValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our AutogradValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\n20\n0.6931471805599453\nPassed!\n\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\n\nQ8\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the foward_grads property of the operation such that: - foward_grads has an entry for every input that appears in foward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self, args):\n    self.forward_grads = {} \n    grads = None\n    for ind, node in enumerate(args):\n        if hasattr(node, 'forward_grads'):\n            if grads is None:\n                grads = self.grads(*self.parent_values)\n                self.forward_grads = {}\n                \n            for key, value in node.forward_grads.items():\n                if key not in self.forward_grads:\n                    self.forward_grads[key] = 0\n                self.forward_grads[key] += value * grads[ind]\n                \n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nForwardValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nPassed!\n\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\ndL/da = -0.067, dL/db = -0.333\n\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x * x\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0\n\n\nIn the next homework, we’ll combine our forward-mode AD implementation with our neural network class. Then we’ll look at how to do automatic-differentiation more efficiently with reverse-mode AD."
  },
  {
    "objectID": "assignments/homeworks-sp24/homework3-logistic-regression/solutions.html",
    "href": "assignments/homeworks-sp24/homework3-logistic-regression/solutions.html",
    "title": "Homework 3: Logistic regression and feature transforms",
    "section": "",
    "text": "In this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)\n\\(C: \\quad\\ \\text{Number of classes, so } y_i \\in \\{1,...,C\\}\\)\n\n# Run me first!\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom hw2_code_backup import get_dataset, gradient_descent, test_nll, test_nll_grad, test_predict, test_predict_probability, test_softmax, test_split\n\n# UNCOMMENT IF NEEDED, SEE Q10\nimport autograd.numpy as np\n\n\nBackground\nIn class we derived the logistic regression model for making predictions on binary data. Recall the the prediction function for logistic regression can be written as:\n\\[f(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\\]\nThe estimated probability of \\(y=1\\) as: \\[p(y=1\\mid \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{x}^T\\mathbf{w})\\]\nAlso recall that the negative log-likelihood loss for logistic regression can be written as:\n\\[\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\log \\sigma\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\nand it’s gradient with respect to \\(\\mathbf{w}\\) is: \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\big(1 - \\sigma((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w})\\big) \\big(2 y_i - 1\\big)\\mathbf{x}_i\\]\nBelow is an implementation of logistic regression using the functions we derived in class. In this example, we’ve created a logistic regression class that encapsulates the weights along with all of the functions we need to train and make predictions with the model.\n\ndef linear_function(X, w):\n    # Returns a linear function of X (and adds bias)\n    X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n    return np.dot(X, w)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1 / (1 + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1,))\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (int array): A length N array of predictions in {0, 1}\n        '''\n        return (linear_function(X, self.weights) &gt; 0).astype(int)\n    \n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): A length N vector of predicted class probabilities\n        '''\n        return sigmoid(linear_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        return np.mean(self.predict(X) == y)\n\n    def nll(self, X, y):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (int array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        return -np.sum(np.log(py))\n    \n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n    \n    def nll_and_grad(self, X, y):\n        '''\n        Compute both the NLL and it's gradient\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nLet’s take a look at how to use this class. The provided code includes a function get_dataset that downloads and loads one of serval different datasets. For this first example, we will use the humans and horses dataset, a dataset of images of humans and horses. We can load the dataset as follows:\n\nimages, labels, label_names = get_dataset('horses_and_humans')\n\n\n\n\n\n\n\n\nAs we saw in class, before we can use logistic regression on image data, we first need to reshape it from a 3-dimensional array into a 2-dimensional matrix:\n\nimage_shape = images[0].shape                # Keep track of the original image shape\nX = images.reshape((images.shape[0], -1))    # Reshape into an N x d matrix X\ny = labels\nprint('Image shape: ', images.shape, ', X shape: ', X.shape)\n\nImage shape:  (1027, 48, 48) , X shape:  (1027, 2304)\n\n\nWe can create a model using the LogisticRegression class, specifying the number of features (\\(d\\)):\n\nmodel = LogisticRegression(X.shape[1])\n\nWe can train the model using the gradient_descent function provided in the support code:\n\nlosses = gradient_descent(model, X, y, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\n\n# Uncomment to run with a live visualization\n# losses = gradient_descent(model, X, y, lr=1e-6, steps=500, image_shape=images[0].shape, watch=True)\n\nLoss 711.86, accuracy: 0.57:   0%|          | 0/2500 [00:00&lt;?, ?it/s]Loss 358.28, accuracy: 0.86: 100%|██████████| 2500/2500 [00:48&lt;00:00, 51.11it/s]\n\n\nWe can make predictions using the built-in methods:\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = np.where(prediction, probabilities, 1 - probabilities)\n\n# Show an image and the corresponding prediction\nplt.imshow(X[0].reshape(image_shape), cmap='gray')\nprint('Prediction: %s, probability: %.3f' % (label_names[prediction[0]], probability_of_prediction[0]))\n\nPrediction: human, probability: 0.641\n\n\n\n\n\n\n\n\n\n\n\nPart 1: Logistic regression and feature transforms\nWe’ll first evaluate the performance of the logistic regression model above.\n\nQ1: Train and test splits\nWrite a function to split the provided dataset into a train set and a test set. The train set should include 70% of the observations and the test set should include the remaining 30%. The data should be randomly shuffled to make sure there is no bias in the ordering.\n\ndef split_data(X, y):\n    inds = np.arange(X.shape[0])\n    np.random.shuffle(inds)\n    Xtrain, Xtest = X[inds[:700]], X[inds[700:]]\n    ytrain, ytest = y[inds[:700]], y[inds[700:]]\n\n    return Xtrain, ytrain, Xtest, ytest\n\n# Test the function\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\ntest_split(X, y, Xtrain, ytrain, Xtest, ytest)\n\nPassed!\n\n\n\n\nQ2: Model evaluation\nUsing the function you just wrote, train a new logistic regression model on just the training data. Evaluate the accuracy and loss of the trained model on both the training data and the test data.\n\n## YOUR CODE HERE\nnp.random.seed(10)\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\nmodel = LogisticRegression(X.shape[1])\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain, ytrain), model.nll(Xtrain, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest, ytest), model.nll(Xtest, ytest)\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 254.93, accuracy: 0.86: 100%|██████████| 2500/2500 [00:36&lt;00:00, 67.96it/s]\n\n\nTraining accuracy: 0.863, loss: 254.908\nTest accuracy: 0.813, loss: 141.683\n\n\nRecall that in class we dicussed feature transforms an easy way to get more expressive models, using our linear model tools. Here we’ll try applying some basic feature transforms to this problem and see if we can improve the performance.\n\n\nQ3: Quadratic feature transforms\nCreate a transformed versions of the training and test datasets by adding quadratic features. Only add the unary quadratic terms (\\(x_i^2\\)) not the cross terms (\\(x_i x_j\\)). For a single dimension the transform would look like: \\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ x_i^2 \\end{bmatrix}\\]\nIn general, the transform should look like:\n\\[\\textbf{Single observation: }\\phi(\\mathbf{x}) = \\begin{bmatrix}x_1 \\\\ \\vdots \\\\ x_d \\\\ x_1^2 \\\\ \\vdots \\\\ x_d^2 \\end{bmatrix}, \\quad \\textbf{Dataset: } \\phi(\\mathbf{X}) = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1d} & x_{11}^2 & \\dots & x_{1d}^2 \\\\ x_{21} & x_{22} & \\dots & x_{2d} & x_{21}^2 & \\dots & x_{2d}^2 \\\\  \\vdots & \\vdots & & \\vdots & \\vdots & & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nd} & x_{N1}^2 & \\dots & x_{Nd}^2 \\\\  \\end{bmatrix} \\]\n\n## YOUR CODE HERE\nXtrain_quad = np.concatenate([Xtrain, Xtrain ** 2], axis=1)\nXtest_quad = np.concatenate([Xtest, Xtest ** 2], axis=1)\n\nassert Xtrain_quad.shape == (Xtrain.shape[0], 2 * Xtrain.shape[1])\n\n\n\nQ4: Evaluating quadratic transforms\nTrain a new logistic regression model and evaluate the training and test accuracy and loss as you did in question 2.\n\n## YOUR CODE HERE\nmodel = LogisticRegression(Xtrain_quad.shape[1])\nlosses = gradient_descent(model, Xtrain_quad, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain_quad, ytrain), model.nll(Xtrain_quad, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest_quad, ytest), model.nll(Xtest_quad, ytest)\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 190.14, accuracy: 0.92: 100%|██████████| 2500/2500 [01:00&lt;00:00, 41.39it/s]\n\n\nTraining accuracy: 0.920, loss: 190.113\nTest accuracy: 0.853, loss: 109.164\n\n\n\n\nQ5: Evaluating sin transforms\nRepeat questions 3 & 4, but using a different transform, defined as:\n\\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ \\sin(10 x_i) \\end{bmatrix}\\]\n\n## YOUR CODE HERE\nXtrain_sin = np.concatenate([Xtrain, np.sin(10 * Xtrain)], axis=1)\nXtest_sin = np.concatenate([Xtest, np.sin(10 * Xtest)], axis=1)\n\nassert Xtrain_sin.shape == (Xtrain.shape[0], 2 * Xtrain.shape[1])\n\nmodel = LogisticRegression(Xtrain_sin.shape[1])\nlosses = gradient_descent(model, Xtrain_sin, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain_sin, ytrain), model.nll(Xtrain_sin, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest_sin, ytest), model.nll(Xtest_sin, ytest)\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\n  0%|          | 0/2500 [00:00&lt;?, ?it/s]Loss 136.40, accuracy: 0.98: 100%|██████████| 2500/2500 [00:59&lt;00:00, 42.21it/s]\n\n\nTraining accuracy: 0.979, loss: 136.363\nTest accuracy: 0.844, loss: 121.323\n\n\n\n\nQ6: Comparing feature transforms\nBased on the results, would you use any feature transform for this problem? If so, which one?\nYOUR ANSWER HERE\n\n\n\nPart 2: Multinomial logistic regression\nIn this part, we will look at implementing multinomial logistic regression. Recall that this model extends logistic regression to the cases where there may be more than 2 possible labels, so \\(y\\in\\{1,...,C\\}\\), where \\(C\\) is the number of classes (possible outputs).\nWe saw that rather than having a single weight vector, this model has a weight vector for each class, \\(\\mathbf{w}_1,...,\\mathbf{w}_C\\). We can view these together as the rows of a weight matrix \\(\\mathbf{W}\\): \\[\\mathbf{W} = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_C^T \\end{bmatrix}\\]\nWe saw that the prediction function for this model was: \\[f(\\mathbf{x}) = \\underset{c\\in \\{1,...,C\\}}{\\text{argmax}}\\ \\mathbf{x}^T\\mathbf{w}\\]\nThe probabilistic model was defined as: \\[\np(y_i=c \\mid \\mathbf{x}, \\mathbf{W}) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c=\\frac{e^{\\mathbf{x}^T\\mathbf{w}_c}}{\\sum_{j=1}^Ce^{\\mathbf{x}^T\\mathbf{w}_j}}\n\\]\nThe negative log-likelihood loss was defined as: \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nIn the next few questions we will create a modified version of our logistic regression class that supports multinomal logistic regression. The class definition is below. A few things to note:\n1: We will still assume y is an array of int in numpy. We can convert an array y to an array of int with y = y.astype(int) and back with y = y.astype(float)\n2: Remeber that numpy is 0-indexed, so our classes will actually be \\(0\\) to \\(C-1\\), (\\(y\\in \\{0,...,C-1\\}\\))\n2: We will assume our weight matrix is an \\(C \\times d\\) matrix as shown below\n\nclass MultinomialLogisticRegression(LogisticRegression):\n    def __init__(self, classes, dims):\n        '''\n        Args:\n            classes (int): C, the number of possible outputs\n            dims (int): d, the dimension of each input\n        '''\n        self.classes = classes\n        self.weights = np.zeros((classes, dims + 1,))\n\n\nQ7: Prediction\nWrite a function to make a prediction using the multinomial logistic regression prediction rule above. (assume self is the MultinomialLogisticRegression object)\n\ndef multiclass_predict(self, X):\n    '''\n    Predict labels given a set of inputs.\n\n    Args:\n        X (array): An N x d matrix of observations.\n    Returns:\n        pred (int array): A length N array of predictions in {0,...,(C-1)}\n    '''\n    W = self.weights\n\n    ## YOUR CODE HERE\n    pred = linear_function(X, self.weights.T).argmax(axis=-1)\n    return pred\n\n## Test the function\ntest_predict(multiclass_predict)\n\n## Add it to our class\nMultinomialLogisticRegression.predict = multiclass_predict\n\nPassed!\n\n\n\n\nQ7: Softmax\nImplement the softmax function. \\[\n\\text{softmax}(\\mathbf{x})_c = \\frac{e^{x_c}}{\\sum_{j=1}^Ce^{x_j}}, \\quad\n\\text{softmax}(\\mathbf{x}) = \\begin{bmatrix}\\frac{e^{x_1}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\frac{e^{x_2}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\vdots \\\\ \\frac{e^{x_C}}{\\sum_{j=1}^Ce^{x_j}} \\end{bmatrix}\n\\]\nYou function should accept inputs as either a length \\(C\\) vector or as an \\(N\\times C\\) matrix. If the input is a matrix, the softmax function should be applied to each row of the matrix.\n\ndef softmax(x):\n    '''\n    Apply the softmax function to a vector or matrix\n\n    Args:\n        X (array): An N x C matrix of transformed inputs (or a length C vector)\n    Returns:\n        probs (array):  An N x C matrix with the softmax function applied to each row\n    ''' \n    ex = np.exp(x)\n    return ex / np.sum(ex, axis=-1, keepdims=True)\n\n\ntest_softmax(softmax)\n\nPassed!\n\n\n\n\nQ7: Multinomial logistic regression NLL\nImplement a function to compute the multinomial logistic regression negative log-likelihood. \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nHint: Recall that \\(y_i\\) is an integer, so \\(\\mathbf{w}_{j}\\) refers to the row of the weight matrix at index \\(y_i\\) (you could access this as W[y[i]]). It’s possible to answer this question without loops, but you may find it easier to loop over each possible class/observation.\n\ndef nll(self, X, y):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        nll (float): The NLL loss\n    '''\n    xw = linear_function(X, self.weights.T)\n    loss = xw[np.arange(X.shape[0]), y].sum() - np.log(np.sum(np.exp(xw), axis=1)).sum()\n    return -loss\n\ntest_nll(nll)\nMultinomialLogisticRegression.nll = nll\n\nPassed!\n\n\n\n\nQ8: Gradient of NLL\nDerive the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}_c\\), the weight vector for a single class.\nHint: Again note that \\(\\mathbf{w}_{y_i}\\) refers to the weight vector corresponding to the true class of observation \\(i\\), and so only depend on \\(\\mathbf{w}_c\\) if \\(y_i=c\\). This means that: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\begin{cases}\\mathbf{x}_i \\quad \\text{ if } y_i = c \\\\ 0 \\quad \\ \\text{ otherwise}  \\end{cases}\\] We can write this more compactly using an indicator function: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\mathbb{I}(y_i=c)\\ \\mathbf{x}_i \\]\n\\[\\nabla_{\\mathbf{w}_c} \\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\frac{d}{d\\mathbf{w}_c}-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\]\nThe first step is to apply the addition/subtraction rule:\n\\[= -\\sum_{i=1}^N \\bigg(\\frac{d}{d\\mathbf{w}_c}\\big(\\mathbf{x}_i^T\\mathbf{w}_{y_i}\\big)- \\frac{d}{d\\mathbf{w}_c}\\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\]\nThen we can apply the rule we see above: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\frac{d}{d\\mathbf{w}_c}\\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\] Next we’ll apply the chain rule to the \\(\\log\\) function: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\ \\frac{d}{d\\mathbf{w}_c} \\bigg(\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg) \\bigg)\\] We see that only one term in the inner summation depends on \\(\\mathbf{w}_c\\) \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(\\frac{d}{d\\mathbf{w}_c}e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}\\bigg) \\bigg)\\] Applying the chain rule to the exponential we get: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(e^{\\mathbf{x}_i^T\\mathbf{w}_{c}} \\frac{d}{d\\mathbf{w}_c} \\mathbf{x}_i^T\\mathbf{w}_{c}\\bigg) \\bigg)\\] \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}  \\mathbf{x}_i\\bigg) \\bigg)\\] Factoring out \\(\\mathbf{x}_i\\) we get: \\[= -\\sum_{i=1}^N  \\mathbf{x}_i\\bigg(\\mathbb{I}(y_i=c) - \\frac{e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}  }{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}} \\bigg)\\]\n\n\nQ9: Implementing the gradient\nWrite a function that computes the gradient of the negative log-likelihood with repect to the weight vector for a given class, using the results of the derivation above.\n\ndef nll_gradient_c(W, X, y, c):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        W (array): The C x d weight matrix.\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n        c (int): The class to compute the gradient for\n    Returns:\n        grad (array): A length d vector representing the gradient with respect to w_c\n    '''\n    X = np.pad(X, [(0, 0), (0, 1)], constant_values=1.)\n    grad = 1 / np.exp(np.dot(X, W.T)).sum(axis=-1)\n\n    gradc = - X[y == c].sum(axis=0)\n    wc = W[:, c]\n    exwc = np.exp(np.dot(X, wc))\n    gradc = gradc + (grad * exwc).dot(X)\n    return gradc\n\n\n\n\nQ10: Implementing the full gradient\nUsing the function you just wrote, write a function to compute the full gradient with respect to the \\(C \\times d\\) weight matrix. Hint: The output should be a matrix!\n\ndef nll_gradient(self, X, y):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        grad (array): A C x d matrix representing the gradient with respect to W\n    '''\n    X = np.pad(X, [(0, 0), (0, 1)], constant_values=1.)\n    grad = 1 / np.exp(np.dot(X, self.weights.T)).sum(axis=-1)\n\n    grads = []\n    for c in range(self.classes):\n        gradc = - X[y == c].sum(axis=0)\n        wc = self.weights[c]\n        exwc = np.exp(np.dot(X, wc))\n        gradc = gradc + (grad * exwc).dot(X)\n        grads.append(gradc)\n    return np.stack(grads)\n\n\ntest_nll_grad(nll_gradient)\nMultinomialLogisticRegression.nll_gradient = nll_gradient\n\nPassed!\n\n\nNote if you are struggling with this problem, you can uncomment the following cell and the import statement at the top of this notebook to get a valid gradient function based on you nll function.\n\n'''\ndef autograd_nll_gradient(self, X, y):\n    import autograd\n    def autograd_nll(W):\n        temp_model = MultinomialLogisticRegression(self.classes, X.shape[1])\n        temp_model.weights = W\n        return temp_model.nll(X, y)\n    return autograd.grad(autograd_nll)(self.weights)\n#test_nll_grad(nll_gradient)\ntest_nll_grad(autograd_nll_gradient)\nMultinomialLogisticRegression.nll_gradient = autograd_nll_gradient\n'''\n\n'\\ndef autograd_nll_gradient(self, X, y):\\n    import autograd\\n    def autograd_nll(W):\\n        temp_model = MultinomialLogisticRegression(self.classes, X.shape[1])\\n        temp_model.weights = W\\n        return temp_model.nll(X, y)\\n    return autograd.grad(autograd_nll)(self.weights)\\n#test_nll_grad(nll_gradient)\\ntest_nll_grad(autograd_nll_gradient)\\nMultinomialLogisticRegression.nll_gradient = autograd_nll_gradient\\n'\n\n\nFinally, we will test out our multinomial logistic regression classifier on the MNIST dataset (https://en.wikipedia.org/wiki/MNIST_database), one of the most popular datasets in machine learning! We’ll start by loading it as before.\n\nimages, labels, label_names = get_dataset('mnist')\n\nimage_shape = images[0].shape                # Keep track of the original image shape\nX = images.reshape((images.shape[0], -1))    # Reshape into an N x d matrix X\ny = labels\nprint('Image shape: ', images.shape, ', X shape: ', X.shape)\n\n# Create the initial model\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\n\n\n\n\n\n\n\n\nImage shape:  (5000, 28, 28) , X shape:  (5000, 784)\n\n\n\n\nQ11: Repeat question 2 using the MNIST dataset\n\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\n\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain, ytrain), model.nll(Xtrain, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest, ytest), model.nll(Xtest, ytest)\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 442.68, accuracy: 0.87: 100%|██████████| 2500/2500 [01:07&lt;00:00, 37.21it/s]\n\n\nTraining accuracy: 0.870, loss: 442.595\nTest accuracy: 0.845, loss: 3025.243\nTraining accuracy: 0.870, loss: 442.595\nTest accuracy: 0.845, loss: 3025.243\n\n\n\nfor i in range(10):\n    plt.imshow(model.weights[i, :-1].reshape((28, 28)))\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ12: Repeat question 3 using the MNIST dataset\n\n## YOUR CODE HERE\nXtrain_quad = np.concatenate([Xtrain, Xtrain ** 2], axis=1)\nXtest_quad = np.concatenate([Xtest, Xtest ** 2], axis=1)\n\nassert Xtrain_quad.shape == (Xtrain.shape[0], 2 * Xtrain.shape[1])\nassert Xtrain_quad.shape == (Xtrain.shape[0], 2 * Xtrain.shape[1])\n\n\n\nQ13: Repeat question 4 using the MNIST dataset\n\n## YOUR CODE HERE\n\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=Xtrain_quad.shape[1])\n\nlosses = gradient_descent(model, Xtrain_quad, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain_quad, ytrain), model.nll(Xtrain_quad, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest_quad, ytest), model.nll(Xtest_quad, ytest)\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 414.28, accuracy: 0.89: 100%|██████████| 2500/2500 [01:16&lt;00:00, 32.50it/s]\n\n\nTraining accuracy: 0.887, loss: 414.195\nTest accuracy: 0.850, loss: 2944.114\n\n\n\n\nQ14: Repeat question 5 using the MNIST dataset\n\n## YOUR CODE HERE\nXtrain_sin = np.concatenate([Xtrain, np.sin(10 * Xtrain)], axis=1)\nXtest_sin = np.concatenate([Xtest, np.sin(10 * Xtest)], axis=1)\n\nassert Xtrain_sin.shape == (Xtrain.shape[0], 2 * Xtrain.shape[1])\n\nmodel = MultinomialLogisticRegression(len(label_names), Xtrain_sin.shape[1])\nlosses = gradient_descent(model, Xtrain_sin, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain_sin, ytrain), model.nll(Xtrain_sin, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest_sin, ytest), model.nll(Xtest_sin, ytest)\n\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 388.06, accuracy: 0.89: 100%|██████████| 2500/2500 [01:12&lt;00:00, 34.38it/s]\n\n\nTraining accuracy: 0.890, loss: 387.972\nTest accuracy: 0.850, loss: 2865.387\n\n\n\n\nQ15: Final evaluation\nBased on the results, would you use any feature transform for this problem? If so, which one?\nIn this case we see that the feature transform makes very little difference."
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html",
    "title": "Homework 8: Optimization and Normalization",
    "section": "",
    "text": "For this homework and for the final project, you may find it useful to run your code with access to a sufficient GPU, which may allow your code to run faster (we will talk about why later in the course). If you do not have access to a powerful GPU on your personal computer (e.g. if you primarily use a laptop), then there are 2 options you may consider for using a remotely hosted GPU.\nNote that some laptops may actually run this code faster than the course server, so you may want to try it first on your laptop regardless\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\ndata_path = '/tmp/data'"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html#set-hyperparameters",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html#set-hyperparameters",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Set Hyperparameters",
    "text": "Set Hyperparameters\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\nfrom torchsummary import summary\n\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import Compose, Normalize, ToTensor\n\nfrom fastprogress.fastprogress import master_bar, progress_bar\n\nimport matplotlib.pyplot as plt\n\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using '{device}' device.\")\n\n# Model hyperparameters\nneurons_per_hidden_layer = [20] * 2\n\n# Mini-Batch SGD hyperparameters\nbatch_size = 256\nnum_epochs = 10\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\n\nUsing 'cpu' device."
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html#prepare-the-dataset",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html#prepare-the-dataset",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Prepare the Dataset",
    "text": "Prepare the Dataset\n\ndef get_fmnist_data_loaders(path, batch_size, valid_batch_size=0):\n    # Computing normalization constants for Fashion-MNIST (commented out since we only need to do this once)\n    # train_loader, valid_loader = get_fmnist_data_loaders(data_path, 0)\n    # X, _ = next(iter(train_loader))\n    # s, m = torch.std_mean(X)\n\n\n    # Data specific transforms\n    data_mean = (0.2860,)\n    data_std = (0.3530,)\n    xforms = Compose([ToTensor(), Normalize(data_mean, data_std)])\n\n    # Training data loader\n    train_dataset = FashionMNIST(root=path, train=True, download=True, transform=xforms)\n\n    # Set the batch size to N if batch_size is 0\n    tbs = len(train_dataset) if batch_size == 0 else batch_size\n    train_loader = DataLoader(train_dataset, batch_size=tbs, shuffle=True)\n\n    # Validation data loader\n    valid_dataset = FashionMNIST(root=path, train=False, download=True, transform=xforms)\n\n    # Set the batch size to N if batch_size is 0\n    vbs = len(valid_dataset) if valid_batch_size == 0 else valid_batch_size\n    valid_loader = DataLoader(valid_dataset, batch_size=vbs, shuffle=True)\n\n    return train_loader, valid_loader\n\n\n# Load the example dataset (Fashion MNIST)\ntrain_loader, valid_loader = get_fmnist_data_loaders(data_path, batch_size)\n\nprint(\"Training dataset shape   :\", train_loader.dataset.data.shape)\nprint(\"Validation dataset shape :\", valid_loader.dataset.data.shape)\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|██████████| 26.4M/26.4M [00:27&lt;00:00, 944kB/s] \n\n\nExtracting /tmp/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n\n\n100%|██████████| 29.5k/29.5k [00:00&lt;00:00, 510kB/s]\n\n\nExtracting /tmp/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n\n\n100%|██████████| 4.42M/4.42M [00:03&lt;00:00, 1.19MB/s]\n\n\nExtracting /tmp/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n\n\n100%|██████████| 5.15k/5.15k [00:00&lt;00:00, 25.5MB/s]\n\n\nExtracting /tmp/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/FashionMNIST/raw\n\nTraining dataset shape   : torch.Size([60000, 28, 28])\nValidation dataset shape : torch.Size([10000, 28, 28])\n\n\n\n\n\n\n# Let's plot a few images as an example\nnum_to_show = 8\nimages = train_loader.dataset.data[:num_to_show]\ntargets = train_loader.dataset.targets[:num_to_show]\nlabels = [train_loader.dataset.classes[t] for t in targets]\n\nfig, axes = plt.subplots(1, num_to_show)\n\nfor axis, image, label in zip(axes, images, labels):\n    axis.imshow(image.squeeze(), cmap=\"Greys\")\n    axis.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n    axis.set_xticks([])\n    axis.set_yticks([])\n    axis.set_title(f\"{label}\")"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html#create-a-neural-network",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html#create-a-neural-network",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Create a Neural Network",
    "text": "Create a Neural Network\n\nclass Layer(nn.Module):\n    # This class will represent a basic neural network layer with a linear function\n    # and an activation (in this case ReLU)\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        self.linear = nn.Linear(in_dimensions, out_dimensions)\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = self.activation(x)\n        return x\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self, layer_sizes, layer_class=Layer):\n        super(NeuralNetwork, self).__init__()\n\n        # The first \"layer\" just rearranges the Nx28x28 input into Nx784\n        first_layer = nn.Flatten()\n\n        # The hidden layers include:\n        # 1. a linear component (computing Z) and\n        # 2. a non-linear comonent (computing A)\n        hidden_layers = [\n            (layer_class(nlminus1, nl) if nlminus1 == nl else Layer(nlminus1, nl))\n            for nl, nlminus1 in zip(layer_sizes[1:-1], layer_sizes)\n        ]\n\n        # The output layer must be Linear without an activation. See:\n        #   https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n        output_layer = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n\n        # Group all layers into the sequential container\n        all_layers = [first_layer] + hidden_layers + [output_layer]\n        self.layers = nn.Sequential(*all_layers)\n\n    def forward(self, X):\n        return self.layers(X)"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html#implement-an-optimizer",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html#implement-an-optimizer",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Implement an Optimizer",
    "text": "Implement an Optimizer\n\nclass SGDOptimizer:\n    def __init__(self, parameters, lr=0.01):\n        # Set the learning rate\n        self.lr = lr\n        # Store the set of parameters that we'll be optimizing\n        self.parameters = list(parameters)\n\n    def step(self):\n        # Take a step of gradient descent\n        for ind, parameter in enumerate(self.parameters):\n            # Compute the update to the parameter\n            update = self.lr * parameter.grad\n\n            # Update the parameter: w &lt;- w - lr * grad\n            parameter -= update"
  },
  {
    "objectID": "assignments/homeworks/Homework 8/solutions-ED50PD.html#train-classifier",
    "href": "assignments/homeworks/Homework 8/solutions-ED50PD.html#train-classifier",
    "title": "Homework 8: Optimization and Normalization",
    "section": "Train Classifier",
    "text": "Train Classifier\n\n# Here we'll define a function to train and evaluate a neural network with a specified architecture\n# using a specified optimizer.\ndef run_model(optimizer=SGDOptimizer,\n              layer_type=Layer,\n              number_of_hidden_layers=2,\n              neurons_per_hidden_layer=20,\n              learning_rate=0.001):\n\n    # Get the dataset\n    train_loader, valid_loader = get_fmnist_data_loaders(data_path, batch_size)\n\n    # The input layer size depends on the dataset\n    nx = train_loader.dataset.data.shape[1:].numel()\n\n    # The output layer size depends on the dataset\n    ny = len(train_loader.dataset.classes)\n\n    # Preprend the input and append the output layer sizes\n    layer_sizes = [nx] + [neurons_per_hidden_layer] * number_of_hidden_layers + [ny]\n\n    # Do model creation here so that the model is recreated each time the cell is run\n    model = NeuralNetwork(layer_sizes, layer_type).to(device)\n\n    t = 0\n    # Create the optimizer, just like we have with the built-in optimizer\n    opt = optimizer(model.parameters(), learning_rate)\n\n    # A master bar for fancy output progress\n    mb = master_bar(range(num_epochs))\n\n    # Information for plots\n    mb.names = [\"Train Loss\", \"Valid Loss\"]\n    train_losses = []\n    valid_losses = []\n\n    for epoch in mb:\n\n        #\n        # Training\n        #\n        model.train()\n\n        train_N = len(train_loader.dataset)\n        num_train_batches = len(train_loader)\n        train_dataiterator = iter(train_loader)\n\n        train_loss_mean = 0\n\n        for batch in progress_bar(range(num_train_batches), parent=mb):\n\n            # Grab the batch of data and send it to the correct device\n            train_X, train_Y = next(train_dataiterator)\n            train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n            # Compute the output\n            train_output = model(train_X)\n\n            # Compute loss\n            train_loss = criterion(train_output, train_Y)\n\n            num_in_batch = len(train_X)\n            tloss = train_loss.item() * num_in_batch / train_N\n            train_loss_mean += tloss\n            train_losses.append(train_loss.item())\n\n            # Compute gradient\n            model.zero_grad()\n            train_loss.backward()\n\n            # Take a step of gradient descent\n            t += 1\n            with torch.no_grad():\n                opt.step()\n\n        #\n        # Validation\n        #\n        model.eval()\n\n        valid_N = len(valid_loader.dataset)\n        num_valid_batches = len(valid_loader)\n\n        valid_loss_mean = 0\n        valid_correct = 0\n\n        with torch.no_grad():\n\n            # valid_loader is probably just one large batch, so not using progress bar\n            for valid_X, valid_Y in valid_loader:\n\n                valid_X, valid_Y = valid_X.to(device), valid_Y.to(device)\n\n                valid_output = model(valid_X)\n\n                valid_loss = criterion(valid_output, valid_Y)\n\n                num_in_batch = len(valid_X)\n                vloss = valid_loss.item() * num_in_batch / valid_N\n                valid_loss_mean += vloss\n                valid_losses.append(valid_loss.item())\n\n                # Convert network output into predictions (one-hot -&gt; number)\n                predictions = valid_output.argmax(1)\n\n                # Sum up total number that were correct\n                valid_correct += (predictions == valid_Y).type(torch.float).sum().item()\n\n        valid_accuracy = 100 * (valid_correct / valid_N)\n\n        # Report information\n        tloss = f\"Train Loss = {train_loss_mean:.4f}\"\n        vloss = f\"Valid Loss = {valid_loss_mean:.4f}\"\n        vaccu = f\"Valid Accuracy = {(valid_accuracy):&gt;0.1f}%\"\n        mb.write(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\n        # Update plot data\n        max_loss = max(max(train_losses), max(valid_losses))\n        min_loss = min(min(train_losses), min(valid_losses))\n\n        x_margin = 0.2\n        x_bounds = [0 - x_margin, num_epochs + x_margin]\n\n        y_margin = 0.1\n        y_bounds = [min_loss - y_margin, max_loss + y_margin]\n\n        valid_Xaxis = torch.linspace(0, epoch + 1, len(train_losses))\n        valid_xaxis = torch.linspace(1, epoch + 1, len(valid_losses))\n        graph_data = [[valid_Xaxis, train_losses], [valid_xaxis, valid_losses]]\n\n        mb.update_graph(graph_data, x_bounds, y_bounds)\n\n    print(f\"[{epoch+1:&gt;2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n\nrun_model()\n\n\n\n\n\n[ 1/10] Train Loss = 2.3014; Valid Loss = 2.2766; Valid Accuracy = 18.7%[ 2/10] Train Loss = 2.2435; Valid Loss = 2.2085; Valid Accuracy = 24.4%[ 3/10] Train Loss = 2.1662; Valid Loss = 2.1201; Valid Accuracy = 28.7%[ 4/10] Train Loss = 2.0617; Valid Loss = 1.9984; Valid Accuracy = 39.1%[ 5/10] Train Loss = 1.9215; Valid Loss = 1.8403; Valid Accuracy = 42.8%[ 6/10] Train Loss = 1.7482; Valid Loss = 1.6559; Valid Accuracy = 44.9%[ 7/10] Train Loss = 1.5613; Valid Loss = 1.4729; Valid Accuracy = 48.9%[ 8/10] Train Loss = 1.3903; Valid Loss = 1.3183; Valid Accuracy = 54.5%[ 9/10] Train Loss = 1.2532; Valid Loss = 1.2001; Valid Accuracy = 58.4%[10/10] Train Loss = 1.1504; Valid Loss = 1.1125; Valid Accuracy = 61.8%\n\n\n\n\n\n\n\n\n\n[10/10] Train Loss = 1.1504; Valid Loss = 1.1125; Valid Accuracy = 61.8%"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/main.html",
    "href": "assignments/homeworks/Homework 6/main.html",
    "title": "Homework 6: Vectorization",
    "section": "",
    "text": "In this homework we will update a our reverse-mode automatic differentiation library to use vectorized operations. It should make it a lot faster!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw6_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw6_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/main.html#overview",
    "href": "assignments/homeworks/Homework 6/main.html#overview",
    "title": "Homework 6: Vectorization",
    "section": "",
    "text": "In this homework we will update a our reverse-mode automatic differentiation library to use vectorized operations. It should make it a lot faster!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw6_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw6_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/main.html#part-0-setting-up-automatic-differentiation",
    "href": "assignments/homeworks/Homework 6/main.html#part-0-setting-up-automatic-differentiation",
    "title": "Homework 6: Vectorization",
    "section": "Part 0: Setting up automatic differentiation",
    "text": "Part 0: Setting up automatic differentiation\nHere we’ll re-use our automatic differentiation library from the previous homework as our starting point for this assignment.\nIn the marked cells below, copy the corresponding answers from homework 5. You may use either your own answers or published solutions.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        parent_values    (list): A list of raw values of each input (as floats)\n        forward_grads (dict): A dictionary mapping inputs to gradients\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.parent_values = [arg.value if isinstance(arg, AutogradValue) else arg for arg in args]\n        self.forward_grads = {}\n        self.value = self.forward_pass()\n        self.grad = 0. # Used later for reverse mode\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.parent_values)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\n\nDefining operations\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\nclass _add(AutogradValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _neg(AutogradValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(AutogradValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(AutogradValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _div(AutogradValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _exp(AutogradValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nclass _log(AutogradValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\n\n\nBackward pass\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef backward_pass(self):\n    ## COPY CODE FROM HOMEWORK 5 HERE\n    local_grads = self.grads(*self.args)\n\nAutogradValue.backward_pass = backward_pass\n\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## COPY CODE FROM HOMEWORK 5 HERE\n\nAutogradValue.backward = backward\n\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/main.html#training-a-neural-network",
    "href": "assignments/homeworks/Homework 6/main.html#training-a-neural-network",
    "title": "Homework 6: Vectorization",
    "section": "Training a neural network",
    "text": "Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks!\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if isinstance(a, AutogradValue) or isinstance(b, AutogradValue) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + np.exp(-x))\n\ndef log(x):\n    # Computes the sigmoid function\n    return x.log() if isinstance(x, AutogradValue) else np.log(x)\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid(xw * (2 * y - 1))\n        return -(log(py)).sum()\n\n\nAutograd for a neural network\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    # YOUR CODE HERE\n    \n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    # YOUR CODE HERE\n\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/main.html#part-1-vectorizing-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 6/main.html#part-1-vectorizing-reverse-mode-automatic-differentiation",
    "title": "Homework 6: Vectorization",
    "section": "Part 1: Vectorizing Reverse-mode automatic differentiation",
    "text": "Part 1: Vectorizing Reverse-mode automatic differentiation\nWe might notice that our reverse-mode automatic differentiation implementation is quite slow! The main reason for this is that our implementation operates on individual numbers (scalars) rather than entire arrays. This means that for a big operation like a matrix multiplication, an AutogradValue object needs to be tracked for each of the \\(O(n^3)\\) individual operations! Even worse, it also means that internally Numpy can’t use the very fast C and C++ implementations it has for array operations on type float, our array elements are now objects so it has to fall back on slow Python-loop based implementations.\nIdeally we’d like our AutogradValue objects to operate at the level of array operations, rather than scalar operations. This would circumvent these problems as we could represent an entire matrix multiplication with a single AutogradValue. In order to do this efficiently, we’ll need to make use of the Vector-Jacobian Product idea that we discussed in class. Let’s review the concept here.\nRecall that in backward_pass for a node c we assume that we have the gradient (derivative) of the loss with respect to c: \\(\\frac{dL}{d\\mathbf{c}}\\) and we need to update the gradients for the parents (say a and b) as:\n\\[\\frac{dL}{da} = \\frac{dL}{dc} \\frac{dc}{da}, \\quad \\frac{dL}{dc} = \\frac{dL}{dc} \\frac{dc}{db}\\]\nWhen \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\) are vectors the derivates \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) and \\(\\frac{d\\mathbf{c}}{d\\mathbf{b}}\\) are Jacobian matrices with possibly many entries and our updates become vector-Jacobian products:\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T, \\quad \\frac{dL}{d\\mathbf{b}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{b}}\\bigg)^T\\]\n\nQ1 (5 points)\nIn this case, let’s assume that \\(\\mathbf{a}\\) is a length \\(n\\) vector and \\(\\mathbf{c}\\) is a length \\(m\\) vector. So we would say that: \\[\\mathbf{a} \\in \\mathbb{R}^n, \\quad \\mathbf{c} \\in \\mathbb{R}^m\\]\nRemember that our loss, \\(L\\), is generally a scalar (\\(L\\in \\mathbb{R}\\)). Based on this, what is the shape of each term in the equation below?\n\\[\\frac{dL}{d\\mathbf{a}} = \\bigg(\\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}\\bigg)^T\\]\nYour answer should be as matrix/vector dimensions e.g. \\((n \\times m)\\)\n\\[\\frac{dL}{d\\mathbf{a}} = ?\\] \\[\\frac{dL}{d\\mathbf{c}} = ?\\] \\[\\frac{d\\mathbf{c}}{d\\mathbf{a}} = ?\\]\n\n\nElement-wise operations\nWe often don’t need to actually construct the Jacobians fully to compute these vector-Jacobian products, as is the case for element-wise operations. As long as we can compute the correct values for \\(\\frac{dL}{d\\mathbf{a}}\\), we’re good! For example if \\[\\mathbf{c} = \\mathbf{a}^2, \\quad \\mathbf{c} = \\begin{bmatrix} a_1^2 \\\\ a_2^2 \\\\ a_3^2 \\\\ \\vdots \\end{bmatrix}\\]\nWe can easily see that we can just update the derivate for each element of \\(\\mathbf{a}\\) independently. \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix} = 2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\]\nIf we want to be more formal we can note that technically, the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is diagonal (\\(\\frac{\\partial c_i}{\\partial a_j}\\) is only nonzeros for \\(i=j\\)). Therefore we can write the Vector-Jacobian Product as:\n\\[\\frac{dL}{d\\mathbf{a}}^T = \\frac{dL}{d\\mathbf{c}}^T \\frac{d\\mathbf{c}}{d\\mathbf{a}}  = \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 2 a_1 & 0 & 0 & \\dots \\\\0  & 2 a_2 & 0 & \\dots \\\\ 0 & 0 & 2 a_3 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 2 a_1 \\\\  \\frac{dL}{dc_2} \\cdot 2 a_2 \\\\  \\frac{dL}{dc_3} \\cdot 2 a_3 \\\\ \\vdots  \\end{bmatrix}^T = \\bigg(2 \\mathbf{a} \\odot \\frac{dL}{d\\mathbf{c}}\\bigg)^T\\]\nFor the case of addition, things are even simpler! If: \\[\\mathbf{c} = \\mathbf{a} + \\mathbf{b}\\]\nWe can again see that we can just update the derivative for each element of \\(\\mathbf{a}\\) independently, but this time each local derivative (\\(\\frac{dc_i}{da_i}\\)) is just \\(1\\), so \\[\\frac{dL}{d\\mathbf{a}} =  \\begin{bmatrix} \\frac{dL}{dc_1} \\cdot 1 \\\\  \\frac{dL}{dc_2} \\cdot 1 \\\\  \\frac{dL}{dc_3} \\cdot 1 \\\\ \\vdots  \\end{bmatrix} = \\frac{dL}{d\\mathbf{c}}\\]\nIn this case the Jacobian \\(\\frac{d\\mathbf{c}}{d\\mathbf{a}}\\) is simply the identity matrix, so: \\[\\frac{dL}{d\\mathbf{a}}^T =  \\begin{bmatrix} \\frac{dL}{dc_1} \\\\  \\frac{dL}{dc_2} \\\\  \\frac{dL}{dc_3} \\\\ \\vdots  \\end{bmatrix}^T \\begin{bmatrix} 1 & 0 & 0 & \\dots \\\\0  & 1 & 0 & \\dots \\\\ 0 & 0 & 1 & \\dots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}= \\frac{dL}{d\\mathbf{c}}^T \\mathbf{I} = \\frac{dL}{d\\mathbf{c}}^T\\]\n\n\nQ2 (10 points)\nAssume that we have the following formula for \\(\\mathbf{a}\\): \\[\\mathbf{a}= \\exp \\big( \\mathbf{A} \\mathbf{w} \\big) + \\mathbf{w}^2\\] Where \\(\\mathbf{A}\\) is a constant \\(n \\times n\\) matrix. Given the gradient of \\(L\\) with respect to \\(\\mathbf{a}\\): \\(\\frac{dL}{d\\mathbf{a}}\\), what is the gradient of \\(L\\) with respect to \\(\\mathbf{w}\\) (\\(\\frac{dL}{d\\mathbf{w}}\\)) in terms of: \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{w}\\)?\nHint: You do not need to write a formula for the Jacobian (\\(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\)). As we see above, many VJPs can be written without definining the Jacobian explicitly (e.g. for element-wise functions). You can use \\(\\odot\\) (\\odot) to denote an element-wise product between vectors: \\[ \\mathbf{a} \\odot \\mathbf{b} = \\begin{bmatrix}\na_1 b_1 \\\\\na_2 b_3 \\\\\n\\vdots \\\\\na_d b_d \\\\\n\\end{bmatrix}\n\\]\nYour answer:\n\\[ \\frac{dL}{d\\mathbf{w}} = ?\\]\n\n\nQ3 (15 points)\nLet’s replace our operation implementations above with ones that compute Vector-Jacobian products. We’ll start with element-wise operations. Complete the vjp function for each operation below. Unlike the grads methods we implemented before which computed the derivative of the output with respect to each input: \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\) (if applicable), each vjp method should directly compute the gradient of the loss with respect to each input: \\(\\frac{dL}{d\\mathbf{a}}\\) and \\(\\frac{dL}{d\\mathbf{b}}\\), assuming the grad argument provides the gradient of the loss with respect to the output: \\(\\frac{dL}{d\\mathbf{c}}\\).\nHint: For binary operations (+,-,*,/), you do not need to account for broadcasting. That is, you can assume that a, b and c are always the same shape! We’ve started you off with a few examples to base your answers on.\n\nclass _add(AutogradValue):\n    # An example representing the addition operation.\n    def func(self, a, b):\n        '''\n        Computes the result of the operation (a + b). Assumes a and b are the same shape.\n\n        Args:\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            c (array of float): The result c = a + b\n        '''\n        return a + b\n\n    def vjp(self, grad, a, b):\n        '''\n        Computes dL/da and dL/db given dL/dc.\n\n        Args:\n            grad (array of float): The gradient of the loss with respect to the output (dL/dc)\n            a (array of float): The first operand\n            b (array of float): The second operand\n        Returns:\n            grads (tuple of arrays): A tuple containing the gradients dL/da and dL/db\n        '''\n        return grad, grad\n\nclass _square(AutogradValue):\n    # Another example class implementing c = a^2\n    def func(self, a):\n        return a ** 2\n\n    def vjp(self, grad, a):\n        return (2 * a * grad,)\n\nclass _pad(AutogradValue):\n    # An implementation for padding with a column of 1s.\n    def func(self, a):\n        return np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\n    def vjp(self, grad, a):\n        return (grad[:, :-1],)\n\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return np.exp(a)\n\n    def vjp(self,grad,  a):\n        # YOUR CODE HERE\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return np.log(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_neg, '_neg', )\ntest_vjp(_exp, '_exp', true_func=anp.exp)\ntest_vjp(_log, '_log', true_func=anp.log)\ntest_vjp(_sub, '_sub', True)\ntest_vjp(_mul, '_mul', True)\ntest_vjp(_div, '_div', True)\n\n\n\nQ4 (15 points)\nConsider the operation defined by np.sum, that takes the sum over all elements of a matrix or vector, producing a scalar:\n\\[c  = \\sum_{i=1}^n a_i\\]\nWrite a vjp method for this operation that computes: \\(\\frac{dL}{d\\mathbf{a}}\\) given \\(\\frac{dL}{dc}\\).\nHint: Note that \\(L\\), \\(c\\) and \\(\\frac{dL}{dc}\\) are all scalars, so for any entry \\(i\\) of our output we can simply apply the chain rule and compute \\(\\frac{dL}{da_i} = \\frac{dL}{dc} \\frac{dc}{da_i}\\). As the equation above for \\(c\\) given \\(\\mathbf{a}\\) is a sum, \\(\\frac{dc}{da_i}\\) should be simple!\n\nclass _sum(AutogradValue):\n    def func(self, a):\n        return np.sum(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_sum, '_sum', true_func=anp.sum, issum=True)\n\n\n\nMatrix multiplication\nFor the next few problems, it may be useful to refer to this diagram of matrix multiplication.\n\n\n\nimage.png\n\n\nThe last important operation we’ll need a vjp method for in order to use our vectorized AutogradValue class for a neural network is matrix multiplication. Let’s consider the operation:\n\\[\\mathbf{C} = \\mathbf{A}\\mathbf{B}\\]\nWhere \\(\\mathbf{A}\\) is an \\(N\\times h\\) matrix, \\(\\mathbf{B}\\) is a \\(h \\times d\\) matrix and \\(\\mathbf{C}\\) is an \\(N\\times d\\) matrix.\nRecall that for vjp want to compute \\(\\frac{dL}{d\\mathbf{A}}\\) (and \\(\\frac{dL}{d\\mathbf{B}}\\) ) given \\(\\frac{dL}{d\\mathbf{C}}\\). We can compute a given entry \\(i,j\\) of \\(\\frac{dL}{d\\mathbf{A}}\\) by applying the chain rule using each element of \\(\\mathbf{C}\\):\n\\[\\frac{dL}{dA_{ij}} = \\sum_{k=1}^N \\sum_{l=1}^d \\frac{dL}{dC_{kl}}\\frac{dC_{kl}}{dA_{ij}}\\]\nHowever, each entry of \\(\\mathbf{C}\\) only depends on a single row of \\(\\mathbf{A}\\) and a single column of \\(\\mathbf{B}\\), thus for most \\(i,j,k,l\\), \\(\\frac{dC_{kl}}{dA_{ij}}=0\\).\n\nQ5 (5 points)\nUsing this observation, simplify the expression for \\(\\frac{dL}{dA_{ij}}\\) above. (The derivative of the loss with respect to the entry of \\(\\mathbf{A}\\) at row \\(i\\), column \\(j\\)).\nHint: Your answer should have a similar form, but should only have a single summation and a subset of the indices \\(i,j,k,l\\).\n\\[\\frac{dL}{dA_{ij}} = \\]\n\n\nQ6 (5 points)\nRecalling the definition of matrix-multiplication, give a simple expression for \\(\\frac{dC_{il}}{dA_{ij}}\\), then substitue it into your expression for \\(\\frac{dL}{dA_{ij}}\\).\n\\[\\frac{dC_{il}}{dA_{ij}}= , \\quad\\frac{dL}{dA_{ij}} = \\]\n\n\nQ7 (5 points)\nUsing your expression in Q13, write an expression for \\(\\frac{dL}{d\\mathbf{A}}\\) as a matrix multiplication between two of the 3 given matrices: \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\), \\(\\mathbf{B}\\). Make sure to inlude any nessecary transposes.\nHint: Recall that \\(\\frac{dL}{d\\mathbf{C}}\\) is the same shape as \\(\\mathbf{C}\\) (\\(N\\times d\\)), \\(\\mathbf{A}\\) has shape \\(N \\times h\\) and \\(\\mathbf{B}\\) has shape \\(h \\times d\\).\n\\[\\frac{dL}{d\\mathbf{A}}= \\]\n\n\nQ8 (10 points)\nWrite the corresponding formula for \\(\\frac{dL}{d\\mathbf{B}}\\).\nHint: You can use the fact that \\(C^T = B^T A^T\\) and that \\(\\frac{dL}{d\\mathbf{C}^T} = (\\frac{dL}{d\\mathbf{C}})^T\\)\n\\[\\frac{dL}{d\\mathbf{B}}=\\]\n\n\nQ9 (10 points)\nUsing the expressions you derived in Q14 and Q15, implement the vjp function for the matmul operation to compute \\(\\frac{dL}{d\\mathbf{A}}\\) and \\(\\frac{dL}{d\\mathbf{B}}\\) given \\(\\frac{dL}{d\\mathbf{C}}\\), \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\).\n\nclass _matmul(AutogradValue):\n    def func(self, a, b):\n        return np.matmul(a, b)\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\ntest_vjp(_matmul, '_matmul', binary=True, true_func=anp.matmul)\n\nNow that we’ve written the vjp versions of our operators, we’ll update our AutogradValue class to use them!\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.vjp = lambda self, g, a: (1.,)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.pad = lambda a: _pad(a)\nAutogradValue.sum = lambda a: _sum(a)\nAutogradValue.matmul = lambda a, b: _matmul(a, b)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nAs a final step, we need to update our backward_pass method to use our new vjp method instead of relying on grads.\n\n\nQ10 (10 points)\nUpdate your backward_pass method to use vjp instead of grads.\nHint: Recall that vjp directly computes \\(\\frac{dL}{d\\mathbf{a}}\\), \\(\\frac{dL}{d\\mathbf{b}}\\), whereas grads computed \\(\\frac{dc}{da}\\), \\(\\frac{dc}{db}\\)\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n\n\n\nAutogradValue.backward_pass = backward_pass\n\n\n\nQ11 (10 points)\nFinally update the nll_and_grad function for our NeuralNetwork class to use our shiny new vectorized reverse-mode implementation.\nHint: We should no longer need to use our wrap_array and unwrap_gradient functions, as AutogradValue objects can now contain arrays!\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe should be able to run it with a much larger network now!\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [25, 25])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 6/submission.html",
    "href": "assignments/homeworks/Homework 6/submission.html",
    "title": "Homework 6: Vectorization",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%206/hw6_support.py\n\n# Run me first!\nfrom hw6_support import *\n\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\nclass _add(AutogradValue):\n    # Addition operator (a + b)\n    def func(self, a, b):\n        return a + b\n\n    def grads(self, a, b):\n        return 1., 1.\n\nclass _neg(AutogradValue):\n    # Negation operator (-a)\n    def func(self, a):\n        return -a\n\n    def grads(self, a):\n        return (-1.,)\n\nclass _sub(AutogradValue):\n    # Subtraction operator (a - b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _mul(AutogradValue):\n    # Multiplication operator (a * b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _div(AutogradValue):\n    # Division operator (a / b)\n    def func(self, a, b):\n        # Your code here\n\n    def grads(self, a, b):\n        # Your code here\n\nclass _exp(AutogradValue):\n    # Exponent operator (e^a, or exp(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nclass _log(AutogradValue):\n    # (Natural) log operator (log(a))\n    def func(self, a):\n        # Your code here\n\n    def grads(self, a):\n        # Your code here\n\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef backward_pass(self):\n    ## COPY CODE FROM HOMEWORK 5 HERE\n    local_grads = self.grads(*self.args)\n\nAutogradValue.backward_pass = backward_pass\n\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    ## COPY CODE FROM HOMEWORK 5 HERE\n\nAutogradValue.backward = backward\n\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks!\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if isinstance(a, AutogradValue) or isinstance(b, AutogradValue) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + np.exp(-x))\n\ndef log(x):\n    # Computes the sigmoid function\n    return x.log() if isinstance(x, AutogradValue) else np.log(x)\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid(xw * (2 * y - 1))\n        return -(log(py)).sum()\n\n\nAutograd for a neural network\nCopy the corresponding answers from homework 5 here. You may use either your own answers or published solutions.\n\ndef wrap_array(a):\n    # YOUR CODE HERE\n    \n\ndef unwrap_gradient(a):\n    # YOUR CODE HERE\n\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ1\n\\[\\frac{dL}{d\\mathbf{a}} = ?\\] \\[\\frac{dL}{d\\mathbf{c}} = ?\\] \\[\\frac{d\\mathbf{c}}{d\\mathbf{a}} = ?\\]\n\n\n\n\n\nQ2\n\\[ \\frac{dL}{d\\mathbf{w}} = ?\\]\n\n\n\n\n\nQ3\n\nclass _add(AutogradValue):\n    def func(self, a, b):\n        return a + b\n\n    def vjp(self, grad, a, b):\n        return grad, grad\n\nclass _pad(AutogradValue):\n    def func(self, a):\n        return np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\n    def vjp(self, grad, a):\n        return (grad[:, :-1],)\n\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\nclass _exp(AutogradValue):\n    def func(self, a):\n        return np.exp(a)\n\n    def vjp(self,grad,  a):\n        # YOUR CODE HERE\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return np.log(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_neg, '_neg', )\ntest_vjp(_exp, '_exp', true_func=anp.exp)\ntest_vjp(_log, '_log', true_func=anp.log)\ntest_vjp(_sub, '_sub', True)\ntest_vjp(_mul, '_mul', True)\ntest_vjp(_div, '_div', True)\n\n\n\n\n\n\nQ4\n\nclass _sum(AutogradValue):\n    def func(self, a):\n        return np.sum(a)\n\n    def vjp(self, grad, a):\n        # YOUR CODE HERE\n\ntest_vjp(_sum, '_sum', true_func=anp.sum, issum=True)\n\n\n\n\n\n\nQ5\n\\[\\frac{dL}{dA_{ij}} = \\]\n\n\n\n\n\nQ6\n\\[\\frac{dC_{il}}{dA_{ij}}= , \\quad\\frac{dL}{dA_{ij}} = \\]\n\n\n\n\n\nQ7\n\\[\\frac{dL}{d\\mathbf{A}}= \\]\n\n\n\n\n\nQ8\n\\[\\frac{dL}{d\\mathbf{B}}=\\]\n\n\n\n\n\nQ9\n\nclass _matmul(AutogradValue):\n    def func(self, a, b):\n        return np.matmul(a, b)\n\n    def vjp(self, grad, a, b):\n        # YOUR CODE HERE\n\ntest_vjp(_matmul, '_matmul', binary=True, true_func=anp.matmul)\n\nNow that we’ve written the vjp versions of our operators, we’ll update our AutogradValue class to use them!\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.vjp = lambda self, g, a: (1.,)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.pad = lambda a: _pad(a)\nAutogradValue.sum = lambda a: _sum(a)\nAutogradValue.matmul = lambda a, b: _matmul(a, b)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\n\n\n\n\n\nQ10\n\ndef backward_pass(self):\n    ## YOUR CODE HERE\n\n\n\nAutogradValue.backward_pass = backward_pass\n\n\n\n\n\n\nQ11\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss.value, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe should be able to run it with a much larger network now!\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [25, 25])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/solutions-AVPHKV.html",
    "href": "assignments/homeworks/Homework 1/solutions-AVPHKV.html",
    "title": "Homework 1: Introduction to Numpy (solutions)",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-1-numpy-basics",
    "href": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-1-numpy-basics",
    "title": "Homework 1: Introduction to Numpy (solutions)",
    "section": "Part 1: Numpy basics",
    "text": "Part 1: Numpy basics\nAs discussed in class, a square matrix \\(A\\) defines a linear mapping: \\(\\mathbb{R}^n\\rightarrow \\mathbb{R}^n\\). Given a vector \\(\\textbf{x}\\), we can find the corresponding output of this mapping \\(\\textbf{b}\\) using matrix-vector multiplication: \\(\\textbf{b}=A \\textbf{x}\\). We can write an example matrix-multiplication using matrix notation as:\n\\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}\n= \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix}\n\\]\n\nQ1\nPerform this matrix-vector multiplication by hand and write the answer in the cell below.\n\n\nAnswer\nPerforming the matrix-vector multiplication by hand:\n\\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}\n= \\begin{bmatrix}\n4(1) + (-3)(-2) + 2(1) \\\\\n6(1) + 5(-2) + 1(1) \\\\\n-4(1) + (-1)(-2) + 2(1)\n\\end{bmatrix}\n= \\begin{bmatrix}\n4 + 6 + 2 \\\\\n6 - 10 + 1 \\\\\n-4 + 2 + 2\n\\end{bmatrix}\n= \\begin{bmatrix}\n12 \\\\\n-3 \\\\\n0\n\\end{bmatrix}\n\\]\n\n\n\n\n\nQ2\nIn the code cell below, create the matrix \\(A\\) and the vector \\(\\textbf{x}\\) shown above, using Numpy. Then use the np.dot function to find the output of the mapping \\(\\textbf{b} = A\\textbf{x}\\). Verify that the answer matches what you derived above.\n\n\nAnswer\n\n# Fill answers here\nA = np.array([[4, -3, 2],\n              [6, 5, 1],\n              [-4, -1, 2]\n              ])\nx = np.array([1, -2, 1])\nb = np.dot(A, x)\n\nprint(b)\n\n[12 -3  0]\n\n\nOften we will have access to the transformed vector \\(\\textbf{b}\\) and need to find the orginal vector \\(\\textbf{x}\\). To do this we need to solve the system of linear equations \\(A\\textbf{x}=\\textbf{b}\\) for \\(\\textbf{x}\\). \\[\\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix} \\cdot \\begin{bmatrix}\n? \\\\\n? \\\\\n?\n\\end{bmatrix} = \\begin{bmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{bmatrix}\n\\]\n\n\nQ3\nFind the missing \\(\\textbf{x}\\) in the equation above using the np.linalg.solve function and verify that \\(A\\textbf{x}=\\textbf{b}\\).\n\n\nAnswer\n\nb = np.array([2, -1, 3])\nx = np.linalg.solve(A, b)\nprint(b, np.dot(A, x))\n\n[ 2 -1  3] [ 2. -1.  3.]\n\n\nIn linear algebra you may have learned how to solve a system of linear equations using Gaussian elimination. Here we will implement an alternative approach known as Richardson iteration. In this method we start with an inital guess for the solution: \\(\\textbf{x}^{(0)}\\), then we will iteratively update this guess until the solution is reached. Given a matrix \\(A\\), a target \\(\\textbf{b}\\) and a current guess \\(\\textbf{x}^{(k)}\\), we can compute the Richardson update as:\n\\[\\textbf{x}^{(k+1)} \\leftarrow \\textbf{x}^{(k)} + \\omega \\left(\\textbf{b} - A\\textbf{x}^{(k)}\\right)\\]\nHere \\(\\omega\\) is a constant that we can choose to adjust the algorithm. We will set \\(\\omega = 0.1\\).\n\n\nQ4\nFill in the Richardson iteration function below and apply it to the system of linear equations from above using 100 updates. Verify that if gives a similar answer to np.linalg.solve.\n\n\nAnswer\n\n# Fill in function below\ndef richardson_iter(x_guess, A, b, omega=0.1):\n    new_x_guess = x_guess + omega * (b - np.dot(A, x_guess))\n    return new_x_guess\n\nx_guess = np.zeros(3)\nfor i in range(100):\n    x_guess = richardson_iter(x_guess, A, b)\n\nprint(x_guess, x)\n\n[-0.175 -0.2    1.05 ] [-0.175 -0.2    1.05 ]\n\n\nRecall that the length of a vector is given by it’s two-norm, which is defined as: \\[\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.\\]\nCorrespondingly, the (Euclidian) distance between two points \\(\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n\\) can be written as \\(\\|\\mathbf{a} - \\mathbf{b}\\|_2\\). As a convenient measure of error for our Richardson iteration algorithm, we will use the squared Euclidean distance. For a guess \\(\\mathbf{x}^{(k)}\\) we will compute the error \\(e^{(k)}\\) as: \\[e^{(k)} = \\|A\\mathbf{x}^{(k)} - \\mathbf{b}\\|_2^2\\]\nIn expanded form, this would be written as: \\[e^{(k)} = \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\n\n\nQ5\nWrite a function to compute the error of a given guess. Then run Richardson iteration again for 100 steps, computing the error at each step. Finally create a plot of the error for each step (error vs. step). Plot reference\nHint: recall that basic operations in numpy (addition, subtraction, powers) are performed element-wise.\n\n\nAnswer\n\ndef error(x_guess, A, b):\n    err = (np.dot(A, x_guess) - b) ** 2\n    err = err.sum()\n    return err\n\n# Add code to plot the error over time\nx_guess = np.zeros(3)\nall_errors = [error(x_guess, A, b)]\nfor step in range(100):\n    \n    x_guess = richardson_iter(x_guess, A, b)\n    all_errors.append(error(x_guess, A, b))\n\nplt.plot(all_errors)\n\n\n\n\n\n\n\n\n\n\nQ6\nDerive the partial derivative of the error with respect to a single entry of \\(\\mathbf{x}^{(k)}\\) (without loss of generality, we will say \\(x^{(k)}_1\\)). Work in the expanded form as in the equation above, writing your answer in the markdown cell below.\nHint: You may find it helpful to refer to the latex equation cheatsheet on the course website. You may show intermediate steps here or as handwritten work as a separate file in the repository. The final answer should be filled in here.\n\n\nAnswer\n\\[\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1}=  \\frac{\\partial}{\\partial x^{(k)}_1} \\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)^2\\]\nApply sum and chain rules \\[=   2\\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right) \\frac{\\partial}{\\partial x^{(k)}_1}\\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right)\\] Apply sum rule noting that \\(\\frac{\\partial}{\\partial x^{(k)}_1}A_{ij}x_{j} = 0\\) for \\(j\\neq 1\\).\n\\[=2\\sum_{i=1}^n \\left(\\sum_{j=1}^n A_{ij}x^{(k)}_j - b_i\\right) A_{i1}\\]\nIn practice, we will likely want to compute the derivative with respect to all entries of \\(\\mathbf{x}\\): \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}} = \\begin{bmatrix}\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_1} \\\\\n\\vdots \\\\\n\\frac{\\partial e^{(k)}}{\\partial x^{(k)}_n}\n\\end{bmatrix}\\]\n\n\nQ7\nUsing the formula you just derived, write the formula for the vector of all partial derivatives in the compact matrix/vector notation (e.g. \\(A\\mathbf{x}=\\mathbf{b}\\)).\n\n\nAnswer\n\\(\\sum_{j=1}^n A_{ij}x^{(k)}_j\\) of the \\(i^{th}\\) entry of the matrix-vector product \\(\\mathbf{A}\\mathbf{x}^{(k)}\\) \\[=2\\sum_{i=1}^n \\left( (\\mathbf{A}\\mathbf{x}^{(k)})_i - b_i\\right) A_{i1}\\]\nSimilarly subtracting \\(b_i\\) corresponds to vector subtraction with the vector \\(\\mathbf{b}\\) \\[=2\\sum_{i=1}^n \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)_i A_{i1}\\]\nFinally we’re left with the equivalent of a dot product for entry 1!\n\\[\\frac{\\partial e^{(k)}}{\\partial x_1^{(k)}}= 2 \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)^T \\mathbf{A}_{1}\\]\nIf we remove the index into \\(\\mathbf{A}\\), we get an expression for the gradient! \\[\\frac{\\partial e^{(k)}}{\\partial \\mathbf{x}^{(k)}}= 2 \\left( \\mathbf{A}\\mathbf{x}^{(k)} - \\mathbf{b}\\right)^T \\mathbf{A}\\]\n\n\nQ8\nDo you notice any relationship between this result and the Richardson iteration algorithm above? (1-2 sentences) We will discuss this more in class!\n\n\nAnswer\nWe see that this gradient is almost equivalent to the update we made in our Richardson iteration, but scaled by \\(-2\\mathbf{A}\\)!"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-2-working-with-batches-of-vectors",
    "href": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-2-working-with-batches-of-vectors",
    "title": "Homework 1: Introduction to Numpy (solutions)",
    "section": "Part 2: Working with batches of vectors",
    "text": "Part 2: Working with batches of vectors\nRecall that a vector can also be seen as either an \\(n \\times 1\\) matrix (column vector) or a \\(1 \\times n\\) matrix (row vector).\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x}^T = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nNote that we use the same notation for both as they refer to the same concept (a vector). The difference becomes relevant when we consider matrix-vector multiplication. We can write matrix-vector multiplication in two ways: \\[\\text{Matrix-vector: }A\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}^TA^T= \\mathbf{b}^T\\] In matrix-vector multiplication we treat \\(\\textbf{x}\\) as a column vector (\\(n \\times 1\\) matrix), while in vector-matrix multiplication we treat it as a row vector (\\(n \\times 1\\) matrix). Transposing \\(A\\) for left multiplication ensures that the two forms give the same answer.\n\nQ9\nUsing the previously defined \\(\\mathbf{x}\\), create an explicit column vector and row vector. Then using the previously defined \\(A\\), verify that the matrix-vector and vector-matrix multiplications shown above do produce the same resultant vector \\(\\mathbf{b}\\).\nHint: Recall that np.dot is also used for matrix-matrix multiplication. The values of \\(\\mathbf{x}\\) and \\(A\\) are: \\[\\mathbf{x} = \\begin{bmatrix}\n1 \\\\\n-2 \\\\\n1\n\\end{bmatrix}, \\quad A = \\begin{bmatrix}\n4 & -3 & 2 \\\\\n6 & 5  & 1 \\\\\n-4 & -1 & 2\n\\end{bmatrix}\\]\n\n\nAnswer\n\nx_col = x[:, None] # Add new diminsion 1\nx_row = x[None, :] # Add new dimension 0\nprint(np.dot(A, x_col), np.dot(x_row, A.T))\n\n[[ 2.]\n [-1.]\n [ 3.]] [[ 2. -1.  3.]]\n\n\nThe distinction between row and column vectors also affects the behaivior of other operations on np.array objects, particularly through the concept of broadcasting.\n\n\nQ10\nConsider a \\(3 \\times 3\\) matrix of all ones as defined in code below, along with the 1-d vector \\(\\mathbf{x}\\).\n\nones = np.ones((3, 3))\nx = np.array([1, -2, 1])\nones\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n\n\nComplete the line of code below such that the result of the operation is:\n\\[\\begin{bmatrix}\n1 & -2 & 1 \\\\\n1 & -2  & 1 \\\\\n1 & -2 & 1\n\\end{bmatrix}\\]\nHint: You should replace SHAPE with an appropriate shape for broadcasting and OPERATION with an appropriate operation (e.g. +, -, *, /)\n\n\nAnswer\n\nresult = ones * x.reshape((1, -1))\nprint(result)\n\n[[ 1. -2.  1.]\n [ 1. -2.  1.]\n [ 1. -2.  1.]]\n\n\nThroughout this course we will typically use row vectors and vector-matrix multiplication, as this is more conventional in neural-network literature. The concept of row and column vectors becomes handy when transforming collections of vectors.\nRecall that a matrix can be seen as a collection of vectors. In numpy we can create a matrix from a list of (1- dimensional) vectors using the np.stack function. This function assumes that the vectors are row vectors creating the matrix as follows: \\[\\begin{bmatrix}\n3 & 1 & -2\n\\end{bmatrix},\\ \\begin{bmatrix}\n4 & 5 & 3\n\\end{bmatrix},\\ \\begin{bmatrix}\n-2 & -1 & 5\n\\end{bmatrix}\\quad \\overset{\\text{np.stack}}{\\longrightarrow} \\begin{bmatrix}\n3 & 1 & -2 \\\\\n4 & 5 & 3 \\\\\n-2 & -1 & 5\n\\end{bmatrix} \\]\nWe will call this matrix \\(X\\) to denote that it is a collection of vectors, rather than a single vector (\\(\\mathbf{x}\\)).\n\n\nQ11\nCreate this matrix in numpy using th np.stack function.\n\n\nAnswer\n\nX = np.stack([np.array([3, 1, -2]), np.array([4, 5, 3]), np.array([-2, -1, 5])])\nprint(X)\n\n[[ 3  1 -2]\n [ 4  5  3]\n [-2 -1  5]]\n\n\nWhen taken together as a matrix in this way, we can apply the linear mapping \\(A\\) to all vectors using matrix-matrix multiplication: \\[B=XA^T\\]\nLet’s put this into practice with a visual example.\n\n\nQ12\nCreate a \\(20 \\times 3\\) matrix, circle, in numpy of the following form\n\\[ \\begin{bmatrix} \\sin(\\theta_1) & \\cos(\\theta_1)  & 1 \\\\\n\\sin(\\theta_2) & \\cos(\\theta_2)  & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\theta_{20}) & \\cos(\\theta_{20})  & 1 \\\\\n\\end{bmatrix}\\] Where \\(\\theta_1...\\theta_{20}\\) are evenly spaced between \\(0\\) and \\(2\\pi\\).\n\n\nAnswer\n\ntheta = np.linspace(0, 2 * np.pi, 20) # Generates 20 evenly-spaced numbers between 0 and 2π\n\ncircle = np.stack([np.sin(theta), np.cos(theta), np.ones_like(theta)]).T\n\nThe code we just wrote creates a matrix corresponding to a collection of \\(20\\) row vectors of length 3. Each vector represents a point on the unit circle where the first entry is the x-coordinate, the second entry is the y-coordinate and the third entry is always \\(1\\): \\[ \\begin{bmatrix} x & y & 1 \\end{bmatrix}\\]\n\n\nQ13\nPlot the set of 20 points in circle using the plt.plot function. Use only the x and y coordinates, ignoring the column of 1s.\n\n\nAnswer\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\nplt.plot(circle[:, 0], circle[:, 1])\n\n\n\n\n\n\n\n\n\n\nQ14\nTransform all the vectors in circle with the matrix \\(A\\) using a single call to np.dot. Then plot the original set of points in black and the transformed points in red using the plt.plot function.\nYou might also consider why we added the extra column of 1s! We will discuss the answer to that in class. \\(A\\) is the same matrix from q1.\n\n\nAnswer\n\ntransformed_circle = np.dot(circle, A)\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\nplt.plot(circle[:, 0], circle[:, 1], c='k')\nplt.plot(transformed_circle[:, 0], transformed_circle[:, 1], c='r')\n\n\n\n\n\n\n\n\n\n\nQ15\nFinally, shift all the vectors in transformed_circle by the vector \\(\\mathbf{b}\\) defined below, that is, add \\(\\mathbf{b}\\) to every row of the output matrix. Again plot the original set of points in black and the transformed points in red using the plt.plot function.\nHint: the solution to this question should not involve any loops, instead use broadcasting.\n\nb = np.array([4, 1.2, 0])\ntransformed_circle = np.dot(circle, A) + b\n\n\nplt.figure(figsize=(4, 4))\nplt.xlim(-10, 10)\nplt.ylim(-10, 10)\n\nplt.plot(circle[:, 0], circle[:, 1], c='k')\nplt.plot(transformed_circle[:, 0], transformed_circle[:, 1], c='r')"
  },
  {
    "objectID": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-3-loading-and-visualizing-data",
    "href": "assignments/homeworks/Homework 1/solutions-AVPHKV.html#part-3-loading-and-visualizing-data",
    "title": "Homework 1: Introduction to Numpy (solutions)",
    "section": "Part 3: Loading and visualizing data",
    "text": "Part 3: Loading and visualizing data\nFor most of this class we will be working with real-world data. A very well-known dataset in statistics is the Iris flower dataset collected by Edgar Anderson in 1929. The dataset consists of measurments of iris flowers. Each flower has 4 collected measurements: sepal length, sepal width, petal length, petal width, as well as a classification into one of 3 species: Iris setosa, Iris versicolor and Iris virginica. We will return to this dataset in the next homework.\nWe can load this dataset as Numpy objects using the Scikit-Learn library. Below we’ve extrated 4 relevant arrays: - features: a matrix which has one row per observed flower and one column per measurement. - targets: An array that specifies the species of each flower as a number 0-2. - feature_names: a list of strings with the name of each measurement. - target_names: a list of strings with the name of each species.\nIn this homework, we will only visualize this dataset, which is typically a good first step in working with a new type of data. We’ll start by just looking at 2 measurements sepal length and petal length, along with the species.\n\nQ16\nBased on the Iris dataset loaded below, how many flowers did Edgar Anderson measure?\nIn other words, how many observations are in this dataset?\n\n\nAnswer\n\nimport sklearn.datasets as datasets\ndataset = datasets.load_iris()\nfeatures = dataset['data']\ntargets = dataset['target']\nfeature_names = dataset['feature_names']\ntarget_names = dataset['target_names']\n\n# Answer\nnum_observations = features.shape[0]\nprint(num_observations)\n\n150\n\n\nFill in the code to create a scatterplot for the Iris dataset below. Plot sepal length on the x-axis and petal length on the y-axis. Set the color to correspond to the species.\n\n# Fill your code here\n\nplt.figure(figsize=(4, 4))\nplt.scatter(features[:, 0], features[:, 2], c=targets, cmap='viridis')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.title('Sepal Length vs Petal Length')\nplt.colorbar(label='Species')"
  },
  {
    "objectID": "assignments/homeworks/Homework 10/solutions-RMZHDS.html",
    "href": "assignments/homeworks/Homework 10/solutions-RMZHDS.html",
    "title": "Homework 10: Language models",
    "section": "",
    "text": "# Uncomment for Colab\n# !yes | pip uninstall torch\n# !yes | pip uninstall torchtext\n# !yes | pip install torch==2.3.0\n# !yes | pip install torchtext==0.18\n\n# Run me to get the data (should be included!)\n#!wget https://gist.githubusercontent.com/gabehope/286a065f3b7cc081af5f3e8d71502e63/raw/d31a233d8ade78ac5cbd8ecfa45f184017812c52/dataset.txt"
  },
  {
    "objectID": "assignments/homeworks/Homework 10/solutions-RMZHDS.html#part-1-language-modeling",
    "href": "assignments/homeworks/Homework 10/solutions-RMZHDS.html#part-1-language-modeling",
    "title": "Homework 10: Language models",
    "section": "Part 1: Language Modeling",
    "text": "Part 1: Language Modeling\nIn the support code we’ve setup a PyTorch dataset of sentences. As we discussed in class, our neural networks can’t directly work with text, so our dataset has been tokenized using a sentence-piece tokenizer (a variation of the byte-pair tokenizer we discussed in class). This assigns short sequences of characters (such as words) to individual integer ids (0-999 in this assignment). It also includes several special tokens:\n\n&lt;start&gt;: Indicates the start of an sentence.\n&lt;stop&gt;: Indicates the end of an sentence.\n&lt;pad&gt;: Indicates blank space after a sentence.\n&lt;unk&gt;: Indicates an unknown token.\n\nWe can see that when we print an observation in our dataset, it’s represented as a list token ids.\n\nx, y = data[0]\nprint(x)\n\n[1, 428, 53, 4]\n\n\nFor convinence, the “target” y is simply the same observation shifted by one token. This will make it easier to implement our next word prediction language model.\n\nprint(y)\n\n[428, 53, 4, 2]\n\n\nAs we’ve used in previous homeworks, PyTorch provides a convinient object for generating batches of data for training called a DataLoader. The DataLoader will handle selecting observations to use at each step. We’ll create a loader for both our training and vaildation data, specifying a batch size of 64. We’ll also tell the loader for our training data to randomly shuffle the data (you can ignore the collate_fn argument`).\n\ntrain_data, test_data = torch.utils.data.random_split(data, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=lambda x: x)\nvalid_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=lambda x: x)\n\nWe can iterate through a DataLoader to get batches of data. Notice that our batch of data has been grouped into a single Tensor object. Because sentences may have different lengths, the size of the tensor will be determined by the longest sentence in the batch, while shorter sentences will have &lt;pad&gt; tokens added to the end.\n\nfor x, y in train_loader:\n  print(x)\n  break\n\ntensor([[  1,   8, 158,  ...,   0,   0,   0],\n        [  1, 162, 364,  ...,   0,   0,   0],\n        [  1,   6, 907,  ...,   0,   0,   0],\n        ...,\n        [  1,  23,   5,  ...,   0,   0,   0],\n        [  1,   6,  61,  ...,   0,   0,   0],\n        [  1, 247,   5,  ...,   0,   0,   0]])\n\n\nOur data also contains a vocab object that defines our mapping from string tokens to ids. This is called eng_vocab in our dataset. We can get an ordered list of the tokens by calling itos() method of the vocab object.\n\nvocab = data.eng_vocab\nprint(vocab.get_itos())\n\n['&lt;pad&gt;', '&lt;start&gt;', '&lt;stop&gt;', '&lt;unk&gt;', '.', \"'\", '▁I', 't', '▁Tom', 's', '▁you', '▁to', '?', '▁a', '▁', '▁the', 'n', '▁is', 'm', 're', 'e', 'ed', 'd', '▁You', 'ing', '▁in', '▁me', '▁that', '▁was', 'p', 'er', '▁of', '▁be', '▁it', '▁have', ',', 'o', '▁We', '▁do', 'u', 'a', '▁s', '▁for', 'll', '▁He', 'y', '▁did', '▁your', 've', '▁don', '▁like', '▁are', 'l', 'i', 'g', '▁want', '▁this', '▁know', '▁Do', '▁Mary', 'en', '▁can', 'r', '▁with', '▁my', '▁not', '▁he', 'c', '▁The', 'b', '▁at', '▁think', '▁go', '▁f', '▁Why', '▁It', 'h', '▁What', 'ar', 'or', '▁p', '▁on', '▁here', 'ic', '▁his', 'al', 'ly', '▁very', 'f', '▁and', '▁She', 'ce', '▁so', '▁has', 'at', '▁c', 'le', '▁They', '▁Are', 'k', 'w', '▁will', '▁b', '▁we', '▁about', '▁need', 'sh', '▁what', 'es', '▁going', '▁now', '▁all', '▁help', 'ur', 'ri', 'an', '▁an', '▁us', '▁Don', '▁were', '▁as', 'in', '▁This', 'ir', '▁How', '▁e', '▁time', '▁should', '▁That', 'it', '▁still', '▁get', '▁Boston', 'ro', '▁de', '▁d', '▁him', '▁good', '▁really', 'li', '▁no', '▁eat', '▁work', '▁had', '▁up', '▁one', '▁too', '▁see', '▁never', '▁won', '▁car', 'as', '▁Did', '▁there', 'il', '▁home', '▁her', '▁been', '▁doesn', '▁T', 'ra', '▁got', '▁S', '▁French', '▁out', '▁come', '▁play', '▁from', 'on', '▁anything', '▁some', '▁just', 'se', '▁co', '▁much', '▁lot', '▁said', '▁Can', 'ion', 'if', '▁would', '▁tell', '▁love', '▁My', 'v', '▁by', '▁Have', '▁live', 'th', '▁say', '▁w', 'ive', '▁A', 'lo', '▁g', '▁told', 'us', '▁than', '▁day', '▁something', '▁money', '▁back', '▁went', '▁talk', '▁ch', '▁busy', 'ad', 'un', 'ous', '▁There', '▁today', 'ate', '▁po', 'om', '▁Where', '▁always', 'ch', '▁new', '▁Please', 'oo', 'ist', '▁am', '▁last', '▁more', '▁buy', '▁con', '▁Who', 'is', '▁sure', '▁book', '▁any', '▁happy', '▁could', 'ge', 'id', '▁school', '▁who', 'ake', '▁take', '▁must', '▁read', '▁make', '▁C', 'ap', '▁ma', 'ne', 'ry', '▁Let', '▁right', '▁only', '▁speak', '▁stay', '▁wanted', '▁thought', 'ow', '▁feel', 'ok', '▁but', '▁how', '▁give', '▁three', '▁tomorrow', 'act', '▁leave', 'ine', '▁ex', '▁un', '▁hate', '▁late', 'vi', '▁them', '▁plan', '▁problem', '▁look', 'ight', '▁made', '▁friends', '▁many', '▁or', '▁dog', '▁old', 'co', '▁ever', 'ers', '▁call', '▁room', '▁find', '▁when', 'z', '▁ba', '▁o', 'el', '▁house', '!', '▁again', '▁long', '▁doing', '▁teacher', 'ation', '▁sp', 'j', '▁well', '▁dis', '▁off', '▁drink', '▁she', '▁Australia', '▁P', '▁better', '▁yet', '▁wants', '▁job', '▁yesterday', '▁pro', 'ul', '▁our', '▁people', 'age', 'and', '▁ra', 'able', 'ick', '▁please', '▁hope', '▁asked', '▁every', '▁used', '▁saw', 'est', '▁little', 'ay', '▁ask', '▁When', '▁they', '▁believe', '▁hand', '0', 'ated', '▁alone', '▁ready', '▁tired', '▁name', '▁O', '▁ga', '▁next', '▁already', '▁ho', '▁left', '▁does', '▁understand', '▁everything', '▁lost', '▁sing', '▁friend', '▁done', '▁man', 'x', '▁night', 'ant', 'ach', '▁down', 'q', '▁seem', '▁where', 'ig', '▁W', '▁question', '▁came', '▁learn', '▁father', '▁M', 'um', '▁party', '▁nothing', '▁wait', '▁even', 'low', '▁hi', '▁watch', '▁use', '▁answer', '▁th', '▁change', '▁Your', '▁bought', 'uch', '▁Would', '▁before', '▁im', '▁happen', '▁B', '▁study', '▁seen', '▁wrong', 'ful', '▁v', '▁open', '▁often', 'ment', '▁Te', '▁haven', '▁two', '▁morning', '▁why', '▁hard', '▁sleep', '▁E', '▁F', '▁hear', '▁cat', '▁over', '▁anymore', 'ies', '▁married', '▁afraid', '▁walk', '▁week', '▁tonight', '▁into', '▁win', '▁found', '▁other', '▁both', '▁idea', '▁knew', '▁years', '-', '▁way', '▁H', '▁stop', '▁soon', '▁things', '▁coffee', 'ther', '▁angry', '▁looks', '▁tried', '▁these', 'ver', '▁tea', '▁happened', 'Give', '▁beer', 'ock', '▁listen', '▁put', '▁kind', '▁try', '▁gra', 'ually', '▁fun', '▁Does', '▁proud', '▁being', '▁drive', '▁children', '▁Wi', 'ie', '▁seems', 'ance', 'ack', '▁show', '▁mother', '▁together', '▁first', '▁enjoy', '▁young', '▁mistake', '▁Christmas', '▁Monday', '▁same', '▁early', '▁pay', '▁heard', '▁sc', '▁might', '▁wine', '▁L', '▁miss', 'less', '▁brother', '▁No', '▁away', '▁bad', '▁door', '▁enough', '▁worried', '▁life', '▁turn', '▁person', '▁looking', '▁lunch', '▁thing', '▁quit', '▁may', '▁anyone', 'ity', '▁pretty', '▁another', '▁water', '▁working', 'one', '▁best', '▁hungry', '▁hurt', '▁books', '▁food', '▁let', '▁big', '▁hu', '▁without', '▁year', '▁almo', '▁visit', 'ever', '▁phone', '▁favorite', '▁able', '▁waiting', '▁cook', '▁letter', '▁remember', '▁Everyone', '▁start', '▁sister', '▁after', 'ible', '▁care', '▁truth', '▁talking', '▁died', '▁family', '▁hour', '▁true', '▁English', '▁app', '▁dinner', '▁movie', '▁student', '▁wish', '▁parents', '▁trust', '▁keep', '▁rain', '▁Could', '▁write', '▁surprised', '▁looked', 'cause', '▁stupid', 'uck', '▁wonder', '▁library', '▁war', '▁Go', '▁coming', '▁sick', '▁close', '▁computer', '▁called', '▁lie', '▁bit', '▁free', '▁far', '▁nice', '▁interested', '▁started', '▁pass', '▁bus', '▁train', '▁else', '▁place', '▁cold', '▁music', '▁broke', 'R', '▁girl', '▁swim', '▁Be', 'N', '▁D', '▁key', '▁myself', '▁rich', 'V', 'ize', '▁sorry', '▁fish', '▁part', '▁worry', '▁doctor', '▁beautiful', '▁forget', '▁word', '▁trying', 'ia', '▁pen', '▁kiss', '▁minute', '▁near', '▁meet', '▁run', '▁difficult', '▁girlfriend', 'Which', '▁getting', '▁pain', '▁song', '▁agree', '▁picture', '▁All', '▁sound', '▁teach', 'J', '▁arrived', '▁mine', '▁probably', '▁different', '▁fire', '▁great', 'ai', 'old', '▁boy', '▁dance', '▁easy', '▁laugh', '▁serious', '▁killed', '▁order', '▁park', '▁studying', '▁police', '▁class', '▁language', '▁sad', '▁decided', '▁fast', '▁Now', '▁month', '▁himself', '▁die', '▁1', '▁mind', 'aught', '▁expect', '30', '▁glass', '▁breakfast', '▁drunk', '▁few', '▁under', '▁explain', '▁real', '▁May', '▁child', '▁finished', '▁meeting', '▁Nobody', '▁important', '▁His', '▁around', '▁perfect', '▁secret', '▁OK', '▁Stop', '▁promise', '▁safe', '▁spend', '▁forgot', '▁story', 'Come', '▁everyone', '▁ten', '▁summer', '▁Get', '▁nervous', '▁lucky', '▁paid', '▁pizza', '▁own', '▁tall', '▁wife', '▁comp', '▁those', '▁ago', '▁red', '▁clean', '▁while', '▁follow', '▁Thank', '▁apple', '▁careful', '▁small', '▁window', 'G', '▁having', '▁office', '▁strange', '▁kill', '▁dream', 'Maybe', '▁spent', '▁game', '▁accept', '▁trouble', '▁interesting', '▁someone', '▁dress', '▁tree', '▁guy', '▁cut', '▁lose', '▁exam', '▁high', '▁city', '▁\"', '▁bread', '▁tennis', '▁afternoon', '▁price', '▁shoes', '▁accident', '▁became', '▁move', '▁living', '▁ski', '▁yourself', '▁fix', '▁hair', '▁cost', '▁begin', '▁light', '▁reason', '▁stole', '▁Canadian', '▁travel', 'U', '▁bottle', '▁homework', '▁milk', '▁hotel', '▁bicycle', '▁Look', '▁return', '▁Halloween', '▁sell', '▁scared', '▁wrote', '▁country', '▁anybody', '▁strong', '▁fell', '▁restaurant', '▁Everybody', '▁since', '▁Japan', '▁ju', '▁wearing', '▁station', '▁number', '▁began', '▁felt', '▁invited', '▁boyfriend', '▁exactly', '▁town', '▁Sunday', '▁basketball', '▁world', '▁born', '▁thirty', '3', '▁weekend', '▁table', '▁kept', '▁end', '▁swimming', '▁expensive', '▁sign', '▁stopped', '▁complain', '▁borrow', '▁test', '▁unti', '▁box', '▁present', '2', '▁kid', '▁save', '▁supposed', '▁golf', '▁break', '▁neighbor', 'ound', '▁Stay', '▁honest', '▁jealous', '.\"', '▁John', '▁daughter', '▁making', '▁full', '2:', '▁apologize', '▁possible', '▁umbrella', '▁message', '▁woman', '1', '▁matter', '▁rest', '▁most', '▁snow', '▁bring', '▁asleep', '▁ta', '▁appreciate', '▁short', '▁outside', '▁Keep', '▁advice', '▁crazy', '▁hat', '▁large', '▁ticket', '▁church', '▁blame', '▁smart', '▁prefer', '▁black', 'hose', '▁count', '▁become', '▁disappoint', '▁hospital', '▁opinion', '▁spoke', 'Y', 'taking', '▁funny', '▁smoke', '▁Japanese', '▁bank', '▁finish', '▁leg', '▁protect', '▁smile', '▁decision', '▁America', '▁cup', '▁glad', '▁dollars', '▁everybody', '▁famous', '▁river', '▁clothes', '▁baseball', '▁behind', '▁prepared', '▁prison', '▁weather', '▁correct', '▁joke', '▁impress', '▁piano', '▁store', '▁moment', '▁paper', '▁pencil', '▁Everything', '▁certain', '▁report', '▁wall', '▁check', '▁risk', '▁smoking', '▁knife', '▁rule', '▁curious', '▁deserve', '▁grow', '▁inside', '▁information', '▁solve', '▁studied', '▁sugar', '▁horse', '▁writing', 'xcuse', '▁guitar', '▁uncle', '▁enter', '▁patient', '▁brought', '▁drank', '▁leaving', '▁clear', '▁consider', '▁ignor', '▁join', '▁confused', '▁obvious', '▁health', '▁choice', '▁concert', '▁recognize', '▁dark', '▁respect', '▁six', '▁suggest', '▁translate', '▁trip', '▁photo', '▁continue', '▁Should', '▁birthday', '▁hurry', '▁second', '▁embarrass', '▁garden', '▁Leave', '▁building', '▁sometimes', '▁vote', 'either', '▁attend', '▁smell', '▁terrible', '▁lawyer', '▁ugly', 'clock', '▁sentence', '▁guess', '▁accus', '▁admit', '▁attention', '▁vacation', '▁white', '▁company', '▁death', '▁satisfied', '▁also', '▁special', 'eople', '▁business', '▁doubt', '▁remain', '▁complete', '▁situation', '▁address', '▁welcome', '▁Nothing', '▁advise', '▁blue', '▁through', '▁decide', 'K', '▁Someone', '▁apartment', '▁jail', '▁radio', '▁convinced', 'I', '▁dictionary', '▁guilty', '▁street', '▁surprise', '▁abroad', '▁quiet', '▁arrested', '▁discuss', '▁fault', '▁taxi', 'gotten', '▁arrive', '▁excited', '▁taste', '▁fruit', '▁unhappy', '▁extreme', '▁sandwich', '▁afford', '▁dancing', '▁husband', '▁stuff', '▁success', '5', '9', 'P', 'S', 'A', '8', 'D', '6', 'B', '$', '\"', 'Q', '4', 'O']\n\n\n\nQ1\nFor our language model to be useful, we’ll need to be able to translate batches of data back into English text. Complete the function below which takes a tensor of token ids, as shown above, along with a vocab object and returns a list of strings. Each entry should be the text corresponding to a single observation in the batch (a row of the tensor). Test your function on the first batch from valid_loader.\nHint: While it’s not nessecary for full credit, an ideal implementation would ignore the special characters defined above which aren’t a part of the text.\n\ndef convertToText(x, vocab):\n    '''\n    Converts a batch of token ids into text.\n\n    Inputs:\n      x (tensor of ints): An N x L int tensor of N sentences with L tokens each.\n      vocab (vocabulary object)\n\n    Returns:\n      text (list of strings): A length N list of translated strings\n    '''\n    # YOUR CODE HERE\n    outputs = []\n    itos = data.eng_vocab.get_itos()\n    for sample_i in x.detach().cpu().numpy():\n      sentence = ''\n      for word in sample_i[1:]:\n        if word == 2:\n          break\n        sentence += itos[word].replace('▁', ' ')\n      outputs.append(sentence)\n    return outputs\n\n# Convert the first batch of validation data here\nx, y = next(iter(valid_loader))\ntext = convertToText(x, data.eng_vocab)\nprint(text)\n\n[' I can still work.', ' Where did you find that dress?', \" I'm not able to translate this sentence.\", \" Tom decided to ignore Mary's request.\", \" Midterm exams start next week. Just cramming the night before won't get you ready. There'll be a lot of tough questions. You should start studying today.\", ' They fine you in Singapore if you throw trash in the streets.', \" I'm proud of you.\", \" He's almost as tall as me.\", ' I have a different idea.', \" Let's get back to work.\", ' Did you receive my letter?', ' How many tiles do you need?', \" I would've done it at that time.\", \" Tom is still angry with you, isn't he?\", ' This coat is rainproof.', ' Have I arrived too late?', ' No one can help Tom.', ' She is not as beautiful as she was before.', \" I'm not sick.\", ' Tom made a terrible mistake.', ' I did it according to your instructions.', ' I was very jealous.', ' Tom is an imbecile.', ' You are interested in computers.', ' Tom died young.', ' People dine very late in Spain.', \" I have no idea what I'm doing.\", ' Why do your friends all hate me?', \" I'm back at work now.\", ' Is Tom at work?', \" They'll get married next month.\", ' His mobile has been stolen.', ' What did you want to ask me?', ' You should vote.', ' Tom wanted information.', ' I can teach you how to translate.', ' How could I ever trust you?', ' He gave his seat to the old man.', ' Tom asks too many questions.', ' The key to the garage is gone.', ' Do you come to this restaurant often?', ' He had to withdraw.', \" Maybe Tom won't do that.\", ' What do you want me to do now?', \" There's something I need to talk to you about.\", \" I've never actually been in love.\", ' It was his narrative that bored me to death.', \" I'm not a fool.\", ' I want you to take this medicine.', ' I think Tom is friendly.', \" Don't struggle.\", ' There is a traffic jam on the highway.', ' The women gave us a lot to eat.', \" Aren't you still at work?\", \" It wasn't expensive.\", \" I think it's wonderful.\", ' Tom says he wants to lose weight.', \" I'm in no hurry.\", \" I don't care about the money.\", \" I can't eat any more.\", \" I'd really like to get something to drink.\", ' Can Tom come tomorrow?', ' My cat and dog get along.', ' It makes no difference who I meet.', ' Any day will do except Monday.', \" You're really nice.\", \" I can't go into details.\", ' Am I missing something here?', ' Tom has maintained his innocence.', \" Tom won't be home this weekend.\", \" You hate school, don't you?\", ' Are we going on foot?', ' Tom is helping Mary do her homework.', ' Are you going to eat that bread?', \" Tom won't likely buy ice cream.\", ' Why should I come to Australia?', \" I'm trying to lose weight.\", ' You are a prude.', \" Tom can't hurt you.\", \" I'll stop you.\", ' You make me nervous.', \" I'm sure you're very busy.\", ' I just decided to do it.', ' Tom told Mary that I was always late.', ' Tom asked me to do this for Mary.', \" Tom seemed quite busy, didn't he?\", ' We never killed anybody.', ' I thought that he was innocent.', ' Tom brought Mary with him.', \" Here's the bus.\", \" Tom is domineering, isn't he?\", ' I sat among them.', ' Answer the question.', \" I'm hardly ever home.\", ' What time did Tom get here?', ' He is able to speak ten languages.', \" I'm sure you're very busy.\", \" We won't be able to do it without your help.\", \" I'm talking on the phone.\", \" I didn't do it for Tom.\", \" Don't pay attention to him.\", \" I'll call you at seven.\", ' Tom had no place to go.', \" You're nice.\", ' Tom was reading the newspaper.', ' Can I start again?', \" You don't go to school on Sunday, do you?\", ' Tom and I have nothing in common.', \" If I were you, I wouldn't do it.\", \" That's all I can tell you.\", ' Tom refused to wait for Mary.', \" It's your turn to vacuum the house.\", ' Tom never hurt a soul.', ' My mother died when I was a kid.', \" I shouldn't worry.\", ' Do you have a uniform?', ' Tom was at a loss for words.', \" Since you're here, you can help me.\", \" You're an excellent chef.\", \" You're too suspicious.\", \" This flower is beautiful, isn't it?\", ' Are they American?', ' Can you continue?', ' She gets up early.', \" You're ambitious, aren't you?\", ' Tom drinks wine.', ' You said that you loved her.', ' Tom has already been punished.', ' Tom needs surgery.', ' Tom knew who Mary wanted to talk to.', ' You need to lower your standards.', \" I'll catch up with you soon.\", \" You're no longer invited to my party.\", \" Tom's disappointment was obvious.\", ' Do you have medical insurance?', \" I've decided to leave Boston.\", ' Bush followed Reagan as president.', ' Tom is very frank.', \" Tom isn't fussy.\", ' I think we should help you.', \" I'm very proud of my parents.\", \" Tom didn't poison anybody.\", \" I didn't hear any cars.\", ' He gave a nice present to me.', ' Do you want some company?', ' Their team lost again.', \" We're surrounded.\", ' I persuaded the policeman not to shoot the monkey.', ' I came here to save you.', ' You may sit next to me.', ' Where did Tom buy those shoes?', ' I can do it blindfolded.', \" Tom is a man's name and Mary is a woman's name.\", \" I think it's true.\", \" There's Tom.\", ' What do your parents want for Christmas?', ' Do you shave every morning?', \" I don't want to talk about Tom.\", ' How long do you think it will take to go to the airport?', ' Tom came here yesterday.', ' Tom said he found something strange.', ' He is always asking for money.', \" The bus driver didn't see the pedestrian.\", ' Tom is just doing his job.', \" I'm allergic to chalk dust.\", \" You're not leaving, are you?\", ' Tom has young children.', ' As wisdom grows, and so does pain.', ' She has a double chin.', ' Tom loves cheese.', ' Tom sells fish.', ' Tom is insolent.', ' Tom was arrested for drunken driving.', \" I've thought about it recently.\", ' He has a sharp tongue.', \" That's what they always say.\", \" Tom's hyperventilating.\", ' Do you think I should take it?', ' No one will speak for you.', ' My wife is away for the weekend.', \" I'm the same age as Tom is.\", \" They aren't going to help you.\", ' Tom boiled an egg.', ' Have you ever been on a ship?', ' Are you going to go swimming today?', ' You must be patient.', ' When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"&lt;unk&gt;\\'re next! You\\'re next!\" They only stopped this nonsense when I began to do the same thing at funerals.', \" What's Tom going to do?\", ' Tom has another job.', ' Mary is quite attractive.', \" I'm not very disappointed.\", ' There is no beach in this area.', ' What color is the book?', ' I think I have an idea.', ' Do you want to continue living like this?', \" There's almost no water in the bucket.\", ' It was a great privilege working with you.', ' Please give this to Tom.', ' I knit.', ' Was anyone surprised?', ' Go on without me.', ' Tom dreamed of becoming a writer.', ' Tom and I often traveled together.', \" Why didn't you call me last night?\", \" Tom's parents were hippies.\", ' I was relieved.', ' He lives in a gated community.', \" Hold on! I haven't said anything yet.\", ' They are now aboard the ship.', ' I mentioned your name to him.', \" Tom is really happy, isn't he?\", ' Tom drank a lot of beer.', \" I've got work to do.\", ' I want to hear Tom speak.', ' Tom took part in the race.', ' Try to learn a little French.', ' They remained good friends.', ' Japan has a high population density.', ' Go home and get some sleep.', \" You're so beautiful!\", ' His victory made him a hero.', ' What do you know about this place?', ' This is incorrect.', ' We need to leave real soon.', \" It's not your choice.\", ' Do you know where Australia is?', \" It isn't too hard to learn French.\", \" Everyone's looking at you.\", ' This supermarket is open &lt;unk&gt; hours a day.', ' Tom was abusive.', ' How big is your house?', ' Tom is an architect.', ' I am going to Hawaii next year.', ' Drink less and sleep more.', \" Tom shouldn't have bought what he bought.\", ' Can you make me a copy?', ' Take the children inside.', ' Do you want some cheese?', ' I wonder whether Tom is excited.', ' The king got undressed.', ' Tom just called.', ' Tom stayed out all night.', ' Who does Tom think did that?', ' They play together a lot.', ' Were you invited to her birthday party?', ' I need lots of time.', ' It is getting darker and darker.', \" I guess I'm well adjusted.\", ' Tom is my best friend.', ' He sent me a present.', ' Tom started drawing.', ' Give it to me now.', ' I think Tom is too young.', \" I've got nothing to do.\", ' What makes you think I wrote that?', \" I'm seeking answers.\"]\n\n\nNow we can verify that our targets are indeed just our input senteces shifted by one.\n\nprint('Input 0: ', convertToText(x, data.eng_vocab)[0])\nprint('Target 0: ', convertToText(y, data.eng_vocab)[0])\n\nInput 0:   I can still work.\nTarget 0:   can still work.\n\n\nAs discussed in class, words don’t have an inherent ordering as implied by their token ids. Instead of using our token ids as features directly, we’ll learn a word embedding. That is, we’ll represent each word with a unique random vector and then allow our gradient descent to update these vectors to better represent each word as we train our model.\nNote that we can also think of as representing each word with a one-hot vector just we would with multi-class labels! Multiplying a one-hot vector with a (weight) matrix is equivalent to selecting a row of that matrix. Therefore a word embedding can be thought of as a combination of one-hot encoding each word and applying a linear layer. That said, it’s far more efficient to just select rows directly.\n\n\n\nebeddings.png\n\n\n\n\nQ2\nComplete the following implementation of a word embedding PyTorch layer. The forward method should take as input an \\(N \\times L\\) tensor of integers corresponding to a batch of sentences represented by token ids in the range 0 to 1000 and return an \\(N \\times L \\times D\\) tensor replacing each integer entry with the corresponding row of the embdedding matrix. The __init__ method should take the embedding dimension as input. That is, the length of the vector being used to represent each word.\nHint: You’ll want to use the nn.Parameter class for the embedding matrix, just as we did for the weight matricies for our own version of the Linear layer. Make sure to initialize the entries of this matrix randomly! For forward you should not need any loops. Try using the input matrix to index the embedding matrix\n\nclass Embedding(nn.Module):\n  def __init__(self, embedding_dimension):\n      super().__init__() # Needed for PyTorch!\n\n      self.embedding_matrix = nn.Parameter((embedding_dimension ** -0.5) * torch.randn((1000, embedding_dimension)))\n\n  def forward(self, x):\n      return self.embedding_matrix[x]\n\n# Test output shape\nx, y = next(iter(valid_loader))\nassert Embedding(64)(x).shape == torch.Size([256, 112, 64])\n\nOur goal is ultimately to create a language model. To do so we’ll need a neural network layer that can take as input sequences of different lengths. One such layer that we’ve seen is a Recurrent Neural Network Layer. Let’s refresh our memory on what this looks like. We’ll let \\(\\mathbf{x}_i\\) refer to the vector representing ith word in our input. Our layer will transform our featues so that after the layer we’ll have a new representation for word \\(i\\): \\(\\mathbf{\\phi}_i\\). A recurrent layer defines \\(\\phi_i\\) recursively as:\n\\[\\phi_i = \\text{ReLU}(\\phi_{i-1}^T \\mathbf{W}_\\phi + \\mathbf{x}_i^T \\mathbf{W}_x + \\mathbf{b})\\]\nHere we’ll used the ReLU activation function, but this could just as easily be any other activation. For simplicity, we’ll assume that when computing the representation \\(\\phi_{0}\\) we can pretend the previous value was 0. That is, we’ll assume: \\[\\phi_{-1}=\\mathbf{0}\\]\nNotice that at every location we’ll use the same parameters and these parameters will define a linear function.\n\n\nQ3\nComplete the implementation of an RNN layer below, using the definition above.\nHint: You can assume that forward is always given a batch of inputs of size N. The formula above is for a single input. x[n, i] will give us the (length \\(D\\)) representation for the \\(i^{th}\\) word in sentence \\(n\\), while x[:, i] will give us an \\(N \\times D\\) matrix of the representation of the \\(i^{th}\\) word in every sentence. Because each word’s new representation depends on the previous word’s new representation, you’ll need to loop over every word position explicitly.\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x):\n        ''' Computes the forward pass of an RNN\n\n        Inputs:\n            x: tensor (float), An N x L x D tensor of input data\n\n        Returns:\n            h: tensor (float), An N x L x H tensor of transformed features\n        '''\n        x = self.input_layer(x)\n        carry = torch.zeros_like(x[..., 0, :])\n        outputs = torch.zeros_like(x)\n\n        for i in range(x.shape[-2]):\n            carry = x[..., i, :] + self.hidden_layer(carry)\n            carry = self.activation(carry)\n            outputs[..., i, :] = carry\n\n        return outputs\n\nAs with any neural network layer represented as a PyTorch module, we can compose several RNN layers together to make a more complex network.\n\nclass RNNGenerator(nn.Module):\n  def __init__(self, vocab_size=1000, dimension=128):\n    super().__init__()\n    self.embedding = Embedding(dimension)\n    self.block1 = RNN(dimension, dimension)\n    self.block2 = RNN(dimension, dimension)\n    self.block3 = RNN(dimension, dimension)\n    self.output = nn.Linear(dimension, vocab_size)\n\n  def forward(self, x):\n    x = self.embedding(x)\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    return self.output(x)\n\nmodel = RNNGenerator()\n\nYou can see that the final layer of this network is a linear function that outputs our final prediction. This linear function is applied at each word separately, so the output for a given word \\(i\\) is computed as:\n\\[f(\\mathbf{x})_i=\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0\\]\nWe can apply this model to a batch of data and see that it gives use 1000 outputs for each word in each sentece. That is the output size is \\(N \\times L \\times 1000\\).\n\nprint(model(next(iter(train_loader))[0]).shape)\n\ntorch.Size([64, 26, 1000])\n\n\nAs we saw, each target \\(y_i\\) is simply the next word in the sentence, so \\(y_i =x_{i+1}\\). This is our autoregressive language modelling framework or next-word prediction. Since we have 1000 possible tokens (words), we essentially need to make a prediction for each target of one of 1000 classes. We’ll use our 1000 dimensional output at each word to estimate the probability of each possible next word. Recall that we can use the Softmax function to map an arbitrary vector to a positive vector that sums to 1. \\[p(y_i = c | \\mathbf{x}_{0}, \\mathbf{x}_{i}) = \\text{Softmax}(\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0)_c\\] This says that the probability that \\(y_i\\) is some token \\(c\\) is modelled as the \\(c^{th}\\) output of the softmax function.\nWith this in mind we can now define our negative log-likelihood loss for a given word as: \\[\\text{NLL}(y_i, \\mathbf{x}, \\mathbf{W}) = -\\log p(y_i | \\mathbf{x}_{0}, \\mathbf{x}_{i}) = -\\log \\text{Softmax}(\\phi_i^T \\mathbf{W}_0 +\\mathbf{b}_0)_{y_i}\\]\nWe want to calculate this loss over each of the \\(L\\) words in each of our \\(N\\) sentences, so we should be taking the softmax over the last dimension of the input (of size 1000).\n\n\nQ4\nComplete the method below to compute the negative log-likelihood for a batch of sentences given the output of the network and the labels. Note that the output of the network will be of size \\(N \\times L \\times 1000\\), as shown above while the targets (\\(y\\)), will be a matrix of token ids of size \\(N \\times L\\) (again each token id is in the range [0-999]). The output should be an \\(N \\times L\\) matrix of float representing the negative log-likelihood loss for each predicted word.\nHint: an appropriate softmax function has been provided for you!\n\ndef softmax(x):\n    # Compute the softmax for each entry in a tensor\n    ex = torch.exp(x)\n    sum_ex = torch.sum(ex, dim=-1, keepdims=True)\n    return ex / sum_ex\n\ndef autoregressive_loss(f, y):\n    ''' The loss for each word in a batch of predictions.\n\n        Inputs:\n            f: tensor (float), An N x L x 1000 tensor network outputs\n            y: tensor (int), An N x L tensor of true token ids in the range [0-999]\n\n        Returns:\n            loss: tensor (float), An N x L tensor of losses\n        '''\n    loss = nn.CrossEntropyLoss(reduction='none')(f.permute(0, 2, 1), y)\n    return torch.mean(loss)\n\nFor our final loss we’ll need a single number, in this case we’ll take the average NLL over every word in every sentence. In the simplest case this would look like: \\[ \\text{Loss}(\\mathbf{y}, \\mathbf{X}, \\mathbf{W}) = \\frac{1}{N\\cdot L} \\sum_{n=1}^{N}\\sum_{i=1}^{L} \\text{NLL}(y_{ni}, \\mathbf{x}_{ni}, \\mathbf{W})\\]\nHowever, this isn’t quite right! Remember that our actual sentences can be different lengths and that shorter sentences are lengthened with extra &lt;pad&gt; tokens to be length \\(L\\). For example if our longest sentence has 8 words, then \\(L=8\\) and we need to transform:\n&lt;start&gt; I love purple cats &lt;stop&gt; -&gt; &lt;start&gt; I love purple cats &lt;stop&gt;  &lt;pad&gt; &lt;pad&gt;\nSince &lt;pad&gt; tokens don’t correspond to actual words in a sentence, we don’t want to try to predict them and therefore we’ll want to exclude words where \\(y_i\\) is &lt;pad&gt;. In our setup &lt;pad&gt; is represented by a token id of 0. So our loss should actually be:\n\\[ \\text{Loss}(\\mathbf{y}, \\mathbf{X}, \\mathbf{W}) = \\frac{1}{\\sum_{n=1}^{N}\\sum_{i=1}^{L} \\mathbb{I}(y_{ni} &gt; 0)} \\sum_{n=1}^{N}\\sum_{i=1}^{L} \\mathbb{I}(y_{ni} &gt; 0) \\text{NLL}(y_{ni}, \\mathbf{x}_{ni}, \\mathbf{W})\\]\nHere \\(\\mathbb{I}(\\cdot)\\) is the indicator function so: \\[ \\mathbb{I}(y_{ni} &gt; 0) = \\begin{cases} 1 \\text{ if }y_{ni} &gt; 0 \\\\ 0 \\text{ if }y_{ni} = 0\\end{cases}\\]\n\n\nQ5\nModify your autoregressive_loss function to take the mean loss over all words where \\(y_{ni}&gt;0\\).\nHint: torch.where may come in handy here\n\ndef autoregressive_loss(f, y):\n    ''' The mean loss for each word in a batch of predictions.\n\n        Inputs:\n            f: tensor (float), An N x L x 1000 tensor network outputs\n            y: tensor (int), An N x L tensor of true token ids in the range [0-999]\n\n        Returns:\n            loss: (float) The averge loss\n        '''\n    loss = nn.CrossEntropyLoss(reduction='none')(f.permute(0, 2, 1), y)\n    loss = torch.where(y != 2, loss, 0.)\n    return torch.mean(loss)\n\nOk, we’re finally ready to do some training!\n\n\nQ6\nComplete the train loop below. At each iteration, make sure to compute the model output and the loss using the autoregressive_loss function you just wrote. Then do any nessecary steps for gradient descent using the provided optimizer.\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Do model creation here so that the model is recreated each time the cell is run\nmodel = model.to(device)\nmodel.train()\n\n# Create the optimizer, just like we have with the built-in optimizer\nopt = torch.optim.Adam(model.parameters(), 0.01)\n\n# Information for plots\ntrain_losses = []\n\nfor iteration, (train_X, train_Y) in enumerate(tqdm.tqdm(train_loader)):\n    # Grab the batch of data and send it to the correct device\n    train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n    # Compute the output, loss, and gradient and take a step of gradient descent\n    train_output = model(train_X)\n\n    # Compute loss\n    loss = autoregressive_loss(train_output, train_Y)\n\n    # Compute gradient\n    model.zero_grad()\n    loss.backward()\n\n    # Take a step of gradient descent\n    with torch.no_grad():\n        opt.step()\n\n    train_losses.append(loss.item())\n\n    if iteration &gt; 100:\n      break\n\n\n# Plot the loss over the first 100 iterations\nplt.plot(train_losses)\nplt.title('Loss vs. Iterations')\n\n  2%|▏         | 101/4101 [00:03&lt;02:31, 26.35it/s]\n\n\nText(0.5, 1.0, 'Loss vs. Iterations')\n\n\n\n\n\n\n\n\n\n\n\nQ7\nYou might notice that the plotted loss above has pretty poor behaivior! This could be due to vanishing or exploding gradients. Briefly explain, why RNNs might be especially prone to this problem and how you might address it. Then show how you might implement this approach within your RNN layer.\nRNNs are especially prone to this problem because information passes through many layers. We could try to fix this with normalization or residual connections.\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.activation = nn.ReLU()\n        self.input_layer = nn.Linear(input_size, hidden_size)\n        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x):\n        ''' Computes the forward pass of an RNN\n\n        Inputs:\n            x: tensor (float), An N x L x D tensor of input data\n\n        Returns:\n            h: tensor (float), An N x L x H tensor of transformed features\n        '''\n        x = self.input_layer(x)\n        carry = torch.zeros_like(x[..., 0, :])\n        outputs = torch.zeros_like(x)\n\n        for i in range(x.shape[-2]):\n            carry = x[..., i, :] + self.hidden_layer(carry)\n            carry = self.activation(carry)\n\n            # Normalize the carry\n            carry = (carry - carry.mean(dim=-1, keepdims=True)) / carry.std(dim=-1, keepdims=True)\n            outputs[..., i, :] = carry\n\n        return outputs\n\n# Create a model\nmodel = RNNGenerator()\n\nTry out your implementation by copying your training loop from above (this does not need to actually improve on Q6 for full credit).\n\n# Use the GPUs if they are available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Do model creation here so that the model is recreated each time the cell is run\nmodel = model.to(device)\nmodel.train()\n\n# Create the optimizer, just like we have with the built-in optimizer\nopt = torch.optim.Adam(model.parameters(), 0.01)\n\n# Information for plots\ntrain_losses = []\n\nfor iteration, (train_X, train_Y) in enumerate(tqdm.tqdm(train_loader)):\n    # Grab the batch of data and send it to the correct device\n    train_X, train_Y = train_X.to(device), train_Y.to(device)\n\n    # Compute the output, loss, and gradient and take a step of gradient descent\n    train_output = model(train_X)\n\n    # Compute loss\n    loss = autoregressive_loss(train_output, train_Y)\n\n    # Compute gradient\n    model.zero_grad()\n    loss.backward()\n\n    # Take a step of gradient descent\n    with torch.no_grad():\n        opt.step()\n\n    train_losses.append(loss.item())\n\n    if iteration &gt; 100:\n      break\n\n\n# Plot the loss over the first 100 iterations\nplt.plot(train_losses)\nplt.title('Loss vs. Iterations')\n\n  2%|▏         | 101/4101 [00:03&lt;02:20, 28.46it/s]\n\n\nText(0.5, 1.0, 'Loss vs. Iterations')\n\n\n\n\n\n\n\n\n\nIf we want to make use of our language model, we’ll need a way to actually generate text from it. Recall from class that we’ll need to do this one token at a time. We know that any text will always start with our designated &lt;start&gt; token, which has token id 1 in our vocabulary. Therefore we can start generating a sentence by using our model to sample the next word given &lt;start&gt;.\nTo sample a word we’ll use our model to predict a probability distribution over every possible next token and sample from that distribution. For example we might have the following sequence of samples:\n\\[\\text{I} \\sim p(y_1| \\text{&lt;start&gt;})\\] \\[\\text{love} \\sim p(y_2| \\text{&lt;start&gt;}, \\text{I})\\] \\[\\text{purple} \\sim p(y_3| \\text{&lt;start&gt;}, \\text{I}, \\text{love})\\] \\[\\text{cats} \\sim p(y_4| \\text{&lt;start&gt;}, \\text{I}, \\text{love})\\] \\[\\text{&lt;stop&gt;} \\sim p(y_4| \\text{&lt;start&gt;}, \\text{I}, \\text{love}, \\text{purple})\\]\nThe following function will take a tensor of size \\(N \\times ... \\times C\\), where all entries are non-negative and the entries along the last dimension sum to 1 (therefore forming a valid categorical distribution). It returns a sample tensor of ints of size \\(N\\times ...\\), sampling each entry from the corresponding input distribution.\n\nimport torch\ndef sample_categorical(probs):\n  assert torch.all(torch.isclose(p.sum(dim=-1), torch.tensor(1.)))\n  return torch.distributions.Categorical(probs=probs).sample()\n\n# 4 x 3 matrix of probabilities (each row sums to 1.)\np = torch.tensor([[0.3, 0.2, 0.5],\n                  [0.0, 0.9, 0.1],\n                  [0.9, 0.0, 0.1],\n                  [0.3, 0.3, 0.4]])\n\n# Length 4 vector of samples\nprint(sample_categorical(p))\n\n# 2 x 2 x 3 matrix of probabilities (each final dimension sums to 1.)\np = torch.tensor([\n                  [\n                    [0.3, 0.2, 0.5],\n                    [0.0, 0.9, 0.1]],\n                  [\n                    [0.9, 0.0, 0.1],\n                    [0.3, 0.3, 0.4]\n                  ]\n                  ])\n\n# 2x2 matrix of samples\nprint(sample_categorical(p))\n\ntensor([2, 1, 0, 0])\ntensor([[2, 1],\n        [0, 0]])\n\n\n\n\nQ8\nComplete the function below to sample a batch of sentences given a trained model. The function should return a matrix of size \\(N \\times L\\), where \\(N\\) is the given batch size and \\(L\\) is the given maximum sentence length.\nHint: Remember that you’ll need to sample sequentially, one word at a time in each sentence, so you should have a loop that runs \\(L\\) times. Also remember that the model outputs a prediction for every word in a sentence, but at each step you only need the prediction for the last word that has yet to be seen.\n\ndef sample(model, data, batch_size=1, max_length=50):\n  model.eval()\n\n  # Start with an N x 1 matrix where each entry is just the &lt;start&gt; token.\n  # After the first iteration this should be N x 2, then N x 3 ... until N x L.\n  sample = torch.ones((batch_size, 1)).int().to(device)\n  for i in range(max_length):\n    new_sample = sample_categorical(softmax(model(sample)))[..., -1:]\n    sample = torch.cat([sample, new_sample], dim=-1)\n  return sample\n\n# Test sampling\nsample_sentence = sample(model, data)\nprint('Tokens:', sample_sentence)\nprint('Text:', convertToText(sample_sentence, data.eng_vocab))\n\nTokens: tensor([[  1,   6, 101,  61,  15, 150, 496,  11,   4,  41,   7,  29, 133,  60,\n         358,   4, 191,  26,   4,  14, 336,  52,  36, 274,   4,   4,  96,  82,\n         117,  18,   7,   4,  14, 243,  63,  15, 279,   4, 264, 232, 318,  21,\n           4,  61,  10,  91,   4,  12, 411,   0,   0]])\nText: [' I will can the carity to. stproenant.ive me. 0loight..le here usmt. ap with the dog.ine couldanded. can youce.? anymore&lt;pad&gt;&lt;pad&gt;']\n\n\nNow recall that RNNs actually aren’t ideal for language modeling. In recent years they’ve mostly been replaced by attention layers. A scaled dot-product attention layer is defined by the formula: \\[\\text{Attention}(Q, K, V) = \\text{Softmax}\\bigg(\\frac{QK^T}{\\sqrt{h}} \\bigg)V\\]\nIn the above formula, \\(Q\\), \\(K\\) and \\(V\\) are all assumed to be \\(L \\times h\\) matrices given by affine functions of the input: \\[Q = X W_Q + b_Q\\] \\[K = X W_K + b_K\\] \\[V = X W_V + b_V\\]\n\n\nQ9\nComplete the following implementation of a (single-headed) attention layer. The forward method should assume a batched input of shape \\(N \\times L \\times d\\), so the attention equation above should be applied for each observation yielding an \\(N \\times L \\times h\\) output.\nHint: you can use t.transpose(-1, -2) to transpose the last two dimensions of a tensor, e.g. to turn an \\(N \\times L \\times h\\) tensor into an \\(N \\times h \\times L\\) tensor\n\nclass Attention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n        Q = self.query_layer(x)\n        K = self.key_layer(x)\n        V = self.value_layer(x)\n\n        W = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d)\n        W = torch.nn.functional.softmax(W, dim=-1)\n        return torch.matmul(W, V)\n\nIn order to do autoregressive generation, we need to make sure that future words don’t influence past words. As we saw in class we can accomplish this by masking our attention matrix before applying the softmax function:\n\\[\\text{MaskedAttention}(Q, K, V) = \\text{Softmax}\\bigg( \\text{Mask} \\bigg( \\frac{QK^T}{\\sqrt{h}} \\bigg) \\bigg)V\\]\nOur masking function will work as follows: \\[\\text{Mask}(M)_{ij} = \\begin{cases} -\\infty \\text{ if } i &lt; j \\\\ M_{ij} \\text{ if } i \\geq j\\end{cases}\\] After the softmax operation entries set to \\(-\\infty\\) will become \\(0\\). Luckily PyTorch provides us with a useful function called torch.tril that can help us: \\[\\text{TriL}(M)_{ij} = \\begin{cases} 0\\  \\ \\ \\  \\text{ if } i &lt; j \\\\ M_{ij} \\text{ if } i \\geq j\\end{cases}\\]\n\n\nQ10\nComplete the following implementation of masked attention. Using your previous attention implementation as a starting point.\n\nclass MaskedAttention(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size\n\n    def forward(self, x):\n        '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n        Q = self.query_layer(x)\n        K = self.key_layer(x)\n        V = self.value_layer(x)\n\n        W = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d)\n        mask = torch.tril(torch.ones_like(W))\n        W = torch.where(mask == 0, -torch.inf, W)\n\n        W = torch.nn.functional.softmax(W, dim=-1)\n        return torch.matmul(W, V)\n\nFinally the last addition we’ll make to our attention layer (for now) is to implement a Multi-headed attention layer. In this case our layer will take an additional argument num_heads that specifies the number of attention heads to use.\nRecall that for multi-headed attention we’ll compute \\(Q\\), \\(K\\) and \\(V\\) the same way as before, but this time before computing the attention forumla as above, we’ll split each into num_heads chunks along the last dimension. That is, if \\(Q\\) is of shape \\(N \\times L \\times h\\), and num_heads is 8, we’ll create 8 new query matricies \\(Q_1...Q_8\\), each of size \\(N \\times L \\times \\frac{h}{8}\\).\nWe’ll then compute num_heads different attention outputs, where the output for head i is: \\[\\text{Head}_i = \\text{Softmax}\\bigg( \\text{Mask} \\bigg( \\frac{Q_iK_i^T}{\\sqrt{h/8}} \\bigg) \\bigg)V_i\\] Each head will similarly return an output of size \\(N \\times L \\times \\frac{h}{8}\\), and we can then use torch.cat(heads, dim=-1) to recombine them into a final output tensor of size \\(N \\times L \\times h\\).\n\n\nQ11\nComplete the implementation of MaskedMultiheadedAttention below, using the formula above.\n\nclass MaskedMultiheadAttention(nn.Module):\n    def __init__(self, input_size, hidden_size, num_heads=1):\n        super().__init__()\n        self.query_layer = nn.Linear(input_size, hidden_size)\n        self.key_layer = nn.Linear(input_size, hidden_size)\n        self.value_layer = nn.Linear(input_size, hidden_size)\n        self.d = hidden_size // num_heads\n        self.num_heads = num_heads\n\n    def forward(self, x):\n      '''\n        Inputs:\n          x: tensor (float), an N x L x d tensor of embeddings\n\n        Outputs:\n          transformed: tensor (float), and N x L x h tensor of transformed\n                        embeddings, where h is the specified hidden_size\n        '''\n      Q = self.query_layer(x)\n      K = self.key_layer(x)\n      V = self.value_layer(x)\n\n      Q = Q.reshape(Q.shape[:-1] + (self.num_heads, self.d)).transpose(-2, -3)\n      K = K.reshape(K.shape[:-1] + (self.num_heads, self.d)).transpose(-2, -3)\n      V = V.reshape(V.shape[:-1] + (self.num_heads, self.d)).transpose(-2, -3)\n\n      W = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d)\n      mask = torch.tril(torch.ones_like(W))\n      W = torch.where(mask == 0, -torch.inf, W)\n\n      W = torch.nn.functional.softmax(W, dim=-1)\n      phi = torch.matmul(W, V).transpose(-2, -3)\n      return phi.reshape(phi.shape[:-2] + (-1,))\n\n\n\nQ12\nExplain, in your own words, the potential advantages of attention-based models over RNN-based models for the language modelling problem.\nAttention layers can handle aribitray-length dependencies and don’t suffer from vanishing/exploding gradients."
  },
  {
    "objectID": "assignments/homeworks/Homework 7/main.html",
    "href": "assignments/homeworks/Homework 7/main.html",
    "title": "Homework 7: PyTorch",
    "section": "",
    "text": "Now that we’ve successfully built our own tool for automatic differentiation and neural networks, let’s look at an industry-standard tool for accomplishing the same tasks: PyTorch.\nThroughout this homework to may find it helpful to refer to the PyTorch documentation, as well as the lecture notebook on Pytorch.\nWe saw in class that we can create a function with parameters in PyTorch using the torch.nn module that we’ll import as just nn. We can do this by creating a subclass of nn.Module and defining the parameters with nn.Parameter.\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/4d66c02805cb1a8b1b1f6043f08c5929/raw/14332b6d752fe1c7420647a2fe7eeb587cd767ef/hw6_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw7_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\nimport torch\nfrom torch import nn\nfrom hw7_support import *\n\n\nclass LinearZeros(nn.Module):\n    '''\n    A PyTorch module representing a linear/affine function with weights W and bias b:\n        f(X) = XW + b\n    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n\n    This version of the Linear module initializes the parameters to 0.\n    '''\n    def __init__(self, in_dimensions, out_dimensions):\n        # Call the nn.Module __init__ function\n        super().__init__()\n\n        # Create parameters that we can fit with gradient descent.\n        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n        # This assumes X is 2-dimensional (a matrix)!\n        return torch.matmul(x, self.weights) + self.bias\n\nWe can create a 1-dimensional linear function by creating a LinearZeros object, specifying that both the input and output dimensions should be 1. The method model.parameters() will give us access to all the weights we can fit with gradient descent.\n\nmodel = LinearZeros(1, 1)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[0.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nWe can also call this model just like any other function.\n\n# Create 4 1-dimensional inputs\nx = torch.ones((4, 1))\n\nmodel(x)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;AddBackward0&gt;)\n\n\nLet’s start by creating a simple dataset to use for the next few problems. We’ll use a regression dataset similar to the one we saw in class. In this case, I’ve provied data already split into training and validation sets.\n\n# Create the training inputs and labels\nx = torch.rand(200, 1) * 10 - 5.\ny = x ** 2 / 2 + torch.sin(x * 5) - 5\n\n# Create the validation inputs and labels\nxvalid = torch.rand(200, 1) * 10 - 5.\nyvalid = xvalid ** 2 / 2 + torch.sin(xvalid * 5 + torch.pi) - 5\n\nplotRegression(x, y, xvalid, yvalid)\n\n\n\n\n\n\n\n\nWe can make predictions for our data using the model we just definied:\n\npredictions = model(x)\npredictions[:5]\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;SliceBackward0&gt;)\n\n\nHowever if we plot the prediction function, we’ll see that it isn’t very good as we haven’t optimized the parameters yet:\n\nplotRegression(x, y, xvalid, yvalid, model=model)\n\n\n\n\n\n\n\n\nThe first thing we’ll need to optimize our model is a loss function. As we saw in class, the convention in PyTorch is to separate the loss from the model, so we’ll write a simple function that takes in predictions and labels, returning the mean squared error loss.\n\n\nComplete the mse_loss function below. The function should compute the same MSE loss we’ve seen in previous homeworks, but using PyTorch operations.\n\\[\\textbf{Loss}(\\mathbf{a}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N(a_i - y_i)^2\\]\nHint: As we see above, our linear module returns a column-vector (predictions is 2-dimensional), but y is just a vector (y is 1-dimensional). Make sure to account for this!\n\ndef mse_loss(prediction, labels):\n    # YOUR CODE HERE\n\n# Test to check\ntorch.manual_seed(0)\nassert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)\n\nWith our loss in hand, we can run gradient descent to optimize our model’s parameters. This time, we’ll use the torch.optim module, which includes many useful variations of gradient descent.\n\n\n\nComplete the gradient descent function below. The function should: - Create an optim.SGD optimizer for the model’s parameters with the specified learning rate - At each step: - Compute the model output and loss (loss_func) on the training data - Compute the gradients of the loss with respect to the model parameters - Take a gradient descent step - Reset the parameter gradients to 0 - Compute the validation loss\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=1000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)\n\n\nmodel = LinearZeros(1, 1)\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nNow that we have a function to train a PyTorch model, we can try something bigger and more exciting! Let’s train a neural network.\n\n\n\nCreate a PyTorch model for a neural network with the following specification: - The network should have 4 hidden layers, each with 20 neurons - The network should take 1-dimensional inputs as above - Each layer should use the LinearZeros module we just wrote - Each linear layer should be followed by a ReLU activation (except the output), use the nn.ReLU() module.\nHint: Remember that you can use the nn.Sequential class to easily compose a sequence of functions in PyTorch.\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build\ntest_build(model, LinearZeros, dropout_type=None, type='zeros')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nWhat happened when you attempted to train the model above? Why did this happen? Give a short 1-2 sentence answer.\nYOUR ANSWER HERE\nLet’s try modifying our Linear module with a different strategy for initialization.\n\n\n\nModify the LinearZeros implementation from above to initialize the weights and bias parameters from a standard normal distribution \\(w,b \\sim \\mathcal{N}(0, 1)\\). Then modify your model from Q6 to use this new module.\nHint: You may find the torch.randn function useful here. You might also find that the model doesn’t train! We’ll address this in the next question.\n\nclass LinearNormal(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build and LinearNormal\ntest_normal(LinearNormal)\ntest_build(model, LinearNormal, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nIn the previous question you might have found that gradient descent didn’t work. This could suggest that our learning rate is set wrong. Think about a strategy that you might use to find an appropriate learning rate for fitting this model and try it out below. Then explain the strategy that you used. Is there any way you could improve this strategy to make finding a learning rate quicker?\n\n# Modify this code to choose a good learning rate\nmodel =\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nEXPLAIN YOUR APPROACH HERE\n\n\n\nWe saw in class that a common, useful approach for initializing neural networks is to use a Kaiming normal initialization. In this approach we draw each initial weight from a normal distribution where the standard deviation is scaled by the square root of the number of input dimensions to the layer. If \\(\\mathbf{W} \\in \\mathbb{R}^{d\\times e}\\) then: \\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\mathbf{W}: d \\times e\\] \\[b_j = 0 \\quad \\mathbf{b}: e\\] We’ll initialize the biases to \\(0\\). Below, implement a linear module using the Kaiming normal initialization, then repeat Q5 using the LinearKaiming class and the learning rate you chose in Q8. If needed, adjust the learning rate until your model almost perfectly fits the training data.\n\nclass LinearKaiming(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\nlr =\n\n# Test the model build and LinearKaiming\ntest_kaiming(LinearKaiming)\ntest_build(model, LinearKaiming, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nIf all went well so far, we should find that our model fits our data well, but perhaps a little bit too well. Let’s try out some of the strategies we’ve seen to reduce overfitting, starting with early stopping.\n\n\n\nModify your gradient descent algorithm to implment a basic form of early stopping: stop gradient descent as soon as the validation loss increases from the previous iteration. Test this approach with the same model from Q9.\n\ndef gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nDid this approach work as intended? Why or why not? Think about how you might improve this approach and explain any ideas you have in 1-2 sentences.\nYOUR ANSWER HERE\n\n\n\nModify your early stopping gradient descent so that it always runs for at least 50 iterations. Then after 50 iterations stop if at any point the validation loss is larger than the average validation loss for the previous 50 iterations.\n\ndef gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nNow let’s try out L1 regualrization! We will consider a scaled version of L1 regularization, where for a \\(d \\times e\\) weight matrix \\(\\mathbf{W}\\) we will define the L1 loss as: \\[\\textbf{Loss}_{L1}(\\mathbf{W})= \\frac{\\lambda}{d e}\\sum_{i=1}^d\\sum_{j=1}^e |w_{ij}| \\quad \\mathbf{W}: d \\times e\\] Here \\(\\lambda\\) is a value that we can choose to control how much weight we put on our L1 loss (we’ll call it l1_weight below).\n\n\n\nModify your original gradient descent algorithm from Q4 (no early stopping) to add the L1 loss for each parameter in the model to the loss.\nHint: Recall that we can access every parameter in the model using the model.parameters() method. In this question you do not need to worry about distinguishing between weights and biases, you can apply L1 regularization to biases as well if it simplifies your approach. Your validation loss should not include the regularization terms.\n\nfrom torch import optim\n\ndef gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n        losses.append(loss.detach().numpy()) # Track loss without L2 terms\n\n        l2_loss =\n        loss = loss + l1_weight * l2_loss\n        # CODE FOR GRAIDENT DESCENT STEP HERE\n\n        valid_loss =\n\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)\n\n\n\n\nApply gradient_descent_l1 as in previous problems. Find an appropriate setting of l1_weight that minimizes the validation loss.\nHint: How you go about choosing l1_weight is up to you! Your validation loss should be lower than the validation loss without regularization.\n\nmodel = # YOUR CODE HERE\nlr =\nl1_weight =\nlosses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nFinally let’s try out dropout regularization. We will implement dropout as its own module, so we can think of it as a function that transforms a vector or matix into a vector or matrix of the same shape with elements randomly set to \\(0\\). In this case we can write the dropout function as: \\[\\text{Dropout}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix},\\ d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\nHere \\(\\odot\\) denotes element-wise multiplication (so \\(\\mathbf{D}\\) and \\(\\mathbf{X}\\) are the same shape), \\(r\\) is the dropout rate so \\(p(d_{ij}=0)=r\\).\nAt evaluation time, we do not want to randomly drop elements. Instead we will scale \\(\\mathbf{X}\\) by \\((1-r)\\): \\[\\text{Dropout}_{\\text{eval}}(\\mathbf{X}, r) = (1-r)\\mathbf{X}\\]\n\n\n\nComplete the implementation of the Dropout module below.\nHint: The built-in training property of an nn.Module instance specifies if our model is in training mode or evaluation mode. By default models are in training mode (training == True), but we can set a model to evaluation mode by calling model.eval(). Then we can use model.train() to set it back to training mode.\nYou may find the function torch.rand_like() helpful for this problem. You might also find it helpful to know that you can convert and boolean tensor X into a float tensor by calling X.float() (True becomes 1., False becomes 0.)\n\nclass Dropout(nn.Module):\n    def __init__(self, rate=0.01):\n        # Rate specifies the dropout rate (r)\n        super().__init__()\n        self.rate = rate\n\n    def forward(self, x):\n        # YOUR CODE HERE\n        if self.training:\n\n        else:\n\n\n# Test our module\ntest_dropout(Dropout)\n\n\n\n\nModify your gradient_descent function to put the model into train mode before calculating the training loss and into eval mode before calculating the validation loss. Then create a model based on your network from Q9, but this time add a Dropout layer before each LinearKaiming layer. You can use the default dropout rate of 0.01 or try something different! Verify that dropout gives different results to previous approaches.\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n\n# YOUR CODE HERE\nmodel =\n\n# Test our model build\ntest_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
  },
  {
    "objectID": "assignments/homeworks/Homework 7/main.html#part-1-introduction-to-pytorch",
    "href": "assignments/homeworks/Homework 7/main.html#part-1-introduction-to-pytorch",
    "title": "Homework 7: PyTorch",
    "section": "",
    "text": "Now that we’ve successfully built our own tool for automatic differentiation and neural networks, let’s look at an industry-standard tool for accomplishing the same tasks: PyTorch.\nThroughout this homework to may find it helpful to refer to the PyTorch documentation, as well as the lecture notebook on Pytorch.\nWe saw in class that we can create a function with parameters in PyTorch using the torch.nn module that we’ll import as just nn. We can do this by creating a subclass of nn.Module and defining the parameters with nn.Parameter.\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/4d66c02805cb1a8b1b1f6043f08c5929/raw/14332b6d752fe1c7420647a2fe7eeb587cd767ef/hw6_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw7_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\nimport torch\nfrom torch import nn\nfrom hw7_support import *\n\n\nclass LinearZeros(nn.Module):\n    '''\n    A PyTorch module representing a linear/affine function with weights W and bias b:\n        f(X) = XW + b\n    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n\n    This version of the Linear module initializes the parameters to 0.\n    '''\n    def __init__(self, in_dimensions, out_dimensions):\n        # Call the nn.Module __init__ function\n        super().__init__()\n\n        # Create parameters that we can fit with gradient descent.\n        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n        # This assumes X is 2-dimensional (a matrix)!\n        return torch.matmul(x, self.weights) + self.bias\n\nWe can create a 1-dimensional linear function by creating a LinearZeros object, specifying that both the input and output dimensions should be 1. The method model.parameters() will give us access to all the weights we can fit with gradient descent.\n\nmodel = LinearZeros(1, 1)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[0.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nWe can also call this model just like any other function.\n\n# Create 4 1-dimensional inputs\nx = torch.ones((4, 1))\n\nmodel(x)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;AddBackward0&gt;)\n\n\nLet’s start by creating a simple dataset to use for the next few problems. We’ll use a regression dataset similar to the one we saw in class. In this case, I’ve provied data already split into training and validation sets.\n\n# Create the training inputs and labels\nx = torch.rand(200, 1) * 10 - 5.\ny = x ** 2 / 2 + torch.sin(x * 5) - 5\n\n# Create the validation inputs and labels\nxvalid = torch.rand(200, 1) * 10 - 5.\nyvalid = xvalid ** 2 / 2 + torch.sin(xvalid * 5 + torch.pi) - 5\n\nplotRegression(x, y, xvalid, yvalid)\n\n\n\n\n\n\n\n\nWe can make predictions for our data using the model we just definied:\n\npredictions = model(x)\npredictions[:5]\n\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], grad_fn=&lt;SliceBackward0&gt;)\n\n\nHowever if we plot the prediction function, we’ll see that it isn’t very good as we haven’t optimized the parameters yet:\n\nplotRegression(x, y, xvalid, yvalid, model=model)\n\n\n\n\n\n\n\n\nThe first thing we’ll need to optimize our model is a loss function. As we saw in class, the convention in PyTorch is to separate the loss from the model, so we’ll write a simple function that takes in predictions and labels, returning the mean squared error loss.\n\n\nComplete the mse_loss function below. The function should compute the same MSE loss we’ve seen in previous homeworks, but using PyTorch operations.\n\\[\\textbf{Loss}(\\mathbf{a}, \\mathbf{y}) = \\frac{1}{N}\\sum_{i=1}^N(a_i - y_i)^2\\]\nHint: As we see above, our linear module returns a column-vector (predictions is 2-dimensional), but y is just a vector (y is 1-dimensional). Make sure to account for this!\n\ndef mse_loss(prediction, labels):\n    # YOUR CODE HERE\n\n# Test to check\ntorch.manual_seed(0)\nassert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)\n\nWith our loss in hand, we can run gradient descent to optimize our model’s parameters. This time, we’ll use the torch.optim module, which includes many useful variations of gradient descent.\n\n\n\nComplete the gradient descent function below. The function should: - Create an optim.SGD optimizer for the model’s parameters with the specified learning rate - At each step: - Compute the model output and loss (loss_func) on the training data - Compute the gradients of the loss with respect to the model parameters - Take a gradient descent step - Reset the parameter gradients to 0 - Compute the validation loss\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=1000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)\n\n\nmodel = LinearZeros(1, 1)\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nNow that we have a function to train a PyTorch model, we can try something bigger and more exciting! Let’s train a neural network.\n\n\n\nCreate a PyTorch model for a neural network with the following specification: - The network should have 4 hidden layers, each with 20 neurons - The network should take 1-dimensional inputs as above - Each layer should use the LinearZeros module we just wrote - Each linear layer should be followed by a ReLU activation (except the output), use the nn.ReLU() module.\nHint: Remember that you can use the nn.Sequential class to easily compose a sequence of functions in PyTorch.\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build\ntest_build(model, LinearZeros, dropout_type=None, type='zeros')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nWhat happened when you attempted to train the model above? Why did this happen? Give a short 1-2 sentence answer.\nYOUR ANSWER HERE\nLet’s try modifying our Linear module with a different strategy for initialization.\n\n\n\nModify the LinearZeros implementation from above to initialize the weights and bias parameters from a standard normal distribution \\(w,b \\sim \\mathcal{N}(0, 1)\\). Then modify your model from Q6 to use this new module.\nHint: You may find the torch.randn function useful here. You might also find that the model doesn’t train! We’ll address this in the next question.\n\nclass LinearNormal(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build and LinearNormal\ntest_normal(LinearNormal)\ntest_build(model, LinearNormal, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nIn the previous question you might have found that gradient descent didn’t work. This could suggest that our learning rate is set wrong. Think about a strategy that you might use to find an appropriate learning rate for fitting this model and try it out below. Then explain the strategy that you used. Is there any way you could improve this strategy to make finding a learning rate quicker?\n\n# Modify this code to choose a good learning rate\nmodel =\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nEXPLAIN YOUR APPROACH HERE\n\n\n\nWe saw in class that a common, useful approach for initializing neural networks is to use a Kaiming normal initialization. In this approach we draw each initial weight from a normal distribution where the standard deviation is scaled by the square root of the number of input dimensions to the layer. If \\(\\mathbf{W} \\in \\mathbb{R}^{d\\times e}\\) then: \\[w_{ij} \\sim \\mathcal{N}\\bigg(0, \\frac{1}{\\sqrt{d}}\\bigg) \\quad \\mathbf{W}: d \\times e\\] \\[b_j = 0 \\quad \\mathbf{b}: e\\] We’ll initialize the biases to \\(0\\). Below, implement a linear module using the Kaiming normal initialization, then repeat Q5 using the LinearKaiming class and the learning rate you chose in Q8. If needed, adjust the learning rate until your model almost perfectly fits the training data.\n\nclass LinearKaiming(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\nlr =\n\n# Test the model build and LinearKaiming\ntest_kaiming(LinearKaiming)\ntest_build(model, LinearKaiming, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nIf all went well so far, we should find that our model fits our data well, but perhaps a little bit too well. Let’s try out some of the strategies we’ve seen to reduce overfitting, starting with early stopping.\n\n\n\nModify your gradient descent algorithm to implment a basic form of early stopping: stop gradient descent as soon as the validation loss increases from the previous iteration. Test this approach with the same model from Q9.\n\ndef gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\nDid this approach work as intended? Why or why not? Think about how you might improve this approach and explain any ideas you have in 1-2 sentences.\nYOUR ANSWER HERE\n\n\n\nModify your early stopping gradient descent so that it always runs for at least 50 iterations. Then after 50 iterations stop if at any point the validation loss is larger than the average validation loss for the previous 50 iterations.\n\ndef gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nNow let’s try out L1 regualrization! We will consider a scaled version of L1 regularization, where for a \\(d \\times e\\) weight matrix \\(\\mathbf{W}\\) we will define the L1 loss as: \\[\\textbf{Loss}_{L1}(\\mathbf{W})= \\frac{\\lambda}{d e}\\sum_{i=1}^d\\sum_{j=1}^e |w_{ij}| \\quad \\mathbf{W}: d \\times e\\] Here \\(\\lambda\\) is a value that we can choose to control how much weight we put on our L1 loss (we’ll call it l1_weight below).\n\n\n\nModify your original gradient descent algorithm from Q4 (no early stopping) to add the L1 loss for each parameter in the model to the loss.\nHint: Recall that we can access every parameter in the model using the model.parameters() method. In this question you do not need to worry about distinguishing between weights and biases, you can apply L1 regularization to biases as well if it simplifies your approach. Your validation loss should not include the regularization terms.\n\nfrom torch import optim\n\ndef gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n        losses.append(loss.detach().numpy()) # Track loss without L2 terms\n\n        l2_loss =\n        loss = loss + l1_weight * l2_loss\n        # CODE FOR GRAIDENT DESCENT STEP HERE\n\n        valid_loss =\n\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)\n\n\n\n\nApply gradient_descent_l1 as in previous problems. Find an appropriate setting of l1_weight that minimizes the validation loss.\nHint: How you go about choosing l1_weight is up to you! Your validation loss should be lower than the validation loss without regularization.\n\nmodel = # YOUR CODE HERE\nlr =\nl1_weight =\nlosses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nFinally let’s try out dropout regularization. We will implement dropout as its own module, so we can think of it as a function that transforms a vector or matix into a vector or matrix of the same shape with elements randomly set to \\(0\\). In this case we can write the dropout function as: \\[\\text{Dropout}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix},\\ d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\nHere \\(\\odot\\) denotes element-wise multiplication (so \\(\\mathbf{D}\\) and \\(\\mathbf{X}\\) are the same shape), \\(r\\) is the dropout rate so \\(p(d_{ij}=0)=r\\).\nAt evaluation time, we do not want to randomly drop elements. Instead we will scale \\(\\mathbf{X}\\) by \\((1-r)\\): \\[\\text{Dropout}_{\\text{eval}}(\\mathbf{X}, r) = (1-r)\\mathbf{X}\\]\n\n\n\nComplete the implementation of the Dropout module below.\nHint: The built-in training property of an nn.Module instance specifies if our model is in training mode or evaluation mode. By default models are in training mode (training == True), but we can set a model to evaluation mode by calling model.eval(). Then we can use model.train() to set it back to training mode.\nYou may find the function torch.rand_like() helpful for this problem. You might also find it helpful to know that you can convert and boolean tensor X into a float tensor by calling X.float() (True becomes 1., False becomes 0.)\n\nclass Dropout(nn.Module):\n    def __init__(self, rate=0.01):\n        # Rate specifies the dropout rate (r)\n        super().__init__()\n        self.rate = rate\n\n    def forward(self, x):\n        # YOUR CODE HERE\n        if self.training:\n\n        else:\n\n\n# Test our module\ntest_dropout(Dropout)\n\n\n\n\nModify your gradient_descent function to put the model into train mode before calculating the training loss and into eval mode before calculating the validation loss. Then create a model based on your network from Q9, but this time add a Dropout layer before each LinearKaiming layer. You can use the default dropout rate of 0.01 or try something different! Verify that dropout gives different results to previous approaches.\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n\n# YOUR CODE HERE\nmodel =\n\n# Test our model build\ntest_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
  },
  {
    "objectID": "assignments/homeworks/Homework 7/submission.html",
    "href": "assignments/homeworks/Homework 7/submission.html",
    "title": "Homework 7: PyTorch",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%207/hw7_support.py\n\n\nimport torch\nfrom torch import nn\nfrom hw7_support import *\n\n\nclass LinearZeros(nn.Module):\n    '''\n    A PyTorch module representing a linear/affine function with weights W and bias b:\n        f(X) = XW + b\n    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n\n    This version of the Linear module initializes the parameters to 0.\n    '''\n    def __init__(self, in_dimensions, out_dimensions):\n        # Call the nn.Module __init__ function\n        super().__init__()\n\n        # Create parameters that we can fit with gradient descent.\n        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n\n    def forward(self, x):\n        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n        # This assumes X is 2-dimensional (a matrix)!\n        return torch.matmul(x, self.weights) + self.bias\n\n\n\n\n\nQ1\n\ndef mse_loss(prediction, labels):\n    # YOUR CODE HERE\n\n# Test to check\ntorch.manual_seed(0)\nassert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)\n\n\n\n\n\n\nQ2\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=1000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)\n\n\nmodel = LinearZeros(1, 1)\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ3\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build\ntest_build(model, LinearZeros, dropout_type=None, type='zeros')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ4\nYOUR ANSWER HERE\n\n\n\n\n\nQ5\n\nclass LinearNormal(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\n\n# Test the model build and LinearNormal\ntest_normal(LinearNormal)\ntest_build(model, LinearNormal, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ6\n\n# Modify this code to choose a good learning rate\nmodel =\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\nEXPLAIN YOUR APPROACH HERE\n\n\n\n\n\nQ7\n\nclass LinearKaiming(nn.Module):\n    def __init__(self, in_dimensions, out_dimensions):\n        super().__init__()\n        # YOUR CODE HERE\n        self.weights =\n        self.bias =\n\n    def forward(self, x):\n        return torch.matmul(x, self.weights) + self.bias\n\n# YOUR CODE HERE\nmodel =\nlr =\n\n# Test the model build and LinearKaiming\ntest_kaiming(LinearKaiming)\ntest_build(model, LinearKaiming, dropout_type=None, type='normal')\n\n# Run the model\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ8\n\ndef gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ9\nYOUR ANSWER HERE\n\n\n\n\n\nQ10\n\ndef gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\nmodel = # YOUR CODE HERE\nlr =\nlosses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ11\n\nfrom torch import optim\n\ndef gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n        losses.append(loss.detach().numpy()) # Track loss without L2 terms\n\n        l2_loss =\n        loss = loss + l1_weight * l2_loss\n        # CODE FOR GRAIDENT DESCENT STEP HERE\n\n        valid_loss =\n\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n# Test our function\ntest_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)\n\n\n\n\n\n\nQ12\n\nmodel = # YOUR CODE HERE\nlr =\nl1_weight =\nlosses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)\n\n\n\n\n\n\nQ13\n\nclass Dropout(nn.Module):\n    def __init__(self, rate=0.01):\n        # Rate specifies the dropout rate (r)\n        super().__init__()\n        self.rate = rate\n\n    def forward(self, x):\n        # YOUR CODE HERE\n        if self.training:\n\n        else:\n\n\n# Test our module\ntest_dropout(Dropout)\n\n\n\n\n\n\nQ14\n\nfrom torch import optim\n\ndef gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n    optimizer = # YOUR CODE HERE\n\n    losses = []\n    valid_losses = []\n    for _ in tqdm.trange(steps):\n        # YOUR CODE HERE\n        loss =\n\n        valid_loss =\n        losses.append(loss.detach().numpy())\n        valid_losses.append(valid_loss.detach().numpy())\n\n    return losses, valid_losses\n\n\n# YOUR CODE HERE\nmodel =\n\n# Test our model build\ntest_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n\nlr =\nlosses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\nplotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
  },
  {
    "objectID": "assignments/homeworks/Homework 9/solutions-MTCMFU.html",
    "href": "assignments/homeworks/Homework 9/solutions-MTCMFU.html",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "For this homework and for the final project, you may find it useful to run your code with access to a sufficient GPU, which may allow your code to run faster (we will talk about why later in the course). If you do not have access to a powerful GPU on your personal computer (e.g. if you primarily use a laptop), then there are 2 options you may consider for using a remotely hosted GPU.\nNote that some laptops may actually run this code faster than the course server, so you may want to try it first on your laptop regardless\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/3e574b9d225004ff1a179136c29ef4d5/raw/288949bfc3b768b7603fe4decafbcd589c9a72d5/hw9_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw9_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# This is the path that the dataset for this homework will be downloaded to.\n# If you are running on the course server or Colab you can keep this line, if you are\n# running on a personal computer, you may want to change this location.\nfrom hw9_support import *\ndata_path = '/tmp/data'\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nUsing 'cpu' device.\n\n\n\n\n\nWe have a GPU server available for this course that you all should have access to. (If you are not a Mudd student we may need to get you setup with a Mudd CS account). The server name is teapot.cs.hmc.edu.\nYou can login to the server via a terminal using your hmc username and password:\nssh &lt;USERNAME&gt;@teapot.ssh.hmc.edu\nThen run the command:\nsource /cs/cs152/venv/bin/activate\nto activate the course Python enviornment, followed by:\njupyter lab --no-browser\nto start a Jupyter server (if you want to keep a server running you can use tmux). At the end of the Jupyter startup output you should see a line like this:\n\n\n\nimage.png\n\n\nThis tells us the port and password we need to access the server remotely. In order to access the server we’ll start an ssh tunnel. Open a new terminal window and run the command:\nssh -L 9000:localhost:&lt;PORT&gt; &lt;USERNAME&gt;@teapot.cs.hmc.edu\nWhere &lt;PORT&gt; is the port output from JupyterLab above (8888 in the example image). 9000 is a local network port for your compute to access the server. If 9000 is in use, you can change the number to something different. Once the ssh tunnel is running you can access the notebook server by navigating to http://localhost:9000/lab in a web browser.\nYou can also setup VSCode to connect to this server. At the top right of the window click the kernel menu:\n\n\n\nimage.png\n\n\nYou should see the following popup:\n\n\n\nimage.png\n\n\nClick Select another kernel, then Existing Jupyter Server and paste the address from above:\n\n\n\nimage.png\n\n\nPaste the token from the Jupyter output when prompted for a password. If given multiple kernel options, select Python3. You should now be running the notebook code remotely!\n\n\n\nIf you are unable to get the course server to work, another option is to use Google’s Colab service which provides a simple way to run GPU-accelerated Jupyter notebooks on the web.\nTo start, go to: https://colab.research.google.com/\n\n\n\nimage.png\n\n\nOnce you open the notebook, you’ll want to add a GPU. To do this navigate to runtime-&gt;change runtime type in the top menu.\nIn the popup menu select T4 GPU and click save.\n\n\n\nimage.png\n\n\nNow you should be able to run the notebook! Once you’ve completed the assignment, you can download the notebook to submit it as usual."
  },
  {
    "objectID": "assignments/homeworks/Homework 9/solutions-MTCMFU.html#option-1-use-the-course-gpu-server",
    "href": "assignments/homeworks/Homework 9/solutions-MTCMFU.html#option-1-use-the-course-gpu-server",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "We have a GPU server available for this course that you all should have access to. (If you are not a Mudd student we may need to get you setup with a Mudd CS account). The server name is teapot.cs.hmc.edu.\nYou can login to the server via a terminal using your hmc username and password:\nssh &lt;USERNAME&gt;@teapot.ssh.hmc.edu\nThen run the command:\nsource /cs/cs152/venv/bin/activate\nto activate the course Python enviornment, followed by:\njupyter lab --no-browser\nto start a Jupyter server (if you want to keep a server running you can use tmux). At the end of the Jupyter startup output you should see a line like this:\n\n\n\nimage.png\n\n\nThis tells us the port and password we need to access the server remotely. In order to access the server we’ll start an ssh tunnel. Open a new terminal window and run the command:\nssh -L 9000:localhost:&lt;PORT&gt; &lt;USERNAME&gt;@teapot.cs.hmc.edu\nWhere &lt;PORT&gt; is the port output from JupyterLab above (8888 in the example image). 9000 is a local network port for your compute to access the server. If 9000 is in use, you can change the number to something different. Once the ssh tunnel is running you can access the notebook server by navigating to http://localhost:9000/lab in a web browser.\nYou can also setup VSCode to connect to this server. At the top right of the window click the kernel menu:\n\n\n\nimage.png\n\n\nYou should see the following popup:\n\n\n\nimage.png\n\n\nClick Select another kernel, then Existing Jupyter Server and paste the address from above:\n\n\n\nimage.png\n\n\nPaste the token from the Jupyter output when prompted for a password. If given multiple kernel options, select Python3. You should now be running the notebook code remotely!"
  },
  {
    "objectID": "assignments/homeworks/Homework 9/solutions-MTCMFU.html#option-2-google-colab",
    "href": "assignments/homeworks/Homework 9/solutions-MTCMFU.html#option-2-google-colab",
    "title": "Homework 9: Convolutional Neural Networks",
    "section": "",
    "text": "If you are unable to get the course server to work, another option is to use Google’s Colab service which provides a simple way to run GPU-accelerated Jupyter notebooks on the web.\nTo start, go to: https://colab.research.google.com/\n\n\n\nimage.png\n\n\nOnce you open the notebook, you’ll want to add a GPU. To do this navigate to runtime-&gt;change runtime type in the top menu.\nIn the popup menu select T4 GPU and click save.\n\n\n\nimage.png\n\n\nNow you should be able to run the notebook! Once you’ve completed the assignment, you can download the notebook to submit it as usual."
  },
  {
    "objectID": "assignments/homeworks/Homework 2/main.html",
    "href": "assignments/homeworks/Homework 2/main.html",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nIn this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/main.html#part-1-linear-regression",
    "href": "assignments/homeworks/Homework 2/main.html#part-1-linear-regression",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\nLet’s begin by reviewing the context of linear regression.\nRecall that the linear regression model makes predictions of the following form:\n\\[f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} + b\\]\nOr if we consdier the augmented representation:\n\\[\\mathbf{x} \\rightarrow \\begin{bmatrix}\\mathbf{x} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\\\ 1 \\end{bmatrix},\\quad \\mathbf{w} \\rightarrow \\begin{bmatrix}\\mathbf{w} \\\\ b \\end{bmatrix} = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_d \\\\ b \\end{bmatrix}\\] Then we can use the more convenient linear form: \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\]\n\nQ1 (5 points)\nWrite a function that takes in an input \\((\\mathbf{x})\\) and a set of weights \\((\\mathbf{w})\\) and makes a prediction using the function above. Your implementation should assume that the bias \\((b)\\) is included in the weights \\((\\mathbf{w})\\) and thus should augment the input to account for this (or separate \\(b\\) from \\(\\mathbf{w}\\)).\n\n# Test inputs\nx = np.array([1, -3, 5])\nw = np.array([-1, 2, 0.5, 2])\ny = -2.5\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## Validate the function\nassert y == linear_regression(x, w)\n\nAs discussed in class, we can compactly refer to an entire dataset of inputs and outputs using the notation \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) respectively. Our convention will be that row \\(i\\) of \\(\\mathbf{X}\\) will correspond to the \\(i^{th}\\) observed input \\(\\mathbf{x}_i\\), while the corresponding entry \\(y_i\\) of \\(\\mathbf{y}\\) is the observed output. In other words \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) are defined as: \\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}, \\quad\n                \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nWith this notation, we can make predictions for an entire set of inputs as: \\[f(\\mathbf{X}) = \\mathbf{X}\\mathbf{w}\\] Where the output is now a vector of predictions. We see that each entry corresponds to the prediction for input \\(\\mathbf{x}_i\\): \\[f(\\mathbf{X})_i = \\mathbf{x}_i^T\\mathbf{w} = f(\\mathbf{x}_i)\\]\n\n\nQ2 (10 points)\nModify (if needed) your linear regression prediction function to accept a set of inputs as a matrix as described above and return a vector of predictions. Once again you should not assume the data includes the extra bias dimension. Then plot the prediction function given by the provided weights on the range \\([0, 5]\\). Recall that np.linspace(a, b, n) produces a vector of n equally spaced numbers between a and b.\n\n# Test inputs\nw = np.array([0.5, 2])\n\ndef linear_regression(x, w):\n    ### YOUR CODE HERE\n    pass\n\n## CODE TO PLOT THE FUNCTION HERE\nX =\ny = linear_regression(X, w)\n\n\nRecall that ordinary least squares finds the parameter \\(\\mathbf{w}\\) that minimizes the mean of squared error between the true outputs \\(\\mathbf{y}\\) and predictions. \\[\\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2\\]\nObserve that this is the same formula as the error we used for evaluating Richardson iteration in the last homework, we’ve simply renamed the variables from \\((\\mathbf{A}, \\mathbf{x}, \\mathbf{b})\\) to \\((\\mathbf{X}, \\mathbf{w}, \\mathbf{y})\\)! (We’ve also added the constant \\(\\frac{1}{N}\\), but this doesn’t change the optimal \\(\\mathbf{w}\\))\nWe’ve now seen 3 equivalent ways to write the same formula. From most compact to least compact these are: \\[\\textbf{1: } \\frac{1}{N} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 \\quad \\textbf{2: } \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2 \\quad \\textbf{3: } \\frac{1}{N} \\sum_{i=1}^n \\left(\\sum_{j=1}^n X_{ij}w_j - y_i\\right)^2\\]\n\n\nQ3 (10 points)\nUsing the gradient formula we derived in class, write a function that returns both the mean squared error and the gradient of the error with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\). Hint: don’t forget to augment X when computing the gradient!\n\ndef mse_and_grad(w, X, y):\n    ### YOUR CODE HERE\n    return mse, grad_w\n\nRecall that we can use the gradient descent algorithm to find the input that minimizes a function, using the corresponding gradient function.\nGiven an initial guess of the optimal input, \\(\\mathbf{w}^{(0)}\\), gradient descent uses the following update to improve the guess: \\[\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}),\\] where \\(\\alpha\\) is the learning rate or step size.\n\n\nQ4 (10 points)\nWrite a function to perform gradient descent. The function should take as input: - value_and_grad: A function that produces the output and gradient of the function to optimize (e.g. the mse_and_grad) - w0: An inital guess \\(\\mathbf{w}^{(0)}\\) - lr: The learning rate \\((\\alpha)\\) - niter: The number of updates to perform - *args: Any additional argumets to pass to value_and_grad (e.g. X and y)\nThe function should return: - w: The final guess - losses: A list (or array) that tracks the value of the function at each update\n\ndef gradient_descent(value_and_grad, w0, lr, niter, *args):\n    # Get the inital loss\n    initial_loss, _ = value_and_grad(w0, *args)\n    losses = []\n\n    ### YOUR CODE HERE\n\n    return w, losses"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/main.html#part-2-applications-to-real-data",
    "href": "assignments/homeworks/Homework 2/main.html#part-2-applications-to-real-data",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 2: Applications to real data",
    "text": "Part 2: Applications to real data\nNow that we’ve setup a full implementation of linear regression, let’s test it on a real dataset. We’ll use the MPG dataset that we saw in class. The following code will load the data and rescale it.\n\ndata = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n# Uncomment if on Colab!\n# import urllib.request\n# link = 'https://gist.githubusercontent.com/gabehope/4df286bbd9a672ce7731d52afe3ca07e/raw/65026711d71affaafb9713ddf5b6ef29125ba0fb/auto.csv'\n# data = np.genfromtxt(urllib.request.urlopen(link), delimiter=',', missing_values=['?'], filling_values=[0])\n\n# MPG is the output value\ntarget = 'MPG'\ny = data[:, 0]\n\n# The other variables are inputs in the order listed\nfeatures = ['displacement', 'weight', 'acceleration', 'year']\nX = data[:, [2, 4, 5, 6]]\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\nLet’s start by fitting a model that just uses the feature weight.\n\nQ5 (5 points)\nUse the gradient_descent and mse_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 0.1. Plot the loss (MSE) as a function of the number of updates.\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw, losses =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\nQ6 (5 points)\nPlot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\).\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\nQ7 (5 points)\nRepeat Q5 using all 4 features and compare the final loss to the final loss using only weight as an input. Describe any differences you observe.\n\nw0 = np.zeros((5,))\n\n### YOUR CODE HERE\nw, losses =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nDESCRIBE RESULTS HERE\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\n\n\nQ8 (5 points)\nSplit the MPG dataset into training and test datasets. Use 70% of the observations for training and 30% for test. Then repeat Q5 to fit a linear regression model on just the training dataset using only the weight feature (you don’t need to plot the loss for this question). Report the final loss (MSE) on the training dataset and on the test dataset.\n\n### CODE TO SPLIT DATASET HERE\nXweight_train =\ny_train =\n\nXweight_test =\ny_test =\n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((2,))\nw, losses =\n\n### CODE TO EVALUATE MODEL HERE\nmse_train =\nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\n\n\nQ9 (5 points)\nRepeat Q8 using the all 4 features. Compare the results to the model using only weight.\n\n### CODE TO SPLIT DATASET HERE\nX_train =\ny_train =\n\nX_test =\ny_test =\n\n### CODE TO FIT MODEL HERE\nw0 = np.zeros((5,))\nw, losses =\n\n### CODE TO EVALUATE MODEL HERE\nmse_train =\nmse_test =\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nDESCRIBE RESULTS HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/main.html#part-3-maximum-likelihood-training",
    "href": "assignments/homeworks/Homework 2/main.html#part-3-maximum-likelihood-training",
    "title": "Homework 2: Linear regression and maximum likelihood",
    "section": "Part 3: Maximum Likelihood Training",
    "text": "Part 3: Maximum Likelihood Training\n\nBackground:\nWe saw in lecture that we can view linear regression as the following probibalistic model: \\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\] Where \\(\\mathcal{N}(\\mu, \\sigma)\\) is the Normal distribution, which has the following probability density function: \\[\np(y\\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\] We saw that a reasonable way to choose the optimal \\(\\mathbf{w}\\) is to maximize the likelihood of our observed dataset, which is equivalent to minimizing the negative log likelihood: \\[\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) =\n\\underset{\\mathbf{w}}{\\text{argmin}} -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\frac{1}{2\\sigma^2}\\sum_{i=1}^N  (y_i -\\mathbf{x}_i^T\\mathbf{w})^2 + C\n\\] Where \\(C\\) is a constant: \\(C = N \\log \\sigma \\sqrt{2\\pi}\\). We further saw that this is equivalent to minimizing the mean squared error for any choice of \\(\\sigma\\).\n\n\nLaplace Maximum Likelihood Estimation\nA natural question about the above model is: why choose the Normal distribution? In principal, we could define a linear model using any distribution over the real numbers \\(\\mathbb{R}\\). Let’s explore an alternative choice: the Laplace distribution (Wiki). The Laplace distribution \\(L(\\mu, a)\\) has the following PDF:\n\\[p(y\\mid \\mu, a) = \\frac{1}{2a} \\exp\\bigg(- \\frac{|y-\\mu|}{a} \\bigg) \\]\nAs for the normal distribution \\(\\mu\\) is the mean, while \\(a\\) defines the “width” of the distribution (analogous to variance for the Normal). We can compare the two distributions visually:\n\nylp = np.linspace(-3, 3, 200)\nmu, sigma2_or_a = 0, 1\np_y_normal = (1 / np.sqrt(sigma2_or_a * 2 * np.pi)) * np.exp(- (0.5 / sigma2_or_a) * (ylp - mu) ** 2)\np_y_laplace = (1 / (2 * sigma2_or_a)) * np.exp(- (1 / sigma2_or_a) * np.abs(ylp - mu))\n\nplt.figure(figsize=(4,3))\nplt.plot(ylp, p_y_normal, label=r\"Normal PDF\")\nplt.plot(ylp, p_y_laplace, label=r\"Laplace PDF\")\nplt.xlabel('$y$')\nplt.ylabel('$p(y)$')\nplt.legend()\npass\n\n\n\n\n\n\n\n\nLet’s now consider the Laplace version of our probabilistic linear model: \\[\ny_i \\sim L\\big(\\mathbf{x}_i^T \\mathbf{w},\\ a\\big)\n\\] Recall that the negative log-likelihood is defined as: \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, a)\\]\n\nQ10 (5 points)\nWrite out the negative log-likelihood for this model in terms of \\(\\mathbf{w}, a, \\mathbf{X}, y\\) using the Laplace PDF shown above.\nYOUR ANSWER HERE \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = \\]\nNote that if we drop the constants, we would call this loss the sum absolute error.\n\n\nQ11 (10 points)\nFind the gradient with respect to \\(\\mathbf{w}\\) of the negative log-likelihood for this model. Hint: remember that the gradient is the vector of partial derivatives!\nYou should use the following definition of the derivative of the absolute value \\(|\\cdot |\\) operator: \\[\\frac{d}{dx}|x| = sign(x), \\quad sign(x) = \\begin{cases} +1 \\quad \\text{ if  } x &gt; 0 \\\\ -1 \\quad \\text{ if  } x &lt; 0 \\\\ \\ \\ \\ 0 \\quad \\text{ if  } x = 0 \\end{cases}\\] (Technically \\(\\frac{d}{dx}|x|\\) is undefined at \\(x=0\\), but it is convinient to assume \\(\\frac{d}{dx}|0|=0\\) in practice.)\nYOUR ANSWER HERE \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) = \\]\n\n\nQ12 (5 points)\nUsing the formula you just derived, write a function that returns both the negative log-likelihood and the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) (assume that \\(a=1\\)). We’ll divide both outputs by \\(N\\) to make our results more comparable to MSE. Hint: np.sign will compute the sign function descibed above.\n\ndef nll_and_grad(w, X, y):\n    N = X.shape[0]\n    ### YOUR CODE HERE\n\n\n    return nll / N, grad_w / N\n\n\n\nQ13 (5 points)\nUse the gradient_descent and nll_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 1.0. Plot the loss (NLL) as a function of the number of updates. Use the full dataset as in Q5 and note the change in learning rate!\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n### YOUR CODE HERE\nw_laplace, losses_laplace =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\n\n\nQ14 (5 points)\nPlot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\). Finally, copy your code from Q5 to once again find the optimal \\(\\mathbf{w}\\) using the MSE loss and plot this function on the same plot in a different color. Describe any differences you see between the two models\n\n### CODE FROM Q5 HERE\nw_mse, losses_mse =\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\n\nWRITTEN ANSWER HERE\n\n\nQ15 (10 points)\nUsing the parameters that you just found, plot the Laplace NLL loss as a function of the first entry in w (w1 below), holding the other (the bias) constant. Plot this loss on the range \\([-10, 0]\\). Then, in a separate cell, plot the MSE loss as a function of the first entry in w on the same range.\n\n# Example of deconstructing and reconstructing the parameter vector.\nw1, b = w\nwi = np.array([w1, b])\n\n### PLOTTING CODE FOR NLL HERE\nplt.figure(figsize=(6, 4))\n\n\n### PLOTTING CODE FOR MSE HERE\nplt.figure(figsize=(6, 4))\n\nIn the cells below, copy your code for Q5 and Q13. Try out different learning rates and and numbers of iterations. Observe what happens to the loss plot in each case.\n\n### COPY Q5 CODE HERE\n\n\n### COPY Q13 CODE HERE\n\nBased on what you’ve obsevered above and in the previous questions, why might you choose the Normal distribution or the Laplace distribution for linear regression? What effect does the learning rate have (what happens if it’s set too high or too low)?\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/solutions-QXP5GA.html",
    "href": "assignments/homeworks/Homework 2/solutions-QXP5GA.html",
    "title": "Homework 2: Linear regression and maximum likelihood (solutions)",
    "section": "",
    "text": "# Run me first!\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nIn this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-1-linear-regression",
    "href": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-1-linear-regression",
    "title": "Homework 2: Linear regression and maximum likelihood (solutions)",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\nLet’s begin by reviewing the context of linear regression.\nRecall that the linear regression model makes predictions of the following form:\n\\[f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} + b\\]\nOr if we consdier the augmented representation:\n\\[\\mathbf{x} \\rightarrow \\begin{bmatrix}\\mathbf{x} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\\\ 1 \\end{bmatrix},\\quad \\mathbf{w} \\rightarrow \\begin{bmatrix}\\mathbf{w} \\\\ b \\end{bmatrix} = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_d \\\\ b \\end{bmatrix}\\] Then we can use the more convenient linear form: \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\]\n\nQ1\nWrite a function that takes in an input \\((\\mathbf{x})\\) and a set of weights \\((\\mathbf{w})\\) and makes a prediction using the function above. Your implementation should assume that the bias \\((b)\\) is included in the weights \\((\\mathbf{w})\\) and thus should augment the input to account for this (or separate \\(b\\) from \\(\\mathbf{w}\\)).\n\n\nAnswer\n\n# Test inputs\nx = np.array([1, -3, 5])\nw = np.array([-1, 2, 0.5, 2])\ny = -2.5\n\ndef linear_regression(x, w):\n    x = np.pad(x, ((0, 1)), constant_values=1)\n    return np.dot(x, w)\n\n## Validate the function\nassert y == linear_regression(x, w)\n\nAs discussed in class, we can compactly refer to an entire dataset of inputs and outputs using the notation \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) respectively. Our convention will be that row \\(i\\) of \\(\\mathbf{X}\\) will correspond to the \\(i^{th}\\) observed input \\(\\mathbf{x}_i\\), while the corresponding entry \\(y_i\\) of \\(\\mathbf{y}\\) is the observed output. In other words \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) are defined as: \\[\n\\mathbf{X} =\n\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}, \\quad\n                \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n\\]\nWith this notation, we can make predictions for an entire set of inputs as: \\[f(\\mathbf{X}) = \\mathbf{X}\\mathbf{w}\\] Where the output is now a vector of predictions. We see that each entry corresponds to the prediction for input \\(\\mathbf{x}_i\\): \\[f(\\mathbf{X})_i = \\mathbf{x}_i^T\\mathbf{w} = f(\\mathbf{x}_i)\\]\n\n\nQ2\nModify (if needed) your linear regression prediction function to accept a set of inputs as a matrix as described above and return a vector of predictions. Once again you should not assume the data includes the extra bias dimension. Then plot the prediction function given by the provided weights on the range \\([0, 5]\\). Recall that np.linspace(a, b, n) produces a vector of n equally spaced numbers between a and b.\n\n\nAnswer\n\n# Test inputs\nw = np.array([0.5, 2])\n\ndef linear_regression(x, w):\n    # Account for the extra dimension in pad\n    x = np.pad(x, ((0, 0), (0, 1)), constant_values=1)\n    return np.dot(x, w)\n\nX = np.linspace(0, 5, 200).reshape((-1, 1))\ny = linear_regression(X, w)\nplt.plot(X.flatten(), y)\n\n\n\n\n\n\n\n\nRecall that ordinary least squares finds the parameter \\(\\mathbf{w}\\) that minimizes the mean of squared error between the true outputs \\(\\mathbf{y}\\) and predictions. \\[\\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2\\]\nObserve that this is the same formula as the error we used for evaluating Richardson iteration in the last homework, we’ve simply renamed the variables from \\((\\mathbf{A}, \\mathbf{x}, \\mathbf{b})\\) to \\((\\mathbf{X}, \\mathbf{w}, \\mathbf{y})\\)! (We’ve also added the constant \\(\\frac{1}{N}\\), but this doesn’t change the optimal \\(\\mathbf{w}\\))\nWe’ve now seen 3 equivalent ways to write the same formula. From most compact to least compact these are: \\[\\textbf{1: } \\frac{1}{N} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 \\quad \\textbf{2: } \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2 \\quad \\textbf{3: } \\frac{1}{N} \\sum_{i=1}^n \\left(\\sum_{j=1}^n X_{ij}w_j - y_i\\right)^2\\]\n\n\nQ3\nUsing the gradient formula we derived in class, write a function that returns both the mean squared error and the gradient of the error with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\). Hint: don’t forget to augment X when computing the gradient!\n\n\nAnswer\n\ndef mse_and_grad(w, X, y):\n    error = linear_regression(X, w) - y\n    mse = np.mean(error ** 2)\n    grad_w = 2 * np.dot(error, np.pad(X, [(0,0), (0,1)], constant_values=1)) / X.shape[0]\n    return mse, grad_w\n\nRecall that we can use the gradient descent algorithm to find the input that minimizes a function, using the corresponding gradient function.\nGiven an initial guess of the optimal input, \\(\\mathbf{w}^{(0)}\\), gradient descent uses the following update to improve the guess: \\[\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}),\\] where \\(\\alpha\\) is the learning rate or step size.\n\n\nQ4\nWrite a function to perform gradient descent. The function should take as input: - value_and_grad: A function that produces the output and gradient of the function to optimize (e.g. the mse_and_grad) - w0: An inital guess \\(\\mathbf{w}^{(0)}\\) - lr: The learning rate \\((\\alpha)\\) - niter: The number of updates to perform - *args: Any additional argumets to pass to value_and_grad (e.g. X and y)\nThe function should return: - w: The final guess - losses: A list (or array) that tracks the value of the function at each update\n\n\nAnswer\n\ndef gradient_descent(value_and_grad, w0, lr, niter, *args):\n    # Get the inital loss\n    initial_loss, grad = value_and_grad(w0, *args)\n    losses = [initial_loss]\n    w = w0\n\n    for i in range(niter):\n        w = w - lr * grad\n        loss, grad = value_and_grad(w, *args)\n        losses.append(loss)\n    return w, losses"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-2-applications-to-real-data",
    "href": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-2-applications-to-real-data",
    "title": "Homework 2: Linear regression and maximum likelihood (solutions)",
    "section": "Part 2: Applications to real data",
    "text": "Part 2: Applications to real data\nNow that we’ve setup a full implementation of linear regression, let’s test it on a real dataset. We’ll use the MPG dataset that we saw in class. The following code will load the data and rescale it.\n\ndata = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n# Uncomment if on Colab!\n# import urllib.request\n# link = 'https://gist.githubusercontent.com/gabehope/4df286bbd9a672ce7731d52afe3ca07e/raw/65026711d71affaafb9713ddf5b6ef29125ba0fb/auto.csv'\n# data = np.genfromtxt(urllib.request.urlopen(link), delimiter=',', missing_values=['?'], filling_values=[0])\n\n# MPG is the output value\ntarget = 'MPG'\ny = data[:, 0]\n\n# The other variables are inputs in the order listed\nfeatures = ['displacement', 'weight', 'acceleration', 'year']\nX = data[:, [2, 4, 5, 6]]\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\nLet’s start by fitting a model that just uses the feature weight.\n\nQ5\nUse the gradient_descent and mse_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 0.1. Plot the loss (MSE) as a function of the number of updates.\n\n\nAnswer\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n\n(w, losses) = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight, y)\n\n### PLOTTING CODE HERE\nplt.figure(figsize=(6, 4))\nplt.plot(losses)\nprint(losses[-1])\n\n18.780939855850434\n\n\n\n\n\n\n\n\n\n\n\nQ6\nPlot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\).\n\n\nAnswer\n\nplt.figure(figsize=(8, 6))\nplt.scatter(Xweight.flatten(), y)\n\nx = np.linspace(-3, 3, 100).reshape((-1, 1))\nplt.plot(x.flatten(), linear_regression(x, w), c='r')\n\n\n\n\n\n\n\n\n\n\nQ7\nRepeat Q5 using all 4 features and compare the final loss to the final loss using only weight as an input. Describe any differences you observe.\n\n\nAnswer\n\nw0 = np.zeros((5,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, X, y)\n\nplt.figure(figsize=(6, 4))\nplt.plot(losses)\nprint(losses[-1])\n\n12.01314055689771\n\n\n\n\n\n\n\n\n\nWe see that in both cases the loss converges very quickly, but with 5 features, the final loss is significantly smaller (12 vs 18)\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\n\n\nQ8\nSplit the MPG dataset into training and test datasets. Use 70% of the observations for training and 30% for test. Then repeat Q5 to fit a linear regression model on just the training dataset using only the weight feature (you don’t need to plot the loss for this question). Report the final loss (MSE) on the training dataset and on the test dataset.\n\n\nAnswer\n\nXweight_train = Xweight[:int(X.shape[0] * .7)]\ny_train = y[:int(X.shape[0] * .7)]\n\nXweight_test = Xweight[int(X.shape[0] * .7):]\ny_test = y[int(X.shape[0] * .7):]\n\nw0 = np.zeros((2,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight_train, y_train)\n\nmse_train, _ = mse_and_grad(w, Xweight_train, y_train)\nmse_test, _ = mse_and_grad(w, Xweight_test, y_test)\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nLoss on training data: 8.4172, loss on test data: 60.1368\n\n\n\n\nQ9\nRepeat Q8 using the all 4 features. Compare the results to the model using only weight.\n\n\nAnswer\n\nX_train = X[:int(X.shape[0] * .7)]\ny_train = y[:int(X.shape[0] * .7)]\n\nX_test = X[int(X.shape[0] * .7):]\ny_test = y[int(X.shape[0] * .7):]\n\nw0 = np.zeros((5,))\nw, losses = gradient_descent(mse_and_grad, w0, 0.1, 50, X_train, y_train)\n\nmse_train, _ = mse_and_grad(w, X_train, y_train)\nmse_test, _ = mse_and_grad(w, X_test, y_test)\n\nprint('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))\n\nLoss on training data: 7.5947, loss on test data: 43.7603\n\n\nWe see that with all 5 features, both the training and the test loss are lower than with only weight!"
  },
  {
    "objectID": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-3-maximum-likelihood-training",
    "href": "assignments/homeworks/Homework 2/solutions-QXP5GA.html#part-3-maximum-likelihood-training",
    "title": "Homework 2: Linear regression and maximum likelihood (solutions)",
    "section": "Part 3: Maximum Likelihood Training",
    "text": "Part 3: Maximum Likelihood Training\n\nBackground:\nWe saw in lecture that we can view linear regression as the following probibalistic model: \\[\ny_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n\\] Where \\(\\mathcal{N}(\\mu, \\sigma)\\) is the Normal distribution, which has the following probability density function: \\[\np(y\\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n\\] We saw that a reasonable way to choose the optimal \\(\\mathbf{w}\\) is to maximize the likelihood of our observed dataset, which is equivalent to minimizing the negative log likelihood: \\[\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) =\n\\underset{\\mathbf{w}}{\\text{argmin}} -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\frac{1}{2\\sigma^2}\\sum_{i=1}^N  (y_i -\\mathbf{x}_i^T\\mathbf{w})^2 + C\n\\] Where \\(C\\) is a constant: \\(C = N \\log \\sigma \\sqrt{2\\pi}\\). We further saw that this is equivalent to minimizing the mean squared error for any choice of \\(\\sigma\\).\n\n\nLaplace Maximum Likelihood Estimation\nA natural question about the above model is: why choose the Normal distribution? In principal, we could define a linear model using any distribution over the real numbers \\(\\mathbb{R}\\). Let’s explore an alternative choice: the Laplace distribution (Wiki). The Laplace distribution \\(L(\\mu, a)\\) has the following PDF:\n\\[p(y\\mid \\mu, a) = \\frac{1}{2a} \\exp\\bigg(- \\frac{|y-\\mu|}{a} \\bigg) \\]\nAs for the normal distribution \\(\\mu\\) is the mean, while \\(a\\) defines the “width” of the distribution (analogous to variance for the Normal). We can compare the two distributions visually:\n\nylp = np.linspace(-3, 3, 200)\nmu, sigma2_or_a = 0, 1\np_y_normal = (1 / np.sqrt(sigma2_or_a * 2 * np.pi)) * np.exp(- (0.5 / sigma2_or_a) * (ylp - mu) ** 2)\np_y_laplace = (1 / (2 * sigma2_or_a)) * np.exp(- (1 / sigma2_or_a) * np.abs(ylp - mu))\n\nplt.figure(figsize=(4,3))\nplt.plot(ylp, p_y_normal, label=r\"Normal PDF\")\nplt.plot(ylp, p_y_laplace, label=r\"Laplace PDF\")\nplt.xlabel('$y$')\nplt.ylabel('$p(y)$')\nplt.legend()\npass\n\n\n\n\n\n\n\n\nLet’s now consider the Laplace version of our probabilistic linear model: \\[\ny_i \\sim L\\big(\\mathbf{x}_i^T \\mathbf{w},\\ a\\big)\n\\] Recall that the negative log-likelihood is defined as: \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, a)\\]\n\nQ10\nWrite out the negative log-likelihood for this model in terms of \\(\\mathbf{w}, a, \\mathbf{X}, y\\) using the Laplace PDF shown above.\n\n\nAnswer\nWe can simply replace \\(p(y_i|\\mathbf{x}_i, a)\\) with the formula given above so we get: \\[\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log \\frac{1}{2a} \\exp \\bigg(-\\frac{|y_i-\\mathbf{x}_i^T\\mathbf{w}|}{a}\\bigg)\\]\n\\[ = \\frac{1}{a}\\sum_{i=1}^N |y_i-\\mathbf{x}_i^T\\mathbf{w}| + N\\log 2a\\]\nNote that if we drop the constants, we would call this loss the sum absolute error.\n\n\nQ11\nFind the gradient with respect to \\(\\mathbf{w}\\) of the negative log-likelihood for this model. Hint: remember that the gradient is the vector of partial derivatives!\nYou should use the following definition of the derivative of the absolute value \\(|\\cdot |\\) operator: \\[\\frac{d}{dx}|x| = sign(x), \\quad sign(x) = \\begin{cases} +1 \\quad \\text{ if  } x &gt; 0 \\\\ -1 \\quad \\text{ if  } x &lt; 0 \\\\ \\ \\ \\ 0 \\quad \\text{ if  } x = 0 \\end{cases}\\] (Technically \\(\\frac{d}{dx}|x|\\) is undefined at \\(x=0\\), but it is convinient to assume \\(\\frac{d}{dx}|0|=0\\) in practice.)\n\n\nAnswer\n\\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) =  \\frac{d}{d\\mathbf{w}} \\frac{1}{a}\\sum_{i=1}^N |y_i-\\mathbf{x}_i^T\\mathbf{w}| + N\\log 2a\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N \\frac{d}{d\\mathbf{w}}|y_i-\\mathbf{x}_i^T\\mathbf{w}|\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N sign(y_i-\\mathbf{x}_i^T\\mathbf{w})\\frac{d}{d\\mathbf{w}}(y_i-\\mathbf{x}_i^T\\mathbf{w})\\]\n\\[=   \\frac{1}{a}\\sum_{i=1}^N sign(y_i-\\mathbf{x}_i^T\\mathbf{w})\\mathbf{x}_i\\]\n\n\nQ12\nUsing the formula you just derived, write a function that returns both the negative log-likelihood and the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}\\), given \\(\\mathbf{w}\\), \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) (assume that \\(a=1\\)). We’ll divide both outputs by \\(N\\) to make our results more comparable to MSE. Hint: np.sign will compute the sign function descibed above.\n\n\nAnswer\n\ndef nll_and_grad(w, X, y):\n    N = X.shape[0]\n    error = linear_regression(X, w) - y\n    mae = np.sum(np.abs(error))\n    nll = mae + np.log(2) \n    Xaug = np.pad(X, [(0, 0), (0, 1)], constant_values=1)\n    \n    grad_w = np.dot(np.sign(error), Xaug)\n    return nll / N, grad_w / N\n\n\n\nQ13\nUse the gradient_descent and nll_and_grad functions you wrote above to fit a linear regression model that takes in a car’s weight and predicts its MPG rating. Start with the weights equal to 0 and perform 100 updates of gradient descent with a learning rate of 1.0. Plot the loss (NLL) as a function of the number of updates. Use the full dataset as in Q5 and note the change in learning rate!\n\n\nAnswer\n\ny.shape\n\n(398,)\n\n\n\nXweight = X[:, 1:2]\nw0 = np.zeros(2,)\n\nw, losses = gradient_descent(nll_and_grad, w0, 0.1, 500, Xweight, y)\nwmse, mselosses = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight, y)\n\nplt.figure(figsize=(6, 4))\nplt.plot(losses, label='Laplace NLL')\nplt.plot(mselosses, label='Mean squared error')\nplt.legend()\nprint(losses[-1])\n\n3.262693397826824\n\n\n\n\n\n\n\n\n\n\n\nQ14\nPlot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range \\([-3, 3]\\). Finally, copy your code from Q5 to once again find the optimal \\(\\mathbf{w}\\) using the MSE loss and plot this function on the same plot in a different color. Describe any differences you see between the two models\n\n\nAnswer\n\nplt.figure(figsize=(6, 4))\nplt.scatter(Xweight[:,0], y)\nplt.plot(np.linspace(-3, 3, 200), linear_regression(np.linspace(-3, 3, 200).reshape((-1, 1)), w), label='Laplace NLL weights')\n\nXweight = X[:, 1:2]\nw0 = np.zeros((2,))\n(w, losses) = gradient_descent(mse_and_grad, w0, 0.1, 50, Xweight, y)\nplt.plot(np.linspace(-3, 3, 200), linear_regression(np.linspace(-3, 3, 200).reshape((-1, 1)), wmse), label='MSE weights')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nQ15\nUsing the parameters that you just found, plot the Laplace NLL loss as a function of the first entry in w (w1 below), holding the other (the bias) constant. Plot this loss on the range \\([-10, 0]\\). Then, in a separate cell, plot the MSE loss as a function of the first entry in w on the same range.\n\n\nAnswer\n\n# Example of deconstructing and reconstructing the parameter vector.\nw1, b = w\nwi = np.array([w1, b])\n\nlosses = [nll_and_grad(np.array([wi, b]), Xweight, y)[0] for wi in np.linspace(-10, 0)]\nmse_losses = [mse_and_grad(np.array([wi, b]), Xweight, y)[0] for wi in np.linspace(-10, 0)]\n\nplt.figure(figsize=(6, 4))\nplt.plot(mse_losses, label='Mean squared error')\nplt.plot(losses, label='Laplace NLL')\n\nplt.legend()\nplt.ylabel('$w_1$')\nplt.xlabel('Loss')\n\nText(0.5, 0, 'Loss')\n\n\n\n\n\n\n\n\n\nBased on what you’ve obsevered above and in the previous questions, why might you choose the Normal distribution or the Laplace distribution for linear regression? What effect does the learning rate have (what happens if it’s set too high or too low)?\n\n\nAnswer\nWe see that the MSE weights are more sensitive to outliers than the Laplace NLL weights."
  },
  {
    "objectID": "assignments/homeworks/Homework 5/solutions-CCLQOR.html",
    "href": "assignments/homeworks/Homework 5/solutions-CCLQOR.html",
    "title": "Homework 5: Automatic Differentiation",
    "section": "",
    "text": "In this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#overview",
    "href": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#overview",
    "title": "Homework 5: Automatic Differentiation",
    "section": "",
    "text": "In this homework we will build a tiny reverse-mode automatic differentiation library!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/d3e6b10338a1ba78f53204fc7502eda5/raw/52631870b1475b5ef8d9701f1c676fa97bf7b300/hw5_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw5_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n# Run me first!\nfrom hw5_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-1-forward-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-1-forward-mode-automatic-differentiation",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 1: Forward-mode automatic differentiation",
    "text": "Part 1: Forward-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses forward-mode automatic differentiation.\nRecall that for this version of automatic differentiaion each operation needs to keep track of the derivative of it’s value with respect each original input. Since for every operation we need to store these extra pieces of data and functions for computing both the operation and its derivative, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties: - value: The value of the operation (c) - forward_grads: A dictionary that contains the derivatives with respect to each original input (e.g. (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))). - func: A function that computes the operation (a+b) - grads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\nFor this homework, we’ve provided the outline of such a class, called ForwardValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using ForwardValue.\na = ForwardValue(5)\nb = ForwardValue(2)\nThen we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new ForwardValue object representing the result of that operation.\nAs each result should maintain the derivatives with respect to each original inputs, we can access the final derivatives we’re interested (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)) in from L.\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = L.forward_grads[a] # Will work because a is an ForwardValue\ndL_ds = L.forward_grads[s] # Will give an error because s is not an ForwardValue\nNow that we’ve seen what our final product will look like, let’s define our ForwardValue class.\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. Represents variable delcaration.\n    Subclasses will overwrite func and grads to define new operations.\n\n    Properties:\n        parents (list): A list of the inputs to the operation, may be AutogradValue or float\n        parent_values    (list): A list of raw values of each input (as floats)\n        forward_grads (dict): A dictionary mapping inputs to gradients\n        grad    (float): The derivative of the final loss with respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.parent_values = [arg.value if isinstance(arg, AutogradValue) else arg for arg in args]\n        self.forward_grads = {}\n        self.value = self.forward_pass()\n        self.grad = 0. # Used later for reverse mode\n\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\n    def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation\n        return self.func(*self.parent_values)\n\n    def __repr__(self):\n        # Python magic function for string representation.\n        return str(self.value)\n\nclass ForwardValue(AutogradValue):\n    '''\n    Subclass for forward-mode automatic differentiation. Initialized the forward_grads\n    dict to include this value.\n    '''\n\n    def __init__(self, *args):\n        super().__init__(*args)\n        if len(self.forward_grads.keys()) == 0:\n            self.forward_grads = {self: 1}\n\nNote that in the base case, when we declare a variable the derivative with respect to itself is just 1 (\\(\\frac{da}{da}=1\\))\nda_da = a.forward_grads[a] # Will be 1\nNow that we’ve defined the framework for an operation that can be used in automatic differentiation, we need to define some actual useful operations by subclassing ForwardValue\n\nQ1: Defining operations\nFill out the func and grads methods of each subclass below. Recall that func should always return the result of the operation and grads should always return a tuple of the derivative with respect to each input.\nHint: Look at the _add and _neg examples as a template!\n\n\nAnswer\n\nclass _add(AutogradValue):\n    def func(self, a, b):\n        return a + b\n    \n    def grads(self, a, b):\n        return 1., 1.\n\nclass _sub(AutogradValue):\n    def func(self, a, b):\n        return a - b\n    \n    def grads(self, a, b):\n        return 1., -1.\n\nclass _neg(AutogradValue):\n    def func(self, a):\n        return -a\n    \n    def grads(self, a):\n        return (-1.,)\n    \nclass _mul(AutogradValue):\n    def func(self, a, b):\n        return a * b\n    \n    def grads(self, a, b):\n        return b, a\n\nclass _div(AutogradValue):\n    def func(self, a, b):\n        return a / b\n    \n    def grads(self, a, b):\n        return 1 / b, -a / (b * b)\n    \nclass _exp(AutogradValue):\n    def func(self, a):\n        return math.exp(a)\n    \n    def grads(self, a):\n        return (math.exp(a),)\n\nclass _log(AutogradValue):\n    def func(self, a):\n        return math.log(a)\n    \n    def grads(self, a):\n        return (1 / a,)\n\nBelow, we’ll define our basic functions and operators in terms of the operator classes we just wrote.\n\ndef exp(a):\n    return _exp(a) if isinstance(a, AutogradValue) else math.exp(a)\ndef log(a):\n    return _log(a) if isinstance(a, AutogradValue) else math.log(a)\n\n# Note: Remember that above we defined a class for each type of operation\n# so in this code we are overriding the basic operators for AutogradValue\n# such that they construct a new object of the class corresponding to the\n# given operation and return it.\n# (You don't need to everything that's happening here to do the HW)\nAutogradValue.exp = lambda a: _exp(a)\nAutogradValue.log = lambda a: _log(a)\nAutogradValue.__add__ = lambda a, b: _add(a, b)\nAutogradValue.__radd__ = lambda a, b: _add(b, a)\nAutogradValue.__sub__ = lambda a, b: _sub(a, b)\nAutogradValue.__rsub__ = lambda a, b: _sub(b, a)\nAutogradValue.__neg__ = lambda a: _neg(a)\nAutogradValue.__mul__ = lambda a, b: _mul(a, b)\nAutogradValue.__rmul__ = lambda a, b: _mul(b, a)\nAutogradValue.__truediv__ = lambda a, b: _div(a, b)\nAutogradValue.__rtruediv__ = lambda a, b: _div(b, a)\n\nWe should now be able to use our ForwardValue objects as if they are numbers!\n\na = ForwardValue(5)\nb = ForwardValue(2)\n\nprint((a + 5) * b)\nprint(log(b))\n\ntest_operators(ForwardValue)\n\n20\n0.6931471805599453\nPassed!\n\n\nWe see now that our forward_pass method needs to update forward_grads (e.g. to compute \\(\\frac{dg}{da}\\) and \\(\\frac{dg}{db}\\)) using the forward_grads values of its parents (e.g. \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\nQ2: Defining forward-mode autodiff\nUpdate the forward_pass method below for forward-mode automatic differentiation. This method should update the forward_grads property of the operation such that: - forward_grads has an entry for every input that appears in forward_grads of any parent operation. - If an input appears in more than 1 parent, make sure to add the gradients appropritately (if g has parents b and c then \\(\\frac{dg}{da} = \\frac{dg}{db}\\frac{db}{da} + \\frac{dg}{dc}\\frac{dc}{da}\\) ) - Parents that are not AutogradValue objects are ignored\nIf our forward_pass method is working correctly, we should have the following behaivior:\n\n# Define our inputs as ForwardValue objects\na = ForwardValue(5)\nb = ForwardValue(2)\n\n# Perform operations\nc = a * b\ng = 3 * c + a\n\n\n# We should have the following in the forward_grads property of c and d (note that the keys are ForwardValue objects!)\nc.forward_grads = {a: 2, b: 5}  # dc/da and dc/db\ng.forward_grads = {a: 3 * 2 + 1, b: 3 * 5} # dg/da = dg/dc dc/da + dg/da, dg/db = dg/dc dc/db\n\nImplement the method below\n\ndef forward_pass(self):\n    self.forward_grads = {}\n    grads = self.grads(*self.parent_values)\n                \n    # Again iterate through pairs of parent, local derivative\n    for node, grad  in zip(self.parents, grads):\n        # Check if the parent has a forward_grads property\n        if hasattr(node, 'forward_grads'):\n            # Iterate through all inputs in the parents forward_grad dict. \n            # Add it to our forward_grads if we haven't yet and update it\n            for key, value in node.forward_grads.items():\n                if key not in self.forward_grads:\n                    self.forward_grads[key] = 0\n                self.forward_grads[key] += value * grad\n                \n    # Make sure to still return the operation's value\n    return self.func(*self.parent_values)\n\n# Overwrite the AutogradValue method so that operators still work\nAutogradValue.forward_pass = forward_pass\ntest_forward_mode(ForwardValue)\n\nPassed!\n\n\nWe can now take derivates of functions!\n\na = ForwardValue(5)\nb = ForwardValue(2)\nL = -log(5 *b + a)\n\ndL_da = L.forward_grads[a]\ndL_db = L.forward_grads[b]\nprint('dL/da = %.3f, dL/db = %.3f' % (dL_da, dL_db))\n\ndL/da = -0.067, dL/db = -0.333\n\n\nWe could also implement our own very simple version of Autograd’s grad.\n\ndef grad(f):\n    def ad_function(x, *args):\n        x = ForwardValue(x)\n        output = f(x, *args)\n        return output.forward_grads[x]\n    return ad_function\n\n# Define a function\ndef f(x):\n    return x * x\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-2-reverse-mode-automatic-differentiation",
    "href": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-2-reverse-mode-automatic-differentiation",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 2: Reverse-mode automatic differentiation",
    "text": "Part 2: Reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, just like forward-mode automactic differentiation, it makes sense to define a class to represent the result of an operation.\nIn this case, we’ll reuse the AutogradValue class we defined above as the the base class. The set of properties will be the same, except that instead of keeping track of a forward_grads dictionary, we’ll keep track of a new grad property. - grad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\))\nRemember that this will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5).\nLet’s see how this will work in practice. If we want to take derivatives using reverse-mode, we will first define the inputs using AutogradValue.\na = AutogradValue(5)\nb = AutogradValue(2)\nAs before, we can perform whatever operations we want on these inputs:\nc = a + b\nL = log(c)\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\nL.backward()\ndL_da = a.grad\nAgain, we’ll be able to compute operations with non-AutogradValue numbers, but won’t be able to compute derivaitives with respect to these values.\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\nNow that we’ve seen what our final produce will look like, let’s define our AutogradValue class.\nLet’s confirm that we do keep the entire compuational graph for operations defined in this way.\n\nQ3: Computational graph\nWrite a function graph_print that takes a single argument. If the argument is an AutogradValue (or one of its subclasses), print its value property and then call graph_print on each of its parents. If the argument is not an AutogradValue, just print it. The format of printing is not important.\nHint: You can use the built-in Python function isinstance to determine if something is an AutogradValue or one of its subclasses. e.g. isinstance(a, AutogradValue)\n\ndef graph_print(a):\n    # Check if we're an AutogradValue\n    if isinstance(a, AutogradValue):\n        # Recursively call on each parent\n        for p in a.parents:\n            graph_print(p)\n        print(a.value)\n    else:\n        print(a)\n\na = AutogradValue(5.)\nb = AutogradValue(2.)\nc = log((a + 5) * b)\ngraph_print(c)\n\n5.0\n5.0\n5\n10.0\n2.0\n2.0\n20.0\n2.995732273553991\n\n\nThe function should print (it’s ok if the numbers or order aren’t exact):\n2.995732273553991\n20.0\n10.0\n5.0\n5.0\n5\n2.0\n2.0\nNow in order to do automatic differentiation, we need to define how to do the backward pass. We’ll start with the backward_step for a single operation.\n\n\nQ4: Backward pass\nFill in the method backward_pass which computes a single step of the reverse pass through the computational graph (assume self is an AutogradValue instance). If backward_pass is called on a value c, the method should: - Assume that self.grad contains the derivaive of the final loss with respect to c (\\(\\frac{dL}{dc}\\)). - Check if each parent of c is an AutogradValue. If it is, update that parent’s grad property to account for c (e.g. for parent a, update the value of \\(\\frac{dL}{da}\\))\nFor example: if c represents the result of an addition so c = a + b, calling backward_pass on c will update the grad property of both a and b. (a.grad represents \\(\\frac{dL}{da}\\) and is initialized to 0).\nHint: grads will be one of the methods we wrote in the last homework (and shown above). Recall that if c has parents a and b then grads method will give \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\).\n\ndef backward_pass(self):\n    local_grads = self.grads(*self.parent_values)\n\n    # Loop through pairs of parents and their corresponding grads\n    for node, grad in zip(self.parents, local_grads):\n        # Update the gradient of each AutogradValue parent\n        if isinstance(node, AutogradValue):\n            node.grad += self.grad * grad\n\n\nAutogradValue.backward_pass = backward_pass\n\n# Test our implementation\ntest_backward_pass(AutogradValue)\n\nPassed!\n\n\nFinally we need to define the backward method itself. We will call this on the loss value to find the derivatives of the loss with respect to each input. This means working our way backward through the sequence of operations. Remember that if c=a+b, then if c.grad is \\(\\frac{dL}{dc}\\), calling backward_pass on c will update \\(\\frac{dL}{da}\\) (a.grad) and \\(\\frac{dL}{db}\\) (b.grad).\nThe complication is that c may be used in multiple operations, so we can’t call backward_pass on c until we’ve called backward_pass on each child operation of c otherwise c.grad won’t have the correct value of \\(\\frac{dL}{dc}\\), as in this example:\nc = a + b\ng = c * 2\nh = c + 4\nL = g * h\n\nL.backward_pass() # Updates dL/dg and dL/dh\nh.backward_pass() # Updates dL/dc\n\n##WRONG ORDER\nc.backward_pass() # Incorrect because dL/dc hasn't accounted for dL/dg\ng.backward_pass()\n\n## CORRECT ORDER\ng.backward_pass() # Updates dL/dc\nc.backward_pass() # Updates dL/da and dL/db\n\n\nQ5: Backward method\nFill in the backward method for AutogradValue. Your backward method should call backward_pass on each operation used to compute the loss (self is the loss value). Some important things to keep in mind: - backward_pass should only be called once on each operation - backward_pass must be called on every child of an operation before it can be called on the operation. - You should not try to call backward_pass on values that aren’t instances of AutogradValue, even though they might be stored in operation.parents\nHint: We discussed a simple approach to this problem in class! In general the problem we’re solving here is a topological sort. We won’t score efficiency in grading, but it still might be worth optimizing this function a bit.\nSimple, but slow implementation\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n\n    # Setup a queue of nodes to visit, starting with self (the final loss)\n    queue = [self]\n    # Setup a list keep track of the order to call backward_pass()\n    order = []\n\n    # Visit each AutogradValue in the queue\n    while len(queue) &gt; 0:\n        node = queue.pop()\n        if isinstance(node, AutogradValue):\n\n            # We only want to keep the last instance of each node in the\n            # order, so if we visit a node already in the order, remove it\n            if node in order:\n                order.remove(node)\n\n            # Add the node to the end of the order and its paraent to the queue\n            order.append(node)\n            queue.extend(node.parents)\n    \n    # Once we have the order call backward pass on every node\n    for node in order:\n        node.backward_pass()\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nPassed!\n\n\nFaster implementation by keeping track of visit counts\n\ndef backward(self):\n    # We call backward on the loss, so dL/dL = 1\n    self.grad = 1.\n    queue = [self]\n    order = []\n\n    # Additionally keep track of the visit counts for each node\n    counts = {}\n    while len(queue) &gt; 0:\n        node = queue.pop()\n        \n        # Rather than removing nodes from the order [slow, O(N)], \n        # just mark that it has been visited again [O(1)]\n        if isinstance(node, AutogradValue):\n            if node in counts:\n                counts[node] += 1\n            else:\n                counts[node] = 1\n\n            order.append(node)\n            queue.extend(node.parents)\n    \n    # Go through the order, but only call backward pass once we're at\n    # the last vist for a given node\n    for node in order:\n        counts[node] -= 1\n        if counts[node] == 0:\n            node.backward_pass()\n\nAutogradValue.backward = backward\n# Test our implementation\ntest_backward(AutogradValue)\n\nPassed!\n\n\nNow we can use our AutogradValue class to compute derivatives!\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nL = -log(5 *b + a)\nL.backward()\nprint(a.grad, b.grad)\n\n-0.06666666666666667 -0.3333333333333333\n\n\nIf we want to train a neural network using our automatic differentiation implementation, we’re going to want to be able to use numpy to do matrix operations. Fortunately, the our AutogradValue class is (mostly) compatible with numpy!\nWe can create arrays of AutogradValue and take derivatives as shown below:\n\na = np.asarray([AutogradValue(5), AutogradValue(2)])\nL = np.dot(a, a)\nL.backward()\nprint('Gradient for a', a[0].grad, a[1].grad)\n\nGradient for a 10.0 4.0\n\n\nIt would be a bit tedious to define every AutogradValue array in this way, so let’s write some convinience functions to make doing automatic differentiation with numpy easier.\n\n\nQ6: Array support\nComplete the following two functions wrap_array and unwrap_gradient.\nwrap_array should take a numpy array of floats and return a new array where every element has been made into an AutogradValue.\nunwrap_gradient should take a numpy array of AutogradValue and return a new array of floats, where every element is the extracted grad property of the corresponding element from the original array.\nBoth of these functions should work on 2-D arrays (matrices) at a minimum (but more general solutions that support 1 and/or &gt;2 dimensional arrays are also possible).\nHint: You can create an array from nested lists as np.asarray([[1, 2], [3, 4]]).\nWe’ll start by creating a function that applys a function to each element of an array\n\ndef element_map(f, a):\n    '''\n    Creates a new array the same shape as a, with a function f applied to each element.\n\n    Args:\n        a (function): The function to apply\n        a (array): The array to map\n    Returns:\n        g (array): An array g, such that g[i,j] = f(a[i,j])\n    '''\n\n    # Store the original shape\n    shape = a.shape\n    \n    # Create a 1-d array with the same elements using flatten()\n    # then iterate through applying f to each element\n    flat_wrapped = np.asarray([f(ai) for ai in a.flatten()])\n\n    # Reshape back to the original shape\n    return flat_wrapped.reshape(shape)\n\nWe can use our element_map function to implement both wrapping and unwrapping\n\ndef wrap_array(a):\n    '''\n    Wraps the elements of an array with AutogradValue\n\n    Args:\n        a (array of float): The array to wrap\n    Returns:\n        g (array of AutogradValue): An array g, such that g[i,j] = AutogradValue(a[i,j])\n    '''\n    return element_map(AutogradValue, a)\n    \n\ndef unwrap_gradient(a):\n    '''\n    Unwraps the gradient of an array with AutogradValues\n\n    Args:\n        a (array of AutogradValue): The array to unwrap\n    Returns:\n        g (array of float): An array g, such that g[i,j] = a[i,j].grad\n    '''\n    return element_map(lambda ai: ai.grad, a)\n\n\ntest_wrap_unwrap(wrap_array, unwrap_gradient, AutogradValue)\n\nPassed!"
  },
  {
    "objectID": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-2-training-a-neural-network",
    "href": "assignments/homeworks/Homework 5/solutions-CCLQOR.html#part-2-training-a-neural-network",
    "title": "Homework 5: Automatic Differentiation",
    "section": "Part 2: Training a neural network",
    "text": "Part 2: Training a neural network\nNow we’re ready to test out our AutogradValue implementation in the context it’s designed for: neural networks! Below is a (slightly modified) version of the neural network class we wrote for the last homework.\n\n\ndef pad(a):\n    # Pads an array with a column of 1s (for bias term)\n    return a.pad() if isinstance(a, AutogradValue) else np.pad(a, ((0, 0), (0, 1)), constant_values=1., mode='constant')\n\ndef matmul(a, b):\n    # Multiplys two matrices\n    return _matmul(a, b) if isinstance(a, AutogradValue) else np.matmul(a, b)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + (-x).exp()) if isinstance(x, AutogradValue) else 1. / (1. + np.exp(-x))\n\nclass NeuralNetwork:\n    def __init__(self, dims, hidden_sizes=[]):\n        # Create a list of all layer dimensions (including input and output)\n        sizes = [dims] + hidden_sizes + [1]\n        # Create each layer weight matrix (including bias dimension)\n        self.weights = [np.random.normal(scale=1., size=(i + 1, o))\n                        for (i, o) in zip(sizes[:-1], sizes[1:])]\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (list of arrays): A list of weight matrices\n        Returns:\n            pred (array): An N x 1 matrix of f(X).\n        '''\n        # Iterate through the weights of each layer and apply the linear function and activation\n        for wi in w[:-1]:\n            X = pad(X) # Only if we're using bias\n            X = sigmoid(matmul(X, wi))\n\n        # For the output layer, we don't apply the activation\n        X = pad(X)\n        return matmul(X, w[-1])\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n\n\nQ7: Autograd for a neural network\nImplement an nll_and_grad method for the NeuralNetwork class using your reverse-mode automatic differentiation implmentation to compute the gradient with respect to each weight matrix.\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    # Wrap the array we want to differentiate with respect to (weights)\n    w = [wrap_array(wi) for wi in self.weights]\n\n    # Run the NLL function and call backward to populate the gradients\n    nll = self.nll(X, y, w)\n    nll.backward()\n\n    # Get both the nll value and graident\n    return nll.value, [unwrap_gradient(wi) for wi in w]\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [10, 10])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\nLoss 11.25, accuracy: 0.95: 100%|██████████| 250/250 [00:40&lt;00:00,  6.24it/s]\n\n\nModel accuracy: 0.950"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/main.html",
    "href": "assignments/homeworks/Homework 4/main.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and try out automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/main.html#overview",
    "href": "assignments/homeworks/Homework 4/main.html#overview",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "In this homework we will build a tiny neural network libarary from scratch and try out automatic differentiation!\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/cb9e69f642104f107f25826a0931629a/raw/163f9cf5325db28826f4103d0f168702c77dfca1/hw4_support.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw4_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nfrom hw4_support import *\n\n\n\nThis homework makes use of a few fancy features in Python that are worth knowing about if you are unfamiliar. - Variable length arguments (e.g. *args) - List comprehensions (e.g. [a**2 for a in range(5)]) - Magic methods (e.g. __add__)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/main.html#part-1-autograd",
    "href": "assignments/homeworks/Homework 4/main.html#part-1-autograd",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 1: Autograd",
    "text": "Part 1: Autograd\nIn this homework we will be using a special version of Numpy from a package called Autograd. Assuming it is installed (pip install autograd), we can import it as follows:\n\nimport autograd.numpy as np\n\nThis special version of Numpy behaives exactly like normal numpy. We can create and do calculations with arrays just like we would before:\n\nx = np.array([3., 2., 1])\nprint('x:\\t', x)\nprint('x^2:\\t', x ** 2)\nprint('sum(x):\\t', np.sum(x))\n\nx:   [3. 2. 1.]\nx^2:     [9. 4. 1.]\nsum(x):  6.0\n\n\nHowever, Autograd also has a very important trick up its sleeve: it can take derivatives (and gradients) for us! This functionality can be accessed through the grad function. Let’s start by seeing it in action with a very simple example, where we know the correct answer. The square function and its derivative can be written as:\n\\(f(x) = x^2, \\quad f'(x) = 2x\\)\nThe following code uses Autograd to compute this derivative automatically:\n\nfrom autograd import grad\n\n# Define a function\ndef f(x):\n    return x ** 2\n\n# Use 'grad' to compute the derivative function\nf_prime = grad(f)\n\n# Verify that we get the correct answer\nx = 5.\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", f_prime(x))\n\nx:   5.0\nf(x):    25.0\nf'(x):   10.0\n\n\nWe can start to see how grad operates. grad takes as input a function (e.g. \\(f(x)\\)) and returns a new function that computes the derivative of \\(f\\) at \\(x\\). (\\(f'(x)\\)). So:\n\\(\\text{grad}(f) \\longrightarrow f'\\)\n\nQ1: Trying out autograd (5 points)\nDefine the following function in python:\n\\(f(x) = \\log(\\sin(x^3) + 3 x)\\)\nUse grad to compute the derivative of \\(f\\) at \\(1.5\\) (i.e. compute \\(f'(1.5)\\))\n\n## YOUR CODE HERE\n\n\nanswer =\nprint(\"f'(1.5)=\", answer)\n\nAs the name would imply, grad can more generally be used to compute the gradient of a function of the form \\(f(\\mathbf{x}): \\mathbb{R}^d\\rightarrow \\mathbb{R}\\). Remember that for a function that takes in a vector and outputs a scalar, the gradient is vector of all partial derivatives of the output with respect to each input. For example, consider a function that gives the square of the 2-norm of a vector:\n\\(f(\\mathbf{x}) = ||\\mathbf{x}||^2_2 = \\mathbf{x}^T\\mathbf{x} = \\sum_{i=1}^d x_i^2\\)\nThink about why these expressions are equivalent!\nAs we’ve seen, the gradient of this function can be written as:\n\\(\\nabla f(\\mathbf{x}) = 2\\mathbf{x} = \\begin{bmatrix}2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_d \\end{bmatrix}\\)\nLet’s see what Autograd gives us in this case:\n\n# Define a function\ndef f(x):\n    return np.sum(x ** 2)\n\n# Use 'grad' to compute the derivative function\ngrad_f = grad(f)\n\n# Verify that we get the correct answer\nx = np.array([1., 2., 3])\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nx:   [1. 2. 3.]\nf(x):    14.0\nf'(x):   [2. 4. 6.]\n\n\nWe see that the gradient has the same shape as the input. So the gradient function is of the form: \\(\\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\)\nThis makes sense as the gradient should have exactly one partial derivative for each entry in the input to the function. As discussed, this even extends beyond vectors! We could have a function that takes in any datastructure and computes the set of partial derivatives with respect to each entry.\n\n\nQ2: More complex autograd (5 points)\nWrite a function that takes a list of vectors and computes the sum of the squared 2-norm for each vector. That is:\n\\(f([\\mathbf{a}, \\mathbf{b}, \\mathbf{c}...]) = ||\\mathbf{a}||^2 + ||\\mathbf{b}||^2 + ||\\mathbf{c}||^2+...\\)\nRecall from above how we can compute each term in this sum!\nThen use grad to compute the gradient of this function with respect to the given input.\n\n# Define a function\ndef f(x):\n    '''\n    Compute the sum of squared 2-norms for a list of vectors\n\n    Args:\n        x (list of arrays): A list of 1-dimensional arrays\n    Returns:\n        output (float): The result\n    '''\n    ## YOUR CODE HERE\n\n# Use 'grad' to compute the derivative function\ngrad_f =\n\n# Verify that we get the correct answer\nx = [np.array([1., 2., 3]), np.array([7., 2.]), np.array([6.])]\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\nA useful argument that we can give to grad is argnum. If our function takes more than one argument argnum lets us specify which one to take the gradient with respect to. For example, if we have the function:\n\\(f(x, y) = x^2y\\)\nThen:\n\\(f'_x(x,y)=2xy, \\quad f'_y(x, y)=x^2\\)\n\ndef f(x, y):\n    return x ** 2 * y\n\nprint('f(3, 5) = ', f(3., 5.))\n\ndf_dx = grad(f, argnum=0)(3., 5.)\ndf_dy = grad(f, argnum=1)(3., 5.)\n\nprint('df_dx = ', df_dx)\nprint('df_dy = ', df_dy)\n\nNow that we have everything we need to apply automatic differentiation to train a neural network!\nBefore we do that though, let’s try out our automatic differentiation for logistic regression. Below is a slight modification of LogisticRegression implementation we saw in the last homework.\n\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1. / (1. + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1, 1))\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w)\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        X = np.pad(X, ((0,0), (0,1)), constant_values=1., mode='constant')\n        return np.dot(X, w)\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (array): An N x 1 column vector of predictions in {0, 1}\n        '''\n        return (self.prediction_function(X, self.weights) &gt; 0)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): An N x 1 column vector of predicted class probabilities\n        '''\n        return sigmoid(self.prediction_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        y = y.reshape((-1, 1))\n        return (self.predict(X) == y).mean()\n\n    def nll(self, X, y, w=None):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n            w (array, optional): A (d+1) x 1 matrix of weights.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        if w is None:\n            w = self.weights\n\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, w)\n        py = sigmoid((2 * y - 1) * xw)\n        return -(np.log(py)).sum()\n\n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        y = y.reshape((-1, 1))\n        xw = self.prediction_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1., mode='constant')\n        return -np.sum(grad, axis=0)\n\n    def nll_and_grad_no_autodiff(self, X, y):\n        # Compute nll_and_grad without automatic diferentiation\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\n\nQ3: Logistic regression using autograd (10 points)\nWrite the method nll_and_grad for the LogisticRegression class using the grad function from Autograd. Verify that it gives a similar answer to nll_and_grad_no_autodiff.\nHint: Note that the nll function can optionally take in the parameters. You can use this functionality and the argnum argument of grad in your answer. You can assume that self refers to the model object, so you can access the weights via self.weights\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss, grads\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nThis implementation quite inefficient (we’ll fix this in the future!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/main.html#part-2-feature-transforms",
    "href": "assignments/homeworks/Homework 4/main.html#part-2-feature-transforms",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 2: Feature transforms",
    "text": "Part 2: Feature transforms\nRecall that in class we dicussed feature transforms an easy way to get more expressive models, using our linear model tools. Here we’ll try applying some basic feature transforms to this problem and see if we can improve the performance.\n\nQ4: Quadratic feature transforms (10 points)\nBelow we’ve started a sub-class of LogisticRegression that should first compute a transformed version of the input data by adding quadratic features. Only add the unary quadratic terms (\\(x_i^2\\)) not the cross terms (\\(x_i x_j\\)). For a single dimension the transform would look like: \\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ x_i^2 \\end{bmatrix}\\]\nIn general, the transform should look like:\n\\[\\textbf{Single observation: }\\phi(\\mathbf{x}) = \\begin{bmatrix}x_1 \\\\ \\vdots \\\\ x_d \\\\ x_1^2 \\\\ \\vdots \\\\ x_d^2 \\end{bmatrix}, \\quad \\textbf{Dataset: } \\phi(\\mathbf{X}) = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1d} & x_{11}^2 & \\dots & x_{1d}^2 \\\\ x_{21} & x_{22} & \\dots & x_{2d} & x_{21}^2 & \\dots & x_{2d}^2 \\\\  \\vdots & \\vdots & & \\vdots & \\vdots & & \\vdots \\\\ x_{N1} & x_{N2} & \\dots & x_{Nd} & x_{N1}^2 & \\dots & x_{Nd}^2 \\\\  \\end{bmatrix} \\]\n\nclass QuadraticRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        transformed_dims = dims * 2\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a quadratic feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\nHere we’ll try out our quadratic feature transform.\n\nX, y = make_moons(100, noise=0.1)\nmodel = QuadraticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nQ5: Evaluating sin transforms (10 points)\nRepeat question 4, but using a different transform, defined as:\n\\[\\phi(x_i) = \\begin{bmatrix} x_i \\\\ \\sin(10 x_i) \\end{bmatrix}\\]\n\nclass SineRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        transformed_dims = dims * 2\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a sinusoidal feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = SineRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nQ6: Comparing feature transforms (5 points)\nBased on the results, would you use any feature transform for this problem? If so, which one?\nYOUR ANSWER HERE\n\n\nQ7: Creating your own transform (15 points)\nRepeat question 4, but define your own transform to try to get as close as you can to classifying all the points correctly.\nThis doesn’t need to be perfect for full credit, just try to improve on the examples.\n\\[\\phi(x_i) = ?\\]\n\nclass MyRegression(LogisticRegression):\n    def __init__(self, dims):\n        transformed_dims = # YOUR CODE HERE\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        '''\n        Get the result of our base function for prediction (i.e. x^t w), \n        including a sinusoidal feature transform.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            w (array): A (d+1) x 1 vector of weights.\n        Returns:\n            pred (array): A length N vector of f(X).\n        '''\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = MyRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=2500)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/main.html#part-3-implementing-a-neural-network",
    "href": "assignments/homeworks/Homework 4/main.html#part-3-implementing-a-neural-network",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "Part 3: Implementing a neural network",
    "text": "Part 3: Implementing a neural network\nNow let’s extend our model to be a neural network! We’ll create a neural network class that extends our logistic regression class. First we’ll setup the needed weight matrices.\n\nQ8: Initializing a neural network (10 points)\nFill in the Neural Network __init__ method below. The method should take in the input data dimension and a list of integers specifying the size of each hidden layer (the number of neurons in each layer). The function should create a list of numpy arrays of the appropriate shapes for the weight matrices.\nFor example if dims is 2 and hidden_sizes is [4, 4], then self.weights should have 3 entries of shapes [(4x2), (4x4), (1x4)]. This network is shown below (may not show in colab).\n\n\nInput Layer ∈ ℝ²Hidden Layer ∈ ℝ⁴Hidden Layer ∈ ℝ⁴Output Layer ∈ ℝ¹\n\nIf you find it easier you could also define the weights in terms of \\(W^T\\) instead, in which case the shapes would be: [(2x4), (4x4), (4x1)]. You could also consider how to add a bias term at each layer as in logistic regression (but this isn’t nessecary for full credit).\nThe values in each array should be drawn from a normal distribution with standard deviation 1. You can create such a matrix in numpy using:\nnp.random.normal(scale=1., size=shape)\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        ## YOUR CODE HERE\n        self.weights =\n\ntest_nn_constructor(NeuralNetwork)\n\nRecall that for logistic regression the prediction function (before threholding or sigmoid) was \\(\\mathbf{X}\\mathbf{w}\\). We now want to implement the prediction function for our neural network class. This function should perform the appropriate feature transforms and multiply by the regression weights. For a neural network with a single hidden layer this will look like:\n\\(f(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{w}_0\\)\nUse the sigmoid activation function for this problem.\nFor multiple layers we can also think of this a a chain of feature transforms: \\[\\Phi_1 = \\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\] \\[\\Phi_2 = \\sigma(\\Phi_1 \\mathbf{W}_2^T)\\] \\[...\\] \\[\\Phi_l = \\sigma(\\Phi_{l-1} \\mathbf{W}_l^T)\\] \\[f(\\mathbf{X}) = \\Phi_l\\mathbf{w}_0\\] Where \\(\\Phi_i\\) is just the variable that represents the neurons at layer \\(i\\) (the result of the first \\(i\\) transforms applied to \\(\\mathbf{X}\\)).\n\nQ9: Prediction function (15 points)\nImplement the prediction function as described above. Note that the prediction function should use the weights passed into the w argument rather than self.weights, this will make it easier to implement the next question.\nHint: Note that this function should not apply a final sigmoid or thresholding, instead it should be the equivalent of linear_function from the previous homework\n\ndef prediction_function(self, X, w):\n    '''\n    Get the result of our base function for prediction (i.e. x^t w)\n\n    Args:\n        X (array): An N x d matrix of observations.\n        w (list of arrays): A list of weight matrices\n    Returns:\n        pred (array): An N x 1 matrix of f(X).\n    '''\n    ## YOUR CODE HERE\n\n    return pred.reshape((-1, 1))\n\nNeuralNetwork.prediction_function = prediction_function\ntest_nn_prediction_function(NeuralNetwork)\n\n\n\nQ10: Neural network loss (10 points)\nImplement an nll_and_grad method for the NeuralNetwork class using Autograd to compute the gradient with respect to each weight matrix.\nHint: If you use np.pad anywhere in your implementation, Autograd may complain if you don’t include the keyword argument mode='constant'\n\ndef nll_and_grad(self, X, y):\n    '''\n    Get the negative log-likelihood loss and its gradient\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels\n    Returns:\n        nll (float): The negative log-likelihood\n        grads (list of arrays): A list of the gradient of the nll with respect\n                                to each value in self.weights.\n    '''\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\nWe now have everything in place to train a neural network from scratch! Let’s try it on our tiny dataset. Feel free to change the inputs.\nHint: If this give very poor results and/or runs very slowly, make sure to carefully check the shape of each operation in your code to make sure it matches your expectation.\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\nQ11: Comparison (5 points)\nHow does the neural network compare to explicit feature transforms in this case? How would you expect it to compare on other datasets?\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 4/submission.html",
    "href": "assignments/homeworks/Homework 4/submission.html",
    "title": "Homework 4: Automatic Differentiation and Neural Networks",
    "section": "",
    "text": "Name\nYOUR NAME HERE\n\n\nCollaborators\nPlease list anyone you discussed or collaborated on this assignment with below.\nLIST COLLABORATORS HERE\n\n\nCourse feedback\nPlease submit this week’s course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8\n\n\nConvert to PDF\nPlease convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/\n\n# Uncomment and run if using Colab!\n\n#!wget https://cs152.github.io/assignments/homeworks/Homework%204/hw4_support.py\n\n\n# Run me first!\nfrom hw4_support import *\nimport autograd.numpy as np\nfrom autograd import grad\n\n\n\n\n\nQ1\n\n## YOUR CODE HERE\n\n\nanswer =\nprint(\"f'(1.5)=\", answer)\n\n\n\n\n\n\nQ2\n\n# Define a function\ndef f(x):\n    ## YOUR CODE HERE\n\n# Use 'grad' to compute the derivative function\ngrad_f =\n\n# Verify that we get the correct answer\nx = [np.array([1., 2., 3]), np.array([7., 2.]), np.array([6.])]\nprint('x:\\t', x)\nprint('f(x):\\t', f(x))\nprint(\"f'(x):\\t\", grad_f(x))\n\n\n\n\n\n\nQ3\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss, grads\n\nLogisticRegression.nll_and_grad = nll_and_grad\n\nThis implementation quite inefficient (we’ll fix this in the future!), so we’ll test our model on a very small dataset.\n\nX, y = make_moons(100, noise=0.1)\nmodel = LogisticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ4\n\nclass QuadraticRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        transformed_dims = dims * 2\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\nHere we’ll try out our quadratic feature transform.\n\nX, y = make_moons(100, noise=0.1)\nmodel = QuadraticRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ5\n\nclass SineRegression(LogisticRegression):\n    def __init__(self, dims):\n        # Multiply the number of dimensions for our weights by 2\n        transformed_dims = dims * 2\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = SineRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ6\nYOUR ANSWER HERE\n\n\n\n\n\nQ7\n\nclass MyRegression(LogisticRegression):\n    def __init__(self, dims):\n        transformed_dims = # YOUR CODE HERE\n        super().__init__(transformed_dims)\n\n    def prediction_function(self, X, w):\n        Xtransformed = ## YOUR CODE HERE\n        Xtransformed = np.pad(Xtransformed, ((0,0), (0,1)), constant_values=1.)\n        return np.dot(Xtransformed, w)\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = MyRegression(2)\ngradient_descent(model, X, y, lr=3e-2, steps=2500)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ8\n\nclass NeuralNetwork(LogisticRegression):\n    def __init__(self, dims, hidden_sizes=[]):\n        ## YOUR CODE HERE\n        self.weights =\n\ntest_nn_constructor(NeuralNetwork)\n\n\n\n\n\n\nQ9\n\ndef prediction_function(self, X, w):\n    ## YOUR CODE HERE\n\n    return pred.reshape((-1, 1))\n\nNeuralNetwork.prediction_function = prediction_function\ntest_nn_prediction_function(NeuralNetwork)\n\n\n\n\n\n\nQ10\n\ndef nll_and_grad(self, X, y):\n    ## YOUR CODE HERE\n    loss =\n    grads =\n    return loss, grads\n\nNeuralNetwork.nll_and_grad = nll_and_grad\n\n\nX, y = make_moons(100, noise=0.1)\nmodel = NeuralNetwork(2, [5, 5])\ngradient_descent(model, X, y, lr=3e-2, steps=250)\n\nprint('Model accuracy: %.3f' % model.accuracy(X, y))\nplot_boundary(model, X, y)\n\n\n\n\n\n\nQ11\nYOUR ANSWER HERE"
  },
  {
    "objectID": "assignments/homeworks/Homework 3/solutions-NCLZ0K.html",
    "href": "assignments/homeworks/Homework 3/solutions-NCLZ0K.html",
    "title": "Homework 3: Logistic regression and classification (solutions)",
    "section": "",
    "text": "In this homework, we will use the following convention for dimentionality:\n\\(N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\)\n\\(d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d\\)\n\\(C: \\quad\\ \\text{Number of classes, so } y_i \\in \\{1,...,C\\}\\)\n\n# Uncomment and run if using Colab!\n\n#import urllib.request\n#remote_url = 'https://gist.githubusercontent.com/gabehope/2f0c3af9eed3b910037df98e21c6c035/raw/925ff6b8ad5dcc2c17674b6ec609d854a811c453/hw2_code.py'\n#with urllib.request.urlopen(remote_url) as remote, open('hw3_support.py', 'w') as local:\n#  [local.write(str(line, encoding='utf-8')) for line in remote]\n\n\n# Run me first!\nimport autograd.numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom hw3_support import get_dataset, gradient_descent, test_nll, test_nll_grad, test_predict, plot_boundary, test_softmax, test_split, test_predict_probability, test_nll_gradient_c\n\n\nBackground\nIn class we derived the logistic regression model for making predictions on binary data. Recall the the prediction function for logistic regression can be written as:\n\\[f(\\mathbf{x}) = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} \\geq 0)\\]\nThe estimated probability of \\(y=1\\) as: \\[p(y=1\\mid \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{x}^T\\mathbf{w})\\]\nAlso recall that the negative log-likelihood loss for logistic regression can be written as:\n\\[\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\log \\sigma\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\nand it’s gradient with respect to \\(\\mathbf{w}\\) is: \\[\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\big(1 - \\sigma((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w})\\big) \\big(2 y_i - 1\\big)\\mathbf{x}_i\\]\nBelow is an implementation of logistic regression using the functions we derived in class. In this example, we’ve created a logistic regression class that encapsulates the weights along with all of the functions we need to train and make predictions with the model.\n\ndef linear_function(X, w):\n    # Returns a linear function of X (and adds bias)\n    X = np.pad(X, ((0,0), (0,1)), constant_values=1.)\n    return np.dot(X, w)\n\ndef sigmoid(x):\n    # Computes the sigmoid function\n    return 1 / (1 + np.exp(-x))\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        '''\n        Args:\n            dims (int): d, the dimension of each input\n        '''\n        self.weights = np.zeros((dims + 1,))\n\n    def predict(self, X):\n        '''\n        Predict labels given a set of inputs.\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            pred (int array): A length N array of predictions in {0, 1}\n        '''\n        return (linear_function(X, self.weights) &gt; 0).astype(int)\n\n    def predict_probability(self, X):\n        '''\n        Predict the probability of each class given a set of inputs\n\n        Args:\n            X (array): An N x d matrix of observations.\n        Returns:\n            probs (array): A length N vector of predicted class probabilities\n        '''\n        return sigmoid(linear_function(X, self.weights))\n\n    def accuracy(self, X, y):\n        '''\n        Compute the accuracy of the model's predictions on a dataset\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            acc (float): The accuracy of the classifier\n        '''\n        return np.mean(self.predict(X) == y)\n\n    def nll(self, X, y):\n        '''\n        Compute the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (int array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        return -np.sum(np.log(py))\n\n    def nll_gradient(self, X, y):\n        '''\n        Compute the gradient of the negative log-likelihood loss.\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        xw = linear_function(X, self.weights)\n        py = sigmoid((2 * y - 1) * xw)\n        grad = ((1 - py) * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n        return -np.sum(grad, axis=0)\n\n    def nll_and_grad(self, X, y):\n        '''\n        Compute both the NLL and it's gradient\n\n        Args:\n            X (array): An N x d matrix of observations.\n            y (array): A length N vector of labels.\n        Returns:\n            nll (float): The NLL loss\n            grad (array): A length (d + 1) vector with the gradient\n        '''\n        return self.nll(X, y), self.nll_gradient(X, y)\n\n\nLet’s take a look at how to use this class. The code below uses the scikit-learn library to load a simple example dataset. Here we have 2 classes (purple and yellow) and our goal will be to separate the two.\n\n# Load a dataset with sklearn\nX, y = make_blobs(n_samples=200, random_state=48, centers=2, cluster_std=3)\n\n# Show a plot of the data\nplt.scatter(X[:, 0], X[:, 1], c=y,  edgecolor=\"black\");\n\n\n\n\n\n\n\n\nWe can create a model using the LogisticRegression class, specifying the number of features (\\(d\\)):\n\nmodel = LogisticRegression(X.shape[1])\n\nWe can train the model using the gradient_descent function provided in the support code:\nNote: Use this learning rate and number of steps throughout the homework!\n\nlosses = gradient_descent(model, X, y, lr=1e-4, steps=2500, watch=False)\n\n# Uncomment to run with a live visualization\n# losses = gradient_descent(model, X, y, lr=1e-6, steps=500, watch=True)\n\nLoss 19.77, accuracy: 0.97: 100%|██████████| 2500/2500 [00:01&lt;00:00, 2275.07it/s]\n\n\nWe provide a built-in function to visualize the data and decision boundary\n\n# Show an image and the corresponding prediction\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nWe can also make predictions using the built-in methods. Here we’ll visualize which observations we predicted incorrectly:\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = np.where(prediction, probabilities, 1 - probabilities)\nplt.scatter(X[:, 0], X[:, 1], c=(1 - prediction == y), edgecolor='black', cmap='Reds')\nplt.title('Incorrect predictions');\n\n\n\n\n\n\n\n\n\n\nPart 1: Logistic regression\nWe’ll first evaluate the performance of the logistic regression model above.\n\nQ1: Train and test splits\nWrite a function to split the provided dataset into a train set and a test set. The train set should include 70% of the observations and the test set should include the remaining 30%. The data should be randomly shuffled to make sure there is no bias in the ordering.\n\n\nAnswer\n\ndef split_data(X, y):\n    # Shuffle the data\n    indices = np.arange(X.shape[0])\n    np.random.shuffle(indices)\n    X = X[indices]\n    y = y[indices]\n\n    # Split the data\n    split_index = int(0.7 * X.shape[0])\n    Xtrain, Xtest = X[:split_index], X[split_index:]\n    ytrain, ytest = y[:split_index], y[split_index:]\n    return Xtrain, ytrain, Xtest, ytest\n\n# Test the function\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\ntest_split(X, y, Xtrain, ytrain, Xtest, ytest)\n\nPassed!\n\n\n\n\nQ2: Model evaluation\nUsing the function you just wrote, train a new logistic regression model on just the training data. Evaluate the accuracy and loss of the trained model on both the training data and the test data.\n\n\nAnswer\n\nnp.random.seed(10)\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\nmodel = LogisticRegression(X.shape[1])\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-4, steps=2500, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain, ytrain), model.nll(Xtrain, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest, ytest), model.nll(Xtest, ytest)\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 20.75, accuracy: 0.95: 100%|██████████| 2500/2500 [00:01&lt;00:00, 2351.91it/s]\n\n\nTraining accuracy: 0.950, loss: 20.743\nTest accuracy: 0.967, loss: 4.935\n\n\n\n\n\n\n\n\nPart 2: Alternative losses\nOur original goal for classification was simply to maximize the number of correct classifications we’d make. Using accuracy as a loss function looked something like this:\n\\[\\mathbf{Acc.}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\mathbb{I}\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w} \\geq 0 \\big)\\]\nWhich unfortunately wasn’t differentiable and therefore we couldn’t optimize it with gradient descent.\nThe maximum likelihood principal helped us derive a useful loss function for classification:\n\\[\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\log \\sigma\\big((2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\n(and had the additional benefit of letting us estimate probabilities). But as we saw with linear regression that we’re not limited to thinking about things from the probabilistic perspective. Now that we’ve seen what a reasonable loss function for classification looks like, we could try some variations with similar properties.\nLet’s consider the exponential loss:\n\\[\\mathbf{ExpLoss}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=\\sum_{i=1}^N \\exp\\big(-(2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big)\\]\nNote that \\(\\exp(x) = e^x\\)\nPlotting this we see that just like negative log-likelihood, the loss monotonically increases as we get further from a correct prediction, which is what we’d like!\n\nyxw = np.linspace(-3, 3, 200)\nacc = np.where(yxw &gt; 0, 0., 1.)\nnll = -np.log(sigmoid(yxw))\nexp = np.exp(-yxw)\n\nplt.plot(yxw, acc, label='Acc. (0-1 loss)')\nplt.plot(yxw, nll, label='Neg. Log-lik.')\nplt.plot(yxw, exp, label='Exp.')\nplt.ylim((-0.2, 3))\nplt.legend();\n\n\n\n\n\n\n\n\n\nQ3: Exponential loss gradient\nDerive the gradient of the exponential loss with respect to \\(\\mathbf{w}\\), the weight vector for the linear model.\n\n\nAnswer\nThe gradient of the exponential loss with respect to the weight vector \\(\\mathbf{w}\\) is:\n\\[\\nabla_{\\mathbf{w}} \\textbf{ExpLoss}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\exp\\big(-(2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\big) \\cdot (2 y_i - 1) \\mathbf{x}_i\\]\n\n\nQ4: Exponential loss implementation\nLet’s try using the exponential loss. Below is a sub-class of the LogisticRegression class above that replaces the negative log-likelihood loss with the exponential loss.\nComplete the nll_gradient method using the gradient you derived above.\n\nclass ExponentialRegression(LogisticRegression):\n  def nll(self, X, y):\n    '''\n    Compute the exponential loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        nll (float): The exponential loss\n    '''\n    xw = linear_function(X, self.weights)\n    return np.sum(np.exp(-(2 * y - 1) * xw))\n\n  def nll_gradient(self, X, y):\n    '''\n    Compute the gradient of the exponential loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (array): A length N vector of labels.\n    Returns:\n        grad (array): A length (d + 1) vector with the gradient\n    '''\n    xw = linear_function(X, self.weights)\n    exp_term = np.exp(-(2 * y - 1) * xw)\n    grad = -(exp_term * (2 * y - 1)).reshape((-1, 1)) * np.pad(X, [(0,0), (0,1)], constant_values=1.)\n    return np.sum(grad, axis=0)\n\n\n\nQ5: Exponential loss comparison\nRepeat q2, training a new exponential-loss regression model on just the training data. Evaluate the accuracy and loss of the trained model on both the training data and the test data.\n\nnp.random.seed(10)\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\nmodel = ExponentialRegression(X.shape[1])\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-4, steps=2500, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain, ytrain), model.nll(Xtrain, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest, ytest), model.nll(Xtest, ytest)\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\nplot_boundary(model, X, y)\n\nLoss 26.63, accuracy: 0.96: 100%|██████████| 2500/2500 [00:01&lt;00:00, 2484.45it/s]\n\n\nTraining accuracy: 0.957, loss: 26.626\nTest accuracy: 1.000, loss: 7.118\n\n\n\n\n\n\n\n\n\nWhat differences (if any) do you notice between this and the log-likelihood loss?\nYOUR ANSWER HERE\n\n\nQ6: Linear losses\nNote that both the negative log-likelihood and exponential losses are strictly positive, and threrefore bounded below by 0. Why is having a lower bound a desirable property for a classification loss?\nFor instance, why not simply use a linear loss?\n\\[\\mathbf{Loss}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N (2 y_i - 1)\\mathbf{x}_i^T\\mathbf{w}\\]\nHint: If you’re unsure, you could try modifying the ExponentialRegression class to use a linear loss and see what happens! Deriving the gradient should be even simpler than for the exponential loss.\n\n\nAnswer\nWithout a lower bound, the loss could decrease indefinitely and our gradient descent would never converge. In practice this could lead to considerable difficulty in training and evaluation.\n\n\n\nPart 3: Multinomial logistic regression\nIn this part, we will look at implementing multinomial logistic regression. Recall that this model extends logistic regression to the cases where there may be more than 2 possible labels, so \\(y\\in\\{1,...,C\\}\\), where \\(C\\) is the number of classes (possible outputs).\nWe saw that rather than having a single weight vector, this model has a weight vector for each class, \\(\\mathbf{w}_1,...,\\mathbf{w}_C\\). We can view these together as the rows of a weight matrix \\(\\mathbf{W}\\): \\[\\mathbf{W} = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_C^T \\end{bmatrix}\\]\nWe saw that the prediction function for this model was: \\[f(\\mathbf{x}) = \\underset{c\\in \\{1,...,C\\}}{\\text{argmax}}\\ \\mathbf{x}^T\\mathbf{w}_c\\]\nThe probabilistic model was defined as: \\[\np(y_i=c \\mid \\mathbf{x}, \\mathbf{W}) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c=\\frac{e^{\\mathbf{x}^T\\mathbf{w}_c}}{\\sum_{j=1}^Ce^{\\mathbf{x}^T\\mathbf{w}_j}}\n\\]\nThe negative log-likelihood loss was defined as: \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nIn the next few questions we will create a modified version of our logistic regression class that supports multinomal logistic regression. The class definition is below. A few things to note:\n1: We will still assume y is an array of int in numpy. We can convert an array y to an array of int with y = y.astype(int) and back with y = y.astype(float)\n2: Remeber that numpy is 0-indexed, so our classes will actually be \\(0\\) to \\(C-1\\), (\\(y\\in \\{0,...,C-1\\}\\))\n2: We will assume our weight matrix is a \\(C \\times d\\) matrix as shown below\n\nclass MultinomialLogisticRegression(LogisticRegression):\n    def __init__(self, classes, dims):\n        '''\n        Args:\n            classes (int): C, the number of possible outputs\n            dims (int): d, the dimension of each input\n        '''\n        self.classes = classes\n        self.weights = np.zeros((classes, dims + 1,))\n\n\nQ7: Prediction\nWrite a function to make a prediction using the multinomial logistic regression prediction rule above. (assume self is the MultinomialLogisticRegression object)\n\n\nAnswer\n\ndef multiclass_predict(self, X):\n    '''\n    Predict labels given a set of inputs.\n\n    Args:\n        X (array): An N x d matrix of observations.\n    Returns:\n        pred (int array): A length N array of predictions in {0,...,(C-1)}\n    '''\n    W = self.weights\n\n    pred = linear_function(X, self.weights.T).argmax(axis=-1)\n    return pred\n\n## Test the function\ntest_predict(multiclass_predict)\n\n## Add it to our class\nMultinomialLogisticRegression.predict = multiclass_predict\n\nPassed!\n\n\n\n\nQ8: Softmax\nImplement the softmax function. \\[\n\\text{softmax}(\\mathbf{x})_c = \\frac{e^{x_c}}{\\sum_{j=1}^Ce^{x_j}}, \\quad\n\\text{softmax}(\\mathbf{x}) = \\begin{bmatrix}\\frac{e^{x_1}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\frac{e^{x_2}}{\\sum_{j=1}^Ce^{x_j}} \\\\ \\vdots \\\\ \\frac{e^{x_C}}{\\sum_{j=1}^Ce^{x_j}} \\end{bmatrix}\n\\]\nYou function should accept inputs as either a length \\(C\\) vector or as an \\(N\\times C\\) matrix. If the input is a matrix, the softmax function should be applied to each row of the matrix.\nThen, use your softmax function to complete the predict_probability method for multinomial logistic regression.\n\n\nAnswer\n\ndef softmax(x):\n    '''\n    Apply the softmax function to a vector or matrix\n\n    Args:\n        X (array): An N x C matrix of transformed inputs (or a length C vector)\n    Returns:\n        probs (array):  An N x C matrix with the softmax function applied to each row\n    '''\n    ex = np.exp(x)\n    return ex / np.sum(ex, axis=-1, keepdims=True)\n\ndef multiclass_predict_probability(self, X):\n    '''\n    Predict the probability of each class given a set of inputs\n\n    Args:\n        X (array): An N x d matrix of observations.\n    Returns:\n        probs (array): A length N x d matrix of predicted class probabilities\n    '''\n    W = self.weights\n\n    pred = softmax(linear_function(X, self.weights.T))\n    return pred\n\n\ntest_softmax(softmax)\ntest_predict_probability(multiclass_predict_probability)\nMultinomialLogisticRegression.predict_probability = multiclass_predict_probability\n\nPassed!\nPassed!\n\n\n\n\nQ9: Multinomial logistic regression NLL\nImplement a function to compute the multinomial logistic regression negative log-likelihood. \\[\n\\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y})=-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\n\\]\nHint: Recall that \\(y_i\\) is an integer, so \\(\\mathbf{w}_{j}\\) refers to the row of the weight matrix at index \\(y_i\\) (you could access this as W[y[i]]). It’s possible to answer this question without loops, but you may find it easier to loop over each possible class/observation.\n\n\nAnswer\n\ndef nll(self, X, y):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        nll (float): The NLL loss\n    '''\n    xw = linear_function(X, self.weights.T)\n    loss = xw[np.arange(X.shape[0]), y].sum() - np.log(np.sum(np.exp(xw), axis=1)).sum()\n    return -loss\n\ntest_nll(nll)\nMultinomialLogisticRegression.nll = nll\n\nPassed!\n\n\n\n\nQ10: Gradient of NLL\nDerive the gradient of the negative log-likelihood with respect to \\(\\mathbf{w}_c\\), the weight vector for a single class.\nHint: Again note that \\(\\mathbf{w}_{y_i}\\) refers to the weight vector corresponding to the true class of observation \\(i\\), and so only depends on \\(\\mathbf{w}_c\\) if \\(y_i=c\\). This means that: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\begin{cases}\\mathbf{x}_i \\quad \\text{ if } y_i = c \\\\ 0 \\quad \\ \\text{ otherwise}  \\end{cases}\\] We can write this more compactly using an indicator function: \\[\\frac{d}{d\\mathbf{w}_c} \\mathbf{x_i}^T \\mathbf{w}_{y_i} = \\mathbb{I}(y_i=c)\\ \\mathbf{x}_i \\]\n\n\nAnswer\n\\[\\nabla_{\\mathbf{w}_c} \\textbf{NLL}(\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\frac{d}{d\\mathbf{w}_c}-\\sum_{i=1}^N \\bigg(\\mathbf{x}_i^T\\mathbf{w}_{y_i}- \\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\]\nThe first step is to apply the addition/subtraction rule:\n\\[= -\\sum_{i=1}^N \\bigg(\\frac{d}{d\\mathbf{w}_c}\\big(\\mathbf{x}_i^T\\mathbf{w}_{y_i}\\big)- \\frac{d}{d\\mathbf{w}_c}\\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\]\nThen we can apply the rule we see above: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\frac{d}{d\\mathbf{w}_c}\\log\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg)\\] Next we’ll apply the chain rule to the \\(\\log\\) function: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\ \\frac{d}{d\\mathbf{w}_c} \\bigg(\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}\\bigg) \\bigg)\\] We see that only one term in the inner summation depends on \\(\\mathbf{w}_c\\) \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(\\frac{d}{d\\mathbf{w}_c}e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}\\bigg) \\bigg)\\] Applying the chain rule to the exponential we get: \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(e^{\\mathbf{x}_i^T\\mathbf{w}_{c}} \\frac{d}{d\\mathbf{w}_c} \\mathbf{x}_i^T\\mathbf{w}_{c}\\bigg) \\bigg)\\] \\[= -\\sum_{i=1}^N \\bigg(\\mathbb{I}(y_i=c)\\ \\mathbf{x}_i- \\bigg(\\frac{1}{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}}\\bigg)\\  \\bigg(e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}  \\mathbf{x}_i\\bigg) \\bigg)\\] Factoring out \\(\\mathbf{x}_i\\) we get: \\[= -\\sum_{i=1}^N  \\mathbf{x}_i\\bigg(\\mathbb{I}(y_i=c) - \\frac{e^{\\mathbf{x}_i^T\\mathbf{w}_{c}}  }{\\sum_{j=1}^Ce^{\\mathbf{x}_i^T\\mathbf{w}_{j}}} \\bigg)\\]\n\n\nQ11: Implementing the gradient\nWrite a function that computes the gradient of the negative log-likelihood with repect to the weight vector for a given class, using the results of the derivation above.\n\n\nAnswer\n\ndef nll_gradient_c(W, X, y, c):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        W (array): The C x d weight matrix.\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n        c (int): The class to compute the gradient for\n    Returns:\n        grad (array): A length d vector representing the gradient with respect to w_c\n    '''\n    X = np.pad(X, [(0, 0), (0, 1)], constant_values=1.)\n    grad = 1 / np.exp(np.dot(X, W.T)).sum(axis=-1)\n\n    gradc = - X[y == c].sum(axis=0)\n    wc = W.T[:, c]\n    exwc = np.exp(np.dot(X, wc))\n    gradc = gradc + (grad * exwc).dot(X)\n    return gradc\n\ntest_nll_gradient_c(nll_gradient_c)\n\n\n\nQ12: Implementing the full gradient\nUsing the function you just wrote, write a function to compute the full gradient with respect to the \\(C \\times d\\) weight matrix. Hint: The output should be a matrix!\n\n\nAnswer\n\ndef nll_gradient(self, X, y):\n    '''\n    Compute the negative log-likelihood loss.\n\n    Args:\n        X (array): An N x d matrix of observations.\n        y (int array): A length N vector of labels.\n    Returns:\n        grad (array): A C x d matrix representing the gradient with respect to W\n    '''\n    X = np.pad(X, [(0, 0), (0, 1)], constant_values=1.)\n    grad = 1 / np.exp(np.dot(X, self.weights.T)).sum(axis=-1)\n\n    grads = []\n    for c in range(self.classes):\n        gradc = - X[y == c].sum(axis=0)\n        wc = self.weights[c]\n        exwc = np.exp(np.dot(X, wc))\n        gradc = gradc + (grad * exwc).dot(X)\n        grads.append(gradc)\n    return np.stack(grads)\n\n\ntest_nll_grad(nll_gradient)\nMultinomialLogisticRegression.nll_gradient = nll_gradient\n\nPassed!\n\n\nNote if you are struggling with this problem, you can uncomment the following cell to get a valid gradient function based on your nll function. You can use this for testing to to complete the remaining questions.\n\n'''\ndef autograd_nll_gradient(self, X, y):\n    import autograd\n    def autograd_nll(W):\n        temp_model = MultinomialLogisticRegression(self.classes, X.shape[1])\n        temp_model.weights = W\n        return temp_model.nll(X, y)\n    return autograd.grad(autograd_nll)(self.weights)\nMultinomialLogisticRegression.nll_gradient = autograd_nll_gradient\n'''\n\nFinally, we will test out our multinomial logistic regression classifier on the MNIST dataset (https://en.wikipedia.org/wiki/MNIST_database), one of the most popular datasets in machine learning!\nWe’ll start by loading it as before. As we saw in class, before we can use logistic regression on image data, we first need to reshape it from a 3-dimensional array into a 2-dimensional matrix.\n\nimages, labels, label_names = get_dataset('mnist')\n\nimage_shape = images[0].shape                # Keep track of the original image shape\nX = images.reshape((images.shape[0], -1))    # Reshape into an N x d matrix X\ny = labels\nprint('Image shape: ', images.shape, ', X shape: ', X.shape)\n\n# Create the initial model\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\n\n\n\n\n\n\n\n\nImage shape:  (5000, 28, 28) , X shape:  (5000, 784)\n\n\n\n\nQ13: Repeat question 2 using the MNIST dataset\n\n\nAnswer\n\nXtrain, ytrain, Xtest, ytest = split_data(X, y)\n\nmodel = MultinomialLogisticRegression(classes=len(label_names), dims=X.shape[1])\n\n## Note that we need to pass \"image_shape\" here to reshape our data to a vector\nlosses = gradient_descent(model, Xtrain, ytrain, lr=1e-6, steps=2500, image_shape=image_shape, watch=False)\ntrain_acc, train_loss = model.accuracy(Xtrain, ytrain), model.nll(Xtrain, ytrain)\ntest_acc, test_loss = model.accuracy(Xtest, ytest), model.nll(Xtest, ytest)\n\nprint('Training accuracy: %.3f, loss: %.3f' % (train_acc, train_loss))\nprint('Test accuracy: %.3f, loss: %.3f' % (test_acc, test_loss))\n\nLoss 1331.97, accuracy: 0.90: 100%|██████████| 2500/2500 [00:50&lt;00:00, 49.83it/s]\n\n\nTraining accuracy: 0.901, loss: 1331.803\nTest accuracy: 0.882, loss: 611.217\n\n\nHere we’ll show an image and the corresponding prediction made by the model.\n\nprediction = model.predict(X)\nprobabilities = model.predict_probability(X)\n\n# Get the probability of the prediction [p(y=1) if prediction is 1 otherwise p(y=0)]\nprobability_of_prediction = probabilities[np.arange(probabilities.shape[0]), prediction]\n\n# Show an image and the corresponding prediction\nplt.imshow(X[0].reshape(image_shape), cmap='gray')\nprint('Prediction: %s, probability: %.3f' % (label_names[prediction[0]], probability_of_prediction[0]))\n\nPrediction: 4, probability: 0.690\n\n\n\n\n\n\n\n\n\n\n\nQ14: Visualize the learned weights\nThe Matplotlib function plt.imshow (or ax.imshow for subplots) will display a matrix as an image as shown above.\nReshape the weight vector for each of the 10 classes in your trained model into a \\(28 \\times 28\\) matrix (ignore the last, bias dimension for each). Then plot each weight vector using the imshow function.\nHint: Your weight matrix should be of size \\(10 \\times 785\\)\n\n\nAnswer\n\nf, ax = plt.subplots(5, 2, figsize=(4, 10))\nfor i in range(10):\n    ax[i // 2, i % 2].imshow(model.weights[i, :-1].reshape((28, 28)))\n    ax[i // 2, i % 2].set_title(f'Class: {i}')\n    ax[i // 2, i % 2].axis('off')\nplt.show()"
  },
  {
    "objectID": "calendar/calendar-old.html",
    "href": "calendar/calendar-old.html",
    "title": "Course Calendar",
    "section": "",
    "text": "Lecture\nDate\nTopics\nTextbook\nMaterials\nHomework\n\n\n\n\n1\n1/17\nCourse introduction, prediction models\nBook 1: 1.2.1-1.2.2, 7.1.1-7.2.4, 7.8.1, 7.8.2\nNotes\nHomework 1 assigned (Drive) Due: 1/25 11:59pm\nSolutions\n\n\n2\n1/22\nLinear regression, Gradient descent\nBook 1: 4.2.1, 4.2.2, 11.1-11.2.4\nNotes\nSlides\n\n\n\n3\n1/24\nLinear regression, maximum likelihood\nBook 1: 4.2.1, 4.2.2, 11.1-11.2.4\nNotes\nSlides\nHomework 2 assigned (Drive, hints) Due: 2/1 11:59pm\nSolutions\n\n\n4\n1/29\nLogistic regression\nBook 1: 10.1, 10.2.1, 10.2.3, 10.3.1-10.3.3\nNotes\nSlides\n\n\n\n5\n1/31\nLogistic regression\nBook 1: 10.1, 10.2.1, 10.2.3, 10.3.1-10.3.3\nNotes\nSlides\nNotebook\nFinal project ethics warm-up assigned (Description) Due: 2/8 11:59pm\n\n\n6\n2/5\nMultinomial logistic regression\nBook 1: 10.2.2\nNotes\nSlides\n\n\n\n7\n2/7\nFeature transforms\nBook 1: 13.1, 13.2\nNotes\nSlides\nHomework 3 assigned (Drive) Due: 2/15 11:59pm\nSolutions\n\n\n8\n2/12\nNeural networks\nBook 1: 13.1, 13.2\nNotebook\nSlides\n\n\n\n9\n2/14\nNeural networks (cont.)\nBook 1: 13.1, 13.2\nNotes\nSlides\nHomework 4 assigned (Drive) Due: 2/23 11:59pm\nSolutions\n\n\n10\n2/19\nAutomatic Differentiation\nBook 1: 13.3\nNotes\nSlides\n\n\n\n11\n2/21\nReverse-mode Automatic Differentiation\nBook 1: 13.3\nNotes\nSlides\n\n\n\n12\n2/26\nReverse-mode Automatic Differentiation (cont.)\nBook 1: 13.4.5, 13.5\nNotes\nSlides\n\n\n\n13\n2/28\nPyTorch\nBook 1: 13.5\nNotebook\nHomework 5 assigned (Drive) (Due: 3/7 11:59pm\n\n\n14\n3/4\nL1 & L2 regularization\nBook 1: 8.4\nNotes\nSlides\n\n\n\n15\n3/6\nRegularization (Cont.), Dropout\nBook 1: 8.4\nNotes\nSlides\n\n\n\n\n3/11\nNo class (Spring break)\n\n\n\n\n\n\n3/13\nNo class (Spring break)\n\n\n\n\n\n16\n3/18\nDropout, Initialization\nBook 1: 13.4.1-13.4.2, 14.2.4\nNotes\nSlides\n\n\n\n17\n3/20\nStochastic gradient descent\nBook 1: 13.4.3-13.4.5\nNotes\nSlides\nHomework 6 assigned (Drive) Due: 3/29 11:59pm\n\n\n18\n3/25\nStochastic gradient descent\nBook 1: 14.1-14.3\nNotes\nSlides\nFinal project proposal assigned (Description) Due: 4/4 11:59pm\n\n\n19\n3/27\nStochastic gradient descent\nBook 1: 14.1-14.3\nNotes\nSlides\n\n\n\n20\n4/1\nResidual networks and Normalization\nBook 1: 14.1-14.3\nSlides\n\n\n\n21\n4/3\nResidual networks and Normalization\nBook 1: 15.1, 15.2.1-15.2.3\nSlides\nHomework 7 assigned (Drive) Due: 4/11 11:59pm\n\n\n22\n4/8\nConvolutional Networks\nBook 1: 15.2.5-15.2.7\nSlides\n\n\n\n23\n4/10\nConvolutional Networks\nBook 1: 15.2.1-15.2.6\nSlides\nHomework 8 assigned (Drive) Due: 4/18 11:59pm\n\n\n24\n4/15\nLanguage models, LSTMs\nBook 1: 15.2.1-15.2.6, http://nlp.seas.harvard.edu/annotated-transformer/\nSlides\n\n\n\n25\n4/17\nAttention layers\nBook 1: 15.4.1, 15.4.2-15.4.6\n\nFinal project check-in assigned (Description) Due: 4/22 11:59pm\n\n\n26\n4/22\nTransformers\nBook 1: 15.4.1, 15.4.2-15.4.6\n\n\n\n\n27\n4/24\nTransformers (cont.), Large language models\n\n\nOptional extra credit homework assigned (Drive)\nDue:\n5/3 11:59pm (seniors)\n5/9 11:59pm (others)\n\n\n\n5/3\n\n\n\nFinal Project Due (11:59pm)\n(Description)"
  },
  {
    "objectID": "lecture3-logistic-regression/viz.html",
    "href": "lecture3-logistic-regression/viz.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std()) &gt; -0\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x, y=None):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  if y is None:\n    return tf.sigmoid(tf.dot(x, w.T))\n  else:\n    y = y.reshape((-1, 1))\n    z = tf.dot(x, w.T)\n    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) \n\nwrange = tf.linspace(-15, 5, 25)\nbrange = tf.linspace(-10, 10, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps &gt; 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())\nlosses = (errors)\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = σ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n\n\n\n\n\n\n\nviewof learningrate = Inputs.range([0, 100], {value: 1, step: 0.01, label: \" Learning rate\"})\n//learningrate = 0\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})"
  },
  {
    "objectID": "lecture3-logistic-regression/viz-discrete.html",
    "href": "lecture3-logistic-regression/viz-discrete.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std()) &gt; -0\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x, y=None):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  if y is None:\n    return tf.sign(tf.dot(x, w.T)) / 2 + 0.5\n  else:\n    y = y.reshape((-1, 1))\n    z = tf.sign(tf.dot(x, w.T))\n    return y * (tf.sign(z) / 2 + 0.5) + (1 - y) * (tf.sign(-z) / 2 + 0.5)\n\nwrange = tf.linspace(-15, 5, 25)\nbrange = tf.linspace(-10, 10, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean(predict(w, x, y), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps &gt; 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())\nlosses = (errors)\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = σ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n\n\n\n\n\n\n\nviewof learningrate = Inputs.range([0, 100], {value: 1, step: 0.01, label: \" Learning rate\"})\n//learningrate = 0\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})"
  },
  {
    "objectID": "plugins/drawer/Readme.html",
    "href": "plugins/drawer/Readme.html",
    "title": "RevealJS drawer plugin (3.2KB gzipped)",
    "section": "",
    "text": "Allows you to draw over your slides. Drawings are saved per slide and kept when slide is changed. Demo. Works with RevealJS Pointer Plugin.\n\nThis plugin only works with RevealJS v4.x or higher.\n\nNo external dependencies, only 7.5KB | &lt;3.2KB gzipped.\n\n\n\nCopy dist/drawer.js into plugins/drawer/drawer.js and import script:\n[...]\n&lt;script src=\"plugin/drawer/drawer.js\"&gt;&lt;/script&gt;\n[...]\nCopy dist/drawer.css into plugins/drawer/drawer.css and import style in &lt;head&gt;&lt;/head&gt;:\n[...]\n&lt;link rel=\"stylesheet\" href=\"plugin/drawer/drawer.css\" /&gt;\n[...]\nAdd RevealDrawer into your plugins initialization:\nplugins: [RevealDrawer];\n\n\n\n\n\nT - toggle drawing board\nD - toggle mode (drawing or not drawing)\nCtrl + Z - remove last line from current slide\n\"1\", \"2\", \"3\", \"4\" - change selected color (base on the order)\n\nIf you’re not changing anything in the Config then you should be able to show drawing board just by hitting T. By default the drawing is enabled.\n\nIf you hit D then drawing mode is toggled and it is going to switch to disabled mode (the pen icon is grayed out).\n\nIn drawing mode you’re not able to interact with other elements (like code) because it would disturb your drawing. That’s why switching between drawing and not drawing mode is important.\nEach time you draw sth, it is saved for this particular slide (slide includes all fragments). You can switch between slides and have a different drawing on each one. Ctrl + Z is available if you make a mistake in your drawing. It also works per slide even if you’re coming back from the different slide.\nYou’re able to change between colors using color icons or numbers on the keyboard. Each color has a number assigned to it and if you have 4 colors then numbers 1,2,3,4 on your keyboard are responsible for switching between them (default option). If you change default colors then numbers are assigned to new ones (base on how many colors you have). E.g. you’ve decided to have simpler colors, so your list looks like ['#FF0000', '#00FF00', '#0000FF'], now only 1,2,3 keys are available.\n\n\n\n\nYou can configure drawer key and tail length in plugin config.\nReveal.initialize({\n  drawer: {\n    toggleDrawKey: \"d\", // (optional) key to enable drawing, default \"d\"\n    toggleBoardKey: \"t\", // (optional) key to show drawing board, default \"t\"\n    colors: [\"#fa1e0e\", \"#8ac926\", \"#1982c4\", \"#ffca3a\"], // (optional) list of colors avaiable (hex color codes)\n    color: \"#FF0000\", // (optional) color of a cursor, first color from `codes` is a default\n    pathSize: 4, // (optional) path size in px, default 4\n  }\n})\nList of available keys:\n\n[“0”, “1”, “2”, “3”, “4”, “5”, “6”, “7”, “8”, “9”, “backspace”, “tab”, “enter”, “shift”, “ctrl”, “alt”, “pausebreak”, “capslock”, “esc”, “space”, “pageup”, “pagedown”, “end”, “home”, “leftarrow”, “uparrow”, “rightarrow”, “downarrow”, “insert”, “delete”, “a”, “b”, “c”, “d”, “e”, “f”, “g”, “h”, “i”, “j”, “k”, “l”, “m”, “n”, “o”, “p”, “q”, “r”, “s”, “t”, “u”, “v”, “w”, “x”, “y”, “z”, “leftwindowkey”, “rightwindowkey”, “selectkey”, “numpad0”, “numpad1”, “numpad2”, “numpad3”, “numpad4”, “numpad5”, “numpad6”, “numpad7”, “numpad8”, “numpad9”, “multiply”, “add”, “subtract”, “decimalpoint”, “divide”, “f1”, “f2”, “f3”, “f4”, “f5”, “f6”, “f7”, “f8”, “f9”, “f10”, “f11”, “f12”, “numlock”, “scrolllock”, “semicolon”, “equalsign”, “comma”, “dash”, “period”, “forwardslash”, “graveaccent”, “openbracket”, “backslash”, “closebracket”, “singlequote”]\n\n\n\n\n\nMake changes in src/plugin.js and run:\nnpm run build\nThis is going to produce dist/drawer.js with bundled iife file."
  },
  {
    "objectID": "plugins/drawer/Readme.html#installation",
    "href": "plugins/drawer/Readme.html#installation",
    "title": "RevealJS drawer plugin (3.2KB gzipped)",
    "section": "",
    "text": "Copy dist/drawer.js into plugins/drawer/drawer.js and import script:\n[...]\n&lt;script src=\"plugin/drawer/drawer.js\"&gt;&lt;/script&gt;\n[...]\nCopy dist/drawer.css into plugins/drawer/drawer.css and import style in &lt;head&gt;&lt;/head&gt;:\n[...]\n&lt;link rel=\"stylesheet\" href=\"plugin/drawer/drawer.css\" /&gt;\n[...]\nAdd RevealDrawer into your plugins initialization:\nplugins: [RevealDrawer];\n\n\n\n\n\nT - toggle drawing board\nD - toggle mode (drawing or not drawing)\nCtrl + Z - remove last line from current slide\n\"1\", \"2\", \"3\", \"4\" - change selected color (base on the order)\n\nIf you’re not changing anything in the Config then you should be able to show drawing board just by hitting T. By default the drawing is enabled.\n\nIf you hit D then drawing mode is toggled and it is going to switch to disabled mode (the pen icon is grayed out).\n\nIn drawing mode you’re not able to interact with other elements (like code) because it would disturb your drawing. That’s why switching between drawing and not drawing mode is important.\nEach time you draw sth, it is saved for this particular slide (slide includes all fragments). You can switch between slides and have a different drawing on each one. Ctrl + Z is available if you make a mistake in your drawing. It also works per slide even if you’re coming back from the different slide.\nYou’re able to change between colors using color icons or numbers on the keyboard. Each color has a number assigned to it and if you have 4 colors then numbers 1,2,3,4 on your keyboard are responsible for switching between them (default option). If you change default colors then numbers are assigned to new ones (base on how many colors you have). E.g. you’ve decided to have simpler colors, so your list looks like ['#FF0000', '#00FF00', '#0000FF'], now only 1,2,3 keys are available.\n\n\n\n\nYou can configure drawer key and tail length in plugin config.\nReveal.initialize({\n  drawer: {\n    toggleDrawKey: \"d\", // (optional) key to enable drawing, default \"d\"\n    toggleBoardKey: \"t\", // (optional) key to show drawing board, default \"t\"\n    colors: [\"#fa1e0e\", \"#8ac926\", \"#1982c4\", \"#ffca3a\"], // (optional) list of colors avaiable (hex color codes)\n    color: \"#FF0000\", // (optional) color of a cursor, first color from `codes` is a default\n    pathSize: 4, // (optional) path size in px, default 4\n  }\n})\nList of available keys:\n\n[“0”, “1”, “2”, “3”, “4”, “5”, “6”, “7”, “8”, “9”, “backspace”, “tab”, “enter”, “shift”, “ctrl”, “alt”, “pausebreak”, “capslock”, “esc”, “space”, “pageup”, “pagedown”, “end”, “home”, “leftarrow”, “uparrow”, “rightarrow”, “downarrow”, “insert”, “delete”, “a”, “b”, “c”, “d”, “e”, “f”, “g”, “h”, “i”, “j”, “k”, “l”, “m”, “n”, “o”, “p”, “q”, “r”, “s”, “t”, “u”, “v”, “w”, “x”, “y”, “z”, “leftwindowkey”, “rightwindowkey”, “selectkey”, “numpad0”, “numpad1”, “numpad2”, “numpad3”, “numpad4”, “numpad5”, “numpad6”, “numpad7”, “numpad8”, “numpad9”, “multiply”, “add”, “subtract”, “decimalpoint”, “divide”, “f1”, “f2”, “f3”, “f4”, “f5”, “f6”, “f7”, “f8”, “f9”, “f10”, “f11”, “f12”, “numlock”, “scrolllock”, “semicolon”, “equalsign”, “comma”, “dash”, “period”, “forwardslash”, “graveaccent”, “openbracket”, “backslash”, “closebracket”, “singlequote”]"
  },
  {
    "objectID": "plugins/drawer/Readme.html#developing",
    "href": "plugins/drawer/Readme.html#developing",
    "title": "RevealJS drawer plugin (3.2KB gzipped)",
    "section": "",
    "text": "Make changes in src/plugin.js and run:\nnpm run build\nThis is going to produce dist/drawer.js with bundled iife file."
  },
  {
    "objectID": "lecture9-optimization/viz.html",
    "href": "lecture9-optimization/viz.html",
    "title": "Stochastic Gradient descent visualization",
    "section": "",
    "text": "MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure()\nscatterfig\n`\n\n\n\n\n\n\n\nviewof batchsize = Inputs.range([1, 250], {value: 5, step: 1, label: \" Batch size\"})\n\n\n\n\n\n\n\nviewof learningrate = Inputs.range([0, 3], {value: 1, step: 0.01, label: \" Learning rate\"})\n\n\n\n\n\n\n\nviewof steps = Inputs.range([1, 100], {value: 1, step: 1, label: \"  Steps\"})\n\n\n\n\n\n\n\nviewof threed = Inputs.toggle({value: false, label: \"Show 3D\"})\nviewof distribution = Inputs.toggle({value: false, label: \"Show Dist.\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput()\nbatchlossplot = PlotlyInput(sync=lossplot)\n\nthreedlossplot = PlotlyFigure(hide_toolbar=False, overlay=False)\nthreedbatchlossplot = PlotlyFigure(hide_toolbar=False, overlay=False)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof l2 = Inputs.range([0, 10], {value: 0, step: 0.01, label: \"  L2 weight\"})\n\n\n\n\n\n\n\nviewof l1 = Inputs.range([0, 10], {value: 0, step: 0.01, label: \"  L1 weight\"})\n\n\n\n\n\n\n\nviewof momentum = Inputs.range([0, 1], {value: 0, step: 0.01, label: \" Momentum\"})\n\n\n\n\n\n\n\nviewof rmsprop = Inputs.range([0, 1], {value: 0, step: 0.01, label: \" RMSProp\"})\n\n\n\n\n\n\n\npy`\n# ${plots}\nthreedlossplot  if bool(${threed}) else ''\n`\n\n\n\n\n\n\n\n\nbatchloss = py`\n# ${plots}\nbatchlossplot\n`\n\n\n\n\n\n\n\nviewof newbatch = Inputs.button('New Batch')\n\n\n\n\n\n\n\nviewof transform = Inputs.select(['none', 'sin', 'cos', 'square'], {label: 'Weight transform'})\n\n\n\n\n\n\n\nviewof bscale = Inputs.range([0, 10], {value: 1, step: 0.01, label: \" Bias scale\"})\n\n\n\n\n\n\n\npy`\n# ${plots}\nthreedbatchlossplot if bool(${threed}) else ''\n`\n\n\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\n\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std())\n\ndef get_batch(batchsize, x, y):\n  batchinds = tf.randomUniformInt((batchsize,), 0, x.shape[0])\n  xbatch = tf.gather(x, batchinds)\n  ybatch = tf.gather(y, batchinds)\n  return xbatch, ybatch\n\ntransforms = dict(none=lambda a: a, sin=tf.sin, cos=tf.cos, square=tf.square)\ntransform = transforms[str(${transform})]\nscale = Tensor([[float(${bscale}), 1.]])\n\ndef predict(w, x):\n  w = transform(w.reshape((-1, 2)) * scale)\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  return tf.dot(x, w.T)\n\nwrange = tf.linspace(-3, 3, 25)\nbrange = tf.linspace(-3, 3, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = float(${l1})\nl2weight = float(${l2})\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean((predict(w, x) - y) ** 2, 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8, contours=dict(x=dict(show=True), y=dict(show=True))))\n\nbatchlossgrid = loss(paramgrid, xbatch, ybatch).reshape(ww.shape)\nbatchlosscontour = plotconvert(dict(x=wrange, y=brange, z=batchlossgrid, type='contour', ncontours=25,))\nbatchlosssurface = plotconvert(dict(x=wrange, y=brange, z=batchlossgrid, showlegend=False, showscale=False, type='surface', opacity=0.8, contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ndist = bool(${distribution})\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\nlr = float(${learningrate})\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\n\nmomentum = float(${momentum})\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = float(${rmsprop})\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  batchweights = batchweightlist[0] if dist else batchweightlist[-1]\n  fullweights = fullweightlist[0] if dist else fullweightlist[-1]\n\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweights)\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweights)\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweights - fullgrad).flatten())\n  batchweightlist.append((batchweights - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nif dist:\n  batchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(width=0))\nelse:\n  batchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'xaxis': {'range': [-3, 3]}, 'yaxis': {'range': [-3, 3]}})\nPlotlyReactive(batchlossplot, [batchlosscontour, startpoint, gradplot, batchgradplot], {'xaxis': {'range': [-3, 3]}, 'yaxis': {'range': [-3, 3]}})\n\nthreed = bool(${threed})\nif threed:\n  PlotlyReactive(threedlossplot, [losssurface, threedgradplot, threedbatchgradplot], {'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}}})\n  PlotlyReactive(threedbatchlossplot, [batchlosssurface], {'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}}})\nelse:\n  PlotlyReactive(threedlossplot, [])\n  PlotlyReactive(threedbatchlossplot, [])\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npy`\n# ${batch}\n# Plot the data scatterplot and prediction function\nscatterdata = dict(x=x.reshape((-1,)), y=y.reshape((-1,)), mode='markers', label='All data', marker=dict(color='rgba(17, 157, 255,0.5)'))\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color='firebrick'))\n\nxrange = tf.linspace(-2, 3, 50)\ncweights = Tensor(${weights})\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\nPlotlyReactive(scatterfig, [scatterdata, batchdata, pfunction], {'xaxis': {'range': [-2, 3]}, 'yaxis': {'range': [-2, 3]}})\n`\n\n\n\n\n\n\n\nbatch = py`\n# ${data}, ${newbatch}\nbatchsize = int(${batchsize})\nbatches = [get_batch(batchsize, x, y) for i in range(int(${steps}))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\npy`\n#eyetheta += 0.01\n\nthreed = bool(${threed})\nif False:\n  def rotate_z(x, y, z, theta):\n    w = x+1j*y\n    return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n\n  xe, ye, ze = rotate_z(1.25, 1.25, 1.25, eyetheta)\n\n  Plotly.relayout(threedlossplot.childNodes[0], to_js({'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}, 'dragmode': False, 'camera': {'eye': {'x': float(xe), 'y': float(ye), 'z': float(ze)}}}}, dict_converter=Object.fromEntries))\n  Plotly.relayout(threedbatchlossplot.childNodes[0], to_js({'scene': {'hovermode' : False, 'xaxis': {'range': [-3, 3], 'visible': False}, 'yaxis': {'range': [-3, 3], 'visible': False}, 'zaxis': {'visible': False}, 'dragmode': False, 'camera': {'eye': {'x': float(xe), 'y': float(ye), 'z': float(ze)}}}}, dict_converter=Object.fromEntries))\n`"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html",
    "href": "lecture5-neural-networks-intro/notes.html",
    "title": "Lecture 5: Neural networks",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\ndata = transpose(data_raw)"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#background-and-a-new-visualization",
    "href": "lecture5-neural-networks-intro/notes.html#background-and-a-new-visualization",
    "title": "Lecture 5: Neural networks",
    "section": "Background and a new visualization",
    "text": "Background and a new visualization\nSo far in this class we have seen how to make predictions of some output \\(y\\) given an input \\(\\mathbf{x}\\) using linear models. We saw that a reasonable model for continuous outputs \\((y\\in\\mathbb{R})\\) is linear regression.\n\\[\n\\textbf{Predict } y\\in \\textbf{ as } \\begin{cases} y = \\mathbf{x}^T\\mathbf{w}\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad (\\text{prediction function}) \\\\\n\\\\ p(y\\mid \\mathbf{x}, \\mathbf{w}, \\sigma^2) = \\mathcal{N}\\big(y\\mid \\mathbf{x}^T\\mathbf{w}, \\sigma^2) \\quad (\\text{probabilistic view})  \\end{cases}\n\\]\nA reasonable model for binary outputs \\((y\\in\\{0,1\\})\\) is logistic regression:\n\\[\n\\textbf{Predict } y\\in \\textbf{ as } \\begin{cases} y = \\mathbb{I}(\\mathbf{x}^T\\mathbf{w} &gt; 0)\\ \\quad\\quad\\quad\\quad\\quad (\\text{prediction function}) \\\\\n\\\\ p(y=1 \\mid \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{x}^T\\mathbf{w}) \\quad (\\text{probabilistic view})  \\end{cases}\n\\]\nA reasonable model for categorical outputs \\((y\\in\\{0,1,…,C\\})\\) is multinomial logistic regression:\n\\[\n\\textbf{Predict } y\\in \\textbf{ as } \\begin{cases} y = \\underset{c}{\\text{argmax}} \\ \\mathbf{x}^T\\mathbf{w}_c \\ \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\ \\  (\\text{prediction function}) \\\\\n\\\\ p(y=c \\mid \\mathbf{x}, \\mathbf{w}) = \\text{softmax}(\\mathbf{x}^T\\mathbf{W})_c \\quad (\\text{probabilistic view})  \\end{cases}\n\\]\nIn each of these cases, the core of our prediction is a linear function \\((\\mathbf{x}^T\\mathbf{w})\\) parameterized by a set of weights \\(\\mathbf{w}\\), with possibly some nonlinear function (e.g. \\(\\sigma(\\cdot)\\)), applied to the result. This type of function is commonly depicted using a diagram like the one shown below.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nEach node corresponds to a scalar value: the nodes on the left correspond to each input dimension and the node on the right corresponds to the prediction. Each edge represents multiplying the value on the left with a corresponding weight."
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#feature-transforms-revisited",
    "href": "lecture5-neural-networks-intro/notes.html#feature-transforms-revisited",
    "title": "Lecture 5: Neural networks",
    "section": "Feature transforms revisited",
    "text": "Feature transforms revisited\nIn the last lecture we saw that we can define more complex and expressive functions by transforming the inputs in various ways. For example, we can define a function as:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} ,\\quad \\phi(\\mathbf{x})  = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\ x_1x_2 \\\\ \\sin(x_1) \\\\ \\sin(x_2) \\end{bmatrix}\n\\]\nWriting this out we get:\n\\[\nf(\\mathbf{x}) = w_1 x_1 + w_2 x_2 + w_3 x_1^2 + w_4 x_2^2 + w_5 x_1 x_2 + w_6 \\sin(x_1) + w_7 \\sin(x_2)\n\\]\n\n\n\n\n\nIn code, we could consider transforming an entire dataset as follows:\n\nsquared_X = X ** 2              # x^2\ncross_X = X[:, :1] * X[:, 1:2]  # x_1 * x_2\nsin_X = np.sin(X)               # sin(x)\n\ntransformedX = np.concatenate([X, squared_X, cross_X, sin_X], axis=1)"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#non-linear-logistic-regression",
    "href": "lecture5-neural-networks-intro/notes.html#non-linear-logistic-regression",
    "title": "Lecture 5: Neural networks",
    "section": "Non-linear logistic regression",
    "text": "Non-linear logistic regression\nWe can create a non-linear logistic regression model using the feature-transfor approach as:\n\\[\np(y=1\\mid \\mathbf{x}, \\mathbf{w}) = \\sigma\\big( \\phi(\\mathbf{x})^T\\mathbf{w} \\big)\n\\]\nPictorally, we can represent this using the diagram we just introduced as:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThis demo application allows us to learn logistic regression models with different feature transforms. Hit the play button to start gradient descent!\nThis approach raises a big question though: how do we actually choose what transforms of our inputs to use?"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#learned-feature-transforms",
    "href": "lecture5-neural-networks-intro/notes.html#learned-feature-transforms",
    "title": "Lecture 5: Neural networks",
    "section": "Learned feature transforms",
    "text": "Learned feature transforms\nWe’ve already seen that we can learn a function by defining our function in terms of a set of parameters \\(\\mathbf{w}\\): \\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}\\] and then minimizing a loss as a function of \\(\\mathbf{w}\\) \\[\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\mathbf{Loss}(\\mathbf{w})\\] Which we can do with gradient descent: \\[\\mathbf{w}^{(k+1)} \\longleftarrow \\mathbf{w}^{(k)} - \\alpha \\nabla_{\\mathbf{w}} \\mathbf{Loss}(\\mathbf{w})\\]\nSo we didn’t choose \\(\\mathbf{w}\\) explicitly, we let our algorithm find the optimal values. Ideally, we could do the same thing for our feature transforms: let our algorithm choose the optimal functions to use. This raises the question:\nCan we learn the functions in our feature transform? The answer is yes! To see how, let’s start by writing out what this would look like. We’ll start with the feature transform framework we’ve already introduced, but now let’s replace the individual transforms with functions that we can learn.\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} ,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  g_1(x_1) \\\\ g_2(x_1) \\\\ g_3(x_1) \\\\ g_4(x_1) \\end{bmatrix}\n\\]\nThe key insight we’ll use here is that we’ve already seen how to learn functions: this is exactly what our regression models are doing! So if we want to learn a feature transform, we can try using one of these functions that we know how to learn this case: logistic regression. \\[g_i(\\mathbf{x}) = \\sigma(\\mathbf{x}^T \\mathbf{w}_i)\\] With this form, we get a new feature transform: \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_4) \\end{bmatrix}\n\\]\nHere we’ll call our original weight vector \\(\\mathbf{w}_0\\) to distinguish it from the others. If we choose different weights for these different transform functions, we can have different feature transforms!\nLet’s look at a very simple example: \\[\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix}, \\quad \\mathbf{w}_0 = \\begin{bmatrix} w_{01} \\\\ w_{02} \\end{bmatrix}\\] \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\end{bmatrix} =\n\\begin{bmatrix}  \\sigma(x_1 w_{11} + x_2 w_{12}) \\\\ \\sigma(x_1 w_{21} + x_2 w_{22}) \\\\ \\sigma(x_1 w_{31} + x_2 w_{32}) \\end{bmatrix}\n\\]\nIn this case, we can write out our prediction function explicitly as: \\[f(\\mathbf{x}) = w_{01} \\cdot\\sigma(x_1 w_{11} + x_2 w_{12}) + w_{02} \\cdot\\sigma(x_1 w_{21} + x_2 w_{22})+ w_{03} \\cdot\\sigma(x_1 w_{31} + x_2 w_{32}) \\]\nWe can represent this pictorially again as a node-link diagram:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe often omit the labels for compactness, which make it easy to draw larger models:"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#neural-networks-1",
    "href": "lecture5-neural-networks-intro/notes.html#neural-networks-1",
    "title": "Lecture 5: Neural networks",
    "section": "Neural networks",
    "text": "Neural networks\nWhat we’ve just seen is a neural network!\nTerminology-wise we call a single feature transform like \\(\\sigma(x_1 w_{11} + x_2 w_{12})\\) a neuron.\nWe call the whole set of transformed features the hidden layer: \\[\\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_4) \\end{bmatrix} \\]\nWe call \\(\\mathbf{x}\\) the input and \\(f(\\mathbf{x})\\) the output."
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#optimizing-neural-networks",
    "href": "lecture5-neural-networks-intro/notes.html#optimizing-neural-networks",
    "title": "Lecture 5: Neural networks",
    "section": "Optimizing neural networks",
    "text": "Optimizing neural networks\nWe can still define a loss function for a neural network in the same way we did with our simpler linear models. The only difference is that now we have more parameters to choose:\n\\[\n\\mathbf{Loss}(\\mathbf{w}_0,\\mathbf{w}_1,\\mathbf{w}_2,…)\n\\]\nLet’s look at the logistic regression negative log-likelihood loss for the simple neural network we saw above:\n\\[\np(y=1\\mid \\mathbf{x}, \\mathbf{w}_0,\\mathbf{w}_1,\\mathbf{w}_2, \\mathbf{w}_3)=\\sigma(\\phi(\\mathbf{x})^T \\mathbf{w}_0),\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\end{bmatrix}\n\\] \\[ = \\sigma\\big(w_{01} \\cdot\\sigma(x_1 w_{11} + x_2 w_{12}) + w_{02} \\cdot\\sigma(x_1 w_{21} + x_2 w_{22})+ w_{03} \\cdot\\sigma(x_1 w_{31} + x_2 w_{32}) \\big)\\]\n\\[\n\\mathbf{NLL}(\\mathbf{w}_0,..., \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\bigg[ y_i\\log p(y=1\\mid \\mathbf{x}, \\mathbf{w}_0,...) + (1-y_i)\\log p(y=0\\mid \\mathbf{x}, \\mathbf{w}_0,...) \\bigg]\n\\]\nWe see that we can write out a full expression for this loss in term of all the inputs and weights. We can even define the gradient of this loss with respect to all the weights:\n\\[\n\\nabla_{\\mathbf{w}_0...} = \\begin{bmatrix} \\frac{\\partial \\mathbf{NLL}}{\\partial w_{01}} \\\\ \\frac{\\partial \\mathbf{NLL}}{\\partial w_{02}} \\\\ \\frac{\\partial \\mathbf{NLL}}{\\partial w_{03}} \\\\ \\vdots\\end{bmatrix}\n\\]\nWhile computing this gradient by hand would be tedious, this does mean we can update all of these weights as before using gradient descent! In future classes, we’ll look at how to automate the process of computing this gradient.\nWe can see this in action for this network here."
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#neural-networks-with-matrix-notation",
    "href": "lecture5-neural-networks-intro/notes.html#neural-networks-with-matrix-notation",
    "title": "Lecture 5: Neural networks",
    "section": "Neural networks with matrix notation",
    "text": "Neural networks with matrix notation\nIt is often more convenient to write all of the weights that are used to create our hidden layer as a single large matrix:\n\\[\\mathbf{W}_1 = \\begin{bmatrix} \\mathbf{w}_1^T \\\\ \\mathbf{w}_2^T \\\\ \\mathbf{w}_3^T \\\\ \\vdots \\end{bmatrix}\\] With this, we can write our general neural network more compactly as: \\[f(\\mathbf{x})= \\sigma( \\mathbf{W}_1 \\mathbf{x})^T \\mathbf{w_0} \\] Or for a whole dataset: \\[\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\mathbf{x}_3^T \\\\ \\vdots \\end{bmatrix}\\]\n\\[f(\\mathbf{x})= \\sigma( \\mathbf{X}\\mathbf{W}_1 )\\mathbf{w_0}\\]"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#linear-transforms",
    "href": "lecture5-neural-networks-intro/notes.html#linear-transforms",
    "title": "Lecture 5: Neural networks",
    "section": "Linear transforms",
    "text": "Linear transforms\nThus far we’ve looked at a logistic regression feature transform as the basis of our neural network. Can we use linear regression as a feature transform?\nLet’s see what happens in our simple example: \\[\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix}, \\quad \\mathbf{w}_0 = \\begin{bmatrix} w_{01} \\\\ w_{02} \\end{bmatrix}\\] \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2 \\\\ \\mathbf{x}^T \\mathbf{w}_3 \\\\ \\end{bmatrix} =\n\\begin{bmatrix}  x_1 w_{11} + x_2 w_{12} \\\\ x_1 w_{21} + x_2 w_{22} \\\\ x_1 w_{31} + x_2 w_{32} \\\\\\end{bmatrix}\n\\] In this case, we can write out our prediction function explicitly as: \\[f(\\mathbf{x}) = w_{01}\\cdot (x_1 w_{11} + x_2 w_{12}) + w_{02} \\cdot(x_1 w_{21} + x_2 w_{22})+ w_{03} \\cdot(x_1 w_{31} + x_2 w_{32}) \\] \\[= (w_{11}w_{01}) x_1 +(w_{12}w_{01}) x_2 +  (w_{21}w_{02}) x_1 +(w_{22}w_{02}) x_2  +(w_{31}w_{03}) x_1 +(w_{32}w_{03}) x_2 \\]\n\\[\n= (w_{11}w_{01} + w_{21}w_{02} + w_{31}w_{03}) x_1 + (w_{12}w_{01} + w_{22} w_{02} + w_{32} w_{03}) x_2\n\\]\nWe see that we ultimately just end up with another linear function of \\(\\mathbf{x}\\) and we’re no better off than in our orginal case. We can see this in practice here.\nIn general: \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2\\\\ \\mathbf{x}^T \\mathbf{w}_3 \\\\ \\mathbf{x}^T \\mathbf{w}_4\\end{bmatrix}\n\\]\n\\[\nf(\\mathbf{x})= w_{01} (\\mathbf{x}^T \\mathbf{w}_1) +  w_{02} (\\mathbf{x}^T \\mathbf{w}_2) +...\n\\] \\[= \\mathbf{x}^T ( w_{01}\\mathbf{w}_1) +  \\mathbf{x}^T (w_{02} \\mathbf{w}_2) +...\n\\] Which is again just a linear function. The motivates the need for using a non-linear function like \\(\\sigma(\\cdot)\\) in our neurons."
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#activation-functions",
    "href": "lecture5-neural-networks-intro/notes.html#activation-functions",
    "title": "Lecture 5: Neural networks",
    "section": "Activation functions",
    "text": "Activation functions\nWhile we need a non-linear function as part of our neural network feature transform, it does not need to be the sigmoid function. A few other common choices are:\n\\[\n\\textbf{Sigmoid:}\\quad \\sigma(x) = \\frac{1}{1+e^{-x}}\n\\]\n\\[\n\\textbf{Hyperbolic tangent:}\\quad \\tanh(x) = \\frac{e^{2x}-1}{e^{2x}+1}\n\\]\n\\[\n\\textbf{Rectifed linear:}\\quad \\text{ReLU}(x) = \\max(x,\\ 0)\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe call these non-linear functions activation functions when used in neural networks. We’ll see other examples over the course of this class\nTry out different activation functions here."
  },
  {
    "objectID": "lecture5-neural-networks-intro/notes.html#multi-layer-neural-networks",
    "href": "lecture5-neural-networks-intro/notes.html#multi-layer-neural-networks",
    "title": "Lecture 5: Neural networks",
    "section": "Multi-layer neural networks",
    "text": "Multi-layer neural networks\nWhat we’ve seen so far is a single hidden-layer neural network. But there’s no reason we’re restricted to a single layer!"
  },
  {
    "objectID": "lecture5-neural-networks-intro/notebook.html",
    "href": "lecture5-neural-networks-intro/notebook.html",
    "title": "Logistic regression",
    "section": "",
    "text": "from demo import *\n\n\nimages, labels = get_dataset('cats_and_dogs')\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\nWarning: unknown JFIF revision number 0.00\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1403 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n\n\n\n\n\n\n\n\nprint('Shape of images: ', images.shape)\nprint('Shape of labels:', labels.shape)\n\nShape of images:  (1027, 64, 64)\nShape of labels: (1027,)\n\n\n\nX = images.reshape((images.shape[0], -1))\ny = labels\n\nprint('Shape of X:', X.shape)\nprint('Shape of y:', X.shape)\n\nShape of X: (23262, 4096)\nShape of y: (23262, 4096)\n\n\n\nw = np.zeros(X.shape[1] + 1)\n\n\ndef linear_function(X, w):\n    w, b = w[:-1], w[-1]\n    return np.dot(X, w) + b\n\ndef predict(X, w):\n    return (linear_function(X, w) &gt; 0).astype(float)\n\n\nimage = 3\nplt.imshow(images[image])\nprint('True label: ', y[image], ' prediction: ', predict(X[image], w))\n\nTrue label:  0.0  prediction:  0.0\n\n\n\n\n\n\n\n\n\n\ndef accuracy(X, y, w):\n    return np.mean(predict(X, w) == y)\n\nprint('Classifier accuracy: ', accuracy(X, y, w))\n\nClassifier accuracy:  0.48685491723466406\n\n\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef predict_probability(X, w):\n    return sigmoid(linear_function(X, w))\n\n\nimage = 4\nprint('True label: ', y[image], ' prediction: ', predict_probability(X[image], w))\n\nTrue label:  0.0  prediction:  0.5\n\n\n\ndef nll(w, X, y):\n    xw = linear_function(X, w)\n    prob_correct = sigmoid((2 * y - 1) * xw)\n    return -np.sum(np.log(prob_correct))\n\n\nnll(w, X, y)\n\n711.8621544350638\n\n\n\ndef dsigmoid(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\ndef grad(w, X, y):\n    xw = linear_function(X, w)\n    signed_xw = (2 * y - 1) * xw\n    prob_correct = sigmoid(signed_xw)\n    dw = -np.dot((1 / prob_correct) * dsigmoid(signed_xw) * (2 * y - 1.), X)\n    db = -np.sum((1 / prob_correct) * dsigmoid(signed_xw) * (2 * y - 1.))\n    return np.concatenate([dw, np.atleast_1d(db)])\n\nprint(grad( w, X, y) /X.shape[0]) \n\n[-0.01946607 -0.01871726 -0.02047718 ... -0.02952198 -0.02973923\n -0.01314508]\n\n\n\nf, ax = plt.subplots(1, 2)\nax[0].cla(), ax[1].cla()\nax[0].imshow(w[:-1].reshape(images[0].shape))\nax[1].imshow(grad( w, X, y)[:-1].reshape(images[0].shape))\n\n\n\n\n\n\n\n\n\ndef gradient_descent(value_and_grad, w0, lr, steps, X, y, images):\n    f, ax = plt.subplots(1, 3, figsize=(12,4))\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, X, y)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax]\n        display.clear_output(wait =True)\n        \n        ax[1].axis('off')\n        ax[2].axis('off')\n        ax[0].plot(losses)\n        ax[1].imshow(weights[:-1].reshape(images[0].shape))\n        ax[2].imshow(g[:-1].reshape(images[0].shape))\n        ax[1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n        display.display(f)\n        time.sleep(0.001)\n        \n    return weights, losses\n\n\nimport time\nfrom IPython import display\n\ndef nll_and_grad(w, X, y):\n    return nll(w, X, y), grad(w, X, y)\n\ndef gradient_descent(value_and_grad, w0, lr, steps, X, y):\n    f, ax = plt.subplots(1, 3, figsize=(12,4))\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, X, y)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax]\n        display.clear_output(wait =True)\n        \n        ax[1].axis('off')\n        ax[2].axis('off')\n        ax[0].plot(losses)\n        ax[1].imshow(weights[:-1].reshape(images[0].shape))\n        ax[2].imshow(g[:-1].reshape(images[0].shape))\n        ax[1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n        display.display(f)\n        time.sleep(0.001)\n        \n    return weights, losses\n\nw = np.zeros(X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, X, y)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef gradient_descent(value_and_grad, w0, lr, steps, X, y, images):\n    dims = np.array(images[0].shape).prod()\n\n    f, ax = plt.subplots(X.shape[1] // dims, 3, figsize=(15,8))\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, X, y)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax.flatten()]\n        [a.axis('off') for a in ax.flatten()[1:]]\n        display.clear_output(wait =True)\n        \n        ax[0, 0].plot(losses)\n        \n\n        ax[0, 1].imshow(weights[:dims].reshape(images[0].shape))\n        ax[0, 2].imshow(g[:dims].reshape(images[0].shape))\n        ax[0, 1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n\n        for j in range(1, ax.shape[0]):\n            ax[j, 1].imshow(weights[(dims * j):(dims * (j+1))].reshape(images[0].shape))\n            ax[j, 2].imshow(g[(dims * j):(dims * (j+1))].reshape(images[0].shape))\n            ax[j, 0].imshow((X[0, (dims * j):(dims * (j+1))].reshape(images[0].shape)) )\n\n        display.display(f)\n        time.sleep(0.001)\n        \n    return weights, losses\n\nphi_X = np.concatenate([X, X ** 2], axis=1)\nw = np.zeros(phi_X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, phi_X, y, images)\nplt.plot(losses)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:515, in _save(im, fp, tile, bufsize)\n    514 try:\n--&gt; 515     fh = fp.fileno()\n    516     fp.flush()\n\nAttributeError: '_idat' object has no attribute 'fileno'\n\nDuring handling of the above exception, another exception occurred:\n\nKeyboardInterrupt                         Traceback (most recent call last)\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 19 line 3\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=36'&gt;37&lt;/a&gt; phi_X = np.concatenate([X, X ** 2], axis=1)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=37'&gt;38&lt;/a&gt; w = np.zeros(phi_X.shape[1] + 1)\n---&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=38'&gt;39&lt;/a&gt; weights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, phi_X, y, images)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=39'&gt;40&lt;/a&gt; plt.plot(losses)\n\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 19 line 3\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=28'&gt;29&lt;/a&gt;         ax[j, 2].imshow(g[(dims * j):(dims * (j+1))].reshape(images[0].shape))\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=29'&gt;30&lt;/a&gt;         ax[j, 0].imshow((X[0, (dims * j):(dims * (j+1))].reshape(images[0].shape)) )\n---&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=31'&gt;32&lt;/a&gt;     display.display(f)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=32'&gt;33&lt;/a&gt;     time.sleep(0.001)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#Y106sZmlsZQ%3D%3D?line=34'&gt;35&lt;/a&gt; return weights, losses\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/IPython/core/display_functions.py:298, in display(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\n    296     publish_display_data(data=obj, metadata=metadata, **kwargs)\n    297 else:\n--&gt; 298     format_dict, md_dict = format(obj, include=include, exclude=exclude)\n    299     if not format_dict:\n    300         # nothing to display (e.g. _ipython_display_ took over)\n    301         continue\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:179, in DisplayFormatter.format(self, obj, include, exclude)\n    177 md = None\n    178 try:\n--&gt; 179     data = formatter(obj)\n    180 except:\n    181     # FIXME: log the exception\n    182     raise\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/decorator.py:232, in decorate.&lt;locals&gt;.fun(*args, **kw)\n    230 if not kwsyntax:\n    231     args, kw = fix(args, kw, sig)\n--&gt; 232 return caller(func, *(extras + args), **kw)\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:223, in catch_format_error(method, self, *args, **kwargs)\n    221 \"\"\"show traceback on failed format call\"\"\"\n    222 try:\n--&gt; 223     r = method(self, *args, **kwargs)\n    224 except NotImplementedError:\n    225     # don't warn on NotImplementedErrors\n    226     return self._check_return(None, args[0])\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:340, in BaseFormatter.__call__(self, obj)\n    338     pass\n    339 else:\n--&gt; 340     return printer(obj)\n    341 # Finally look for special method names\n    342 method = get_real_method(obj, self.print_method)\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/IPython/core/pylabtools.py:152, in print_figure(fig, fmt, bbox_inches, base64, **kwargs)\n    149     from matplotlib.backend_bases import FigureCanvasBase\n    150     FigureCanvasBase(fig)\n--&gt; 152 fig.canvas.print_figure(bytes_io, **kw)\n    153 data = bytes_io.getvalue()\n    154 if fmt == 'svg':\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/matplotlib/backend_bases.py:2366, in FigureCanvasBase.print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\n   2362 try:\n   2363     # _get_renderer may change the figure dpi (as vector formats\n   2364     # force the figure dpi to 72), so we need to set it again here.\n   2365     with cbook._setattr_cm(self.figure, dpi=dpi):\n-&gt; 2366         result = print_method(\n   2367             filename,\n   2368             facecolor=facecolor,\n   2369             edgecolor=edgecolor,\n   2370             orientation=orientation,\n   2371             bbox_inches_restore=_bbox_inches_restore,\n   2372             **kwargs)\n   2373 finally:\n   2374     if bbox_inches and restore_bbox:\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/matplotlib/backend_bases.py:2232, in FigureCanvasBase._switch_canvas_and_return_print_method.&lt;locals&gt;.&lt;lambda&gt;(*args, **kwargs)\n   2228     optional_kws = {  # Passed by print_figure for other renderers.\n   2229         \"dpi\", \"facecolor\", \"edgecolor\", \"orientation\",\n   2230         \"bbox_inches_restore\"}\n   2231     skip = optional_kws - {*inspect.signature(meth).parameters}\n-&gt; 2232     print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n   2233         *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n   2234 else:  # Let third-parties do as they see fit.\n   2235     print_method = meth\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:509, in FigureCanvasAgg.print_png(self, filename_or_obj, metadata, pil_kwargs)\n    462 def print_png(self, filename_or_obj, *, metadata=None, pil_kwargs=None):\n    463     \"\"\"\n    464     Write the figure to a PNG file.\n    465 \n   (...)\n    507         *metadata*, including the default 'Software' key.\n    508     \"\"\"\n--&gt; 509     self._print_pil(filename_or_obj, \"png\", pil_kwargs, metadata)\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:458, in FigureCanvasAgg._print_pil(self, filename_or_obj, fmt, pil_kwargs, metadata)\n    453 \"\"\"\n    454 Draw the canvas, then save it using `.image.imsave` (to which\n    455 *pil_kwargs* and *metadata* are forwarded).\n    456 \"\"\"\n    457 FigureCanvasAgg.draw(self)\n--&gt; 458 mpl.image.imsave(\n    459     filename_or_obj, self.buffer_rgba(), format=fmt, origin=\"upper\",\n    460     dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/matplotlib/image.py:1689, in imsave(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\n   1687 pil_kwargs.setdefault(\"format\", format)\n   1688 pil_kwargs.setdefault(\"dpi\", (dpi, dpi))\n-&gt; 1689 image.save(fname, **pil_kwargs)\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/PIL/Image.py:2432, in Image.save(self, fp, format, **params)\n   2429         fp = builtins.open(filename, \"w+b\")\n   2431 try:\n-&gt; 2432     save_handler(self, fp, filename)\n   2433 except Exception:\n   2434     if open_fp:\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/PIL/PngImagePlugin.py:1407, in _save(im, fp, filename, chunk, save_all)\n   1405     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n   1406 else:\n-&gt; 1407     ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n   1409 if info:\n   1410     for info_chunk in info.chunks:\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:519, in _save(im, fp, tile, bufsize)\n    517     _encode_tile(im, fp, tile, bufsize, fh)\n    518 except (AttributeError, io.UnsupportedOperation) as exc:\n--&gt; 519     _encode_tile(im, fp, tile, bufsize, None, exc)\n    520 if hasattr(fp, \"flush\"):\n    521     fp.flush()\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/PIL/ImageFile.py:538, in _encode_tile(im, fp, tile, bufsize, fh, exc)\n    535 if exc:\n    536     # compress to Python file-compatible object\n    537     while True:\n--&gt; 538         errcode, data = encoder.encode(bufsize)[1:]\n    539         fp.write(data)\n    540         if errcode:\n\nKeyboardInterrupt: \n\n\n\n\n\n\n\n\n\n\n\ndef gradient_descent(value_and_grad, w0, lr, steps, *args):\n    f, ax = plt.subplots(2, 3, figsize=(15,8))\n    X, y = args\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, *args)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax.flatten()]\n        [a.axis('off') for a in ax.flatten()[1:]]\n        display.clear_output(wait =True)\n        \n        ax[0, 0].plot(losses)\n        dims = np.array(images[0].shape).prod()\n\n        ax[0, 1].imshow(weights[:dims].reshape(images[0].shape))\n        ax[0, 2].imshow(g[:dims].reshape(images[0].shape))\n        ax[0, 1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n\n        ax[1, 1].imshow(weights[dims:-1].reshape(images[0].shape))\n        ax[1, 2].imshow(g[dims:-1].reshape(images[0].shape))\n        ax[1, 0].imshow((images[0] ** 2) )\n        display.display(f)\n        time.sleep(0.001)\n        \n    return weights, losses\n\nphi_X = np.concatenate([X, X ** 2], axis=1)\nw = np.zeros(phi_X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, phi_X, y)\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 31 line 3\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=36'&gt;37&lt;/a&gt; phi_X = np.concatenate([X, X ** 2], axis=1)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=37'&gt;38&lt;/a&gt; w = np.zeros(phi_X.shape[1] + 1)\n---&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=38'&gt;39&lt;/a&gt; weights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, phi_X, y)\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=39'&gt;40&lt;/a&gt; plt.plot(losses)\n\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 31 line 8\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=5'&gt;6&lt;/a&gt; weights = w0\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=6'&gt;7&lt;/a&gt; for i in range(steps):\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=7'&gt;8&lt;/a&gt;     loss, g = value_and_grad(weights, *args)\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=8'&gt;9&lt;/a&gt;     weights = weights - lr * g\n     &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=9'&gt;10&lt;/a&gt;     losses.append(loss)\n\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 31 line 5\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; def nll_and_grad(w, X, y):\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt;     return nll(w, X, y), grad(w, X, y)\n\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 31 line 5\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; def grad(w, X, y):\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt;     xw = linear_function(X, w)\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=5'&gt;6&lt;/a&gt;     signed_xw = (2 * y - 1) * xw\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=6'&gt;7&lt;/a&gt;     prob_correct = sigmoid(signed_xw)\n\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb Cell 31 line 3\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; def linear_function(X, w):\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt;     w, b = w[:-1], w[-1]\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture5-neural-networks-intro/notebook.ipynb#X52sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt;     return np.dot(X, w) + b\n\nFile ~/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/autograd/tracer.py:48, in primitive.&lt;locals&gt;.f_wrapped(*args, **kwargs)\n     46     return new_box(ans, trace, node)\n     47 else:\n---&gt; 48     return f_raw(*args, **kwargs)\n\nFile &lt;__array_function__ internals&gt;:200, in dot(*args, **kwargs)\n\nKeyboardInterrupt: \n\n\n\n\n\n\n\n\n\n\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport autograd.numpy as np\ncd = tfds.image_classification.CatsVsDogs()\ncd.download_and_prepare()\n\ndef preprocess(x):\n    x = tf.image.resize(x, (128, 128)).numpy()\n    x = hog(x, orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=False, channel_axis=-1)\n    return tf.tensor(x)\n\ndata = tfds.as_numpy(cd.as_dataset(split='train', as_supervised=True).map(lambda x, y: (tf.image.resize(x, (128, 128)), y)\n).batch(100000))\nimages, labels = next(iter(data))\nimages, labels = images[labels &lt;= 1], labels[labels &lt;= 1].astype(float)\n\nCorrupt JPEG data: 99 extraneous bytes before marker 0xd9\nWarning: unknown JFIF revision number 0.00\nCorrupt JPEG data: 396 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 162 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 252 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 65 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1403 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 214 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 2226 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 128 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 239 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 1153 extraneous bytes before marker 0xd9\nCorrupt JPEG data: 228 extraneous bytes before marker 0xd9\n\n\n\nimport tqdm.notebook as tqdm\nX = np.stack([hog(xi, orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=False, channel_axis=-1) for xi in tqdm.tqdm(images)])\n\n\n\n\n\nimport time\nfrom IPython import display\n\ndef nll_and_grad(w, X, y):\n    return nll(w, X, y), grad(w, X, y)\n\ndef gradient_descent(value_and_grad, w0, lr, steps, X, y):\n    f, ax = plt.subplots(1, 3, figsize=(12,4))\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, X, y)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax]\n        display.clear_output(wait =True)\n        \n        ax[1].axis('off')\n        ax[2].axis('off')\n        ax[0].plot(losses)\n        #ax[1].imshow(weights[:-1].reshape(images[0].shape))\n        #ax[2].imshow(g[:-1].reshape(images[0].shape))\n        ax[1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n        display.display(f)\n        time.sleep(0.001)\n        \n        \n        \n\n    return weights, losses\n\nw = np.zeros(X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, X, y)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport time\nfrom IPython import display\n\ndef nll_and_grad(w, X, y):\n    return nll(w, X, y), grad(w, X, y)\n\ndef gradient_descent(value_and_grad, w0, lr, steps, X, y):\n    f, ax = plt.subplots(1, 3, figsize=(12,4))\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, X, y)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        [a.cla() for a in ax]\n        display.clear_output(wait =True)\n        \n        ax[1].axis('off')\n        ax[2].axis('off')\n        ax[0].plot(losses)\n        ax[1].imshow(weights[:-1].reshape(images[0].shape))\n        ax[2].imshow(g[:-1].reshape(images[0].shape))\n        ax[1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n        display.display(f)\n        time.sleep(0.001)\n        \n        \n        \n\n    return weights, losses\n\nw = np.zeros(X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, X, y)\n\n\n\nfrom skimage.feature import hog\nfrom skimage import data, exposure\n\n\nimage = data.astronaut()\n\nfd, hog_image = hog(images[0][:, :, None], orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=True, channel_axis=-1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n\nax1.axis('off')\nax1.imshow(images[0], cmap=plt.cm.gray)\nax1.set_title('Input image')\n\n# Rescale histogram for better display\nhog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\nax2.axis('off')\nax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\nax2.set_title('Histogram of Oriented Gradients')\nplt.show()\n\n\n\n\n\n\n\n\n\n64 * 64\n\n4096\n\n\n\nf, ax = plt.subplots(1, 3, figsize=(12, 4))\nvedges = (images[:, :-2] - images[:, 2:])\nhedges = (images[:, :, :-2] - images[:, :, 2:])\n\nax[0].imshow(images[0])\nax[1].imshow(vedges[0])\nax[2].imshow(hedges[0])\n\n\n\n\n\n\n\n\n\ndef gradient_descent(value_and_grad, w0, lr, steps, *args):\n    f, ax = plt.subplots(3, 3, figsize=(15,12))\n    X, y = args\n\n    losses = []\n    weights = w0\n    for i in range(steps):\n        loss, g = value_and_grad(weights, *args)\n        weights = weights - lr * g\n        losses.append(loss)\n\n\n        # Plotting code\n        \n        if i % 3 == 0:\n            [a.cla() for a in ax.flatten()]\n            [a.axis('off') for a in ax.flatten()[1:]]\n            display.clear_output(wait =True)\n            \n            ax[0, 0].plot(losses)\n            dims = np.array(images[0].shape).prod()\n            vdims = np.array(vedges[0].shape).prod()\n\n            ax[0, 1].imshow(weights[:dims].reshape(images[0].shape))\n            ax[0, 2].imshow(g[:dims].reshape(images[0].shape))\n            ax[0, 1].set_title('Loss: %.3f, accuracy: %.3f' % (loss, accuracy(X, y, weights)))\n\n            ax[1, 1].imshow(weights[dims:(dims + vdims)].reshape(vedges[0].shape))\n            ax[1, 2].imshow(g[dims:(dims + vdims)].reshape(vedges[0].shape))\n            ax[1, 0].imshow((vedges[0]) )\n            display.display(f)\n            time.sleep(0.001)\n        \n    return weights, losses\nphi_X = np.concatenate([X, vedges.reshape((X.shape[0], -1)), hedges.reshape((X.shape[0], -1))], axis=1)\nw = np.zeros(phi_X.shape[1] + 1)\nweights, losses = gradient_descent(nll_and_grad, np.zeros_like(w), 0.0000003, 500, phi_X, y)\nplt.plot(losses)"
  },
  {
    "objectID": "lecture13-RNNs/figures.html",
    "href": "lecture13-RNNs/figures.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport contextlib\nwith open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n    from manim import *\nimport autograd.numpy as np\n\n\nclass LectureScene(Scene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n\nclass ThreeDLectureScene(ThreeDScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n    \n\nclass VectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-7.5, 7.5, 1],\n            y_range=[-5, 5, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n        \n        #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass PositiveVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-2.5, 12.5, 1],\n            y_range=[-1, 9, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n                #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass ComparisonVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax1 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        self.ax2 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        axgroup = Group(self.ax1, self.ax2)\n        axgroup.arrange_in_grid(buf=2)\n        \n        #axes_labels.set_color(GREY)\n        self.add(axgroup)\nfrom manim_ml.neural_network import NeuralNetwork, Convolutional2DLayer, MaxPooling2DLayer\n\n\ntype(BLACK)\n\n\n%%manim -pql -v WARNING Conv\ndef make_sequence(numbers, sl=0.5, colors=BLACK, fills=WHITE, text_colors=None, opacity=1.,  annot=True, stride=1, padding=0):\n    n = len(numbers)\n    squares = []\n\n    if type(colors) is str:\n        colors = [colors] * n\n    if text_colors is None:\n        text_colors = colors\n    elif type(text_colors) is str:\n        text_colors = [text_colors] * n\n    if type(fills) is str:\n        fills = [fills] * n\n\n    for i in range(n):\n        pos = i * stride * sl * RIGHT\n        square = Square(color=colors[i], fill_color=fills[i], side_length=sl,  fill_opacity=opacity).move_to(pos)\n        if annot:\n            text = Text(str(numbers[i]), color=text_colors[i]).scale(sl).move_to(pos)\n            squares.append(VGroup(square, text))\n        else:\n            squares.append(VGroup(square))\n    \n    if padding &gt; 0:\n        pads = []\n        for i in range(padding):\n            pos = (n + i) * sl * RIGHT\n            pads.append(Text('0', color=GRAY).scale(sl).move_to(pos))\n            pos = (-(i + 1)) * sl * RIGHT\n            pads.append(Text('0', color=GRAY).scale(sl).move_to(pos))\n        return VGroup(*squares), VGroup(*pads)\n\n    return VGroup(*squares)\n\ndef make_stack(numbers, sl=0.5, colors=BLACK, fills=WHITE, text_colors=None, opacity=1., annot=True, stride=1):\n    n = len(numbers)\n\n    if type(colors) is str:\n        colors = [colors] * n\n    if text_colors is None:\n        text_colors = colors\n    elif type(text_colors) is str:\n        text_colors = [text_colors] * n\n    if type(fills) is str:\n        fills = [fills] * n\n\n    seqs = []\n    for i in range(n):\n        seqs.append(make_sequence(numbers[i], sl, colors[i], fills[i], text_colors[i], opacity, annot, stride).shift(i * sl * DOWN))\n    return VGroup(*seqs)\n\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (kernel size: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        eq = Text(f'Output[{0 :2}]=({seqarr[0] :2})({kernelarr[0] :2})+({seqarr[1] :2})({kernelarr[1] :2})+({seqarr[2] :2})({kernelarr[2] :2})={outputarr[0] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n        self.add(sequence, output, highlight, eq)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(12):\n            neweq = Text(f'Output[{i+1 :2}]=({seqarr[0 + i] :2})({kernelarr[0] :2})+({seqarr[1 + i] :2})({kernelarr[1] :2})+({seqarr[2 + i] :2})({kernelarr[2] :2})={outputarr[1 + i] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), FadeIn(neweq), FadeOut(eq))\n            eq = neweq\n        self.wait(2)\n\n\nclass Mat\n\n\n%%manim -pql -v WARNING MovingAround\n\nclass MovingAround(LectureScene):\n    def construct(self):\n        sentence = \"[START] I love purple cats [.] Purple cats are great [END]\".split()\n        length = len(sentence)\n        heights = np.linspace(1, -1, length)\n        yrange = 2\n        rowheight = (heights[1] - heights[0]) * yrange\n\n        dim = 3\n\n        embeddings = np.random.randn(length, dim)\n        rows = []\n        for r, (word, y) in enumerate(zip(sentence, heights)):\n            label = Text(word, color='BLACK').scale( 2 * yrange * (1 / length)).shift(-5 * RIGHT + yrange * y * UP)\n\n            row = []\n            for c in range(dim):\n                box = Square(side_length=rowheight, color=BLACK, fill_color=LIGHTER_GRAY, fill_opacity=1.).shift(-3 * RIGHT + yrange * y * UP).shift(rowheight * RIGHT * c)\n                num = Text('%.2f' % embeddings[r, c], color=BLACK).scale( 1.25 * yrange * (1 / length) ).shift(-3 * RIGHT + yrange * y * UP).shift(rowheight * RIGHT * c)\n                row.append(VGroup(box, num))\n            rows.append(VGroup(label, VGroup(*row)))\n        rows = VGroup(*rows)\n\n        wq = np.random.randn(dim, dim)\n        wk = np.random.randn(dim, dim)\n        wv = np.random.randn(dim, dim)\n\n        ms = []\n        for (mat, y, color) in [(wq, 2, GREEN), (wk, 0, BLUE), (wv, -2, ORANGE)]:\n            m = []\n            for r in range(dim):\n                for c in range(dim):\n                    box = Square(side_length=rowheight, color=BLACK, fill_color=LIGHTER_GRAY, fill_opacity=1.).shift(-1 * RIGHT +  y * UP).shift(rowheight * RIGHT * c + rowheight * UP * r)\n                    num = Text('%.2f' % mat[r, c], color=BLACK).scale( 1.25 * yrange * (1 / length) ).shift(-1 * RIGHT + y * UP).shift(rowheight * RIGHT * c + rowheight * UP * r)\n                    m.append(VGroup(box, num))\n            ms.append(VGroup(*m))\n        ms = VGroup(*ms)\n\n        self.add(rows, ms)\n\n\ndef convolution1d(x, kernel):\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1)\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            output[i] += x[i + j] * kernel[j]\n    return output\n\n\ndef convolution1d(x, kernel):\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1)\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            output[i] += np.dot(x[i + j], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1) + 2 * padding\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            ind = i + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0, stride=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        for j in range(kernel_width):\n            ind = i * stride + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0, stride=1, dialation=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - dialation * (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        for j in range(kernel_width):\n            ind = i * stride + j * dialation - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, bias=0, padding=0, stride=1, dialation=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - dialation * (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        output[i] = bias\n        for j in range(kernel_width):\n            ind = i * stride + j * dialation - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef maxpool1d(x, window, padding=0, stride=1):\n    input_size = len(x)\n\n    output_size = (input_size - (window - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        output[i] = -np.infty\n        for j in range(window):\n            ind = i * stride + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] = np.maximum(x[ind], output[i])\n    return output\n\n\ndef avgpool1d(x, window, padding=0, stride=1):\n    input_size = len(x)\n\n    output_size = (input_size - (window - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        output[i] = 0.\n        for j in range(window):\n            ind = i * stride + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += x[ind] / window\n    return output\n\n\n\nfrom manim import *\n\n\n%%manim -pql -v WARNING MovingAround\n\nfrom manim_ml.neural_network import NeuralNetwork, FeedForwardLayer\nclass MovingAround(Scene):\n    def construct(self):\n        nn = NeuralNetwork([\n            FeedForwardLayer(num_nodes=3),\n            FeedForwardLayer(num_nodes=5),\n            FeedForwardLayer(num_nodes=3)\n        ])\n        self.add(nn)\n        # Make the animation\n        forward_pass_animation = nn.make_forward_pass_animation()\n        # Play the animation\n        self.play(forward_pass_animation)\n\n\nimport manim_ml\n\n\nmanim_ml.ThreeDScene"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html",
    "href": "lecture6-backpropagation/notes.html",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#neural-networks-with-matrices",
    "href": "lecture6-backpropagation/notes.html#neural-networks-with-matrices",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Neural networks with matrices",
    "text": "Neural networks with matrices\nLet’s return to our simple neural network example, where we have 2 inputs and 3 neurons (transforms): \\[\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix}, \\quad \\mathbf{w}_0 = \\begin{bmatrix} w_{01} \\\\ w_{02} \\end{bmatrix}\\] \\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}_0,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{w}_1) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_2) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{w}_3) \\end{bmatrix} =\n\\begin{bmatrix}  \\sigma(x_1 w_{11} + x_2 w_{12}) \\\\ \\sigma(x_1 w_{21} + x_2 w_{22}) \\\\ \\sigma(x_1 w_{31} + x_2 w_{32}) \\end{bmatrix}\n\\]\nAgain, we can represent this pictorially again as a node-link diagram:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nLet’s look at a more compact way to write this, using a weight matrix for the neural network layer. Let’s look at the transform before we apply the sigmoid function:\n\\[\n\\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2 \\\\ \\mathbf{x}^T \\mathbf{w}_3 \\end{bmatrix} =\n\\begin{bmatrix}  x_1 w_{11} + x_2 w_{12} \\\\ x_1 w_{21} + x_2 w_{22} \\\\ x_1 w_{31} + x_2 w_{32} \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} \\\\w_{21} & w_{22} \\\\ w_{31} & w_{32} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\n\\]\nIf we define a matrix \\(\\mathbf{W}\\) for all of the weights as:\n\\[\n\\mathbf{W} = \\begin{bmatrix} w_{11} & w_{12} \\\\w_{21} & w_{22} \\\\ w_{31} & w_{32} \\end{bmatrix}\n\\]\nwe get:\n\\[\n\\begin{bmatrix}  \\mathbf{x}^T \\mathbf{w}_1 \\\\ \\mathbf{x}^T \\mathbf{w}_2 \\\\ \\mathbf{x}^T \\mathbf{w}_3 \\end{bmatrix} = \\mathbf{W}\\mathbf{x} = (\\mathbf{x}^T\\mathbf{W}^T)^T\n\\]\nIf we let \\(h\\) be the number of neuron (or hidden layer units) then this is a \\(h \\times d\\) matrix. Therefore, we can write our transform as:\n\\[\n\\phi(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}^T)^T, \\quad f(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}^T) \\mathbf{w}_0\n\\]\nRecall that if we have multiple observations, as in a dataset, we define them together as an \\(N \\times d\\) matrix \\(\\mathbf{X}\\) such that each row is an observation:\n\\[\n\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\mathbf{x}_3^T  \\\\ \\vdots  \\end{bmatrix}\n\\]\nTherefore, we can transform all of these observations at once by multiplying this matrix by \\(\\mathbf{W}^T\\).\n\\[\n\\phi(\\mathbf{X}) = \\sigma(\\mathbf{X}\\mathbf{W}^T)^T = \\begin{bmatrix} \\sigma(\\mathbf{x}_1^T\\mathbf{w}_1) & \\sigma(\\mathbf{x}_1^T\\mathbf{w}_2) & \\dots  & \\sigma(\\mathbf{x}_1^T\\mathbf{w}_h \\\\\n\\sigma(\\mathbf{x}_2^T\\mathbf{w}_1) & \\sigma(\\mathbf{x}_2^T\\mathbf{w}_2) & \\dots  & \\sigma(\\mathbf{x}_2^T\\mathbf{w}_h) \\\\\n\\vdots & \\vdots & \\ddots  & \\vdots \\\\\n\\sigma(\\mathbf{x}_N^T\\mathbf{w}_1) & \\sigma(\\mathbf{x}_N^T\\mathbf{w}_2) & \\dots  & \\sigma(\\mathbf{x}_N^T\\mathbf{w}_h)\n\\end{bmatrix}\n\\]\nWe see that this is an \\(N \\times h\\) matrix where each row is a transformed observation! We can then write our full prediction function as\n\\[\n\\quad f(\\mathbf{x}) = \\sigma(\\mathbf{X}\\mathbf{W}^T) \\mathbf{w}_0\n\\]\nTo summarize:\n\n\\(\\mathbf{X}: \\quad N \\times d\\) matrix of observations\n\\(\\mathbf{W}: \\quad h \\times d\\) matrix of network weights\n\\(\\mathbf{w}_0: \\quad h\\ (\\times 1)\\) vector of linear regression weights\n\nIf we check that our dimensions work for matrix multiplication we see that we get the \\(N\\times 1\\) vector of predictions we are looking for!\n\\[\n(N \\times d) (h \\times d)^T (h \\times 1) \\rightarrow (N \\times d) (d \\times h) (h \\times 1) \\rightarrow (N \\times h) (h \\times 1)\n\\]\n\\[\n\\longrightarrow (N \\times1)\n\\]"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#benefits-of-neural-networks",
    "href": "lecture6-backpropagation/notes.html#benefits-of-neural-networks",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Benefits of neural networks",
    "text": "Benefits of neural networks\nWe’ve seen that the neural network transform is still fairly restrictive, with a limited number of neurons we can’t fit any arbitrary function. In fact, if we choose our feature transforms wisely we can do better than than a neural network.\nFor example, consider the simple 3-neuron network above. We can see that if we try to fit a circular dataset with it, it performs worse than an explicit transform with \\(x_1^2\\) and \\(x_2^2\\).\n\nCircle dataset with neural network\nCircle dataset with \\(x_1^2\\) and \\(x_2^2\\):\n\nSimilarly, for a cross dataset, we can do better with the feature transform that includes \\(x_1x_2\\) as a feature:\n\nCross dataset with neural network\nCross dataset with \\(x_1x_2\\)\n\nHowever, if we choose the wrong feature transform for a given dataset, we do far worse.\n\nCircle dataset with \\(x_1 x_2\\)\nCross dataset with \\(x_1^2\\) and \\(x_2^2\\)\n\nWe see that the real power of the neural network here is the ability to adapt the transform to the given dataset, without needing to carefully choose the correct transform!"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#deep-neural-networks",
    "href": "lecture6-backpropagation/notes.html#deep-neural-networks",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Deep Neural Networks",
    "text": "Deep Neural Networks\nWhat we’ve seen so far is a neural network with a single hidden layer, meaning that we create a feature transform for our data and then simply use that to make our prediction. We see that each individual feature transform is a bit limited, being just a logistic regression function.\n\\[\\phi(\\mathbf{x})_i = \\sigma(\\mathbf{x}^T \\mathbf{w}_i)\\]\nNo matter what we set \\(\\mathbf{w}_i\\) this transform would not be able to replicate a transform like \\(\\phi(\\mathbf{x})_i = x_i^2\\). However, we’ve already seen a way to make logistic regression more expressive: neural networks!\nThe idea behind a deep or multi-layer neural network is that we can apply this idea of neural network feature transforms recursively:\n\\[\\phi(\\mathbf{x})_i = \\sigma(\\sigma(\\mathbf{x}^T\\mathbf{W}^T) \\mathbf{w}_i)\\]\nHere we’ve transformed our input before computing our feature transform. In terms of a dataset we can write the full prediction function for this 2-layer network as:\n\\[\nf(\\mathbf{X}) = \\sigma(\\sigma(\\mathbf{X}\\mathbf{W}_1^T)\\mathbf{W}_2^T)\\mathbf{w}_0\n\\]\nWe’ve now defined a set of weight parameters for each of our 2 hidden layers \\(\\mathbf{W}_1\\) and \\(\\mathbf{W}_2\\). It’s a little easier to see what’s happening here if we look a our diagram for this case:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe can see that stacking these transforms allows us to fit even more complicated functions here. Note that we are still not limited to doing this twice! We can fit many layers of transforms:\n\nLater on in the semester we’ll talk in more depth about the effect of the number of layers and the number of neurons per layer!"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#optimizing-neural-networks",
    "href": "lecture6-backpropagation/notes.html#optimizing-neural-networks",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Optimizing neural networks",
    "text": "Optimizing neural networks\nWe can still define a loss function for a neural network in the same way we did with our simpler linear models. The only difference is that now we have more parameters to choose:\n\\[\n\\mathbf{Loss}(\\mathbf{w}_0,\\mathbf{W}_1,...)\n\\]\nLet’s look at the logistic regression negative log-likelihood loss for the simple neural network we saw above (for simplicity we’ll just call the network weights \\(\\mathbf{W}\\)). The probability of class 1 is estimated as:\n\\[\np(y=1\\mid \\mathbf{x}, \\mathbf{w}_0,\\mathbf{W})=\\sigma(\\phi(\\mathbf{x})^T \\mathbf{w}_0) = \\sigma(\\sigma(\\mathbf{x}^T \\mathbf{W}^T) \\mathbf{w}_0),\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  \\sigma(\\mathbf{x}^T \\mathbf{W}_{1}) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{W}_{2}) \\\\ \\sigma(\\mathbf{x}^T \\mathbf{W}_{3}) \\end{bmatrix}\n\\] \\[ = \\sigma\\big(w_{01} \\cdot\\sigma(x_1 W_{11} + x_2 W_{12}) + w_{02} \\cdot\\sigma(x_1 W_{21} + x_2 W_{22})+ w_{03} \\cdot\\sigma(x_1 W_{31} + x_2 W_{32}) \\big)\\]\nTherefore the negative log-likelihood is:\n\\[\n\\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\bigg[ y_i\\log p(y=1\\mid \\mathbf{x}, \\mathbf{w}_0,\\mathbf{W}) + (1-y_i)\\log p(y=0\\mid \\mathbf{x}, \\mathbf{w}_0,\\mathbf{W}) \\bigg]\n\\]\n\\[\n= -\\sum_{i=1}^N \\log \\sigma\\big((2y_i-1) \\phi(\\mathbf{x}_i)^T \\mathbf{w}\\big)\n\\]\nWe see that we can write out a full expression for this loss in term of all the inputs and weights. We can even define the gradient of this loss with respect to all the weights:\n\\[\n\\nabla_{\\mathbf{w}_0} \\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = \\begin{bmatrix} \\frac{\\partial \\mathbf{NLL}}{\\partial w_{01}} \\\\ \\frac{\\partial \\mathbf{NLL}}{\\partial w_{02}} \\\\ \\frac{\\partial \\mathbf{NLL}}{\\partial w_{03}} \\\\ \\vdots\\end{bmatrix}, \\quad \\nabla_{\\mathbf{W}}\\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) =\n\\begin{bmatrix} \\frac{\\partial \\mathbf{NLL}}{\\partial W_{11}} &  \\frac{\\partial \\mathbf{NLL}}{\\partial W_{12}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{1d}}  \\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{21}} &  \\frac{\\partial \\mathbf{NLL}}{\\partial W_{22}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{2d}} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial \\mathbf{NLL}}{\\partial W_{h1}} &  \\frac{\\partial \\mathbf{NLL}}{\\partial W_{h2}} & \\dots & \\frac{\\partial \\mathbf{NLL}}{\\partial W_{hd}}\n\\end{bmatrix}\n\\]\nNote that as \\(\\mathbf{W}\\) is a matrix, the gradient with respect to \\(\\mathbf{W}\\) is also a matrix! Our gradient descent algorithm can proceed in the same way it did for our linear models, but here we now need to update both sets of parameters:\n\\[\n\\mathbf{w}_0^{(k+1)} \\longleftarrow \\mathbf{w}_0^{(k)} -\\alpha \\nabla_{\\mathbf{w}_0} \\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y}), \\quad \\mathbf{W}^{(k+1)} \\longleftarrow \\mathbf{W}^{(k)} -\\alpha \\nabla_{\\mathbf{W}} \\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y})\n\\]\nThe important question now becomes: how do we compute these gradients?"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#motivation",
    "href": "lecture6-backpropagation/notes.html#motivation",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Motivation",
    "text": "Motivation\nWe saw above that the NLL for logistic regression with a neural network is:\n\\[\n\\mathbf{NLL}(\\mathbf{w}_0,\\mathbf{W}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log \\sigma\\big((2y_i-1) \\phi(\\mathbf{x}_i)^T \\mathbf{w}\\big)\n\\]\nIf we write this out in terms of the individual values we get:\n\\[\n= -\\sum_{i=1}^N \\log \\sigma\\big((2y_i-1)\\sigma\\big(w_{01} \\cdot\\sigma(x_1 W_{11} + x_2 W_{12}) + w_{02} \\cdot\\sigma(x_1 W_{21} + x_2 W_{22})+ w_{03} \\cdot\\sigma(x_1 W_{31} + x_2 W_{32}) \\big)\\big)\n\\]\nWe could use the same approach as usual to find the derivative of this loss with respect to each individual weight parameter, but it would be very tedious and this is only a single-layer network! Things would only get more complicated with more layers. Furthermore if we changed some aspect of the network, like the activation function, we’d have to do it all over again.\nIdeally we’d like a programmatic way to compute derivatives. Knowing that we compute derivatives using a fixed set of known rules, this should be possible!"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#the-chain-rule-revisited",
    "href": "lecture6-backpropagation/notes.html#the-chain-rule-revisited",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "The chain rule revisited",
    "text": "The chain rule revisited\nWhile we often think about the chain rule in terms of functions:\n\\[\n\\frac{d}{dx}f(g(x)) = f'(g(x))g'(x)\n\\]\nIt’s often easier to view it imperatively, in terms of individual values. For example we might say:\n\\[\nb = g(x)\n\\]\n\\[\na = f(b)\n\\]\nIn this case we can write the chain rule as:\n\\[\n\\frac{da}{dx} = \\frac{da}{db}\\frac{db}{dx}\n\\]\nThis corresponds with how we might think about this in code. For example we might have the code:\n\nb = x ** 2\na = log(b)\n\nIn this case we have:\n\\[\na = \\log(b), \\quad b = x^2\n\\]\nWe can compute the derivative of \\(a\\) with respect to \\(x\\) using the chain rule as:\n\\[\n\\frac{da}{db} = \\frac{1}{b}, \\quad \\frac{db}{dx} = 2x\n\\]\n\\[\n\\frac{da}{dx} = \\bigg(\\frac{1}{b}\\bigg)(2x) = \\frac{2x}{x^2} = \\frac{2}{x}\n\\]"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#composing-many-operations",
    "href": "lecture6-backpropagation/notes.html#composing-many-operations",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Composing many operations",
    "text": "Composing many operations\nFor more complex functions, we might be composing many more operations, but we can break down derivative computations in the same way. For example, if we want the derivative with respect to \\(x\\) of some simple loss:\n\\[\nL=-\\log \\sigma\\big(w x^2\\big)\n\\]\nWe can break this down into each individual operation that we apply:\n\\[\na = x^2\n\\]\n\\[\nb=wa\n\\]\n\\[\nc=\\sigma(b)\n\\]\n\\[\ng= \\log c\n\\]\n\\[\nL=-g\n\\]\nThe chain rule tells us that:\n\\[\n\\frac{dL}{dx} = \\frac{dL}{dg}\\frac{dg}{dc}\\frac{dc}{db}\\frac{db}{da}\\frac{da}{dx}\n\\]\nSince each step is a single operation with a known derivative, we can easily compute every term above! Thus, we begin to see a recipe for computing derivatives programatically. Every time we perform some operation, we will also compute the derivative with respect to the input (we can’t just compute the derivatives because each derivative needs the preceding value, e.g. \\(\\frac{dg}{dc}=\\frac{1}{c}\\), so we need to first compute \\(c\\)).\nWe can visually look at the chain of computation that we’re performing as a diagram that shows each step and the result.\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe call this structure the computational graph."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#forward-and-reverse-mode-automatic-differentiation",
    "href": "lecture6-backpropagation/notes.html#forward-and-reverse-mode-automatic-differentiation",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Forward and reverse mode automatic differentiation",
    "text": "Forward and reverse mode automatic differentiation\nWe are not actually interested in all of the intermediate derivatives ( \\(\\frac{db}{da}, \\frac{dc}{db}\\) etc.), so it doesn’t make much sense to compute all of them and then multiply them together. Instead, we’d rather just incrementally compute the value we’re interested in \\(\\frac{dL}{dx}\\), as we go.\nThere are 2 ways we could consider doing this. One way is to always keep track of the derivative of the current value with respect to \\(x\\). So in the diagram above, each time we perform a new operation we will also compute the derivative of the operation and then update our knowledge of the derivative with respect to \\(x\\). For example for the operation going from \\(b\\) to \\(c\\):\n\\[\nc \\leftarrow \\sigma(b), \\quad \\frac{dc}{dx} \\leftarrow \\frac{dc}{db}\\cdot\\frac{db}{dx}\n\\]\nWe call this approach forward-mode automatic differentiation.\nThe alternative approach is to work backwards, first compute \\(L\\) and \\(\\frac{dL}{dg}\\) and then go backwards through the chain updating the derivative of the final output with respect to each input for the \\(b\\) to \\(c\\) operation this looks like:\n\\[\nc \\leftarrow \\sigma(b), \\quad \\frac{dL}{db} \\leftarrow \\frac{dc}{db}\\cdot\\frac{dL}{dc}\n\\]\nThis means we need to do our computation in 2 passes. First we need to go through the chain of operations to compute \\(L\\), then we need to go backwards through the chain to compute \\(\\frac{dL}{dx}\\). Note that computing each intermediate derivative requires the a corresponding intermediate value (e.g. \\(\\frac{dc}{db}\\) requires \\(b\\) to compute). So we need to store all the intermediate values as we go. The approach is called reverse-mode automatic differentiation or more commonly: backpropagation. We can summarize both approaches below:\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#automatic-differentiation-with-multiple-inputs",
    "href": "lecture6-backpropagation/notes.html#automatic-differentiation-with-multiple-inputs",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Automatic differentiation with multiple inputs",
    "text": "Automatic differentiation with multiple inputs\nYou might wonder why we’d ever use reverse-mode when it seems to require much more complication in keeping track of all the intermediate values. To see why it is useful, lets’s consider the common case where we would like to take derivatives with respect to multiple inputs at the same time. For example we might have an expression like:\n\\[\n-\\log \\sigma (w_1 x_1+w_2x_2 +w_3x_3)\n\\]\nIn this case we want to find the gradient:\n\\[\n\\frac{dL}{d\\mathbf{x}} = \\begin{bmatrix}\\frac{dL}{dx_1} \\\\ \\frac{dL}{dx_2} \\\\ \\frac{dL}{dx_3} \\end{bmatrix}\n\\]\nWe see that in forward mode, we now need to keep a vector of gradients at many steps if we want to compute the derivative with respect to every input!\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn reverse mode, however we only ever need to keep the derivative of the loss with respect to the current value. If we assume that the loss is always a single value, this is much more efficient!\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#reusing-values",
    "href": "lecture6-backpropagation/notes.html#reusing-values",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Reusing values",
    "text": "Reusing values\nOne thing we need to consider is the fact that values can be used in multiple different operations. For example, consider the code below.\n\ndef loss(x):\n    a = x ** 2\n    b = 5 * a\n    c = log(a)\n    g = b * c\n    L = -g\n    return L\n\nThis corresponds to the following sequence of operations:\n\\[\na = x^2\n\\]\n\\[\nb=5a\n\\]\n\\[\nc=\\log a\n\\]\n\\[\ng = bc\n\\]\n\\[\nL=-b\n\\]\nWe see that both \\(b\\) and \\(c\\) depend on \\(a\\). Leading to the following computational graph:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn forward mode this means that we compute 2 different values for \\(\\frac{dg}{dx}\\), one from \\(b\\) \\((\\frac{dg}{db}\\cdot\\frac{db}{dx})\\) and one from \\(c\\) \\((\\frac{dg}{dc}\\cdot\\frac{dc}{dx})\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn reverse mode this means that we compute 2 different values for \\(\\frac{dL}{da}\\), one from \\(b\\) \\((\\frac{dL}{db}\\cdot\\frac{db}{da})\\) and one from \\(c\\) \\((\\frac{dL}{dc}\\cdot\\frac{dc}{da})\\).\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThe resolution in both cases is simple! Just add the two terms. So in forward mode:\n\\[\\frac{dg}{dx} = \\frac{dg}{db}\\cdot \\frac{db}{dx} +\\frac{dg}{dc}\\cdot \\frac{dc}{dx}\\]\nIn reverse mode:\n\\[\\frac{dL}{da} = \\frac{dL}{db}\\cdot \\frac{db}{da} + \\frac{dL}{dc}\\cdot \\frac{dc}{da} \\]\nThe forward case for this example is just an application of the product rule:\n\\[\ng =bc\n\\]\n\\[\n\\frac{dg}{dx} =\\frac{dg}{db}\\cdot \\frac{db}{dx} +\\frac{dg}{dc}\\cdot \\frac{dc}{dx} = c\\cdot \\frac{db}{dx} +b \\cdot \\frac{dc}{dx}\n\\]\nFor reverse mode we need to expand an rearrange a bit:\n\\[\n\\frac{dL}{da} =\\frac{dL}{dg}\\cdot \\frac{dg}{da}\n\\]\n\\[\n\\frac{dg}{da} =\\frac{dg}{db}\\cdot \\frac{db}{da} +\\frac{dg}{dc}\\cdot \\frac{dc}{da}\n\\]\n\\[\n\\frac{dL}{da} =\\frac{dL}{dg}\\bigg( \\frac{dg}{db}\\cdot \\frac{db}{da} +\\frac{dg}{dc}\\cdot \\frac{dc}{da} \\bigg)\n\\]\n\\[\n=\\frac{dL}{dg} \\frac{dg}{db} \\frac{db}{da} + \\frac{dL}{dg}\\frac{dg}{dc} \\frac{dc}{da}\n\\]\n\\[\n=\\frac{dL}{db}\\cdot \\frac{db}{da} + \\frac{dL}{dc}\\cdot \\frac{dc}{da}\n\\]\nThis also works for addition:\n\\[\ng =b + c\n\\]\n\\[\n\\frac{dg}{dx} =\\frac{dg}{db}\\cdot \\frac{db}{dx} +\\frac{dg}{dc}\\cdot \\frac{dc}{dx}\n\\]\n\\[\n\\frac{dg}{db}=1,\\ \\frac{dg}{dc}=1\n\\]\n\\[\n\\frac{dg}{dx} =\\frac{db}{dx} + \\frac{dc}{dx}\n\\]\nAnd in general any binary operation! (Division, powers etc.)."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#partial-and-total-derivatives",
    "href": "lecture6-backpropagation/notes.html#partial-and-total-derivatives",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Partial and total derivatives",
    "text": "Partial and total derivatives\nSo far we’ve been a bit sloppy in our discussion of derivatives. To see why, let’s consider one more case:\n\\[\na = x^2\n\\]\n\\[\nb=5a\n\\]\n\\[\nc = a b\n\\]\n\\[\nL=-c\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nSaying that \\(\\frac{dc}{da}=b\\) isn’t quite correct, because \\(b\\) also depends on \\(a\\), really \\(\\frac{dc}{da} =\\frac{dc}{da}+\\frac{dc}{db}\\frac{db}{da}\\). We already account for this in our automatic differentiation though, so we want a way to talk about the derivative of an operation with respect to it’s inputs ignoring how the inputs may depend on each other.\nThis is where the notion of a partial derivative comes in, the partial derivative of function with respect to an input is the derivative ignoring any dependencies between inputs. We’ve already seen how we denote this:\n\\[\n\\frac{\\partial c}{\\partial a} = b =5a\n\\]\nThe total derivative is the derivative where we do account for this. In our example:\n\\[\n\\frac{dc}{da} =\\frac{\\partial c}{\\partial a}+\\frac{\\partial c}{\\partial b}\\frac{\\partial b}{\\partial a} = 5a + 5a = 10a\n\\]\nIn our earlier examples, we typically had partial derivatives equal to total derivatives, so the distinction wasn’t really important. This example shows why it is.\nLet’s see our earlier example, but this time we’ll make the distinction between partial and total derivatives explicit\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nThis is also why we specify gradients in terms of partial derivatives! If we’re taking the gradient of a function with respect to multiple inputs, we don’t know where these inputs come from. They might depend on each other! By specifying gradients at partial derivatives, we make it clear that we’re not accounting for that."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#implementing-reverse-mode-automatic-differentiation",
    "href": "lecture6-backpropagation/notes.html#implementing-reverse-mode-automatic-differentiation",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Implementing reverse-mode automatic differentiation",
    "text": "Implementing reverse-mode automatic differentiation\nWe’ll start by developing an automatic differentiation class that uses reverse-mode automatic differentiation, as this is what will be most useful for neural networks.\nRecall that for reverse-mode AD to work, everytime we perform an operation on one or more numbers we need to store the result of that operation as well as the parent values (the inputs to the operation). We also need to be able to compute the derivative of that operation. Since for every operation we need to store several pieces of data and several functions, it makes sense to define a class to represent the result of an operation.\nFor example, if we want to make a class that represents the operation c=a+b our class needs several properties:\n\nvalue: The value of the operation (c)\nparents: The parent operations (a and b)\ngrad: The derivative of the final loss with respect to c (\\(\\frac{dL}{dc}\\))\nfunc: A function that computes the operation (a+b)\ngrads: A function that computes the derivatives of the operation (\\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\))\n\nFor this example, we’ll call our class AutogradValue. This will be the base class for all of our possible operations and represents declaring a variable with a value (a = 5). This is useful because it lets us define values that we might want to find derivatives with respect to.\nLet’s see how this will work in practice. If we want to take derivatives we will first define the inputs using AutogradValue.\n\na = AutogradValue(5)\nb = AutogradValue(2)\n\nThen we can perform whatever operations we want on these inputs:\n\nc = a + b\nL = log(c)\n\nEach of these operations will produce a new AutogradValue object representing the result of that operation.\nFinally we can run the backward pass by running a method backward() (that we will write) on the outout L. This will compute the gradients of L with respect to each input that we defined (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)). Rather than returning these derivatives, the backward() method will update the grad property of a and b, making it easy to access the correct derivative.\n\nL.backward()\ndL_da = a.grad\n\nWe’ll also be able to compute operations with non-AutogradValue numbers, but obviously won’t be able to compute derivaitives with respect to these values.\n\ns = 4\nL = s * a\ndL_da = a.grad # Will work because a is an AutogradValue\ndL_ds = s.grad # Will give an error because s is not an AutogradValue\n\nLet’s look at one possible implementation for AutogradValue:\n\nclass AutogradValue:\n    '''\n    Base class for automatic differentiation operations. \n    Represents variable delcaration. Subclasses will overwrite \n    func and grads to define new operations.\n\n    Properties:\n        parents (list):  A list of the inputs to the operation, \n                         may be AutogradValue or float\n        args    (list):  A list of raw values of each \n                         input (as floats)\n        grad    (float): The derivative of the final loss with \n                         respect to this value (dL/da)\n        value   (float): The value of the result of this operation\n    '''\n\n    def __init__(self, *args):\n        self.parents = list(args)\n        self.args = [arg.value if isinstance(arg, AutogradValue) \n                     else arg \n                     for arg in self.parents]\n        self.grad = 0.\n        self.value = self.forward_pass()\n\n    def forward_pass(self):\n        # Calls func to compute the value of this operation \n        return self.func(*self.args)\n\nFor convenience, in this implementation we’ve also defined a property args which simply stores the value of each parent. Note that we can also allow parents to be either be AutogradValue or a primitive data type like float. This will allow us to do things like multiply an AutogradValue variable with a float, e.g. a * 5.\nThe forward_pass function computes the actual value of the node given it’s parents. This will depend on what kind of operation we’re doing (addition, subtraction, multiplication, etc.), so we’ll define a func method that we can override that does the actual calculation. In the base case we’ll just directly assign the value:\n\nclass AutogradValue:\n    def func(self, input):\n        '''\n        Compute the value of the operation given the inputs.\n        For declaring a variable, this is just the identity \n        function (return the input).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            value (float): The result of the operation\n        '''\n        return input\n\nIn subclasses we’ll override func:\n\nclass _square(AutogradValue):\n    # Square operator (a ** 2)\n    def func(self, a):\n        return a ** 2\n\nclass _mul(AutogradValue):\n    # Multiply operator (a * b)\n    def func(self, a, b):\n        return a * b\n\nLet’s consider what the computational graph will look like for the following code:\n\nx = AutogradValue(2)\na = x ** 2\nb = 5 * a\nc = b * a\nL = -c\n\n\nHere the blue nodes represent constants (of type float), while the black nodes are AutogradValue objects. We see that every AutogradValue is populated with the value, parents and args, but that after this first pass grad is still 0 for each object, so we have not computed \\(\\frac{dL}{dx}\\). To do so, we need to run the backward pass by calling L.backward().\n\nL.backward()\nprint('dL_dx', x.grad)\n\nIn the backward pass, each node needs to update the grad property of its parents.\n\nSo first \\(L\\) needs to update the grad property for \\(c\\), which represents \\(\\frac{dL}{dc}\\). Then \\(c\\) is able to update the grad property of \\(a\\) and \\(b\\) (\\(\\frac{dL}{da}\\) and \\(\\frac{dL}{db}\\)).\nNote that the order we perform these updates matters! \\(\\frac{dL}{da}\\) will not be correct until both \\(b\\) and \\(c\\) have updated \\(a\\), thus \\(a\\) cannot perform the update to \\(\\frac{dL}{dx}\\) until both \\(b\\) and \\(c\\) have updated \\(a\\).\nFor each operation, we see that we also need to be able to compute the appropriate local derivatives of the value with respect to each input. For instance \\(a\\) needs to be able to compute \\(\\frac{da}{dx}\\) , \\(c\\) needs to be able to compute \\(\\frac{dc}{da}\\) and \\(\\frac{dc}{db}\\). We will definite another method grads that can compute these values for a given operation and override it for each subclass. Since grads might need to compute multiple derivatives (as for multiplication or addition) we’ll have it return a tuple.\n\nclass AutogradValue:\n        def grads(self, *args):\n        '''\n        Compute the derivative of the operation with respect to each input.\n        In the base case the derivative of the identity function is just 1. (da/da = 1).\n\n        Args:\n            input (float): The input to the operation\n        Returns:\n            grads (tuple): The derivative of the operation with respect to each input\n                            Here there is only a single input, so we return a length-1 tuple.\n        '''\n        return (1,)\n      \nclass _square(AutogradValue):\n    # Square operator (a ** 2)\n    def grads(self, a):\n        return (2 * a,)\n\nclass _mul(AutogradValue):\n    # Multiply operator (a * b)\n    def grads(self, a, b):\n        return (b, a)\n\nWith this in hand we can write a function that performs the backward update for a given operation. We’ll call this method backward_pass."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#computational-graphs-of-vectors",
    "href": "lecture6-backpropagation/notes.html#computational-graphs-of-vectors",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Computational graphs of vectors",
    "text": "Computational graphs of vectors\nAs we’ve seen, in the context of neural networks we typically perform operations on large collections of values such as vectors. For example, we might perform an element-wise square on a large vector:\n\nx = np.ones((500,))\na = x ** 2\n\nIn this case we are performing 500 individual square operations, so our computational graph would look like:\n\nRemember for our automatic differentiation implementation we would need an object for each of these values.\n\nx = np.array([AutogradValue(1), AutogradValue(1), ...])\na = x ** 2\n\nEach of these object introduces some overhead as each object needs to be constructed individually and needs to store not just the value and gradients, but also the parents. Furthermore our backward pass needs to determine the order of nodes to visit. For a large neural network, having a node for every single value would be computationally very complex.\nSince we’re performing the same operation on each entry of the vector, there’s really no need to have a separate node for each entry. Therefore we might instead prefer each node in our computational graph to represent a vector or matrix and for our operations to correspond to vector or matrix operations:\n\nx = AutogradValue(np.ones((500,)))\na = x ** 2\n\nIn this case the computational graph for this operation would be:\n\nOur derivative calculations can similarly be performed as element-wise operations:\n\\[\n\\begin{bmatrix} \\frac{da_1}{dx_1} \\\\ \\frac{da_2}{dx_2} \\\\ \\vdots \\\\ \\frac{da_{500}}{dx_{500}} \\end{bmatrix} =\n\\begin{bmatrix} 2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_{500} \\end{bmatrix} = 2\\mathbf{x}\n\\]\nSo in fact, for this case, we don’t actually need to change our AutogradValue implementation for square at all!\n\nclass _square(AutogradValue):\n    # Square operator (a ** 2)\n    def func(self, a):\n        return a ** 2\n\n    # Returns a vector of the element-wise derivatives!\n    def grads(self, a):\n        return (a ** 2,)"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#automatic-differentiation-for-linear-regression",
    "href": "lecture6-backpropagation/notes.html#automatic-differentiation-for-linear-regression",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Automatic differentiation for linear regression",
    "text": "Automatic differentiation for linear regression\nLet’s take a look at a concrete example how reverse-mode automatic differentiation with vectors would work. Specifically let’s look at taking the gradient of the mean squared error loss we used for linear regression.\n\\[\nL = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\mathbf{x}_i^T\\mathbf{w})^2 = \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{y} - \\mathbf{X}\\mathbf{w})_i^2\n\\]\nHere the right-hand side of the expression corresponds to how we might write this formula using numpy:\n\nse = (y - np.dot(X, w)) ** 2\nmse = np.sum(se) / X.shape[0] \n\nWe are interested in the gradient with respect to \\(\\mathbf{w}\\), or \\(\\frac{dL}{d\\mathbf{w}}\\) for optimizing our model. Let’s start by looking at the simplest sequence of operations:\n\\[\n\\mathbf{a} = \\mathbf{X}\\mathbf{w}\n\\]\n\\[\n\\mathbf{b} = \\mathbf{y} - \\mathbf{a}\n\\]\n\\[\n\\mathbf{c} = \\mathbf{b}^2\n\\]\n\\[\ng = \\sum_{i=1}^N c_i\n\\]\n\\[\nL = \\frac{1}{N}g\n\\]\nWe can setup our computational graph and reverse mode algorithm exactly as we did before, only in this case some of the operations will be on vectors! (\\(g\\) and \\(L\\) are still scalars, but \\(\\mathbf{w}\\), \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\) are vectors)\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nLet’s walk through the computation of \\(\\frac{dL}{d\\mathbf{w}}\\).\nComputing \\(\\frac{dL}{dg}\\): The first step in the backward pass is straightforward:\n\\[\n\\frac{dL}{dg} = \\frac{1}{N}\n\\]\nComputing \\(\\frac{dL}{d\\mathbf{c}}\\):\n\\[\n\\frac{dL}{d\\mathbf{c}}= \\frac{dL}{dg}\\frac{dg}{d\\mathbf{c}}\n\\]\nSince \\(\\mathbf{c}\\) is a vector, \\(\\frac{dg}{d\\mathbf{c}}\\) and \\(\\frac{dL}{d\\mathbf{c}}\\) must be vectors of the derivative of \\(L\\) or \\(g\\) with respect to each entry of \\(\\mathbf{c}\\). In other words \\(\\frac{dg}{d\\mathbf{c}}\\) and \\(\\frac{dL}{d\\mathbf{c}}\\) are gradients!\n\\[\n\\frac{dL}{d\\mathbf{c}}= \\begin{bmatrix} \\frac{dL}{dc_1} \\\\ \\frac{dL}{dc_2} \\\\ \\vdots \\\\ \\frac{dL}{dc_N}  \\end{bmatrix} = \\frac{dL}{dg} \\begin{bmatrix} \\frac{dg}{dc_1} \\\\ \\frac{dg}{dc_2} \\\\ \\vdots \\\\ \\frac{dg}{dc_N}  \\end{bmatrix} = \\frac{dL}{dg}\\frac{dg}{d\\mathbf{c}}\n\\]\nWe know that the derivative of a sum with respect to a single element is \\(1\\), as in: \\(\\frac{d}{dc_1}(c_1+c_2)=1\\), so it follows that the gradient of our summation is simply a vector of 1s.\n\\[\n\\frac{dg}{d\\mathbf{c}} =\\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix}, \\quad \\frac{dL}{d\\mathbf{c}} =\\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix}\\frac{1}{N} = \\begin{bmatrix} \\frac{1}{N} \\\\ \\frac{1}{N} \\\\ \\vdots \\\\ \\frac{1}{N} \\end{bmatrix}\n\\]\nComputing \\(\\frac{dL}{d\\mathbf{b}}\\):\nSince \\(\\mathbf{b}^2\\) is an element-wise operation \\((c_i=b_i^2)\\) we know that:\n\\[\n\\frac{dL}{db_i}=\\frac{dL}{dc_i}\\frac{dc_i}{db_i} = \\frac{1}{N}(2b_i)\n\\]\nTherefore:\n\\[\n\\frac{dL}{d\\mathbf{b}} = \\begin{bmatrix} \\frac{dL}{dc_1}\\frac{dc_1}{db_1}  \\\\ \\frac{dL}{dc_2}\\frac{dc_2}{db_2}  \\\\ \\vdots \\\\ \\frac{dL}{dc_N}\\frac{dc_N}{db_N}   \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{N}b_1  \\\\ \\frac{2}{N}b_2  \\\\ \\vdots \\\\ \\frac{2}{N}b_N   \\end{bmatrix}\n\\]\nComputing \\(\\frac{dL}{d\\mathbf{a}}\\):\nSince \\(\\mathbf{y}-\\mathbf{a}\\) is also an element-wise operation \\((b_i=y_i-a_i)\\) we similarly see that:\n\\[\n\\frac{dL}{da_i}=\\frac{dL}{db_i}\\frac{db_i}{da_i} = \\frac{2b_i}{N}(-1)\n\\]\n\\[\n\\frac{dL}{d\\mathbf{a}} = \\begin{bmatrix} \\frac{dL}{db_1}\\frac{db_1}{da_1}  \\\\ \\frac{dL}{dc_2}\\frac{db_2}{da_2}  \\\\ \\vdots \\\\ \\frac{dL}{dc_N}\\frac{db_N}{da_N}   \\end{bmatrix} = \\begin{bmatrix} \\frac{-2}{N}b_1  \\\\ \\frac{-2}{N}b_2  \\\\ \\vdots \\\\ \\frac{-2}{N}b_N   \\end{bmatrix}\n\\]\nComputing \\(\\frac{dL}{d\\mathbf{w}}\\):\nThis last calculation is less straightforward. \\(\\mathbf{X}\\mathbf{w}\\) is not an element-wise operation, so we can’t just apply the chain rule element-wise. We need a new approach! Let’s break down the general problem that we see here."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#vector-valued-functions",
    "href": "lecture6-backpropagation/notes.html#vector-valued-functions",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Vector-valued functions",
    "text": "Vector-valued functions\nA vector-valued function is a function that takes in a vector and returns a vector:\n\\[\n\\mathbf{y} = f(\\mathbf{x}), \\quad f: \\mathbb{R}^n\\rightarrow\\mathbb{R}^m\n\\]\nFor example the matrix-vector product we’ve just seen is a simple vector-valued function:\n\\[\nf(\\mathbf{w}) =\\mathbf{X}\\mathbf{w}\n\\]\nIf \\(\\mathbf{X}\\) is an \\((N\\times d)\\) matrix and \\(\\mathbf{w}\\) is a length- \\(d\\) vector, then \\(f(\\mathbf{w})=\\mathbf{X}\\mathbf{w}\\) is a mapping \\(\\mathbb{R}^d\\rightarrow \\mathbb{R}^N\\)"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#jacobians",
    "href": "lecture6-backpropagation/notes.html#jacobians",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Jacobians",
    "text": "Jacobians\nA the Jacobian \\((\\mathbf{J})\\) of a vector-valued function is the matrix of partial derivatives of every output with respect to every input. We can think of it as an extension of the gradient for vector-valued functions. If we have a vector-valued function \\(f\\) and \\(\\mathbf{a}\\) is the result of applying \\(f\\) to \\(\\mathbf{w}\\):\n\\[\n\\mathbf{a}=f(\\mathbf{w}), \\quad f:\\mathbb{R}^d\\rightarrow \\mathbb{R}^N\n\\]\nThe corresponding Jacobian is:\n\\[\\frac{d\\mathbf{a}}{d\\mathbf{w}} = \\begin{bmatrix} \\frac{\\partial a_1}{\\partial w_1} & \\frac{\\partial a_1}{\\partial w_2}& \\dots& \\frac{\\partial a_1}{\\partial w_d} \\\\\n\\frac{\\partial a_2}{\\partial w_1} & \\frac{\\partial a_2}{\\partial w_2}& \\dots& \\frac{\\partial a_2}{\\partial w_d} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial a_N}{\\partial w_1} & \\frac{\\partial a_N}{\\partial w_2}& \\dots& \\frac{\\partial a_N}{\\partial w_d} \\\\\n\\end{bmatrix}\\]\nIn general:\n\\[\n\\bigg(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\bigg)_{ij} = \\frac{\\partial a_i}{\\partial w_j}\n\\]\nLet’s consider the Jacobian of a matrix-vector product:\n\\[\n\\mathbf{a} = \\mathbf{X}\\mathbf{w}\n\\]\nWe can find each entry in the Jacobian by taking the corresponding partial derivative.\n\\[\na_i =\\sum_{j=1}^d X_{ij}w_j, \\quad \\frac{\\partial a_i}{\\partial w_j}=X_{ij}\n\\]\nIn this case we see that the Jacobian is just \\(\\mathbf{X}\\)!"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#vector-jacobian-products",
    "href": "lecture6-backpropagation/notes.html#vector-jacobian-products",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Vector-Jacobian products",
    "text": "Vector-Jacobian products\nLet’s return to our linear regression example:\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nWe see that \\(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\) is actually a Jacobian that we now know how to compute, so the remaining question is how to combine it with \\(\\frac{dL}{d\\mathbf{a}}\\) in order to get the gradient we’re looking for \\(\\frac{dL}{d\\mathbf{w}}\\)? The answer turns out to be simple: use the vector-matrix product:\n\\[\n\\frac{dL}{d\\mathbf{w}} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d\\mathbf{a}}{d\\mathbf{w}}\n\\]\nWe might be curious why this is the right thing to do as opposed to a matrix-vector product or some other function. To see why, let’s consider what an entry of our final gradient \\(\\frac{dL}{d\\mathbf{w}}\\) should be. We’ve previously seen that when a value is use by more than one child operation, we need to sum the contribution of each child to the total derivative. So in this case, for a given entry of \\(\\mathbf{w}\\) we need to sum the gradient contribution from every element of \\(\\mathbf{a}\\):\n\\[\n\\frac{dL}{dw_j} = \\frac{dL}{da_1} \\frac{da_1}{dw_j}+\\frac{dL}{da_2} \\frac{da_2}{dw_j}+...\\frac{dL}{da_N} \\frac{da_N}{dw_j} = \\sum_{i=1}^N \\frac{dL}{da_i} \\frac{da_i}{dw_j}\n\\]\nWhich we can see is equivalent to an entry in the vector matrix product:\n\\[\n\\frac{dL}{d\\mathbf{w}} = \\begin{bmatrix} \\frac{dL}{da_1} & \\frac{dL}{da_2} & ... & \\frac{dL}{da_N} \\end{bmatrix}\\begin{bmatrix} \\frac{\\partial a_1}{\\partial w_1} & \\frac{\\partial a_1}{\\partial w_2}& \\dots& \\frac{\\partial a_1}{\\partial w_d} \\\\\n\\frac{\\partial a_2}{\\partial w_1} & \\frac{\\partial a_2}{\\partial w_2}& \\dots& \\frac{\\partial a_2}{\\partial w_d} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial a_N}{\\partial w_1} & \\frac{\\partial a_N}{\\partial w_2}& \\dots& \\frac{\\partial a_N}{\\partial w_d} \\\\\n\\end{bmatrix} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d\\mathbf{a}}{d\\mathbf{w}}\n\\]\nWe call this a vector-Jacobian product or VJP for short. We see that because it’s simply derived from our basic gradient rules, it’s valid for any vector-valued operation, as long as we can compute the Jacobian! We can use this to perform the final step in the backward pass for the MSE.\nComputing \\(\\frac{dL}{d\\mathbf{w}}\\):\nFrom our vector-Jacobian product rule we know that:\n\\[\n\\frac{dL}{d\\mathbf{w}} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d\\mathbf{a}}{d\\mathbf{w}}= \\frac{-2}{N}\\mathbf{b}^T\\mathbf{X}\n\\]\nIf we substitute back in \\(\\mathbf{b}=\\mathbf{y}-\\mathbf{X}\\mathbf{w}\\) we see that this is equivalent to the gradient we derived in a previous class!\n\\[ \\frac{dL}{d\\mathbf{w}} = \\frac{-2}{N}(\\mathbf{y}-\\mathbf{X}\\mathbf{w})^T\\mathbf{X} \\]"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#vjps-for-element-wise-operations",
    "href": "lecture6-backpropagation/notes.html#vjps-for-element-wise-operations",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "VJPs for element-wise operations",
    "text": "VJPs for element-wise operations\nIt’s worth noting that element-wise operations are still vector-valued functions.\n\\[\n\\mathbf{c}=\\mathbf{b}^2, \\quad \\mathbb{R}^n\\rightarrow\\mathbb{R}^n\n\\]\nSo why didn’t we need to do a vector-Jaobian product for that operation? The answer is that we did, just implicitly! If we consider the Jacobian for this operation we see that because each entry of \\(\\mathbf{c}\\) only depends on the corresponding entry of \\(\\mathbf{b}\\), the Jacobian for this operation is \\(0\\) everywhere except the main diagonal:\n\\[\n\\frac{d\\mathbf{c}}{d\\mathbf{b}} = \\begin{bmatrix} \\frac{\\partial c_1}{\\partial b_1} & 0 & \\dots& 0 \\\\\n0 & \\frac{\\partial c_2}{\\partial b_2}& \\dots& 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0& 0& \\dots& \\frac{\\partial c_N}{\\partial b_d} \\\\\n\\end{bmatrix}\n\\]\nThis means that we can write the vector-Jacobian product as we did before:\n\\[\n\\frac{dL}{d\\mathbf{c}}\\frac{d\\mathbf{c}}{d\\mathbf{b}}=\\begin{bmatrix} \\frac{dL}{dc_1}\\frac{dc_1}{db_1}  \\\\ \\frac{dL}{dc_2}\\frac{dc_2}{db_2}  \\\\ \\vdots \\\\ \\frac{dL}{dc_N}\\frac{dc_N}{db_N}   \\end{bmatrix}\n\\]\nThis is a big computational savings over explicitly constructing the full Jacobian and performing a vector-matrix multiplication."
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#vjps-for-matrices",
    "href": "lecture6-backpropagation/notes.html#vjps-for-matrices",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "VJPs for matrices",
    "text": "VJPs for matrices\nSo far we’ve seen VJPs with respect to vectors. What if in the formulation above, we were to take the derivative with respect to \\(\\mathbf{X}\\) instead of \\(\\mathbf{w}\\)?\n\\[\n\\mathbf{a}=\\mathbf{X}\\mathbf{w},\\quad \\frac{d\\mathbf{a}}{d\\mathbf{X}}\n\\]\nIn this case \\(\\mathbf{X}\\) is an \\(N\\times d\\) matrix, so if we were to consider all the partial derivatives making up the Jacobian \\(\\frac{d\\mathbf{a}}{d\\mathbf{X}}\\) there would be \\(N\\times N\\times d\\) values, while the gradient \\(\\frac{dL}{d\\mathbf{X}}\\) is itself an \\(N\\times d\\) matrix of the derivative of \\(L\\) with respect to each value of \\(\\mathbf{X}\\).\nLet’s look at how we can formulate the vector-Jacobian product:\n\\[\n\\frac{dL}{d\\mathbf{X}} = \\frac{dL}{d\\mathbf{a}}^T\\frac{d\\mathbf{a}}{d\\mathbf{X}}\n\\]\nWe know that for a given entry of \\(\\frac{dL}{d\\mathbf{X}}\\), we can again compute the derivative by summing the contribution from each child, in this case every entry of \\(\\mathbf{a}\\)\n\\[\n\\frac{dL}{dX_{jk}} = \\sum_{i=1}^N \\frac{\\partial L}{\\partial a_{i}} \\frac{\\partial a_i}{\\partial X_{jk}}\n\\]\nThis suggests that we can compute the VJP by flattening the Jacobian from an \\(N\\times N \\times d\\) structure into a \\(N \\times Nd\\) matrix. Therefore performing the vector-matrix product will give us a length \\(Nd\\) vector with the appropriate values for us to reshape into our \\(N \\times d\\) Jacobian \\(\\frac{dL}{d\\mathbf{X}}\\).\nIn code this could look like:\n\ndL_da, da_dx  # The computed gradients/jacobians\nda_dx = da_dx.reshape((da_dx.shape[0], -1))\ndL_dx = np.dot(dL_da, da_dx)\ndL_dx = dL_dx.reshape(x.shape)\n\nLet’s return to our example:\n\\[\\mathbf{a}=\\mathbf{X}\\mathbf{w}\\]\nDo we need to instantiate the full Jacobian here? No! In our original operation:\n\\[\na_i = \\sum_{k=1}^d X_{ik}w_k\n\\]\nThus \\(\\frac{\\partial a_i}{\\partial X_{jk}}\\) is only nonzero when \\(j=i\\). Taking the derivative we get:\n\\[\n\\frac{\\partial a_i}{\\partial X_{jk}} = \\frac{\\partial}{\\partial X_{jk}}\\sum_{k=1}^d X_{ik}w_k = \\mathbb{I}(i=j)w_k\n\\]\nWe can therefore write the vector-Jacobian product as:\n\\[\n\\frac{\\partial L}{\\partial X_{ik}}=\\frac{\\partial L}{\\partial a_i}\\frac{\\partial a_i}{\\partial X_{ik}} = \\frac{\\partial L}{\\partial a_i}w_k\n\\]\nIn code we could write this as:\n\nw_mat = w.reshape((1, -1)) # reshape w to 1 x d\ndL_da_mat = dL_da.reshape((-1, 1)) # reshape dL_da to N x 1\ndL_dx = w_mat * dL_da_mat # dL_dx becomes N x d, entry ik = dL_da_i * w_k"
  },
  {
    "objectID": "lecture6-backpropagation/notes.html#forward-mode-ad-with-vectors",
    "href": "lecture6-backpropagation/notes.html#forward-mode-ad-with-vectors",
    "title": "Lecture 6: Deep neural networks and backpropagation",
    "section": "Forward mode AD with vectors",
    "text": "Forward mode AD with vectors\nWhat about forward mode for our linear regression example?\n\\[\n\\mathbf{a} = \\mathbf{X}\\mathbf{w}\n\\]\n\\[\n\\mathbf{b} = \\mathbf{y} - \\mathbf{a}\n\\]\n\\[\n\\mathbf{c} = \\mathbf{b}^2\n\\]\n\\[\ng = \\sum_{i=1}^N c_i\n\\]\n\\[\nL = \\frac{1}{N}g\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nAs we’ve seen \\(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\) is an \\(N\\times d\\) Jacobian matrix. After computing this, the next step will be to compute:\n\\[\\frac{d\\mathbf{b}}{d\\mathbf{w}}=\\frac{d\\mathbf{b}}{d\\mathbf{a}}\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\]\nHere we are multiplying the \\(N\\times N\\) Jacobian \\(\\frac{d\\mathbf{b}}{d\\mathbf{a}}\\) with the \\(N\\times d\\) gradient \\(\\frac{d\\mathbf{a}}{d\\mathbf{w}}\\) to get the \\(N\\times d\\) gradient \\(\\frac{d\\mathbf{b}}{d\\mathbf{w}}\\). We can again verify that this is the correct computation by checking an individual element of \\(\\frac{d\\mathbf{b}}{d\\mathbf{w}}\\):\n\\[\n\\frac{db_i}{dw_j}=\\sum_{k=1}^N \\frac{db_i}{da_k}\\frac{da_k}{dw_j}\n\\]\nWe call this operation a Jacobian-vector product or JVP."
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html",
    "href": "lecture4-feature-transforms/notes.html",
    "title": "Lecture 4: Feature transforms",
    "section": "",
    "text": "Plot = import(\"https://esm.sh/@observablehq/plot\") \nd3 = require(\"d3@7\")\ntopojson = require(\"topojson\")\nMathJax = require(\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.min.js\").catch(() =&gt; window.MathJax)\ntf = require(\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js\").catch(() =&gt; window.tf)\n\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  await require(\"three@0.130.0/examples/js/loaders/SVGLoader.js\").catch(() =&gt; {});\n  return THREE;\n}\n\nfunction sample(f, start, end, nsamples=100) {\n  let arr = [...Array(nsamples).keys()]\n  let dist = end - start\n  function arrmap(ind) {\n    const x = (ind * dist) / nsamples + start;\n    return [x, f(x)];\n  }\n  return arr.map(arrmap)\n}\n\nfunction sigmoid(x){\n  return 1 / (1 + Math.exp(-x));\n}\n\nfunction sum(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s;\n}\n\nfunction mean(x) {\n  let s = 0;\n  for (let i = 0; i &lt; x.length; i++ ) {\n    s += x[i];\n  }\n  return s / x.length;\n}\n\nfunction cross_ent(x, y) {\n  return y ? -Math.log(sigmoid(x)) : -Math.log(sigmoid(-x));\n}\n\nfunction se(x, y) {\n  return (x - y) * (x - y);\n}\n\nfunction shuffle(array) {\n  let currentIndex = array.length,  randomIndex;\n\n  // While there remain elements to shuffle.\n  while (currentIndex &gt; 0) {\n\n    // Pick a remaining element.\n    randomIndex = Math.floor(Math.random() * currentIndex);\n    currentIndex--;\n\n    // And swap it with the current element.\n    [array[currentIndex], array[randomIndex]] = [\n      array[randomIndex], array[currentIndex]];\n  }\n\n  return array;\n}\n\nfunction acc(x, y) {\n  return Number(y == (x  &gt; 0));\n}\n\nfunction grid_func(f, width, height, x1, y1, x2, y2) {\n  let values = new Array(width * height);\n  const xstride = (x2 - x1) / width;\n  const ystride = (y2 - y1) / height;\n\n  \n  let y = 0;\n  let x = 0;\n  let ind = 0;\n  for (let i = 0; i &lt; height; i++ ) {\n    for (let j = 0; j &lt; width; j++, ind++) {\n      x = x1 + j * xstride;\n      y = y1 + i * ystride;\n      values[ind] = f(x, y);\n    }\n  }\n  return {width: width, height: height, x1: x1, y1: y1, x2: x2, y2: y2, values: values};\n}\n\nfunction get_accessors(keys, byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  \n  let index = 0;\n  let indexmap = {};\n  let accessors = [];\n  for (let i = 0; i &lt; keys.length; i++){\n    let k = keys[i];\n    if (Array.isArray(k)) {\n      let access = isString(k[0]) ? (x =&gt; x[k[0]]) : k[0];\n      \n      if (byindex) {\n        if (isString(k[0]) && !(k[0] in indexmap)) {\n          indexmap[k[0]] = index;\n          index++;\n        }\n        let accessindex = indexmap[k[0]];\n        access = x =&gt; x[accessindex];\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      else {\n        let process = k[1];\n        let final_access = x =&gt; process(access(x));\n        accessors.push(final_access);\n      }\n      \n    }\n    else {\n      let access = isString(k) ? (x =&gt; x[k]) : k;\n      if (byindex) { \n        if (isString(k) && !(k in indexmap)) {\n          indexmap[k] = index;\n          index++;\n        }\n        let accessindex = indexmap[k];\n        access = x =&gt; x[accessindex];\n      }\n      accessors.push(access); \n    }\n  }\n  return accessors;\n}\n\nfunction predict(obs, weights, keys=[\"0\", \"1\", \"2\", \"3\"], byindex=false) {\n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys, byindex);\n  \n  let output = weights[0];\n  let wi = 1;\n  for (let i = 0; (i &lt; keys.length) && (wi &lt; weights.length); i++, wi++){\n    output += weights[wi] * accessors[i](obs);\n  }\n  return output;\n}\n\nfunction mean_loss(f, data, weights, keys, label, l2=0) {\n  let reg = 0;\n  if (l2 &gt; 0){\n    for (let i = 1; i &lt; weights.length; i++) {\n      reg += weights[i] * weights[i];\n    }\n  }\n  \n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  return mean(data.map(x =&gt; f(predict(x, weights, keys), get_label(x)))) + l2 * reg;\n}\n\nfunction get_domains(data, accessors, margin=0.1) {\n  let domains = [];\n  for (let i = 0; i &lt; accessors.length; i++){\n    let xdomain = d3.extent(data, accessors[i]);\n    let xdsize = (xdomain[1] - xdomain[0]);\n    let xmin = xdomain[0] - xdsize * margin;\n    let xmax = xdomain[1] + xdsize * margin;\n    domains.push([xmin, xmax]);\n  }\n  return domains;\n}\n\nfunction logisticPlot2d(data, weights, keys, label, interval=0.05) {\n  const accuracy = mean_loss(acc, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Accuracy: \" + accuracy.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [-0.5, 1.5]},\n    marks: [\n      Plot.contour({\n        fill: (x, y) =&gt; sigmoid(predict([x, y], weights, index_accessors)),\n        x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1], interval: interval,\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; (get_label(x) ? 1.35 : -0.35)})\n    ]\n  });\n}\n\nfunction logisticLossPlot2d(data, weights, keys, label) {\n  const loss = mean_loss(cross_ent, data, weights, keys, label);\n  \n  let isString = value =&gt; typeof value === 'string';\n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, accessors);\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  \n  return Plot.plot({\n    x: {tickSpacing: 80, label: \"x\"},\n    y: {tickSpacing: 80, label: \"y\"},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, scheme: \"BuRd\", domain: [0, 5]},\n    marks: [\n      Plot.contour({\n        value: (x, y) =&gt; predict([x, y], weights, index_accessors),\n        fillOpacity: 0.2,\n        stroke: \"black\", x1: domains[0][0], y1: domains[1][0], x2: domains[0][1], y2: domains[1][1],\n        thresholds: [-1e6,  0, 0.00001]\n      }),\n      Plot.dot(data, {x: accessors[0], y: accessors[1], stroke: x=&gt; cross_ent(predict(x, weights, keys), get_label(x)), \n                      strokeOpacity: 0.5 })\n    ]\n  });\n}\n\nfunction lossPlot2d(f, data, keys, label, l2=0, res=100, x1=-40, y1=-0.015, x2=40,  y2=0.015, vmax=50, nlines=25, ctype=\"sqrt\", scale=(x =&gt; x)) {\n  let grid = 0;\n  function lossFunc(w, b) {\n    return scale(mean_loss(f, data, [w, b], keys, label, l2));\n  }\n\n  grid = grid_func(lossFunc,\n                 res, res, x1, y1, x2, y2\n                );\n\n  function plot2d(weights) {\n    let w = weights;\n    if (!(Array.isArray(w[0]))){\n      w = [w];\n    }\n\n    var arrows = w.slice(0, w.length - 1).map(function(e, i) {\n      return e.concat(w[i+1]);\n    });\n\n    let interval= vmax / nlines; \n    let thresholds = [];\n    for (let i = 0; i &lt; nlines; i++) {\n      thresholds.push(i * interval);\n    }\n    let loss = mean_loss(f, data, w[w.length - 1], keys, label, l2)\n    return Plot.plot({\n      title: \"Loss: \" + loss.toFixed(3),\n      color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, vmax], type: ctype},\n      marks: [\n        Plot.contour(grid.values, {width: grid.width, height: grid.height, x1: grid.x1, x2:grid.x2, y1: grid.y1, y2: grid.y2,\n          stroke: Plot.identity, thresholds: thresholds}),\n        Plot.dot(w),\n        Plot.arrow(arrows, {x1: \"0\", y1: \"1\", x2: \"2\", y2: \"3\", stroke: \"black\"})\n      ]\n    })\n  }\n  return plot2d;\n}\n\n\n\nfunction regressionPlot(data, weights, keys, label, l2, f=se, stroke=\"\") {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ]\n  })\n}\n\nfunction errorPlot(data, weights, keys, label, f, options={}) {\n  const isString = value =&gt; typeof value === 'string';\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n  let errors = data.map(x =&gt; [predict(x, weights, keys) - get_label(x), f(predict(x, weights, keys), get_label(x))]);\n\n  \n  let sigma = (options['sigma'] || 1);\n  let plots = [];\n  const xdomain = (options['xdomain'] || [-30, 30]);\n  const ydomain = (options['ydomain'] || [0, 0.1]);\n  \n\n  if (options['plotnormal']){\n    let pdf = x =&gt; Math.exp(-0.5 * x * x / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'crimson'});    \n    plots.push(normal);\n  }\n  if (options['plotlaplace']){\n    let pdf = x =&gt; Math.exp(-0.5 * Math.abs(x) / sigma) * ydomain[1];\n    let normal = Plot.line(sample(pdf, xdomain[0], xdomain[1]), {stroke: 'green'});    \n    plots.push(normal);\n  }\n  \n  return Plot.plot({\n    y: {grid: true, domain: ydomain},\n    x: {domain: xdomain},\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      //Plot.rectY(errors, Plot.binX({y: \"count\", fill: x =&gt; mean(x.map(v =&gt; v[1]))}, {x: \"0\"})),\n      \n      Plot.rectY(errors, Plot.binX({y: \"proportion\"}, {x: \"0\", fill: 'steelblue', interval: 1})),\n      Plot.ruleY([0])\n    ].concat(plots)\n  })\n}\n\nfunction nnPlot(data, weights, keys, label, l2, f=se, stroke=\"\", options=[]) {\n  let loss = mean_loss(f, data, weights, keys, label, l2);\n  let isString = value =&gt; typeof value === 'string';\n  \n  let accessors = get_accessors(keys);\n  let index_accessors = get_accessors(keys, true);\n  let domains = get_domains(data, get_accessors([label].concat(keys)));\n  const get_label = isString(label) ? (x =&gt; x[label]) : label;\n\n  let stroke_shade = stroke;\n  if (stroke == \"\") {\n    stroke_shade = (x =&gt; f(predict(x, weights, keys), get_label(x)))\n  }\n\n  let a = []\n  if (options.indexOf(\"Show feature transforms\") &gt;= 0){\n    a = [Plot.line(sample((x) =&gt;  keys[1][1](x), domains[1][0], domains[1][1]), {stroke: 'red'}),\n      Plot.line(sample((x) =&gt; keys[2][1](x), domains[1][0], domains[1][1]), {stroke: 'blue'})]\n  }\n  \n  return Plot.plot({\n    y: {domain: domains[0]},\n    title: \"Loss: \" + loss.toFixed(3),\n    color: {type: \"linear\", legend: true, label: \"Loss\", scheme: \"BuRd\", domain: [0, 100]},\n    marks: [\n      Plot.line(sample((x) =&gt; predict([x], weights, index_accessors), domains[1][0], domains[1][1]), {stroke: 'black'}),\n      Plot.dot(data, {x: accessors[0], y: get_label, stroke: stroke_shade })\n    ].concat(a)\n  })\n}\ndata = FileAttachment(\"data/auto-mpg.csv\").csv({typed: true})"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#training-and-test-datasets",
    "href": "lecture4-feature-transforms/notes.html#training-and-test-datasets",
    "title": "Lecture 4: Feature transforms",
    "section": "Training and test datasets",
    "text": "Training and test datasets\nIn machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for new data. One way to estimate how well our model our model will generalize to new data is to hold out data while fitting our model. To do this we will split our dataset into two smaller datasets: a training dataset that we will use to fit our model, and a test or held-out dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n\\[\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n\\]\n\\[\n\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n\\]\n\n\n\nTraining data\n\n\n\n\n\n\n\n\n\ncar name\nweight\ndisplacement\nhorsepower\nacceleration\n\n\n\n\n0\nchevrolet chevelle malibu\n3504\n307.0\n130\n12.0\n\n\n1\nbuick skylark 320\n3693\n350.0\n165\n11.5\n\n\n2\nplymouth satellite\n3436\n318.0\n150\n11.0\n\n\n3\namc rebel sst\n3433\n304.0\n150\n12.0\n\n\n4\nford torino\n3449\n302.0\n140\n10.5\n\n\n...\n...\n...\n...\n...\n...\n\n\n295\ndodge colt hatchback custom\n1915\n98.0\n80\n14.4\n\n\n296\namc spirit dl\n2670\n121.0\n80\n15.0\n\n\n297\nmercedes benz 300d\n3530\n183.0\n77\n20.1\n\n\n298\ncadillac eldorado\n3900\n350.0\n125\n17.4\n\n\n299\npeugeot 504\n3190\n141.0\n71\n24.8\n\n\n\n\n300 rows × 5 columns\n\n\n\n\n\n\n\n\nTest data\n\n\n\n\n\n\n\n\n\ncar name\nweight\ndisplacement\nhorsepower\nacceleration\n\n\n\n\n300\noldsmobile cutlass salon brougham\n3420\n260.0\n90\n22.2\n\n\n301\nplymouth horizon\n2200\n105.0\n70\n13.2\n\n\n302\nplymouth horizon tc3\n2150\n105.0\n70\n14.9\n\n\n303\ndatsun 210\n2020\n85.0\n65\n19.2\n\n\n304\nfiat strada custom\n2130\n91.0\n69\n14.7\n\n\n...\n...\n...\n...\n...\n...\n\n\n393\nford mustang gl\n2790\n140.0\n86\n15.6\n\n\n394\nvw pickup\n2130\n97.0\n52\n24.6\n\n\n395\ndodge rampage\n2295\n135.0\n84\n11.6\n\n\n396\nford ranger\n2625\n120.0\n79\n18.6\n\n\n397\nchevy s-10\n2720\n119.0\n82\n19.4\n\n\n\n\n98 rows × 5 columns\n\n\n\n\n\n\nFor example, we might see that our model does well on the data it was fit on and poorly on new data.\n\n\n\nTraining data\n\nregressionPlot(data.slice(0,300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")\n\n\n\n\n\n\n\n\n\nTest data\n\nregressionPlot(data.slice(300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#spliting-data-in-practice",
    "href": "lecture4-feature-transforms/notes.html#spliting-data-in-practice",
    "title": "Lecture 4: Feature transforms",
    "section": "Spliting data in practice",
    "text": "Spliting data in practice\nIn general a good rule of thumb is to reserve \\(30\\%\\) of you data for evaluation, but anywhere from \\(10\\%\\) to \\(50\\%\\) is common in practice.\nIt is also very import very important to split data at random. Often real-world data is stored in a meaningul order and we don’t want this order to bias our results. In fact, the previous example was not split randomly. We see that if we do split randomly our evaluation looks much better.\n\n\n\nTraining data\n\nsdata = data.slice()\na = shuffle(sdata)\nregressionPlot(sdata.slice(0,300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest data\n\nregressionPlot(sdata.slice(300), [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")\n\n\n\n\n\n\n\n\n\nIn numpy we can accomplish this splitting by creating a random order of observations and applying it to both \\(X\\) and \\(y\\)\n\norder = np.arange(X.shape[0])    # Get an array of indices (1...N)\nnumTrain = int(X.shape[0] * 0.7) # Get the number of training obs. (70%)\ntrainInds = order[:numTrain]     # Get the indices of training obs. (70%)\ntestInds = order[numTrain:]      # Get the indices of test obs. (30%)\n\n# Get the data and labels for each split\ntrainX, trainy = X[trainInds], y[trainInds]\ntestX, testy = X[testInds], y[testInds]"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#linear-predictions",
    "href": "lecture4-feature-transforms/notes.html#linear-predictions",
    "title": "Lecture 4: Feature transforms",
    "section": "Linear predictions",
    "text": "Linear predictions\nIn the previous two lectures, we looked at examples of linear models. For example, we saw that the linear regression model makes predictions of the form:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w} = \\sum_{i=1}^n x_i w_i\n\\]\nMeaning that the output will be a weighted sum of the features of the input. In the case of our car example, we will made predictions as:\n\\[\n\\text{Predicted MPG} = f(\\mathbf{x})=\n\\]\n\\[\n(\\text{weight})w_1 + (\\text{horsepower})w_2 + (\\text{displacement})w_3 + (\\text{0-60mph})w_4 + b\n\\]\nGraphically we see this corresponds to a prediction function that is a line or a plane.\n\nregressionPlot(data, [45.32, -0.0077], [\"weight\"], x =&gt; x.mpg, 0, se, \"crimson\")"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#non-linear-data",
    "href": "lecture4-feature-transforms/notes.html#non-linear-data",
    "title": "Lecture 4: Feature transforms",
    "section": "Non-linear data",
    "text": "Non-linear data\nUnfortunately, in the real world the relationship between inputs and outputs is not always linear. For example, what if we tried to fit a linear model to the following dataset.\n\nviewof form_quadratic = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 2.89}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w\", value: 2.0165}),\n  ]\n)\n\n\n\n\n\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_quadratic, [\"0\"], \"1\", 0, se)\n\n\n\n\n\n\nWe see that there is no straight line that is a good fit to our data. We see this with our real-world fuel efficiency dataset as well: we can find a line that reasonably approximates the relationship between weight and efficiency, but a curve would fit the data better.\n\nviewof form_mpg_linear = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w\", value: -0.0077}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_linear, [\"weight\"], \"mpg\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#polynomial-functions",
    "href": "lecture4-feature-transforms/notes.html#polynomial-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Polynomial functions",
    "text": "Polynomial functions\nIf we’re trying to approximate a non-linear relationship between inputs and outputs, it follows that we may want to fit a non-linear approximation.\nOne of the simplest types of non-linear functions we could use are polynomial functions. A polynomial function is simply a function that can be expressed as a polynomial, meaning that it allows for (integer) powers of the input.\nThe simplest type of non-linear polynomial is a quadratic function, which involves powers of up to \\(2\\). A quadratic function of a single variable can be written as:\n\\[\nf(x) = w_2 x^2 + w_1x +b\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nA quadratic function of \\(2\\) variables can be written as:\n\\[\nf(x, y) = w_5 x^2 + w_4y^2 + w_3 xy + w_2x + w_1y +b\n\\]\nSimilarly a cubic function involves powers up to 3:\n\\[\nf(x) = w_3 x^3 + w_2 x^2 + w_1x +b\n\\]\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\nIn general the degree of a polynomial is the largest exponent in any term of the polynomial (or sum of exponents for terms involving more than 1 input). For example we can look at 2 different degree 4 polynomial functions:\n\\[\nf(x, y) = 3 x^4 + 2 xy + y - 2\n\\]\n\\[\nf(x, y) = -2 x^2y^2 + 2 x^3 + y^2 - 5\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#polynomial-functions-as-vector-functions",
    "href": "lecture4-feature-transforms/notes.html#polynomial-functions-as-vector-functions",
    "title": "Lecture 4: Feature transforms",
    "section": "Polynomial functions as vector functions",
    "text": "Polynomial functions as vector functions\nWe can also write polynomial functions as vector-input functions. For example a quadratic function of two variables could be written as:\n\\[\nf(\\mathbf{x}) = w_5 x_2^2 + w_4x_1^2 + w_3 x_1 x_2 + w_2x_2 + w_1x_1 +b\n\\]\nFrom this form we see that a polynomial is a weighted sum of powers of \\(\\mathbf{x}\\)! This means we could write a vector polynomial as a dot product between a weight vector and a vector containing all the powers of \\(\\mathbf{x}\\):\n\\[\nw_5 x_2^2 + w_4x_1^2 + w_3 x_1 x_2 + w_2x + w_1y +b = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix} \\cdot \\begin{bmatrix}  w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\\\ w_5 \\\\  b \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#quadratic-feature-transforms",
    "href": "lecture4-feature-transforms/notes.html#quadratic-feature-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic feature transforms",
    "text": "Quadratic feature transforms\nLet’s consider the mapping from \\(\\mathbf{x}\\) to powers of the elements of \\(\\mathbf{x}\\). We’ll call this mapping \\(\\phi\\):\n\\[\n\\begin{bmatrix}  x_1 \\\\ x_2 \\end{bmatrix}\\underset{\\phi}{\\longrightarrow}\\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nIn this quadratic example \\(\\phi\\) is a non-linear function that maps vectors to vectors \\((\\mathbb{R}^2 \\rightarrow \\mathbb{R}^6)\\). We call this a quadratic feature transform\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nWith this mapping we can our quadratic prediction function simply as:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}\n\\]\nThis is a linear function of \\(\\phi(\\mathbf{x})\\) and \\(\\mathbf{w}\\)!\nAs a simpler example, let’s look at the case where our input has only a single element \\((x_1)\\).\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\  1 \\end{bmatrix}\n\\]\n\nviewof form_quadratic_2 = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 2.89}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_1\", value: 2.0165}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_2\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_quadratic_2, [[\"0\", x =&gt; x], [\"0\", x =&gt; x * x]], \"1\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#fitting-quadratic-regression",
    "href": "lecture4-feature-transforms/notes.html#fitting-quadratic-regression",
    "title": "Lecture 4: Feature transforms",
    "section": "Fitting quadratic regression",
    "text": "Fitting quadratic regression\nIf we treat \\(\\phi(\\mathbf{x})\\) as our new set of inputs, we see that we can apply all the same tools of linear regression that we learned before. Again our new prediction function is:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w}, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nWe can then define a quadratic probabilistic model as:\n\\[\ny_i \\sim \\mathcal{N}\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}, \\sigma^2\\big)\n\\]\nThe corresponding negative log-likelihood loss becomes\n\\[\n\\textbf{Loss}(\\mathbf{w})=\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})=- \\sum_{i=1}^N \\log p(y_i \\mid \\mathbf{x}_i, \\mathbf{w})\n\\]\n\\[\n= \\frac{1}{2\\sigma^2} \\sum_{i=1}^N\\big(y_i - \\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)^2 + N \\log \\sigma \\sqrt{2 \\pi}\n\\]\nWe can now find the optimal \\(\\mathbf{w}\\) by once again minimizing this loss!\n\\[\n\\mathbf{w}^* = \\underset{\\mathbf{w}}{\\text{argmin}} \\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n\\]\nWe see that the gradient doesn’t change, it simply involves \\(\\phi(\\mathbf{x}_i)\\) instead of \\(\\mathbf{x}_i\\).\n\\[\n\\nabla_{\\mathbf{w}}\\textbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y})\n= \\frac{1}{2\\sigma^2}\\sum_{i=1}^N \\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w} - y_i\\big)\\phi(\\mathbf{x}_i)\n\\] This is because we are only taking the gradient with respect to \\(\\mathbf{w}\\). From the perspective of \\(\\mathbf{w}\\), the prediction funciton is still linear."
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#quadratic-regression-on-real-data",
    "href": "lecture4-feature-transforms/notes.html#quadratic-regression-on-real-data",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic regression on real data",
    "text": "Quadratic regression on real data\nLet’s look at our new quadratic regression model on the problem of predicting fuel efficiency from a car’s weight. In this case because our input has only \\(1\\) entry our quadratic feature transform will be simpler:\n\\[\n\\begin{bmatrix}  x_1  \\end{bmatrix}\\underset{\\phi}{\\longrightarrow}\\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\  1 \\end{bmatrix}\n\\]\nOur prediction function will be:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\  1 \\end{bmatrix}\n\\]\nWe see that by varying \\(w_2\\), we can now fit a curve to our data and get a better overall loss!\n\nviewof form_mpg_2 = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_2\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_2, [\"weight\", [\"weight\", x =&gt; (x / 100) * (x / 100)]], \"mpg\", 0, se)"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#quadratic-logistic-regression",
    "href": "lecture4-feature-transforms/notes.html#quadratic-logistic-regression",
    "title": "Lecture 4: Feature transforms",
    "section": "Quadratic logistic regression",
    "text": "Quadratic logistic regression\nJust like with our regression example, we can apply our quadratic feature transform to the logistic regression model as well! In this case our prediction function becomes:\n\\[\nf(\\mathbf{x}) = \\mathbb{I}(\\phi(\\mathbf{x})^T\\mathbf{w} \\geq 0), \\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_1 x_2 \\\\ x_1^2 \\\\ x_2^2 \\\\  1 \\end{bmatrix}\n\\]\nOur Bernoulli probabilistic model becomes:\n\\[\ny_i \\sim \\mathbf{Bernoulli}\\big(\\mathbf{ \\sigma(\\phi(\\mathbf{x}_i)^T\\mathbf{w} })\\big), \\quad p(y_i = 1\\mid \\mathbf{x}_i, \\mathbf{w}) = \\sigma\\big(\\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)\n\\]\nThe corresponding negative log-likelihood is:\n\\[\n\\mathbf{NLL}(\\mathbf{w}, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log\\sigma\\big((2y_i-1)\\phi(\\mathbf{x}_i)^T\\mathbf{w}\\big)\n\\]\nWhich we can once again optimize with gradient descent.\nWith this approach our decision boundary is no longer restricted to be a line!\n\n\n\n\n\n\nviewof form_circles = Inputs.form(\n  [\n    Inputs.range([-100, 100], {step: 0.01, label: \"b\", value: 0}),\n    Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 20}),\n    Inputs.range([-100, 100], {step: 0.0001, label: \"w_2\", value: 20}),\n      Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 0}),\n      Inputs.range([-100, 100], {step: 0.0001, label: \"w_1\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\n\n\nlogisticPlot2d(circles, form_circles, [\"0\", \"1\", [\"0\", x=&gt;x*x], [\"1\", x=&gt;x*x]], \"2\")\n\n\n\n\n\n\n\n\nlogisticLossPlot2d(circles, form_circles, [\"0\", \"1\", [\"0\", x=&gt;x*x], [\"1\", x=&gt;x*x]], \"2\")\n\n\n\n\n\n\n\n\nWe can see where this circular decision boundary comes from if we think about the problem in 3-dimensions.\nRecall that our linear classifier made predictions by thresholding a linear function. Our quadratic classifer thresholds a quadratic function of 1 or more variables, producing the curve that we see above.\n\n\n\nLinear decision boundary\n\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuadratic decision boundary\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#general-polynomial-transforms",
    "href": "lecture4-feature-transforms/notes.html#general-polynomial-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "General polynomial transforms",
    "text": "General polynomial transforms\nWe’ve now seen how to define quadratic models by defining a function \\(\\phi\\) that maps inputs to new new inputs with quadratic terms. However we’re not restricted to just quadratic transform! For example, for a model with \\(1\\) input, we could definite a cubic feature transform as:\n\\[\n\\begin{bmatrix}  x_1  \\end{bmatrix}\\underset{\\phi}{\\longrightarrow}\\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\ x_1^3\\\\  1 \\end{bmatrix}\n\\]\nOur prediction function will be:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_3 x_1^3 + w_2 x_1^2 + w_1x_1 +b, \\quad\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2\\\\ x_1^3 \\\\  1 \\end{bmatrix}\n\\]\nWe can apply this to our regression model for fuel efficiency as before.\n\nviewof form_mpg_3 = Inputs.form(\n  [\n    Inputs.range([-10, 100], {step: 0.01, label: \"b\", value: 45.32}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-0.03, 0.03], {step: 0.0001, label: \"w_2\", value: 0}),\n    Inputs.range([-0.05, 0.05], {step: 0.0001, label: \"w_3\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(data, form_mpg_3, [\"weight\", [\"weight\", x =&gt; (x / 100) * (x / 100)], [\"weight\", x =&gt; (x / 250) * (x / 250) * (x / 250)]], \"mpg\", 0, se)\n\n\n\n\n\n\nWe can also similarly define general polynomial transforms using polynomials of higher degrees. Note that the number of features in the transformed input grows very quickly with the degree of the polynomial and the number of original input features. We’ll often just use a subset of the possible polynomial terms in our transform. For example we might use only powers of individual elements (i.e. \\(x_i^k\\)) with out considering the cross terms (i.e. \\(x_i^kx_j^p\\)).\nFor example we might define the following quadratic transform for 3-feature inputs:\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ x_3 \\\\ x_1^2\\\\ x_2^2 \\\\  x_3^2 \\\\ 1 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture4-feature-transforms/notes.html#general-feature-transforms",
    "href": "lecture4-feature-transforms/notes.html#general-feature-transforms",
    "title": "Lecture 4: Feature transforms",
    "section": "General feature transforms",
    "text": "General feature transforms\nIt’s also not necessary to restrict ourselves to transforms defined by integer powers of the inputs. We can use any scalar non-linear functions we want. For example we could define a transform using \\(\\sin\\) and \\(\\cos\\):\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ \\sin(x_1) \\\\ \\sin(x_2) \\\\ \\cos(x_1) \\\\ \\cos(x_2) \\\\ 1 \\end{bmatrix}\n\\]\nOr using the sigmoid function:\n\\[\n\\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_2 \\\\ \\sigma(x_1) \\\\ \\sigma(x_2)  \\\\ 1 \\end{bmatrix}\n\\]\nWe can see how different features allow us to define different nonlinear functions. In the example below we’ll try the prediction function:\n\\[\nf(\\mathbf{x})=\\phi(\\mathbf{x})^T \\mathbf{w} = w_3 e^{x_1} + w_2 \\sin(x_1) + w_1x_1^2 +b ,\\quad \\phi(\\mathbf{x}) = \\begin{bmatrix}  x_1 \\\\ x_1^2 \\\\ \\sin(x_1) \\\\ e^{x_1}  \\\\ 1 \\end{bmatrix}\n\\]\n\nviewof form_mpg_4 = Inputs.form(\n  [\n    Inputs.range([-10, 10], {step: 0.01, label: \"b\", value: 1}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_1\", value: -0.0077}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_2\", value: 0}),\n    Inputs.range([-10, 10], {step: 0.0001, label: \"w_3\", value: 0}),\n    Inputs.range([-0.5, 0.5], {step: 0.0001, label: \"w_4\", value: 0}),\n  ]\n)\n\n\n\n\n\n\n\nregressionPlot(quadratic_data, form_mpg_4, [\"0\", [\"0\", x =&gt; (x) * (x)], [\"0\", x =&gt; Math.sin(x)], [\"0\", x =&gt; Math.exp(x)]], \"1\", 0, se)\n\n\n\n\n\n\n\nsin_X = np.sin(X)               # sin(x)\nsquared_X = X ** 2              # x^2\nexp_X = np.exp(X)               # e^x\nones = np.ones((X.shape[0], 1)) # Column of 1s\n\ntransformedX = np.concatenate([X, squared_X, sin_X, exp_X, ones], axis=1)"
  },
  {
    "objectID": "lecture4-feature-transforms/figures.html",
    "href": "lecture4-feature-transforms/figures.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom manim import *\nimport autograd.numpy as np\n\n\nclass LectureScene(Scene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n\nclass ThreeDLectureScene(ThreeDScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n    \n\nclass VectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-7.5, 7.5, 1],\n            y_range=[-5, 5, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n        \n        #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass PositiveVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-2.5, 12.5, 1],\n            y_range=[-1, 9, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n                #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass ComparisonVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax1 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        self.ax2 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        axgroup = Group(self.ax1, self.ax2)\n        axgroup.arrange_in_grid(buf=2)\n        \n\n        #axes_labels.set_color(GREY)\n        self.add(axgroup)\n\nManim Community v0.17.3"
  },
  {
    "objectID": "lecture12-convolutions/figures.html",
    "href": "lecture12-convolutions/figures.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport contextlib\nwith open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n    from manim import *\nimport autograd.numpy as np\n\n\nclass LectureScene(Scene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n\nclass ThreeDLectureScene(ThreeDScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.camera.background_color = \"#ffffff\"\n        self.template = TexTemplate()\n        self.template.add_to_preamble(r\"\\usepackage{amsmath}\")\n    \n\nclass VectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-7.5, 7.5, 1],\n            y_range=[-5, 5, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n        \n        #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass PositiveVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax = Axes(\n            x_range=[-2.5, 12.5, 1],\n            y_range=[-1, 9, 1],\n            x_length=12,\n            y_length=8,\n            axis_config={\"color\": GREY},\n        )\n                #axes_labels.set_color(GREY)\n        self.add(self.ax)\n\nclass ComparisonVectorScene(LectureScene):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.ax1 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        self.ax2 = Axes(\n            x_range=[-5, 5, 1],\n            y_range=[-5, 5, 1],\n            x_length=6,\n            y_length=6,\n            axis_config={\"color\": GREY},\n        )\n        axgroup = Group(self.ax1, self.ax2)\n        axgroup.arrange_in_grid(buf=2)\n        \n        #axes_labels.set_color(GREY)\n        self.add(axgroup)\nfrom manim_ml.neural_network import NeuralNetwork, Convolutional2DLayer, MaxPooling2DLayer\n\n\ntype(BLACK)\n\nstr\n\n\n\n%%manim -pql -v WARNING Conv\ndef make_sequence(numbers, sl=0.5, colors=BLACK, fills=WHITE, text_colors=None, opacity=1.,  annot=True, stride=1, padding=0):\n    n = len(numbers)\n    squares = []\n\n    if type(colors) is str:\n        colors = [colors] * n\n    if text_colors is None:\n        text_colors = colors\n    elif type(text_colors) is str:\n        text_colors = [text_colors] * n\n    if type(fills) is str:\n        fills = [fills] * n\n\n    for i in range(n):\n        pos = i * stride * sl * RIGHT\n        square = Square(color=colors[i], fill_color=fills[i], side_length=sl,  fill_opacity=opacity).move_to(pos)\n        if annot:\n            text = Text(str(numbers[i]), color=text_colors[i]).scale(sl).move_to(pos)\n            squares.append(VGroup(square, text))\n        else:\n            squares.append(VGroup(square))\n    \n    if padding &gt; 0:\n        pads = []\n        for i in range(padding):\n            pos = (n + i) * sl * RIGHT\n            pads.append(Text('0', color=GRAY).scale(sl).move_to(pos))\n            pos = (-(i + 1)) * sl * RIGHT\n            pads.append(Text('0', color=GRAY).scale(sl).move_to(pos))\n        return VGroup(*squares), VGroup(*pads)\n\n    return VGroup(*squares)\n\ndef make_stack(numbers, sl=0.5, colors=BLACK, fills=WHITE, text_colors=None, opacity=1., annot=True, stride=1):\n    n = len(numbers)\n\n    if type(colors) is str:\n        colors = [colors] * n\n    if text_colors is None:\n        text_colors = colors\n    elif type(text_colors) is str:\n        text_colors = [text_colors] * n\n    if type(fills) is str:\n        fills = [fills] * n\n\n    seqs = []\n    for i in range(n):\n        seqs.append(make_sequence(numbers[i], sl, colors[i], fills[i], text_colors[i], opacity, annot, stride).shift(i * sl * DOWN))\n    return VGroup(*seqs)\n\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (kernel size: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        eq = Text(f'Output[{0 :2}]=({seqarr[0] :2})({kernelarr[0] :2})+({seqarr[1] :2})({kernelarr[1] :2})+({seqarr[2] :2})({kernelarr[2] :2})={outputarr[0] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n        self.add(sequence, output, highlight, eq)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(12):\n            neweq = Text(f'Output[{i+1 :2}]=({seqarr[0 + i] :2})({kernelarr[0] :2})+({seqarr[1 + i] :2})({kernelarr[1] :2})+({seqarr[2 + i] :2})({kernelarr[2] :2})={outputarr[1 + i] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), FadeIn(neweq), FadeOut(eq))\n            eq = neweq\n        self.wait(2)\n\n                                                                                                              \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING Conv\n\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        output_label = Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT)\n        self.add(output_label)\n        #self.add(Text('Convolution (kernel size: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        eq = Text(f'Output[{0 :2}]=({seqarr[0] :2})({kernelarr[0] :2})+({seqarr[1] :2})({kernelarr[1] :2})+({seqarr[2] :2})({kernelarr[2] :2})={outputarr[0] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n        self.add(sequence, output, highlight, eq)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(12):\n            neweq = Text(f'Output[{i+1 :2}]=({seqarr[0 + i] :2})({kernelarr[0] :2})+({seqarr[1 + i] :2})({kernelarr[1] :2})+({seqarr[2 + i] :2})({kernelarr[2] :2})={outputarr[1 + i] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), FadeIn(neweq), FadeOut(eq), )\n            eq = neweq\n\n        kernel_window = VGroup(*lines)\n        self.wait(1)\n        self.play(FadeOut(kernel_window), FadeOut(output_window), run_time=0.25)\n        self.play(kernel.animate.shift(RIGHT * 2), output.animate.shift(1.5 * UP), output_label.animate.shift(1.5 * UP), run_time=0.5, )\n\n\n\n        kernelarr = [0, 0, 0]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=GREEN, colors=GREEN).move_to(-1 * UP)\n\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=GREEN, opacity=0.2, colors=GREEN).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=GREEN).shift(s * RIGHT)\n            lab = MathTex(r'+', color=GREEN).scale(0.5).next_to(l, 0.5 * LEFT) \n            lines += [l, lab]\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        highlight = VGroup(kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        self.add(sequence, output, highlight)\n\n        for i in range(12):\n            kernelarr[0] += seqarr[0 + i]\n            kernelarr[1] += seqarr[1 + i]\n            kernelarr[2] += seqarr[2 + i]\n            \n            new0 = Text(str(kernelarr[0]), color=GREEN).move_to(kernel[0][1].get_center()).scale(0.5)\n            new1 = Text(str(kernelarr[1]), color=GREEN).move_to(kernel[1][1].get_center()).scale(0.5)\n            new2 = Text(str(kernelarr[2]), color=GREEN).move_to(kernel[2][1].get_center()).scale(0.5)\n            self.play(kernel[0][1].animate.become(new0), kernel[1][1].animate.become(new1), kernel[2][1].animate.become(new2), run_time=0.1)\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.5)\n        self.wait(2)\n\n\n                                                                                                              \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING Conv\n\nfrom copy import deepcopy\ncolors = [GOLD, RED, PURPLE]\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        output_label = Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT)\n        self.add(output_label)\n        self.add(Text('Convolution (kernel size: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=1., colors=GRAY_E, fills=colors).move_to(-1 * UP)\n        kernel.z_index=10\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=GRAY_E, colors=GRAY_E).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=colors, opacity=0.2, colors=GRAY_E, ).move_to(-2 * UP)\n\n        lines = []\n        static_lines = []\n        for s, c in zip([-0.5, 0., 0.5], colors):\n            l = Line(-1.75 * UP, -1.25 * UP, color=c).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=c).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=c)\n            lines += [l, lab, l2]\n\n            l = Line(-1.75 * UP + s * RIGHT, -.25 * UP, color=c)#.shift()\n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=c)\n            static_lines += [l2]\n\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        static_lines = VGroup(*static_lines)\n        \n\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        eq = Text(f'Output[{0 :2}]=({seqarr[0] :2})({kernelarr[0] :2})+({seqarr[1] :2})({kernelarr[1] :2})+({seqarr[2] :2})({kernelarr[2] :2})={outputarr[0] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n        self.add(sequence, output, highlight)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(12):\n            neweq = Text(f'Output[{i+1 :2}]=({seqarr[0 + i] :2})({kernelarr[0] :2})+({seqarr[1 + i] :2})({kernelarr[1] :2})+({seqarr[2 + i] :2})({kernelarr[2] :2})={outputarr[1 + i] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n            sl = deepcopy(static_lines).move_to(highlight)\n            sl.z_index = -100\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), FadeIn(sl) )\n            eq = neweq\n\n        return\n\n        kernel_window = VGroup(*lines)\n        self.wait(1)\n        self.play(FadeOut(kernel_window), FadeOut(output_window), run_time=0.25)\n        self.play(kernel.animate.shift(0.5 * RIGHT), output.animate.shift(.5 * UP), output_label.animate.shift(.5 * UP), sequence.animate.shift(.5 * DOWN), run_time=0.5, )\n\n\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True, text_colors=WHITE).move_to(-2 * UP)\n        outputarr = np.random.randint(-9, 9, (13,))\n\n        output = make_sequence(outputarr, annot=True).move_to(0 * UP)\n\n        self.play(FadeIn(output), FadeIn(sequence), kernel.animate.set_color(GREEN))\n        self.play(Rotate(kernel, 180 * DEGREES))\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=GREEN, colors=GREEN).move_to(-2 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=GREEN, opacity=0.2, colors=GREEN).move_to(0 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-.75 * UP, -.25 * UP, color=GREEN).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=GREEN).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-1.75 * UP, -1.5 * UP, -1.5 * UP + s * RIGHT, -1.25 * UP + s * RIGHT, color=GREEN)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GREEN).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        lines.append(output_window)\n        kernel_window = VGroup(*lines)\n        kernel_window.move_to(kernel)\n        self.play(FadeIn(kernel_window), FadeIn(output_window))\n\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        sequence[-1][1].set_color(BLACK)\n        for i in range(13):\n            self.play(highlight.animate.shift(LEFT * 0.5), sequence[(14 - i -1)][1].animate.set_color(BLACK) )\n            eq = neweq\n        self.play(highlight.animate.shift(LEFT * 0.5), sequence[(0)][1].animate.set_color(BLACK) )\n        self.wait(2)\n\n                                                                                                             \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING Conv\n\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        output_label = Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT)\n        self.add(output_label)\n        self.add(Text('Convolution (kernel size: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        eq = Text(f'Output[{0 :2}]=({seqarr[0] :2})({kernelarr[0] :2})+({seqarr[1] :2})({kernelarr[1] :2})+({seqarr[2] :2})({kernelarr[2] :2})={outputarr[0] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n        self.add(sequence, output, highlight)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(12):\n            neweq = Text(f'Output[{i+1 :2}]=({seqarr[0 + i] :2})({kernelarr[0] :2})+({seqarr[1 + i] :2})({kernelarr[1] :2})+({seqarr[2 + i] :2})({kernelarr[2] :2})={outputarr[1 + i] :3}', color=BLACK, font_size=36, font='Roboto Mono').shift(2 * UP)\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK) )\n            eq = neweq\n\n        kernel_window = VGroup(*lines)\n        self.wait(1)\n        self.play(FadeOut(kernel_window), FadeOut(output_window), run_time=0.25)\n        self.play(kernel.animate.shift(0.5 * RIGHT), output.animate.shift(.5 * UP), output_label.animate.shift(.5 * UP), sequence.animate.shift(.5 * DOWN), run_time=0.5, )\n\n\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True, text_colors=WHITE).move_to(-2 * UP)\n        outputarr = np.random.randint(-9, 9, (13,))\n\n        output = make_sequence(outputarr, annot=True).move_to(0 * UP)\n\n        self.play(FadeIn(output), FadeIn(sequence), kernel.animate.set_color(GREEN))\n        self.play(Rotate(kernel, 180 * DEGREES))\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=GREEN, colors=GREEN).move_to(-2 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, fills=GREEN, opacity=0.2, colors=GREEN).move_to(0 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-.75 * UP, -.25 * UP, color=GREEN).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=GREEN).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-1.75 * UP, -1.5 * UP, -1.5 * UP + s * RIGHT, -1.25 * UP + s * RIGHT, color=GREEN)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GREEN).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        lines.append(output_window)\n        kernel_window = VGroup(*lines)\n        kernel_window.move_to(kernel)\n        self.play(FadeIn(kernel_window), FadeIn(output_window))\n\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        sequence[-1][1].set_color(BLACK)\n        for i in range(13):\n            self.play(highlight.animate.shift(LEFT * 0.5), sequence[(14 - i -1)][1].animate.set_color(BLACK) )\n            eq = neweq\n        self.play(highlight.animate.shift(LEFT * 0.5), sequence[(0)][1].animate.set_color(BLACK) )\n        self.wait(2)\n\n                                                                                                              \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING Conv\n\nclass Conv(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (kernel size: 5)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n\n        kernelarr = [1, -1, 3, -1, 1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1, 1, 1], annot=False, fills=RED, opacity=0.2, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-1., -0.5, 0., 0.5, 1.]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 5 * LEFT)\n        self.add(sequence, output, highlight)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(10):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK))\n        self.wait(2)\n\n                                                                                                              \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING Shuffle\n\nclass Shuffle(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (size: 3) + Shuffle', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (16,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False,  opacity=0.2, fills=RED, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6.5 * LEFT)\n        self.add(sequence, output, highlight)\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(13):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.5)\n        n=16\n        self.play(output_window.animate.set_opacity(0.), kernel_window.animate.set_opacity(0.), sequence.animate.set_opacity(0.5), run_time=0.5)\n\n        stack_anims = []\n        for i, o in enumerate(output):\n            if i % 2 == 0:\n                stack_anims.append(o.animate.shift(RIGHT * 0.25 + 0.25 * UP))\n            else:\n                stack_anims.append(o.animate.shift(LEFT * 0.25 + 0.25 * DOWN))\n        self.play(*stack_anims)\n\n        \n\n        shift_anims = []\n        for i, o in enumerate(output):\n            j = i // 2\n            s = j - (n / 4)\n            shift_anims.append(o.animate.shift(LEFT * s * 0.5 + 0.5 * LEFT))\n        self.play(*shift_anims)\n\n        self.wait(3)\n\n                                                                                                           \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING MovingAround\n\nclass MovingAround(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Pooling', color=BLUE, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + 1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + 2 * UP))\n        self.add(Text('Conv. output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (size: 3) + Max Pooling (size: 3, stride: 2)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (16,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        outputarr2 = maxpool1d(outputarr, 3, stride=2)\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n        output2 = make_sequence(outputarr2.astype(int), annot=True, stride=2, text_colors=WHITE).move_to(2 * UP + 0.25 * LEFT)\n\n        output_window = make_sequence([1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, opacity=0.2, fills=RED,  colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        maxpool_window = make_sequence([1, 1, 1], annot=False, opacity=0.2, colors=BLUE, fills=BLUE).move_to(0 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l2 = CubicBezier(0.25 * UP + s * RIGHT, 0.25 * UP + UP + s * RIGHT, UP, 1.75 * UP, color=BLUE)\n            lines += [l2]\n        lines.append(MathTex(r'\\max', color=BLUE).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(maxpool_window)\n        maxpool_window = VGroup(*lines)\n\n\n        maxpool_output_window = make_sequence([1], annot=False, opacity=0.2, colors=BLUE, fills=BLUE).move_to(2 * UP)\n        maxpool_highlight = VGroup(maxpool_output_window, maxpool_window).shift(0.5 * 5.5 * LEFT)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6.5 * LEFT)\n        self.add(sequence, output, highlight, output2, )\n\n                \n        output[0][1].set_color(BLACK)\n        for i in range(13):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.1)\n        n=16\n\n        self.play(FadeIn(maxpool_highlight), highlight.animate.set_opacity(0.), output2[0][1].animate.set_color(BLACK), sequence.animate.set_opacity(0.5))\n\n        for i in range(5):\n            self.play(maxpool_highlight.animate.shift(RIGHT * 1.), output2[i + 1][1].animate.set_color(BLACK))\n\n        self.play(maxpool_highlight.animate.set_opacity(0.), output.animate.set_opacity(0.5))\n        shift_anims = []\n        for i, o in enumerate(output2):\n            j = i\n            s = j - (4)\n            shift_anims.append(o.animate.shift(LEFT * s * 0.5 + 0.5 * LEFT))\n        self.play(*shift_anims)\n        self.wait(3)\n        \n\n                                                                                                               \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING MovingAround\n\nclass MovingAround(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (size: 3, stride: 2)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence = make_sequence(seqarr, annot=True).move_to(-2 * UP)\n        outputarr = [sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n\n        output = make_sequence(outputarr[::2], annot=True, stride=2, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 6 * LEFT)\n        self.add(sequence, output, highlight)\n                \n        output[0][1].set_color(BLACK)\n        for i in range(6):\n            self.play(highlight.animate.shift(RIGHT * 1), output[i + 1][1].animate.set_color(BLACK))\n\n        self.play(output_window.animate.set_opacity(0.), sequence.animate.set_opacity(0.5), kernel_window.animate.set_opacity(0.))\n        shift_anims = []\n        for i, o in enumerate(output):\n            j = i\n            s = j - (4)\n            shift_anims.append(o.animate.shift(LEFT * s * 0.5 + 0.5 * LEFT))\n        self.play(*shift_anims)\n        self.wait(2)\n\n                                                                                                    \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING MovingAround\n\nfrom scipy.ndimage import correlate\n\n\nclass MovingAround(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -1 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Convolution (size: 3, padding: 1)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n        kernelarr = [-1, 3, -1]\n        kw = len(kernelarr) // 2\n        kernel = make_sequence(kernelarr, annot=True, opacity=0.2, fills=RED, colors=RED).move_to(-1 * UP)\n        seqarr = np.random.randint(-9, 9, (15,))\n\n        sequence, pads = make_sequence(seqarr, annot=True, padding=1)\n        sequence.move_to(-2 * UP), pads.move_to(-2 * UP)\n        outputarr = convolution1d(seqarr, kernelarr, padding=1).astype(int)\n\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(0 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(0 * UP)\n        kernel_window = make_sequence([1, 1, 1], annot=False, opacity=0.2, fills=RED, colors=RED).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.75 * UP, -1.25 * UP, color=RED).shift(s * RIGHT)\n            lab = MathTex(r'\\times', color=RED).scale(0.5).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.75 * UP + s * RIGHT, -.5 * UP + s * RIGHT, -.5 * UP, -.25 * UP, color=RED)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=RED).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * 7 * LEFT)\n        \n        self.add(sequence, output, pads)\n        self.play(FadeIn(highlight), output[0][1].animate.set_color(BLACK))\n                \n        \n        for i in range(14):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.5)\n        \n        self.wait(2)\n        \n\n                                                                                                    \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING MovingAround\n\nclass MovingAround(LectureScene):\n\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + 2 * UP))\n        self.add(Text('Convolution (size: 3, channels: 3, output channels: 1)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n        n = 16\n        \n        seqarr = np.random.randint(-9, 9, (3, n,))\n        sequence = make_stack(seqarr, annot=True).move_to(-2 * UP)\n\n\n        kernelarr = np.random.randint(-3, 3, (3, 3,))\n        kw = len(kernelarr[0]) // 2\n        kernel = make_stack(kernelarr, annot=True, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(0 * UP)\n        outputarr = convolution1d(seqarr.T, kernelarr).astype(int) #np.zeros(14).astype(int)#[sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(1.5 * UP)\n\n        output_window = make_sequence([1], annot=False, opacity=0.2, colors=GRAY, fills=GRAY).move_to(1.5 * UP)\n        kernel_window = make_stack(kernelarr, annot=False, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.25 * UP, -.75 * UP, color=GRAY).shift(s * RIGHT)\n            lab = MathTex(r'\\text{dot}', color=GRAY).scale(0.35).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.25 * UP + UP + s * RIGHT,  UP + s * RIGHT,  UP, .25 * UP + UP, color=GRAY)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GRAY).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * (n-3) / 2 * LEFT)\n        self.add(sequence, output, highlight)\n                \n        output[0][1].set_color(BLACK)\n        for i in range(n - 3):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.5)\n\n        self.wait(2)\n\n        #stack_anims = []\n        #for i, o in enumerate(output):\n        #    if i % 2 == 0:\n        #        stack_anims.append(o.animate.shift(RIGHT * 0.25 + 0.25 * UP))\n        #    else:\n        #        stack_anims.append(o.animate.shift(LEFT * 0.25 + 0.25 * DOWN))\n        #self.play(*stack_anims)\n\n        #shift_anims = []\n        #for i, o in enumerate(output):\n        #    j = i // 2\n        #    s = j - (n / 4)\n        #    shift_anims.append(o.animate.shift(LEFT * s * 0.5))\n        #self.play(*shift_anims)\n\n                                                                                                    \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n%%manim -pql -v WARNING MovingAround\n\nclass MovingAround(LectureScene):\n    def construct(self):\n        self.add(Text('Input', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + -2 * UP))\n        self.add(Text('Kernel', color=RED, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + 0 * UP))\n        self.add(Text('Output', color=GRAY, opacity=0.5, font='Noto Sans').scale(0.6).move_to(5 * LEFT + 2 * UP))\n        self.add(Text('Convolution (size: 3, channels: 3, output channels: 3)', color=BLACK,  font='Noto Sans SemiBold').scale(0.8).move_to(3.5 * UP))\n        n = 16\n        \n        seqarr = np.random.randint(-9, 9, (3, n,))\n        sequence = make_stack(seqarr, annot=True).move_to(-2 * UP)\n\n\n        kernelarr = np.random.randint(-3, 3, (3, 3,))\n        kw = len(kernelarr[0]) // 2\n        kernel = make_stack(kernelarr, annot=True, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(0 * UP)\n        outputarr = convolution1d(seqarr.T, kernelarr).astype(int) #np.zeros(14).astype(int)#[sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(1.5 * UP)\n        output_window = make_sequence([1], annot=False, opacity=0.2, colors=GRAY, fills=GRAY).move_to(1.5 * UP)\n        kernel_window = make_stack(kernelarr, annot=False, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.25 * UP, -.75 * UP, color=GRAY).shift(s * RIGHT)\n            lab = MathTex(r'\\text{dot}', color=GRAY).scale(0.35).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.25 * UP + UP + s * RIGHT,  UP + s * RIGHT,  UP, .25 * UP + UP, color=GRAY)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GRAY).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * (n-3) / 2 * LEFT)\n        self.add(sequence, output, highlight)\n  \n        output[0][1].set_color(BLACK)\n        for i in range(n - 3):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.3)\n\n        self.play(FadeOut(kernel_window),  FadeOut(output_window) , run_time=0.25)\n        self.play(kernel.animate.move_to(5.5 * RIGHT), run_time=0.5)\n        self.play(kernel.animate.shift(2 * UP), run_time=0.5)\n\n\n        kernelarr = np.random.randint(-3, 3, (3, 3,))\n        kw = len(kernelarr[0]) // 2\n        kernel = make_stack(kernelarr, annot=True, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(0 * UP)\n        outputarr = convolution1d(seqarr.T, kernelarr).astype(int) #np.zeros(14).astype(int)#[sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(2 * UP)\n        output_window = make_sequence([1], annot=False, opacity=0.2, colors=GRAY, fills=GRAY).move_to(2 * UP)\n        kernel_window = make_stack(kernelarr, annot=False, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.25 * UP, -.75 * UP, color=GRAY).shift(s * RIGHT)\n            lab = MathTex(r'\\text{dot}', color=GRAY).scale(0.35).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.25 * UP + UP + s * RIGHT,  UP + s * RIGHT,  UP, .25 * UP + UP, color=GRAY)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GRAY).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n        \n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * (n-3) / 2 * LEFT)\n        self.play(FadeIn(output), FadeIn(highlight), run_time=0.5)\n\n        output[0][1].set_color(BLACK)\n        for i in range(n - 3):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.3)\n\n        self.play(FadeOut(kernel_window),  FadeOut(output_window), run_time=0.25)\n        self.play(kernel.animate.move_to(5.5 * RIGHT), run_time=0.5)\n        self.play(kernel.animate.shift(2 * DOWN),  run_time=0.5)\n\n        kernelarr = np.random.randint(-3, 3, (3, 3,))\n        kw = len(kernelarr[0]) // 2\n        kernel = make_stack(kernelarr, annot=True, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(0 * UP)\n        outputarr = convolution1d(seqarr.T, kernelarr).astype(int) #np.zeros(14).astype(int)#[sum([seqarr[s - kw + i] * k for i, k in enumerate(kernelarr)]) for s in range(kw, len(seqarr) - kw)]\n        output = make_sequence(outputarr, annot=True, text_colors=WHITE).move_to(2.5 * UP)\n        output_window = make_sequence([1], annot=False, opacity=0.2, colors=GRAY, fills=GRAY).move_to(2.5 * UP)\n        kernel_window = make_stack(kernelarr, annot=False, opacity=0.2, colors=[RED, GREEN, BLUE], fills=[RED, GREEN, BLUE]).move_to(-2 * UP)\n\n        lines = []\n        for s in [-0.5, 0., 0.5]:\n            l = Line(-1.25 * UP, -.75 * UP, color=GRAY).shift(s * RIGHT)\n            lab = MathTex(r'\\text{dot}', color=GRAY).scale(0.35).next_to(l, 0.5 * LEFT) \n            l2 = CubicBezier(-.25 * UP + UP + s * RIGHT,  UP + s * RIGHT,  UP, .25 * UP + UP, color=GRAY)\n            lines += [l, lab, l2]\n        lines.append(MathTex(r'+', color=GRAY).scale(0.5).next_to(l2, 1.5 * LEFT).shift(0.1 * UP))\n        lines.append(kernel_window)\n        kernel_window = VGroup(*lines)\n\n        highlight = VGroup(output_window, kernel_window, kernel)\n        highlight.shift(0.5 * (n-3) / 2 * LEFT)\n        self.play(FadeIn(output), FadeIn(highlight), run_time=0.5)\n\n        output[0][1].set_color(BLACK)\n        for i in range(n - 3):\n            self.play(highlight.animate.shift(RIGHT * 0.5), output[i + 1][1].animate.set_color(BLACK), run_time=0.3)\n\n        self.play(FadeOut(kernel_window),  FadeOut(output_window), run_time=0.25)\n        self.play(kernel.animate.move_to(5.5 * RIGHT), run_time=0.5)\n        self.play( sequence.animate.set_opacity(0.5), run_time=0.5)\n\n        self.wait(2)\n\n                                                                                                      \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\ndef convolution1d(x, kernel):\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1)\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            output[i] += x[i + j] * kernel[j]\n    return output\n\n\ndef convolution1d(x, kernel):\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1)\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            output[i] += np.dot(x[i + j], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = input_size - (kernel_width - 1) + 2 * padding\n    output = np.zeros((output_size,))\n    for i in range(output_size):\n        for j in range(kernel_width):\n            ind = i + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0, stride=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        for j in range(kernel_width):\n            ind = i * stride + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, padding=0, stride=1, dialation=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - dialation * (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        for j in range(kernel_width):\n            ind = i * stride + j * dialation - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef convolution1d(x, kernel, bias=0, padding=0, stride=1, dialation=1):\n\n    kernel_width = len(kernel)\n    input_size = len(x)\n\n    output_size = (input_size - dialation * (kernel_width - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        output[i] = bias\n        for j in range(kernel_width):\n            ind = i * stride + j * dialation - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] += np.dot(x[ind], kernel[j])\n    return output\n\n\ndef maxpool1d(x, window, padding=0, stride=1):\n    input_size = len(x)\n\n    output_size = (input_size - (window - 1) + 2 * padding - 1) // stride + 1\n    output = np.zeros((output_size,))\n    for i in range(len(output)):\n        output[i] = -np.infty\n        for j in range(window):\n            ind = i * stride + j - padding\n            if ind &gt;= 0 and ind &lt; input_size:\n                output[i] = np.maximum(x[ind], output[i])\n    return output\n\n\n\nfrom manim import *\n\nManim Community v0.17.3\n\n\n\n\n\n%%manim -pql -v WARNING MovingAround\n\nfrom manim_ml.neural_network import NeuralNetwork, FeedForwardLayer\nclass MovingAround(Scene):\n    def construct(self):\n        nn = NeuralNetwork([\n            FeedForwardLayer(num_nodes=3),\n            FeedForwardLayer(num_nodes=5),\n            FeedForwardLayer(num_nodes=3)\n        ])\n        self.add(nn)\n        # Make the animation\n        forward_pass_animation = nn.make_forward_pass_animation()\n        # Play the animation\n        self.play(forward_pass_animation)\n\nConstructing layers\nCurrent layer: FeedForwardLayer\nCurrent layer: FeedForwardLayer\nCurrent layer: FeedForwardLayer\nNeuralNetwork([\n    FeedForwardLayer(z_index=3, title_text= , ),\n    FeedForwardToFeedForward(input_layer=FeedForwardLayer,output_layer=FeedForwardLayer,)(z_index=2, title_text= , ),\n    FeedForwardLayer(z_index=3, title_text= , ),\n    FeedForwardToFeedForward(input_layer=FeedForwardLayer,output_layer=FeedForwardLayer,)(z_index=2, title_text= , ),\n    FeedForwardLayer(z_index=3, title_text= , ),\n])\n\n\n                                                                               \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nimport manim_ml\n\n\nmanim_ml.ThreeDScene\n\n&lt;module 'manim_ml' from '/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/.venv/lib/python3.9/site-packages/manim_ml/__init__.py'&gt;"
  },
  {
    "objectID": "lecture2-linear-regression/viz.html",
    "href": "lecture2-linear-regression/viz.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() =&gt; window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) =&gt; {\n    let globals = {};\n    const code = strings.reduce((result, string, index) =&gt; {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () =&gt; tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () =&gt; tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) =&gt; {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () =&gt; tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start &lt; 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) &gt; 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg = FileAttachment(\"auto-mpg.csv\").csv()\n\n\n\n\n\n\n\ndata = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std())\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  return tf.dot(x, w.T)\n\nwrange = tf.linspace(-3, 3, 25)\nbrange = tf.linspace(-3, 3, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean((predict(w, x) - y) ** 2, 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps &gt; 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta &gt; 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta &gt; 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-3, 3], 'title': 'Slope (w)'}, 'yaxis': {'range': [-3, 3], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = ybatch.reshape((-1,)) - predict(cweights, xbatch.reshape((-1,)),).flatten()\nlosses = (errors) ** 2\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=2))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'Prediction function: y = %.2f x + %.2f' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-2, 3], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\n\nnx = tf.linspace(-3, 3, 100)\nny = tf.exp(-nx ** 2)\nnormdata = dict(x=nx, y=ny, line=dict(color='red'), yaxis='y2',)\n\nPlotlyReactive(histfig, [ histdata, normdata], {'showlegend': False, 'title': 'Distribution of residuals', 'yaxis': {'title': {'text': 'Frequency'}},  'yaxis2': {'overlaying': 'y', 'range': [0, 1], 'visible': False}, 'xaxis': {'range': [-3, 3], 'title': {'text': 'Error (residual)'} }})\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n\n\n\n\n\n\n\n//viewof learningrate = Inputs.range([0, 3], {value: 1, step: 0.01, label: \" Learning rate\"})\nlearningrate = 0\n\n\n\n\n\n\n\n\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//viewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})\nsteps = 0\n\n\n\n\n\n\n\n\nhist = py`\n# Scatterplot figure\nhistfig = PlotlyFigure(width=500, height=500)\nhistfig\n`"
  },
  {
    "objectID": "lecture8-regularization/notes.html",
    "href": "lecture8-regularization/notes.html",
    "title": "Lecture 8: Regularization",
    "section": "",
    "text": "Try out the concepts from this lecture in the Neural Network Playground!"
  },
  {
    "objectID": "lecture8-regularization/notes.html#train-test-splits",
    "href": "lecture8-regularization/notes.html#train-test-splits",
    "title": "Lecture 8: Regularization",
    "section": "Train-test splits",
    "text": "Train-test splits\nAs we’ve seen previously to get an unbiased estimate of how well our model will perform on new data, it is good practice to hold-out a test set of data that we will not use to train our model with gradient descent. Instead we will fit our model on the remaining data (the training set) and then compute the loss (or other metrics like accuracy) on the test set, using this as an estimate of the performance of our model."
  },
  {
    "objectID": "lecture8-regularization/notes.html#train-validation-test-splits",
    "href": "lecture8-regularization/notes.html#train-validation-test-splits",
    "title": "Lecture 8: Regularization",
    "section": "Train-validation-test splits",
    "text": "Train-validation-test splits\nIf our test loss isn’t very good we may decide that we want to change our hyperparameters and train the model again. We could keep doing this over and over until we get a test loss that we’re satisfied with. However, as soon as we use the test data to make choices about our model, the test loss we’ll no longer be an unbiased estimate of the performance of our model on new data! After all, we’ve now used it to fit our model. This isn’t ideal as we will no longer have a reliable estimate for the true performance of our model.\nA simple approach to addressing this is to split our data into 3 parts: a training set that we’ll use for gradient descent, a test set that we’ll use for evaluating our model, and a validation set that we’ll use for choosing hyperparameters. When we run gradient descent, we can hold out both the test and validation sets, but we’ll allow ourselves to use the performance on the validation set (the validation loss) to choose hyperparameters. The test set we’ll reserve for the very end, when we’ve definitively chosen our model and need to estimate how well it will do. At a high-level the process looks like this:"
  },
  {
    "objectID": "lecture8-regularization/notes.html#cross-validation",
    "href": "lecture8-regularization/notes.html#cross-validation",
    "title": "Lecture 8: Regularization",
    "section": "Cross-validation",
    "text": "Cross-validation\nAn alternative approach is multiple splits of the same training data. Rather than partitioning our training set into distinct training and validation sets, we can divide our training set into \\(K\\) groups called folds.\nTo evaluate the performance of a given hyperparameter setting we can train our model multiple times, each time holding out a different group as the validation set. This gives us \\(K\\) estimates of the performance of a given choice of hyperparameters.\n\n\n\n\n\n\n\nCross-validation can be a more reliable way to choose hyperparameters at the expense of needing to retrain to model \\(K\\) times, which can be computationally expensive."
  },
  {
    "objectID": "lecture8-regularization/notes.html#overfitting-and-underfitting",
    "href": "lecture8-regularization/notes.html#overfitting-and-underfitting",
    "title": "Lecture 8: Regularization",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\nThere’s two possible reasons that a model might perform poorly on validation or test data (assuming gradient descent works well).\n\n\nUnderfitting occurs when our model is too simple to capture the data we’re trying to model. For example, if we try to fit a linear model to U-shaped data we see that the model can never fit the data well. We can identify underfitting when both the training and validation/test loss will be poor.\nOverfitting occurs when our prediction function is too complex. In this case the model may capture all of the small variations present in the training data even when these variations are simply due to noise or poor measurements, thus may not be reflected in held-out data. A better approach would be to model these variations as uncertainty rather than variations in the prediction function. We can identify overfitting when the training loss is good, but the validation/loss is poor.\n\nIf we think about plotting our training and validation loss as a function of the complexity of our model, we might see underfitting when the model is very simple and overfitting when the model is very complex. The idea model would be right in the middle when the validation loss is at its minimum.\n\nIn this case model complexity could mean several different things:\n\nNumber of layers\nNumber of neurons per layer\nActivation functions\nExplicit feature transforms applied\n\nLet’s look at a specific example where we’ll fit 3 neural networks of different levels of complexity on the same data:\n\nUnderfit model\n\n\n\nWell-fit model\n\n\n\nOverfit model\n\nIf we take a closer look at the overfit model, we can see that it actually fits the training data almost perfectly, but if we add more data from the same dataset, the performance looks much worse."
  },
  {
    "objectID": "lecture8-regularization/notes.html#tracking-validation-loss",
    "href": "lecture8-regularization/notes.html#tracking-validation-loss",
    "title": "Lecture 8: Regularization",
    "section": "Tracking validation loss",
    "text": "Tracking validation loss\nA common tool for quickly identifying poor performance is to track both the training and validation loss as we perform gradient descent. Doing this can let us see in real time if our model is underfitting or overfitting.\nIf we take a look a this type of plot from real neural network we see something interesting: the plot looks almost exactly like the model complexity plot we saw above.\n\n\n\n\n\n\n\nEarly in training both the training both the training and validation loss are improving, suggesting that at first the model is underfitting. After a while the training loss continues to improve, but the validation loss starts to get worse, suggesting that the model is beginning to overfit."
  },
  {
    "objectID": "lecture8-regularization/notes.html#early-stopping-1",
    "href": "lecture8-regularization/notes.html#early-stopping-1",
    "title": "Lecture 8: Regularization",
    "section": "Early stopping",
    "text": "Early stopping\nThe plot above suggests a simple strategy for preventing overfitting: simply stop gradient descent when the validation loss begins to increase! We call this approach early stopping.\n\nWe saw a simple way to implement this in the previous lecture: if the current validation loss is larger than the previous one, stop training.\n\nfor i in range(steps):\n    loss = compute_loss(model, training_data)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n    valid_loss = compute_loss(model, training_data)\n    if valid_loss &gt; valid_losses[-1]:\n        break\n        \n    valid_losses.append(valid_loss)\n\nIn the real world, the loss can be noisy:\n\nSo it may not make sense to stop the first time the validation loss increases. A common strategy to apply a more patient form of early stopping. In the case we stop if the validation loss hasn’t improved for some specified number of steps:\n\npatience = 5                    # Number of steps to wait before stopping\nsteps_since_improvement = 0     # Steps since validation loss improved\nmin_loss = 1e8                  # Minimum loss seen so far (start large)\n\nfor i in range(steps):\n    ...\n\n    valid_loss = compute_loss(model, training_data)\n\n    # If the validation loss improves reset the counter\n    if valid_loss &lt; min_loss:\n        steps_since_improvement = 0\n        min_loss = valid_loss\n\n    # Otherwise increment the counter\n    else:\n        steps_since_improvement += 1\n\n    # If its been patience steps since the last improvement, stop\n    if steps_since_improvement == patience:\n        break"
  },
  {
    "objectID": "lecture8-regularization/notes.html#l2-regularization",
    "href": "lecture8-regularization/notes.html#l2-regularization",
    "title": "Lecture 8: Regularization",
    "section": "L2 Regularization",
    "text": "L2 Regularization\nOne way that overfitting can manifest is as a prediction function that is overly sensitive to small changes in the input. We can see this in examples like the one below.\n\nHere in the overfit case, our prediction function is trying to capture the noise of the data rather than just the overall trend. This is explicitly encouraged by losses like the mean squared-error loss, as the loss says fit every observation as closely as possible:\n\\[\\textbf{MSE}(\\mathbf{X}, \\mathbf{y}, \\mathbf{w}) = \\frac{1}{N} \\sum_{i=1}^N ((f(\\mathbf{x}_i, \\mathbf{w}) - y_i)^2)\\]\nWhen our prediction function \\(f\\) is complex enough, it can exactly capture variations due to noise in the training data. As we can see, this means that the function must be very non-smooth, small changes in the input correspond to big changes in the output as we can clearly see in the marked region. This means that the function in this region has a very large slope.\nHow does this observation help us think about regularization? Well, we know that the weights of our model control the slope of the function; large weights correspond to large slopes. Therefore if we want to ensure our prediction function is smooth, we need to make sure that the weights are not too large.\n\n\n\nAn overfit network will have large weights to encode large slopes.\n\n\n\n\nA regularized network will have smaller weights encoding a smooth function.\n\n\nWe can account for this in our loss function by adding a loss that encourages our weights to be close to 0. One such loss is the L2 loss. For a given weight vector \\(\\mathbf{w}\\) the L2 loss is simply the squared 2-norm of the vector: \\[\\textbf{L}_2(\\mathbf{w}) = \\|\\mathbf{w}\\|_2^2 = \\sum_{i=1}^d w_i^2\\]\nIf we have a weight matrix \\(\\mathbf{W}\\) as in neural networks or multinomial logistic regression the L2 loss is just the squared matrix 2-norm, which is again simply the sum of every element squared. For a \\(d \\times e\\) weight matrix \\(\\mathbf{W}\\) the L2 loss is:\n\\[\\textbf{L}_2(\\mathbf{W}) = \\|\\mathbf{W}\\|_2^2 = \\sum_{i=1}^d\\sum_{j=1}^e w_{ij}^2\\]\nWe can then train our model with a combination of losses. For example, if we’re training a regression model we could use:\n\\[\\textbf{Loss}(\\mathbf{X}, \\mathbf{y}, \\mathbf{w}) = \\textbf{MSE}(\\mathbf{X}, \\mathbf{y}, \\mathbf{w}) + \\lambda \\textbf{L}_2(\\mathbf{w})\\]\nHere \\(\\lambda\\) is a value that we can choose to trade off between these two losses. Too high a value for \\(\\lambda\\) and we might end up with a value that is too smooth or just flat, too low and or L2 loss might not affect our result at all."
  },
  {
    "objectID": "lecture8-regularization/notes.html#l2-regularization-for-neural-networks",
    "href": "lecture8-regularization/notes.html#l2-regularization-for-neural-networks",
    "title": "Lecture 8: Regularization",
    "section": "L2 Regularization for neural networks",
    "text": "L2 Regularization for neural networks\nIf we are dealing with a neural network model, we may actually have many weight vectors and matrices. For example in a 4 hidden-layer network with sigmoid activations we have a prediction function that looks like: \\[f(\\mathbf{x}, \\mathbf{w}_0,...) = \\sigma( \\sigma( \\sigma( \\sigma( \\mathbf{x^T} \\mathbf{W}_4)^T  \\mathbf{W}_3)^T  \\mathbf{W}_2)^T \\mathbf{W}_1)^T \\mathbf{w}_0\\]\n\nIn this case, we can simply add up the L2 loss for every weight. For a network with \\(L\\) hidden layers the L2 loss would simply be: \\[\\textbf{L}_2(\\mathbf{w}_0, \\mathbf{W}_1,...,\\mathbf{W}_L) = \\sum_{l=0}^L\\|\\mathbf{W}_l\\|_2^2\\]\nIn practice most networks also incorporate bias terms, so each linear function in our network can be written as:\n\\[\n\\mathbf{x}^T\\mathbf{W} + \\mathbf{b}\n\\]\nAnd the full prediction function for a sigmoid-activation network might be:\n\\[f(\\mathbf{x}, \\mathbf{w}_0,...) = \\sigma( \\sigma( \\sigma( \\sigma( \\mathbf{x^T} \\mathbf{W}_4 + \\mathbf{b}_4)^T  \\mathbf{W}_3 + \\mathbf{b}_3)^T  \\mathbf{W}_2 + \\mathbf{b}_2)^T \\mathbf{W}_1 + \\mathbf{b}_1)^T \\mathbf{w}_0 + \\mathbf{b}_0\\]\nEach of these biases is a constant offset and does not affect the slope of the function or how quickly the output changes with small changes in the input. This means that the bias terms do not contribute to overfitting, therefore we do not need to regularize them!"
  },
  {
    "objectID": "lecture8-regularization/notes.html#l2-regularization-in-pytorch",
    "href": "lecture8-regularization/notes.html#l2-regularization-in-pytorch",
    "title": "Lecture 8: Regularization",
    "section": "L2 Regularization in PyTorch",
    "text": "L2 Regularization in PyTorch\nIn PyTorch, L2 regularization is actually handled by the optimizer and is known as weight decay. This name comes from the fact that regularization encourages unimportant weights to decay to 0. When creating a PyTorch optimizer, we can specify how much L2 regularization to add to our loss by setting the weight_decay option to our desired L2 weight ( \\(\\lambda\\) in our notation).\n\nfrom torch import optim\noptimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=0.01)"
  },
  {
    "objectID": "lecture8-regularization/notes.html#l1-regularization",
    "href": "lecture8-regularization/notes.html#l1-regularization",
    "title": "Lecture 8: Regularization",
    "section": "L1 Regularization",
    "text": "L1 Regularization\nA natural alternative to L2 regularization, where we minimized the square of each weight is to simply minimize the absolute value of each weight, which should have a similar effect of encouraging our weights to be close to 0.\n\\[\\text{Vector: }\\textbf{L}_1(\\mathbf{w}) = \\|\\mathbf{w}\\|_1 = \\sum_{i=1}^d |w_i|, \\quad \\text{Matrix: }\\textbf{L}_1(\\mathbf{W}) = \\|\\mathbf{W}\\|_1 = \\sum_{i=1}^d\\sum_{j=1}^e |w_{ij}|\\]\nWe call this L1 regularization, as it is equivalent to minimizing the L1 norm \\((\\|\\cdot\\|_1)\\) of each weight vector/matrix.\nIf we plot the L2 and L1 losses for a single weight \\(w\\), we can get a sense of the differences between these two approaches.\n\n\n\n\n\n\n\n\nWe see that the L2 loss strongly penalizes weights far from 0 compared to the L1 loss. However, this penalty decays quadratically towards 0, so weights close to 0 incur very little loss. The L1 loss decays linearly and thus more strongly penalizes weights that are already close to 0. Intuitively, this means that the L1 loss focuses on decreasing weights already close to 0 just as much as weights that are far from 0. This has the effect of encouraging sparsity, as the L1 loss can trade-off allowing some weights to be large if others go to exactly 0. The L2 loss encourages all weights to be reasonably small.\nWe can see the same distinction if we plot the L2 and L2 losses as a function of 2 weights:\n\nIf we overlay a hypothetical MSE loss as a function of the two weights, we can get a sense of why the L1 loss encourages sparsity. For most curves of constant MSE, the point that minimizes the L1 loss falls at a point where one of the weights is exactly 0. If our L1 weight \\((\\lambda)\\) is high enough, our overall minimum would fall at one of these points.\n\nWe can see the effect these two forms of regularization have on a real network.\n\n\n\nL2 Regularization encourages all weights to be small.\n\n\n\n\nL1 Regularization encourages all but the most relevant weights to go to 0."
  },
  {
    "objectID": "lecture8-regularization/notes.html#dropout",
    "href": "lecture8-regularization/notes.html#dropout",
    "title": "Lecture 8: Regularization",
    "section": "Dropout",
    "text": "Dropout\nAnother way to think about overfitting is through Interdependency. In order to capture small scale variations in our data, our network needs to dedicate many complex connections to capturing these specific variations. Another effective and popular form of regularization is dropout which purposefully breaks connections at training training time in order to encourage the network to learn reduce reliance on single specialized neurons and create redundancy.\nAs shown in this figure from the original dropout paper, dropout randomly removes neurons from the network at each step of training, performing the update with respect to this new randomized network.\n\nThe probability that any given neuron is removed is called the dropout rate \\(r\\). Mathematically, we can view dropout as a randomized function that is applied to the input of each layer. This function performs an element-wise multiplication \\((\\odot)\\) of the input \\(\\mathbf{X}\\) with a random matrix \\(\\mathbf{D}\\) of 1’s and 0’s, where \\(p(d_{ij}=0)=r\\).\n\\[\\text{Dropout}(\\mathbf{X}, r) = \\mathbf{D} \\odot \\mathbf{X}, \\quad \\mathbf{D} =\n\\begin{bmatrix}\nd_{11} & d_{12} & \\dots & d_{1n} \\\\\nd_{21} & d_{22} & \\dots & d_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nd_{m1} & d_{m2} & \\dots &  d_{mn}\n\\end{bmatrix},\\ d_{ij} \\sim \\text{Bernoulli}(1-r)\\]\nWe can shorten \\(\\text{Dropout}(\\mathbf{X}, r)\\) to \\(\\text{DO}_r(\\mathbf{X})\\). With this we can write a network layer with sigmoid activation and dropout as:\n\\[\n\\phi(\\mathbf{x}) = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b})\n\\]\nA network with several dropout layers would have a prediction function defined as:\n\\[f(\\mathbf{x}, \\mathbf{w}_0,...) = \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma( \\text{DO}_r(\\sigma(\\text{DO}_r( \\mathbf{x})^T  \\mathbf{W}_2 + \\mathbf{b}_2))^T \\mathbf{W}_1 + \\mathbf{b}_1))^T \\mathbf{w}_0 + \\mathbf{b}_0\\]\nOr more simply as a sequence of operations:\n\\[\n\\mathbf{a} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W}_2 + \\mathbf{b}_2)\n\\]\n\\[\n\\mathbf{b} = \\sigma(\\text{DO}_r(\\mathbf{a})^T\\mathbf{W}_1 + \\mathbf{b}_1)\n\\]\n\\[\n\\mathbf{f} = \\text{DO}_r(\\mathbf{b})^T\\mathbf{w}_0 + b_0\n\\]\nThe randomness introduced by dropout will cause our prediction function to be noisy. By dropping out different neurons at each step, we get different prediction functions from the same weights:\n\n\n\n\n\n\n\n\n\nIf we average all these networks however, we get something quite smooth, with redundancies in the predictions made by each neuron:\n\nWe can see from this example that unlike L2 and L1 regularization, dropout doesn’t enforce that weights should be small. Rather it encourages redundancy in the network, preventing neurons from becoming co-dependent."
  },
  {
    "objectID": "lecture8-regularization/notes.html#dropout-at-evaluation-time",
    "href": "lecture8-regularization/notes.html#dropout-at-evaluation-time",
    "title": "Lecture 8: Regularization",
    "section": "Dropout at evaluation time",
    "text": "Dropout at evaluation time\nWhen we’re evaluating our model or trying to make predictions on new data, we likely don’t want our prediction function to be noisy. As we can see in the examples above, applying dropout can lead to poor predictions if we’re unlucky. A simple approach might just remove the dropout functions at evaluation time:\n\\[\n\\phi(\\mathbf{x})_{train} = \\sigma(\\text{DO}_r(\\mathbf{x})^T\\mathbf{W} + \\mathbf{b}) \\quad \\rightarrow \\quad \\phi(\\mathbf{x})_{eval} = \\sigma(\\mathbf{x}^T\\mathbf{W} + \\mathbf{b})\n\\]\nHowever this has a problem! To see why consider the expected value of a linear function with dropout:\n\\[\n\\mathbb{E}[ \\text{DO}_r(\\mathbf{x})^T\\mathbf{w}] = \\sum_i d_i x_i w_i, \\quad d_i \\sim \\text{Bernoulli}(1-r)\n\\]\n\\[\n= \\sum_i p(d_i=1) x_i w_i = (1-r)\\sum_i  x_i w_i &lt;  \\sum_i  x_i w_i\n\\]\nIf \\(r=0.5\\) (the value suggested by the original dropout inventors), then on average the output of our function with dropout will only be half as large as the function without dropout! If we simply get rid of the dropout functions, the scale of our predictions will be way off.\nA simple solution is to simply define dropout at evaluation time to scale the output according to the dropout rate. So at evaluation time dropout is defined as:\n\\[\n\\text{Dropout}_{eval}(\\mathbf{X}, r) = (1-r) \\mathbf{X}\n\\]\nThis gives use the smooth prediction function we’re looking for:"
  },
  {
    "objectID": "lecture8-regularization/notes.html#dropout-in-pytorch",
    "href": "lecture8-regularization/notes.html#dropout-in-pytorch",
    "title": "Lecture 8: Regularization",
    "section": "Dropout in PyTorch",
    "text": "Dropout in PyTorch\nIn Pytorch, dropout is implemented as a module (or layer) as with the linear and activation layers we’ve seen previously. We can define a network with dropout very simply using the nn.Dropout module:\n\n# 2 Hidden-layer network with dropout\nmodel = nn.Sequential(nn.Dropout(0.5), nn.Linear(2, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 10), nn.ReLU(), \n                      nn.Dropout(0.5), nn.Linear(10, 1)\n                     )"
  },
  {
    "objectID": "lecture1-background/notes.html",
    "href": "lecture1-background/notes.html",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "",
    "text": "The goal of this course is to learn to build neural neural networks, but first we should make sure that we understand what neural networks do and why we’d be interested in learning about them in the first place. You’re probably already familar with a lot of the real-world applications of neural networks, as in the past few years they’ve changed the way we use technology. Systems for everything from voice recognition, to photo-editing, to text and image generation and more now are largely built on the foundation of neural networks. Let’s start by introducing a few broad categories of neural network applications along with some specific examples that you may or may not have seen.\n\n\nIn prediction applications neural networks are used to assign a label or a prediction to a given input. Examples of applications using neural networks for prediction include:\nImage classification (Example: Google Lens)\nImage classification applications like Google Lens can take an image as input and identify the contents of the image using neural networks. This task will be the focus of one of the later modules in the course.\n\n\n\n\n\nCredit: Google\nMedical diagnosis\nDoes a patient have lung cancer? Neural networks for medical diagnosis might be able take in a patient s symtoms and test results and give an answer.\n\n\n\n\n\nCredit: Microsoft Research\n\n\n\nIn detection applications, neural networks are used to identify any instances of a particular pattern in a given input. For example:\nVoice recognition (Example: Siri)\nWhen you say “Hey Siri!” and your phone responds, it was a neural network that recognized your voice; taking as input the audio captured by your phone’s microphone and detecting any instances of the activation phrase.\n\n\n\n\n\nCredit: Apple\nObject detection (Example: YOLO)\nObject detection neural networks like YOLO (You Only Look Once) can identify multiple objects in an image. These types of networks are often used in applications like autonomous cars, which need to identify vehicles, pedestrians and other hazards on the road.\n\n\n\n\n\n\n\n\nPossibly the most widely discussed application of neural networks in recent years has been generative models, that is models that can generate realistic new data such as images and text.\nText generation (Example: ChatGPT) Large language models, such as the GPT models that power ChatGPT, use neural networks to synthesize realistic language.\n\n\n\n\n\nCredit: OpenAI\nImage generation (Example: Dall-E 3) Deep generative models for images similarly can generate realistic images.\n\n\n\n\n\n\n\n\nTransformation tasks take existing data in the form of images or text and create new and improved versions.\nPhoto editing (Example: Adobe Photoshop)\nImage editing tools like Photoshop use neural networks to output enhanced versions of images, either adjusting properties like color or even filling in missing parts of images!\n\n\n\n\n\nCredit: Adobe\nPhoto editing (Example: Google Translate)\nTranslation tools like Google translate use neural networks to map text in one language to another much more effectively than prior methods.\n\n\n\n\n\nCredit: Google\n\n\n\nMolecular dynamics (Example: AlphaFold)\nNeural networks are finding applications in the physical sciences allowing researchers to create approximate simulations of complex physical systems such as molecules. AlphaFold uses neural networks to predict the structure of proteins given their chemical composition.\n\n\n\n\n\nCredit: Google\nRendering (Example: NeRFs)\nNeural radiance fields (or NeRFs for short) use neural networks to quickly approximate new views of a 3d scene without the need for traditional modeling and rendering."
  },
  {
    "objectID": "lecture1-background/notes.html#numpy",
    "href": "lecture1-background/notes.html#numpy",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Numpy Is the linear algebra library that we will be using for much of this class (later on we will introduce PyTorch, which is more geared towards neural networks). The standard way to import Numpy is:\n\nimport numpy as np\n\nThe most basic object from Numpy that we will just is the array (np.array), which will represent vectors matrices and even higher-dimensional objects known as tensors."
  },
  {
    "objectID": "lecture1-background/notes.html#scalars",
    "href": "lecture1-background/notes.html#scalars",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Scalars are just single numbers. In our math we will typically denote scalars with a lower-case letter. For example, we might call a scalar \\(x\\) and give it a value as \\(x=3.5\\). In code this would be written as:\n\nx = 3.5\n\n# or as a 0-dimensional numpy array\nx = np.array(3.5)\n\nIn general, we will assume that scalars are real numbers meaning decimal numbers in the range \\((-\\infty, \\infty)\\). We can denote this as \\(x \\in \\mathbb{R}\\), meaning “\\(x\\) is in the set of real numbers”."
  },
  {
    "objectID": "lecture1-background/notes.html#vectors",
    "href": "lecture1-background/notes.html#vectors",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Vectors are ordered lists of numbers, as shown below. We will typically denote vectors with bold lower case letters, such as \\(\\mathbf{x}\\).\n\\[\n\\mathbf{x} = \\begin{bmatrix} 2\\\\ 5\\\\ 1\\end{bmatrix}\n\\]\nThis bold notation is common, but not universal, so expect that external resources may denote things differently!\nIn Numpy, we can create an array object representing a vector by passing np.array a list of numbers.\n\nx = np.array([2, 5, 1])\n\n\n\n\n\n\n\nOther useful vector creation functions\n\n\n\n\n\nConstants:\n\na = np.zeros(5) # Create a size 5 vector filled with zeros\nprint(a)\na = np.ones(5) # Create a size 5 vector filled with ones\nprint(a)\n\n[0. 0. 0. 0. 0.]\n[1. 1. 1. 1. 1.]\n\n\nInteger ranges:\n\na = np.array([1,2,3,4,5,6,7])\nprint(a)\n# or equivalently, using Python iterables:\na = np.array( range(1,8) )\nprint(a)\n# or the NumPy function np.arange:\na = np.arange(1, 8)\nprint(a)\n\n[1 2 3 4 5 6 7]\n[1 2 3 4 5 6 7]\n[1 2 3 4 5 6 7]\n\n\nDecimal ranges:\n\nb = np.linspace(1.0, 7.0, 4) # length-4 vector interpolating between 1.0 and 7.0\nprint(b)\nc = np.logspace(0.0, 2.0, 5) # length-7 vector interpolating between 10^0 and 10^2 logarithmically\nprint(c)\n\n[1. 3. 5. 7.]\n[  1.           3.16227766  10.          31.6227766  100.        ]\n\n\nCombining vectors\n\na = np.concatenate([b, c]) # length 4 + 7 vector with the elements of both b and c\n\n\n\n\nThe individual numbers in the vector are called the entries and we will refer to them individually as subscripted scalars: \\(x_1, x_2,…,x_n\\), where \\(n\\) is the number of entries or size of the vector.\n\\[\n\\mathbf{x} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix}\n\\]\nWe may say that \\(\\mathbf{x} \\in \\mathbb{R}^n\\) to mean that \\(\\mathbf{x}\\) is in the set of vectors with \\(n\\) real-valued entries. In numpy we can access individual elements of a vector using [] operators (note that numpy is 0-indexed!).\n\nx[0]\n\nnp.int64(2)\n\n\nA vector represents either a location or a change in location in \\(n\\) -dimensional space. For instance, the \\(\\mathbf{x}\\) vector we defined could represent the point with coordinates \\((2, 5, 1)\\) in 3-D space or a movement of 2 along the first axis, 5 along the second axis and 1 along the third axis.\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture1-background/notes.html#vectors-as-data",
    "href": "lecture1-background/notes.html#vectors-as-data",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Vectors do not necessarily need to represent geometric points or directions. As they are simply ordered collections of numbers, we can a vector to represent any type of data in a more formal way.\nFor example, a space of vectors could represent students, with each entry corresponding to a student’s grade in a different subject:\n\\[\n\\text{Student } \\mathbf{x} = \\begin{bmatrix} \\text{Math} \\\\ \\text{CS} \\\\ \\text{Literature} \\\\\\text{History} \\end{bmatrix}\n\\]\nAny two students might have different grades across the subjects. We can represent these two students (say \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\)) as two vectors.\n\\[\n\\mathbf{x}_1 = \\begin{bmatrix} 3.0 \\\\ 4.0 \\\\ 3.7 \\\\ 2.3 \\end{bmatrix}, \\quad \\mathbf{x}_2 = \\begin{bmatrix} 3.7 \\\\ 3.3 \\\\ 3.3 \\\\ 4.0 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#vector-equality",
    "href": "lecture1-background/notes.html#vector-equality",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "We say that two vectors are equal if and only if all of the corresponding elements are equal, so \\(\\mathbf{x} = \\mathbf{y}\\) implies that \\(x_1=y_1, x_2=y_2…\\). In numpy when we compare two vectors for equality, we get a new vector that indicates which entries are equal.\n\nx = np.array([2, 5, 1])\ny = np.array([3, 5, 2])\nx == y\n\narray([False,  True, False])\n\n\nWe can check if all entries are equal (and therefore the vectors are equal) using the np.all function.\n\nnp.all(x == y), np.all(x == x)\n\n(np.False_, np.True_)\n\n\nOther comparison operators (&gt;,&lt;, &gt;=, &lt;=, !=) also perform element-wise comparison in numpy."
  },
  {
    "objectID": "lecture1-background/notes.html#vector-addition",
    "href": "lecture1-background/notes.html#vector-addition",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "When we add or subtract vectors, we add or subtract the corresponding elements.\n\\[\\mathbf{x} + \\mathbf{y} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} + \\begin{bmatrix} y_1\\\\ y_2\\\\ y_3\\end{bmatrix} = \\begin{bmatrix} x_1 + y_1\\\\ x_2 + y_2\\\\ x_3 + y_3\\end{bmatrix}\\] This works the same in numpy\n\nx + y\n\narray([ 5, 10,  3])\n\n\nThis corresponds to shifting the point \\(\\mathbf{x}\\) by the vector \\(\\mathbf{y}\\).\n\n\nManim Community v0.18.1"
  },
  {
    "objectID": "lecture1-background/notes.html#element-wise-operations",
    "href": "lecture1-background/notes.html#element-wise-operations",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "In both mathematical notation and numpy, most operations on vectors will be assumed to be taken element-wise. That is,\n\\[\n\\mathbf{x}^2 = \\begin{bmatrix} x_1^2 \\\\ x_2^2 \\\\ x_3^2 \\end{bmatrix} , \\quad \\log(\\mathbf{x}) = \\begin{bmatrix} \\log x_1 \\\\ \\log x_2 \\\\ \\log x_3 \\end{bmatrix},\\ \\text{etc.}\n\\]\nIn numpy:\n\nx ** 2, np.log(x)\n\n(array([ 4, 25,  1]), array([0.69314718, 1.60943791, 0.        ]))\n\n\nNote that in this class (and in numpy!) logarithms are assumed to be base \\(e\\), otherwise known as natural logarithms.\nOperations between scalars and vectors are also assumed to be element-wise as in this scalar-vector multiplication\n\\[\na\\mathbf{x} = \\begin{bmatrix} a x_1 \\\\ a x_2 \\\\ a x_3 \\end{bmatrix}, \\quad a + \\mathbf{x} = \\begin{bmatrix} a + x_1 \\\\ a + x_2 \\\\ a + x_3 \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#vector-magnitude",
    "href": "lecture1-background/notes.html#vector-magnitude",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The magnitude of a vector its length in \\(\\mathbb{R}^n\\), or equivalently the Euclidean distance from the origin to the point the vector represents. It is denoted as\\(\\|\\mathbf{x}\\|_2\\) and defined as:\n\\[\n\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}\n\\]\nThe subscript \\(2\\) specifies that we are talking about Euclidean distance. Because of this we will also refer to the magnitude as the two-norm.\nIn numpy we can compute this using the np.linalg.norm function.\n\nxnorm = np.linalg.norm(x)\n\nWe can also compute this explicitly with the np.sum function, which computes the sum of the elements of a vector.\n\nxnorm_explicit = np.sqrt(np.sum(x ** 2))\nxnorm, xnorm_explicit\n\n(np.float64(5.477225575051661), np.float64(5.477225575051661))\n\n\n\n\n\n\n\n\nOther useful aggregation functions\n\n\n\n\n\n\nprint(np.mean(x))    # Take the mean of the elements in x\nprint(np.std(x))     # Take the standard deviation of the elements in x\nprint(np.min(x))     # Find the minimum element in x\nprint(np.max(x))     # Find the maximum element in x\n\n2.6666666666666665\n1.699673171197595\n1\n5\n\n\n\n\n\nA unit vector is a vector with length \\(1\\). We can find a unit vector that has the same direction as \\(\\mathbf{x}\\) by dividing \\(\\mathbf{x}\\) by it’s magnitude:\n\\[\n\\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|_2}\n\\]\n\nx / np.linalg.norm(x)\n\narray([0.36514837, 0.91287093, 0.18257419])"
  },
  {
    "objectID": "lecture1-background/notes.html#dot-products",
    "href": "lecture1-background/notes.html#dot-products",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The dot-product operation between two vectors is defined as\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = \\sum_{i=1}^n x_i y_i\n\\]\nMore commonly in this class we will write the dot-product between the vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) as: \\[\\mathbf{x}^T \\mathbf{y} = \\sum_{i=1}^n x_i y_i\\]$\nThe result of a dot product is a scalar whose value is equal to \\(\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2 \\cos\\theta\\), where \\(\\theta\\) is the angle between them. If\\(\\theta=\\frac{\\pi}{2}\\), the vectors are orthogonal and the dot product with be \\(0\\). If \\(\\theta&gt;\\frac{\\pi}{2}\\) or \\(\\theta &lt; -\\frac{\\pi}{2}\\) , the dot product will be negative.\nIf \\(\\theta=0\\) then \\(\\cos(\\theta)=1\\). In this case we say the vectors are colinear. This formulation implies that given two vectors of fixed length, the dot product is maximized with they are colinear ( \\(\\theta=0\\) ).\nWe can compute dot products in numpy using the np.dot function\n\nnp.dot(x, y)\n\nnp.int64(33)\n\n\nGeometrically, \\(\\|\\mathbf{x}\\|_2\\cos\\theta\\) is the length of the projection of \\(\\mathbf{x}\\) onto \\(\\mathbf{y}\\). Thus, we can compute the length of this projection using the dot-product as \\(\\frac{\\mathbf{x}\\cdot\\mathbf{y}}{\\|\\mathbf{y}\\|}\\) ."
  },
  {
    "objectID": "lecture1-background/notes.html#matrices",
    "href": "lecture1-background/notes.html#matrices",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "A matrix is a 2-dimensional collection of numbers. We will denote matrices using bold capital letters, e.g. \\(\\mathbf{A}\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2  \\end{bmatrix}\n\\]\nIn numpy we can create a matrix by passing np.array as list-of-lists, where each inner list specifies a row of the matrix.\n\nA = np.array([[3, 5, 4], [1, 1, 2]])\nA\n\narray([[3, 5, 4],\n       [1, 1, 2]])\n\n\nAs with vectors we will denote individual elements of a matrix using subscripts. In this case, each element has 2 coordinates. Conventions is to always list the row first.\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can access elements in a matrix similarly.\n\nA[1, 2]\n\nnp.int64(2)\n\n\nAs with vectors, we say that two matrices are equal if and only if all of the corresponding elements are equal.\n\n\n\n\n\n\nOther matrix creation routines\n\n\n\n\n\nBasic creation functions\n\nA0 = np.zeros((3, 4))          # create a 3x4 matrix of all zeros\nA1 = np.ones((4, 4))           # create a 4x4 matrix of all ones\nAinf = np.full((3, 3), np.inf) # create a 3x3 matrix of all infinities\nI = np.eye(3)                  # create a 3x3 itentity matrix\n\nCreating a matrix by “reshaping” a vector with the same number of elements\n\nV = np.arange(1, 13).reshape((3, 4)) # Create a 3x4 matrix with elements 1-12\n\nCreating matrices by combining matrices\n\nB = np.tile(A0, (3, 2))               # create a matrix by \"tiling\" copies of A0 (3 copies by 2 copies)\nB = np.concatenate([A0, A1], axis=0)  # create a (2n x m) matrix by stacking two matrices vertically\nB = np.concatenate([A0, I], axis=1)  # create a (n x 2m) matrix by stacking two matrices horizontally"
  },
  {
    "objectID": "lecture1-background/notes.html#slicing-matrices",
    "href": "lecture1-background/notes.html#slicing-matrices",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Often we will refer to an entire row of a matrix (which is itself a vector) using matrix notation with a single index\n\\[\n\\mathbf{A}_i = \\begin{bmatrix} A_{i1} \\\\ A_{i2} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access a single row similarly.\n\nA[1]\n\narray([1, 1, 2])\n\n\nWe can refer to an entire column by replacing the row index with a \\(*\\), indicating we are referring to all rows in that column.\n\\[\n\\mathbf{A}_{*i} = \\begin{bmatrix} A_{1i} \\\\ A_{2i} \\\\ \\vdots \\end{bmatrix}\n\\]\nIn numpy we can access an entire column (or row) using the slice operator :, which takes all elements along an axis.\n\nA[:, 1] # Take all elements in column 1\n\narray([5, 1])\n\n\nWe can also use the slice operator to take a subset of elements along an axis.\n\nA[:, 1:3] #Take the second and third columns of A\n\narray([[5, 4],\n       [1, 2]])\n\n\n\n\n\n\n\n\nAdvanced slicing in numpy\n\n\n\n\n\n\nA = np.arange(1, 13).reshape((3, 4))\nprint(A)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nOpen-ended slices\n\nprint(\"A[:2]=\", A[:2]) # Take rows up to 2 (not inucluding 2)\nprint(\"A[1:]=\", A[1:]) # Take rows starting at (and including) 1\n\nA[:2]= [[1 2 3 4]\n [5 6 7 8]]\nA[1:]= [[ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nTaking rows and colmns\n\nprint(\"A[0, :]=\", A[0, :])   # first row, all columns\nprint(\"A[:, 1]=\", A[:, 1])   # all rows, second column\nprint(\"A[-1, :]\", A[-1, :])  # all columns of the last row\nprint(\"A[:, -2]\", A[:, -2])  # second to last column of every row\n\nA[0, :]= [1 2 3 4]\nA[:, 1]= [ 2  6 10]\nA[-1, :] [ 9 10 11 12]\nA[:, -2] [ 3  7 11]\n\n\nMore general slicing with steps\n\nprint(\"A[1,0:2]=\", A[1,0:2])\nprint(\"A[0,0:4:2]=\", A[0,0:4:2])\nprint(\"A[:,0:4:2]=\\n\", A[:,0:4:2])\n\nA[1,0:2]= [5 6]\nA[0,0:4:2]= [1 3]\nA[:,0:4:2]=\n [[ 1  3]\n [ 5  7]\n [ 9 11]]\n\n\nTaking one row and selected columns\n\nprint(\"A[2, [1,4]]=\",A[2, [0,3]])\n\nA[2, [1,4]]= [ 9 12]\n\n\nTaking all rows and selected columns\n\nprint(\"A[:, [1,4]]=\\n\",A[:, [0,3]])\n\nA[:, [1,4]]=\n [[ 1  4]\n [ 5  8]\n [ 9 12]]"
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-shapes",
    "href": "lecture1-background/notes.html#matrix-shapes",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The matrix \\(\\mathbf{A}\\) above has 2 rows and 3 columns, thus we would specify it’s shape as \\(2\\times3\\). A square matrix has the same number of rows and columns.\n\\[\n\\mathbf{A} = \\begin{bmatrix} 3 & 5 & 4 \\\\ 1 & 1 & 2 \\\\ 4 & 1 & 3 \\end{bmatrix}\n\\]\nWe can access the shape of a matrix in numpy using its shape property.\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nprint(A.shape)\n\n(3, 3)"
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-transpose",
    "href": "lecture1-background/notes.html#matrix-transpose",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The transpose of a matrix is an operation that swaps the rows and columns of the matrix. We denote the transpose of a matrix \\(\\mathbf{A}\\) as \\(\\mathbf{A}^T\\).\n\\[\n\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\end{bmatrix}, \\quad \\mathbf{A}^T = \\begin{bmatrix} A_{11} & A_{21} \\\\  A_{12} & A_{22} \\\\  A_{13} & A_{23} \\end{bmatrix}\n\\]\nIn numpy we can transpose a matrix by using the T property.\n\nA = np.array([[1, 1, 1], [2, 2, 2]])\nA.T\n\narray([[1, 2],\n       [1, 2],\n       [1, 2]])"
  },
  {
    "objectID": "lecture1-background/notes.html#element-wise-matrix-operations",
    "href": "lecture1-background/notes.html#element-wise-matrix-operations",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "As with vectors, many operations on matrices are performed element-wise:\n\\[\n\\mathbf{A} + \\mathbf{B} = \\begin{bmatrix} A_{11} + B_{11}  & A_{12} + B_{12} & A_{13} + B_{13} \\\\ A_{21} + B_{21} & A_{22} + B_{22} & A_{23} + B_{23} \\end{bmatrix}, \\quad \\log\\mathbf{A} = \\begin{bmatrix} \\log A_{11}  & \\log A_{12} & \\log A_{13} \\\\ \\log A_{21} & \\log A_{22} & \\log A_{23} \\end{bmatrix}\n\\]\nScalar-matrix operation are also element-wise:\n\\[\nc\\mathbf{A} = \\begin{bmatrix} cA_{11}  & cA_{12} & cA_{13} \\\\ cA_{21} & cA_{22} & cA_{23} \\end{bmatrix}\n\\]\nIn numpy:\n\nB = 5 * A \nA + B\n\narray([[ 6,  6,  6],\n       [12, 12, 12]])\n\n\n\n\n\n\n\n\nOther element-wise operations\n\n\n\n\n\nUnary operations\n\nnp.sqrt(A)     # Take the square root of every element\nnp.log(A)      # Take the (natural) log of every element\nnp.exp(A)      # Take e^x for every element x in A\nnp.sin(A)      # Take sin(x) for every element x in A\nnp.cos(A)      # Take cos(x) for every element x in A\n\narray([[ 0.54030231,  0.54030231,  0.54030231],\n       [-0.41614684, -0.41614684, -0.41614684]])\n\n\nScalar operations\n\nA + 2          # Add a scalar to every element of A\nA - 1          # Subtract a scalar from every element of A\nA * 4          # Multiply a scalar with every element of A\nA / 6          # Divide every element by a scalar\nA ** 3         # Take every element to a power\n\narray([[1, 1, 1],\n       [8, 8, 8]])"
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-vector-products",
    "href": "lecture1-background/notes.html#matrix-vector-products",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "A matrix-vector product is an operation between a matrix and a vector that produces a new vector. Given a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we write the matrix-vector product as:\n\\[\n\\mathbf{A}\\mathbf{x} = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^n x_i A_{1i} \\\\  \\sum_{i=1}^n x_i A_{2i} \\\\  \\sum_{i=1}^n x_i A_{3i} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}\\cdot  \\mathbf{A}_{1} \\\\ \\mathbf{x}\\cdot  \\mathbf{A}_{2} \\\\ \\mathbf{x} \\cdot \\mathbf{A}_{2} \\end{bmatrix}\n\\]\nIn other words, each entry of the resulting vector is the dot product between \\(\\mathbf{x}\\) and a row of \\(A\\). In numpy we also use np.dot for matrix-vector products:\n\nA = np.array([[3, 5, 4], [1, 1, 2], [4, 1, 3]])\nx = np.array([2, 5, 1])\n\nnp.dot(A, x)\n\narray([35,  9, 16])\n\n\nWe say that a square matrix \\(A\\) defines a linear mapping from \\(\\mathbb{R}^n\\rightarrow\\mathbb{R}^n\\), which simply means if we multiply any vector \\(\\mathbf{x}\\in\\mathbb{R}^n\\) by \\(A\\) we get a new vector in \\(\\mathbb{R}^n\\) where the elements are a linear combination of the elements in \\(\\mathbf{x}\\).\nGeometrically the matrix \\(A\\) defines a transformation that scales and rotates any vector \\(\\mathbf{x}\\) about the origin.\nThe number of columns of \\(A\\) must match the size of the vector \\(\\mathbf{x}\\), but if \\(A\\) has a different number of rows, the output will simply have a different size.\n\nnp.dot(A[:2], x)\n\narray([35,  9])\n\n\nIn general, an \\(n\\times m\\) matrix defines a linear mapping \\(\\mathbb{R}^n\\rightarrow\\mathbb{R}^m\\), transforming \\(\\mathbf{x} \\in \\mathbb{R}^n\\) into a possibly higher or lower dimensional space \\(\\mathbb{R}^m\\)."
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-multiplication",
    "href": "lecture1-background/notes.html#matrix-multiplication",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Matrix multiplication is a fundamental operation between two matrices. It is defined as:\n\\[\n\\mathbf{A}\\mathbf{B}  = \\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\\\ B_{31} & B_{32} \\end{bmatrix}  =\\begin{bmatrix} \\sum_{i=1}^n A_{1i} B_{i1} & \\sum_{i=1}^n A_{i1}B_{i2} \\\\  \\sum_{i=1}^n A_{2i}B_{i1} & \\sum_{i=1}^n A_{2i}B_{i2}  \\\\  \\sum_{i=1}^n A_{3i}B_{i1} & \\sum_{i=1}^n A_{3i}B_{i2} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2} \\\\ \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{2} \\cdot \\mathbf{B}_{*2}  \\\\ \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*1} & \\mathbf{A}_{1} \\cdot \\mathbf{B}_{*2}  \\end{bmatrix}\n\\]\nThis means that if we multiply an \\(n\\times m\\) matrix \\(\\mathbf{A}\\) with an \\(m\\times k\\) matrix \\(\\mathbf{B}\\) we get an \\(n\\times k\\) matrix \\(\\mathbf{C}\\), such that \\(\\mathbf{C}_{ij}\\) is the dot product of the \\(i\\)-th row of \\(\\mathbf{A}\\) with the \\(j\\)-th row of \\(\\mathbf{B}\\).\nIn numpy we once again use the np.dot function to perform matrix-multiplications.\n\nB = np.array([[2, -1], [3, 1], [-2, 5]])\nC = np.dot(A, B)\n\nNote that the number of rows of \\(\\mathbf{A}\\) must match the number of columns of \\(\\mathbf{B}\\) for the matrix multiplication \\(\\mathbf{A}\\mathbf{B}\\) to be defined. This implies that matrix multiplication is non-communitive:\n\\[\n\\mathbf{A}\\mathbf{B}\\neq \\mathbf{B}\\mathbf{A}\n\\]\nHowever matrix multiplication is associative and distributive:\n\\[\n\\mathbf{A}(\\mathbf{B}\\mathbf{C})=(\\mathbf{A}\\mathbf{B})\\mathbf{C}, \\quad \\mathbf{A}(\\mathbf{B} +\\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}\n\\]\nWe can see matrix multiplication as a composition of linear maps, meaning that if we take the product \\(\\mathbf{A}\\mathbf{B}\\) and apply the resulting matrix to a vector \\(\\mathbf{x}\\), it is equivalent to first transforming \\(\\mathbf{x}\\) with \\(\\mathbf{B}\\) and then with \\(\\mathbf{A}\\). We can state this succinctly as:\n\\[\n(\\mathbf{A}\\mathbf{B})\\mathbf{x} = \\mathbf{A}(\\mathbf{B}\\mathbf{x})\n\\]\nWe can see this in numpy:\n\nx = np.array([1, 3])\nnp.dot(np.dot(A, B), x), np.dot(A, np.dot(B, x))\n\n(array([79, 31, 41]), array([79, 31, 41]))"
  },
  {
    "objectID": "lecture1-background/notes.html#vector-notation",
    "href": "lecture1-background/notes.html#vector-notation",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "As we’ve seen a vector is a 1-dimensional set of numbers. For example, we can write the vector \\(\\mathbf{x} \\in \\mathbb{R}^3\\) as:\n\\[\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\]\nA vector can also be seen as either an \\(n \\times 1\\) matrix (column vector) or a \\(1 \\times n\\) matrix (row vector).\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nNote that we may use the same notation for both as they refer to the same concept (a vector).\nThe difference between row and column vectors becomes relevant when we consider matrix-vector multiplication. We can write matrix-vector multiplication in two ways: \\[\\text{Matrix-vector: }\\mathbf{A}\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}\\mathbf{A}^T= \\mathbf{b}\\] In matrix-vector multiplication we treat \\(\\textbf{x}\\) as a column vector (\\(n \\times 1\\) matrix), while in vector-matrix multiplication we treat it as a row vector (\\(n \\times 1\\) matrix). Transposing \\(A\\) for left multiplication ensures that the two forms give the same answer.\nIn Numpy the np.dot function works in this way. Given a matrix A and a 1-dimensional vector x, performing both operations will give the same result (another 1-dimensional vector):\n\nA = np.array([[ 1,  2, -1],\n              [ 5, -3,  2],\n              [-2,  1, -4],\n             ])\nx = np.array([1, -2, 1])\n\nAx   = np.dot(A, x)\nxA_T = np.dot(x, A.T)\nprint('Ax   = ', Ax)\nprint('xA^T = ', xA_T)\n\nAx   =  [-4 13 -8]\nxA^T =  [-4 13 -8]"
  },
  {
    "objectID": "lecture1-background/notes.html#vector-notation-revisited",
    "href": "lecture1-background/notes.html#vector-notation-revisited",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "It often is much simpler to explicitly define vectors as being either row or column vectors. The common convention in machine learning is to assume that all vectors are column vectors (\\(n \\times 1\\) matricies) and thus a row vector ( \\(1\\times n\\) matrix) is obtained by explicit transposition:\n\\[\\text{Column vector: } \\mathbf{x} = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}, \\quad \\text{Row vector: } \\mathbf{x}^T = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\\]\nIn this case, we would rewrite the matrix-vector and vector-matrix products we saw above as:\n\\[\\text{Matrix-vector: }\\mathbf{A}\\mathbf{x} = \\mathbf{b}, \\quad \\text{Vector-matrix: }\\mathbf{x}^T\\mathbf{A}^T= \\mathbf{b}^T\\]\nIn Numpy, we can make a vector into an explicit column or row vector by inserting a new dimension, either with the np.expand_dims function or with the indexing operator:\n\nrow_x = np.expand_dims(x, axis=0) # Add a new leading dimension to x\nrow_x\n\narray([[ 1, -2,  1]])\n\n\n\ncolumn_x = np.expand_dims(x, axis=1) # Add a new second dimension to x\nassert np.all(column_x.T == row_x)\ncolumn_x\n\narray([[ 1],\n       [-2],\n       [ 1]])\n\n\nAlternatively:\n\nrow_x = x[None, :]\ncolumn_x = x[:, None]"
  },
  {
    "objectID": "lecture1-background/notes.html#element-wise-multiplication",
    "href": "lecture1-background/notes.html#element-wise-multiplication",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "It is important to note that in numpy the * operator does not perform matrix multiplication, instead it performs element-wise multiplication for both matrices and vectors.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nB = np.array([[1, 2], [1, 2], [1, 2]])\nA * B\n\narray([[1, 2],\n       [2, 4],\n       [3, 6]])\n\n\nIn mathematical notation we will denote element-wise multiplication as:\n\\[\n\\mathbf{A} \\odot \\mathbf{B} = \\begin{bmatrix} A_{11} B_{11}  & A_{12}  B_{12} & A_{13}  B_{13} \\\\ A_{21}  B_{21} & A_{22}  B_{22} & A_{23}  B_{23} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-reductions",
    "href": "lecture1-background/notes.html#matrix-reductions",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "As we saw with vectors, we can take the sum of the elements of a matrix using the np.sum function:\n\nnp.sum(A)\n\nnp.int64(12)\n\n\nThe result is a scalar of the form:\n\\[\n\\text{sum}(\\mathbf{A}) = \\sum_{i=1}^n\\sum_{j=1}^m A_{ij}\n\\]\nIn many cases we may wish to take the sum along an axis of a matrix. This operation results in a vector where each entry is the sum of elements from the corresponding row or column of the matrix.\n\\[\n\\text{rowsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{i=1}^n A_{i1} \\\\ \\sum_{i=1}^n A_{i2} \\\\ \\sum_{i=1}^n A_{i3} \\\\ \\vdots\\end{bmatrix}, \\quad \\text{colsum}(\\mathbf{A}) = \\begin{bmatrix} \\sum_{j=1}^m A_{1j} \\\\ \\sum_{j=1}^m A_{2j} \\\\ \\sum_{j=1}^m A_{3j} \\\\ \\vdots\\end{bmatrix}\n\\]\nIn numpy we can specify a sum along an axis by providing an axis argument to np.sum. Setting axis=0 specifies a row-sum, while axis=1 specifies a column sum.\n\nA = np.array([[1, 1], [2, 2], [3, 3]])\nprint(A)\nnp.sum(A, axis=0), np.sum(A, axis=1)\n\n[[1 1]\n [2 2]\n [3 3]]\n\n\n(array([6, 6]), array([2, 4, 6]))\n\n\n\n\n\n\n\n\nOther matrix reduction examples\n\n\n\n\n\n\nprint(np.mean(A))            # Take the mean of all elements in x\nprint(np.std(A, axis=0))     # Take the standard deviation of each column of x\nprint(np.min(A, axis=1))     # Find the minimum element in each row of x\nprint(np.max(A))             # Find the maximum element in x\n\n2.0\n[0.81649658 0.81649658]\n[1 2 3]\n3"
  },
  {
    "objectID": "lecture1-background/notes.html#identity-matrices",
    "href": "lecture1-background/notes.html#identity-matrices",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The identity matrix, denoted at \\(\\mathbf{I}\\) is a special type of square matrix. It is defined as the matrix with \\(1\\) for every diagonal element (\\(\\mathbf{I}_{i=j}=1\\)) and \\(0\\) for every other element (\\(\\mathbf{I}_{i\\neq j}=0\\)). A \\(3\\times 3\\) identity matrix looks like:\n\\[\\mathbf{I} = \\begin{bmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}\\]\nThe identify matrix has the unique property that any appropriately sized matrix (or vector) multiplied with \\(\\mathbf{I}\\) will equal itself:\n\\[\n\\mathbf{I}\\mathbf{A} = \\mathbf{A}\n\\]\nIf we think of matrices as linear mappings the identity matrix simply maps any vector to itself.\n\\[\n\\mathbf{I} \\mathbf{x} = \\mathbf{x}\n\\]\nIn numpy we can create an identity matrix using the np.eye function:\n\nI = np.eye(3) # Create a 3x3 identity matrix"
  },
  {
    "objectID": "lecture1-background/notes.html#solving-systems-of-linear-equations",
    "href": "lecture1-background/notes.html#solving-systems-of-linear-equations",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "Consider the matrix-vector product between a matrix \\(\\mathbf{A}\\) and a vector \\(\\mathbf{x}\\), we can denote the result of this multiplication as \\(\\mathbf{b}\\):\n\\[\n\\mathbf{A}\\mathbf{x} =\\mathbf{b}\n\\]\nIn many common cases we will know the matrix \\(\\mathbf{A}\\) and the vector \\(\\mathbf{b}\\), but not the vector \\(\\mathbf{x}\\). In such cases we need to solve this equation for \\(\\mathbf{x}\\):\n\\[\n\\begin{bmatrix} A_{11} & A_{12} & A_{13} \\\\ A_{21} & A_{22} & A_{23} \\\\ A_{23} & A_{32} & A_{33} \\end{bmatrix} \\begin{bmatrix} \\textbf{?}\\\\ \\textbf{?}\\\\ \\textbf{?}\\end{bmatrix} = \\begin{bmatrix} b_1 \\\\  b_2 \\\\  b_3 \\end{bmatrix}\n\\]\nWe call this solving a system of linear equations. A common algorithm used to find \\(\\mathbf{x}\\) is Gaussian elimination, the details of which are outside the scope of this course. Luckily, numpy gives us a convenient function for solving this problem: np.linalg.solve.\n\nA = np.array([[3, 1], [-1, 4]])\nb = np.array([-2, 1])\nx = np.linalg.solve(A, b)\n\nNote that in some cases there may not be any \\(\\mathbf{x}\\) that satisfies the equation (or there may be infinitely many). The conditions for this are beyond the scope of this course."
  },
  {
    "objectID": "lecture1-background/notes.html#inverse-matrices",
    "href": "lecture1-background/notes.html#inverse-matrices",
    "title": "Prerequisites for neural networks",
    "section": "",
    "text": "The inverse of a square matrix is denoted by \\(\\mathbf{A}^{-1}\\) and is defined as the matrix such that:\n\\[\n\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}\n\\]\nThis corresponds to the inverse of the linear map defined by \\(\\mathbf{A}\\). Any vector transformed by \\(\\mathbf{A}\\) can be transformed back by applying the inverse matrix:\n\\[\n\\mathbf{A}^{-1}\\left(\\mathbf{A}\\mathbf{x}\\right) =\\mathbf{x}\n\\]\nWe can also write the solution to a system of linear equations in terms of the inverse, by multiplying both sides by \\(\\mathbf{A}^{-1}\\):\n\\[\n\\mathbf{A}\\mathbf{x}=\\mathbf{b}\\quad \\longrightarrow \\quad \\mathbf{A}^{-1}(\\mathbf{A}\\mathbf{x})=\\mathbf{A}^{-1}\\mathbf{b} \\quad \\longrightarrow \\quad \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}\n\\]\nIn numpy we can find the inverse of a matrix using the np.linalg.inv function:\n\nA_inv = np.linalg.inv(A)\n\nNote that not every matrix has an inverse! Again, we won’t worry about these cases for now."
  },
  {
    "objectID": "lecture1-background/notes.html#functions",
    "href": "lecture1-background/notes.html#functions",
    "title": "Prerequisites for neural networks",
    "section": "Functions",
    "text": "Functions\nA function is a general mapping from one set to another.\n\\[\ny=f(x),\\quad f:\\mathbb{R}\\rightarrow\\mathbb{R}\n\\]\nIn this course will focus on functions of real numbers, that is, mappings from real numbers to other real numbers this is denoted using the notation \\(\\mathbb{R}\\rightarrow\\mathbb{R}\\) above. We call the set of possible inputs the domain of the function (in this case real numbers) and the corresponding set of possible outputs the codomain or range of the function. In the notation above \\(x\\) is the real valued input and \\(y\\) is the real-valued output.\nWe can definite functions as compositions of simple operations. For example we could define a polynomial function as:\n\\[\nf(x) = x^2 + 3x + 1\n\\]\nIn code we can implement functions as, well, functions:\n\ndef f(x):\n    return x ** 2 + 3 * x + 1\n\nf(5)\n\n41"
  },
  {
    "objectID": "lecture1-background/notes.html#derivatives",
    "href": "lecture1-background/notes.html#derivatives",
    "title": "Prerequisites for neural networks",
    "section": "Derivatives",
    "text": "Derivatives\nThe derivative of a function at input \\(x\\) defines how the function’s output changes as the input changes from \\(x\\). It is equivalent to the slope of the line tangent to the function at the input \\(x\\). We’ll use the notation \\(\\frac{df}{dx}\\) to denote the derivative of the function \\(f\\) at input \\(x\\). Formally:\n\\[\n\\frac{df}{dx} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x+\\epsilon) - f(x)}{\\epsilon}\n\\]\nIntunitively, this means if we change our input \\(x\\) by some small amount \\(\\epsilon\\), the output of our function will change by approximately \\(\\frac{df}{dx}\\epsilon\\)\n\\[\nf(x+\\epsilon) \\approx f(x)+\\frac{df}{dx}\\epsilon\n\\]\nNote that with respect to \\(\\epsilon\\) this approximation is a line with slope \\(\\frac{df}{dx}\\) and intercept \\(f(x)\\), therefore we say that this is a linear approximation to the function \\(f\\) at input \\(x\\).\nWe can also use the notation \\(\\frac{d}{dx}\\) to denote the derivative operator. This means “find the derivative of the following expression with respect to \\(x\\)”.\n\\[\n\\frac{d}{dx}f(x) = \\frac{df}{dx}\n\\]\n\n\n\n\n\n\nCaveat\n\n\n\n\n\nThis definition assumes that the limit exists at the input \\(x\\), which is not always true. We will see practical examples later in the course where this assumption does not hold."
  },
  {
    "objectID": "lecture1-background/notes.html#derivative-functions",
    "href": "lecture1-background/notes.html#derivative-functions",
    "title": "Prerequisites for neural networks",
    "section": "Derivative functions",
    "text": "Derivative functions\nWe can also talk about the function that maps any input \\(x\\) to the derivative \\(\\frac{df}{dx}\\) we call this the derivative function and denote it as \\(f'(x)\\). So:\n\\[\n\\frac{df}{dx}=f'(x)\n\\]\nGiven a function defined as a composition of basic operations, we can use a set of standard rules to find the corresponding derivative function. For example using the rules \\(\\frac{d}{dx}x^a=ax\\) , \\(\\frac{d}{dx}ax=a\\) and \\(\\frac{d}{dx}a=0\\), we can derive the derivative function for the polynomial above:\n\\[\nf(x) = x^2 + 3x + 1\n\\]\n\\[\nf'(x) = 2x + 3\n\\]\n\n\n\n\n\n\nBasic derivative rules\n\n\n\n\n\n\n\n\nOperation\nDerivative \\(\\frac{d}{dx}\\)\n\n\n\n\n\\(a\\)\n\\(0\\)\n\n\n\\(ax\\)\n\\(a\\)\n\n\n\\(x^a\\)\n\\(ax\\)\n\n\n\\(\\log(x)\\)\n\\(\\frac{1}{x}\\)\n\n\n\\(e^x\\)\n\\(e^x\\)\n\n\n\\(f(x) + g(x)\\)\n\\(f'(x)+g'(x)\\)\n\n\n\\(f(x)g(x)\\)\n\\(f'(x)g(x) + f(x)g'(x)\\)\n\n\n\\(\\frac{f(x)}{g(x)}\\)\n\\(\\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}\\)"
  },
  {
    "objectID": "lecture1-background/notes.html#chain-rule",
    "href": "lecture1-background/notes.html#chain-rule",
    "title": "Prerequisites for neural networks",
    "section": "Chain rule",
    "text": "Chain rule\nComposing two functions means to apply one function to the output of another, for example we could apply \\(f\\) to the output of \\(g\\):\n\\[\ny = f\\big(g\\left(x\\right)\\big)\n\\]\nThis is easily replicated in code:\n\ndef f(x):\n    return x ** 2 + 3 * x + 1\n\ndef g(x):\n    return 5 * x - 2\n\nf(g(3))\n\n209\n\n\nThe chain rule tells us how to find the derivative of a composition of functions like this. We can write the rule either in terms of derivatives or derivative functions\n\\[\n\\frac{d}{dx}f\\big(g\\left(x\\right)\\big) = \\frac{df}{dg}\\frac{dg}{dx} \\quad \\text{or} \\quad \\frac{d}{dx}f\\big(g\\left(x\\right)\\big) =  f'\\big(g\\left(x\\right)\\big)g'\\left(x\\right)\n\\]\nNote that in our derivative notation we’re using \\(f\\) and \\(g\\) to denote the outputs of the respective functions.\n\n\n\n\n\n\nDerivatives in code\n\n\n\n\n\nA natural question to ask at this point is: does the derivative operator exist in Python or numpy?. The answer is amazingly: yes! However implementing such an operator is nontrivial. In fact, a significant portion of this course will be devoted to exploring how to implement exactly such an operation for numpy. As a preview, we will end up with the ability to take derivatives as follows:\n\ndef f(x):\n    return x ** 2 + 3 * x + 1\n\nfx = f(5)\ndf_dx = derivative(f)(5)"
  },
  {
    "objectID": "lecture1-background/notes.html#partial-derivatives",
    "href": "lecture1-background/notes.html#partial-derivatives",
    "title": "Prerequisites for neural networks",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nA function does not need to be restricted to having a single input. We can specify a function with multiple inputs as follows:\n\\[\nf(x, y, z) = x^2 + 3xy - \\log(z)\n\\]\nIn code this would look like;\n\ndef f(x, y, z):\n    return x ** 2 + 3 * y + np.log(z)\n\nA partial derivative is the derivative of a multiple-input function with respect to a single input, assuming all other inputs are constant. We will explore the implications of that condition later on in this course. For now, we will simply view partial derivatives as a straightforward extension of derivatives, using the modified notation \\(\\frac{\\partial}{\\partial x}\\).\nMore formally, we can define the partial derivative with respect to each input of a function as:\n\\[\n\\frac{\\partial f}{\\partial x} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x+\\epsilon, y, z) - f(x,y,z)}{\\epsilon}, \\quad \\frac{\\partial f}{\\partial y} = \\underset{\\epsilon\\rightarrow0}{\\lim} \\frac{f(x, y+\\epsilon, z) - f(x,y,z)}{\\epsilon}\n\\]\nThese partial derivatives tell us how the output of the function changes as we change each of the inputs individually."
  },
  {
    "objectID": "lecture1-background/notes.html#partial-derivative-functions",
    "href": "lecture1-background/notes.html#partial-derivative-functions",
    "title": "Prerequisites for neural networks",
    "section": "Partial derivative functions",
    "text": "Partial derivative functions\nWe can also specify partial derivative functions in the same way as derivative functions. We’ll use subscript notation to specify which input we are differentiating with respect to.\n\\[\n\\frac{\\partial f}{\\partial x} = f_x'(x, y, z)\n\\]\nWe can derive partial derivative functions using the same set of derivative rules:\n\\[\nf(x, y, z) = x^2 + 3xy - \\log(z)\n\\]\n\\[\nf_x'(x, y, z) = 2x + 3y\n\\]\n\\[\nf_y'(x, y, z) = 3x\n\\]\n\\[\nf_z'(x, y, z) = -\\frac{1}{z}\n\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#functions-of-vectors",
    "href": "lecture1-background/notes.html#functions-of-vectors",
    "title": "Prerequisites for neural networks",
    "section": "Functions of vectors",
    "text": "Functions of vectors\nWe can also define functions that take vectors (or matrices) as inputs.\n\\[\ny = f(\\mathbf{x}) \\quad f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\n\\]\nHere \\(f\\) is a mapping from length \\(n\\) vectors to real numbers. As a concrete example we could define the function:\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^n x_i^3 + 1\n\\]\nHere’s the same function in numpy:\n\ndef f(x):\n    return np.sum(x ** 3) + 1\n\nf(np.array([1, 2, 3]))\n\nnp.int64(37)\n\n\nNote that functions of vectors are equivalent to multiple-input functions, but with a more compact notation!\n\\[f(\\mathbf{x}) \\equiv f(x_1, x_2, x_3...)\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#partial-derivatives-of-vectors",
    "href": "lecture1-background/notes.html#partial-derivatives-of-vectors",
    "title": "Prerequisites for neural networks",
    "section": "Partial derivatives of vectors",
    "text": "Partial derivatives of vectors\nWe can take partial derivates of vector functions simply by recognizing that the input vector is a set of variables and applying the standard set of derivative rules.\nFor example, given a vector \\(\\mathbf{x}\\in \\mathbb{R}^3\\): \\[\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2\\\\ x_3 \\end{bmatrix}\\] We can find the partial derivative of the dot-product of \\(\\mathbf{x}\\) with itself with respect to a single entry: \\(x_1\\): \\[\\frac{\\partial }{\\partial x_1} \\mathbf{x}^T\\mathbf{x}=\\] \\[\\frac{\\partial }{\\partial x_1} \\sum_{i=1}^n x_i x_i = \\frac{\\partial }{\\partial x_1}(x_1^2 + x_2^2+x_3^2)\\] We see that the terms \\(x_2^2\\) an \\(x_3^2\\) do not depend on \\(x_1\\), therefore the derivative is \\(0\\) and the final result is: \\[=\\frac{\\partial }{\\partial x_1} x_1^2 = 2 x_1\\]\nIn general, the addition rule applies to summations, so: \\[\\frac{\\partial }{\\partial x}\\sum f(x) = \\sum \\frac{\\partial }{\\partial x} f(x)\\]\nOther derivative rules also apply. For example, the chain rule works as normal: \\[\\frac{\\partial }{\\partial x_1} f(\\mathbf{x}^T\\mathbf{x})=\\] \\[f'(\\mathbf{x}^T\\mathbf{x}) \\frac{\\partial }{\\partial x_1} \\mathbf{x}^T\\mathbf{x} = f'(\\mathbf{x}^T\\mathbf{x}) (2x_1)\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#gradients",
    "href": "lecture1-background/notes.html#gradients",
    "title": "Prerequisites for neural networks",
    "section": "Gradients",
    "text": "Gradients\nThe gradient of a vector-input function is a vector such that each element is the partial derivative of the function with respect to the corresponding element of the input vector. We’ll use the same notation as derivatives for gradients.\n\\[\n\\frac{df}{d\\mathbf{x}} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\frac{\\partial f}{\\partial x_3} \\\\ \\vdots \\end{bmatrix}\n\\]\nThe gradient is a vector that tangent to the function \\(f\\) at the input \\(\\mathbf{x}\\). Just as with derivatives, this means that the gradient defines a linear approximation to the function at the point \\(\\mathbf{x}\\).\n\\[\nf(\\mathbf{x}+\\mathbf{\\epsilon}) \\approx f(\\mathbf{x}) + \\frac{df}{d\\mathbf{x}} \\cdot \\mathbf{\\epsilon}\n\\]\nWhere \\(\\mathbf{\\epsilon}\\) is now a small vector. Intuitively, this means that if we take a small step in any direction as defined by \\(\\mathbf{\\epsilon}\\), the gradient will approximate the change in the output of the function. Becuase we are now in more than 1 dimension, this approximation defines a plane in \\(\\mathbb{R}^n\\).\nAnother extremely important property of the gradient is that it points in the direction of maximum change in the function. Meaning that if we were to take an infinitesimal step \\(\\mathbf{\\epsilon}\\) from \\(\\mathbf{x}\\) in any direction, stepping in the gradient direction would give use the maximum value of \\(f(\\mathbf{x} +\\mathbf{\\epsilon})\\). We can see this from the approximation above: \\(f(\\mathbf{x} +\\mathbf{\\epsilon})\\) is maximized when \\(\\frac{df}{d\\mathbf{x}}\\) and \\(\\mathbf{\\epsilon}\\) are colinear.\nWe can define the gradient in this sense this more formally as:\n\\[\n\\frac{df}{d\\mathbf{x}}= \\underset{\\gamma \\rightarrow 0}{\\lim}\\ \\underset{\\|\\mathbf{\\epsilon}\\|_2 &lt; \\gamma}{\\max} \\frac{f(\\mathbf{x} + \\mathbf{\\epsilon}) - f(\\mathbf{x})}{\\|\\mathbf{\\epsilon}\\|_2}\n\\]"
  },
  {
    "objectID": "lecture1-background/notes.html#gradient-functions",
    "href": "lecture1-background/notes.html#gradient-functions",
    "title": "Prerequisites for neural networks",
    "section": "Gradient functions",
    "text": "Gradient functions\nJust as with derivatives and partial derivatives, we can define a gradient function that maps an input vector \\(\\mathbf{x}\\) to the gradient of the function \\(f\\) at \\(\\mathbf{x}\\) as:\n\\[\n\\frac{df}{d\\mathbf{x}}=\\nabla f(\\mathbf{x})\n\\]\nHere \\(\\nabla f\\) is the gradient function for \\(f\\). If the function takes multiple vectors as input, we can specify the gradient function with respect to a particular input using subscript notation:\n\\[\n\\frac{df}{d\\mathbf{x}}= \\nabla_{\\mathbf{x}} f(\\mathbf{x}, \\mathbf{y}), \\quad \\frac{df}{d\\mathbf{y}}= \\nabla_{\\mathbf{y}} f(\\mathbf{x}, \\mathbf{y})\n\\]\nNote that the gradient function is a mapping from \\(\\mathbb{R}^n\\rightarrow\\mathbb{R}^n\\), meaning that it returns a vector with the same size as the input."
  },
  {
    "objectID": "lecture1-background/notes.html#getting-started",
    "href": "lecture1-background/notes.html#getting-started",
    "title": "Prerequisites for neural networks",
    "section": "Getting started",
    "text": "Getting started\nThe standard way to import MatPlotLib is:\n\nimport matplotlib.pyplot as plt\n\nThe standard approach to interacting with MatPlotLib can take some getting used to. In MatPlotLib the current plot that we’re working on is part of the global state, meaning that we don’t create an explicit plot object, we simply call functions of plt to update what the current plot will look like.\nWhen working in Jupyter notebooks, the current plot is displayed at the end of the current cell when it is run."
  },
  {
    "objectID": "lecture1-background/notes.html#scatterplots-and-line-plots",
    "href": "lecture1-background/notes.html#scatterplots-and-line-plots",
    "title": "Prerequisites for neural networks",
    "section": "Scatterplots and line plots",
    "text": "Scatterplots and line plots\nThe most typical action is to plot one sequence (x-values) against another (y-values); this can be done using disconnected points (a scatterplot), or by connecting adjacent points in the sequence (in the order they were provided). The latter is usually used to give a nice (piecewise linear) visualization of a continuous curve, by specifying x-values in order, and the y-values given by the function at those x-values.\nPlotting a scatter of data points:\n\nx_values = np.random.rand(1,10)   # unformly in [0,1)\ny_values = np.random.randn(1,10)  # Gaussian distribution\nplt.plot(x_values, y_values, 'ko');\n\n\n\n\n\n\n\n\nThe string determines the plot appearance – in this case, black circles. You can use color strings (‘r’, ‘g’, ‘b’, ‘m’, ‘c’, ‘y’, …) or use the “Color” keyword to specify an RGB color. Marker appearance (‘o’,‘s’,‘v’,‘.’, …) controls how the points look.\nIf we connect those points using a line appearance specification (‘-’,‘–’,‘:’,…), it will not look very good, because the points are not ordered in any meaningful way. Let’s try a line plot using an ordered sequence of x values:\n\nx_values = np.linspace(0,8,100)\ny_values = np.sin(x_values)\nplt.plot(x_values,y_values,'b');\n\n\n\n\n\n\n\n\nThis is actually a plot of a large number of points (100), with no marker shape and connected by a solid line.\nFor plotting multiple point sets or curves, you can pass more vectors into the plot function, or call the function multiple times:\n\nx_values = np.linspace(0,8,100)\ny1 = np.sin(x_values)         # sinusoidal function\ny2 = (x_values - 3)**2 / 12   # a simple quadratic curve\ny3 = 0.5*x_values - 1.0       # a simple linear function\n\nplt.plot(x_values, y1, 'b-', x_values, y2, 'g--');  # plot two curves\nplt.plot(x_values, y3, 'r:'); # add a curve to the plot\n\n\n\n\n\n\n\n\nYou may want to explicitly set the plot ranges – perhaps the most common pattern is to plot something, get the plot’s ranges, and then restore them later after plotting another function:\n\nx_values = np.linspace(0,8,100)\ny1 = np.sin(x_values)         # sinusoidal function\ny3 = 0.5*x_values - 1.0       # a simple linear function\n\nplt.plot(x_values, y1, 'b-') \nax = plt.axis()               # get the x and y axis ranges\nprint(ax)\n# now plot something else (which will change the axis ranges):\nplt.plot(x_values, y3, 'r:'); # add the linear curve\nplt.axis(ax);                 # restore the original plot's axis ranges\n\n(np.float64(-0.4), np.float64(8.4), np.float64(-1.099652011574681), np.float64(1.0998559934443881))"
  },
  {
    "objectID": "lecture1-background/notes.html#legends",
    "href": "lecture1-background/notes.html#legends",
    "title": "Prerequisites for neural networks",
    "section": "Legends",
    "text": "Legends\nWhen plotting multiple point sets or curves we’ll likely want to be able to distinguish what each plot represents. We can do this by specifying a label for each plot, then adding a legend that tells us what each represents.\n\nx_values = np.linspace(0,8,100)\ny1 = np.sin(x_values)         # sinusoidal function\ny2 = (x_values - 3)**2 / 12   # a simple quadratic curve\ny3 = 0.5*x_values - 1.0       # a simple linear function\n\nplt.plot(x_values, y1, 'b-', label='sin(x)');  # plot two curves\nplt.plot(x_values, y2, 'g--', label='$(x-3)^2 / 12$')\nplt.plot(x_values, y3, 'r:', label='$.5x-1$'); # add a curve to the plot\nplt.legend();\n\n\n\n\n\n\n\n\nHere surrounding text in a label with $ $ allows us to write mathamatical equations as in LaTex!"
  },
  {
    "objectID": "lecture1-background/notes.html#titles-and-labels",
    "href": "lecture1-background/notes.html#titles-and-labels",
    "title": "Prerequisites for neural networks",
    "section": "Titles and labels",
    "text": "Titles and labels\nTypically we would like those viewing our plot to understand what the axes mean! We can label the x and y axes using plt.xlabel() and plt.ylabel() respectively. We can also set a title for our plot using plt.title()\n\nx_values = np.linspace(0,8,100)\ny = np.sin(x_values)          # sinusoidal function\n\nplt.plot(x_values, y, 'b-');  # plot two curves\nplt.xlabel('x')               # set the label for the x-axis\nplt.ylabel('$sin(x)$')        # set the label for the y-axis\nplt.title('x vs. $sin(x)$');  # set the title for the plot"
  },
  {
    "objectID": "lecture1-background/notes.html#histograms",
    "href": "lecture1-background/notes.html#histograms",
    "title": "Prerequisites for neural networks",
    "section": "Histograms",
    "text": "Histograms\nHistograms are also useful visualizations:\n\nplt.hist(y2, bins=20);\n\n\n\n\n\n\n\n\nThe outputs of hist include the bin locations, the number of data in each bin, and the “handles” to the plot elements to manipulate their appearance, if desired."
  },
  {
    "objectID": "lecture1-background/notes.html#subplots-and-plot-sizes",
    "href": "lecture1-background/notes.html#subplots-and-plot-sizes",
    "title": "Prerequisites for neural networks",
    "section": "Subplots and plot sizes",
    "text": "Subplots and plot sizes\nIt is often useful to put more than one plot together in a group; you can do this using the subplot function. There are various options; for example, “sharex” and “sharey” allow multiple plots to share a single axis range (or, you can set it manually, of course).\nI often find it necessary to also change the geometry of the figure for multiple subplots – although this is more generally useful as well, if you have a plot that looks better wider and shorter, for example.\n\nfig,ax = plt.subplots(1,3, figsize=(8.0, 2.0))      # make a 1 x 3 grid of plots:\nax[0].plot(x_values, y1, 'b-');   # plot y1 in the first subplot\nax[1].plot(x_values, y2, 'g--');  #   y2 in the 2nd\nax[2].plot(x_values, y3, 'r:');   #   and y3 in the last"
  },
  {
    "objectID": "lecture1-background/notes.html#subplot-options",
    "href": "lecture1-background/notes.html#subplot-options",
    "title": "Prerequisites for neural networks",
    "section": "Subplot options",
    "text": "Subplot options\nIf we want to add legends or labeling to individual subplots we need to call methods of the individual subplot objects. In this case, the methods we need change a bit! Rather than using plt.title(), plt.xlabel() and plt.ylabel(), we need to use the methods ax.set_title(), ax.set_xlabel() and ax.set_ylabel()\n\nfig,ax = plt.subplots(1,2, figsize=(8.0, 2.0))      # make a 1 x 3 grid of plots:\nax[0].plot(x_values, y1, 'b-', label='sin(x)');   # plot y1 in the first subplot\nax[1].plot(x_values, y2, 'g--', label='$(x-3)^2 / 12$');  #   y2 in the 2nd\n\n# Add titles to both subplots\nax[0].set_title('x vs. sin(x)')\nax[1].set_title('x vs. $(x-3)^2 / 12$')\n\n# Add axis labels\nax[0].set_xlabel('x')\nax[0].set_ylabel('sin(x)')\n\nax[1].set_xlabel('x')\nax[1].set_ylabel('$(x-3)^2 / 12$')\n\n# Create legends for both subplots\nax[0].legend()\nax[1].legend();"
  },
  {
    "objectID": "lecture1-background/notes-1.html",
    "href": "lecture1-background/notes-1.html",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "",
    "text": "The goal of this course is to learn to build neural neural networks, but first we should make sure that we understand what neural networks do and why we’d be interested in learning about them in the first place. You’re probably already familar with a lot of the real-world applications of neural networks, as in the past few years they’ve changed the way we use technology. Systems for everything from voice recognition, to photo-editing, to text and image generation and more now are largely built on the foundation of neural networks. Let’s start by introducing a few broad categories of neural network applications along with some specific examples that you may or may not have seen.\n\n\nIn prediction applications neural networks are used to assign a label or a prediction to a given input. Examples of applications using neural networks for prediction include:\nImage classification (Example: Google Lens)\nImage classification applications like Google Lens can take an image as input and identify the contents of the image using neural networks. This task will be the focus of one of the later modules in the course.\n\n\n\n\n\nCredit: Google\nMedical diagnosis\nDoes a patient have lung cancer? Neural networks for medical diagnosis might be able take in a patient s symtoms and test results and give an answer.\n\n\n\n\n\nCredit: Microsoft Research\n\n\n\nIn detection applications, neural networks are used to identify any instances of a particular pattern in a given input. For example:\nVoice recognition (Example: Siri)\nWhen you say “Hey Siri!” and your phone responds, it was a neural network that recognized your voice; taking as input the audio captured by your phone’s microphone and detecting any instances of the activation phrase.\n\n\n\n\n\nCredit: Apple\nObject detection (Example: YOLO)\nObject detection neural networks like YOLO (You Only Look Once) can identify multiple objects in an image. These types of networks are often used in applications like autonomous cars, which need to identify vehicles, pedestrians and other hazards on the road.\n\n\n\n\n\n\n\n\nPossibly the most widely discussed application of neural networks in recent years has been generative models, that is models that can generate realistic new data such as images and text.\nText generation (Example: ChatGPT) Large language models, such as the GPT models that power ChatGPT, use neural networks to synthesize realistic language.\n\n\n\n\n\nCredit: OpenAI\nImage generation (Example: Dall-E 3) Deep generative models for images similarly can generate realistic images.\n\n\n\n\n\n\n\n\nTransformation tasks take existing data in the form of images or text and create new and improved versions.\nPhoto editing (Example: Adobe Photoshop)\nImage editing tools like Photoshop use neural networks to output enhanced versions of images, either adjusting properties like color or even filling in missing parts of images!\n\n\n\n\n\nCredit: Adobe\nPhoto editing (Example: Google Translate)\nTranslation tools like Google translate use neural networks to map text in one language to another much more effectively than prior methods.\n\n\n\n\n\nCredit: Google\n\n\n\nMolecular dynamics (Example: AlphaFold)\nNeural networks are finding applications in the physical sciences allowing researchers to create approximate simulations of complex physical systems such as molecules. AlphaFold uses neural networks to predict the structure of proteins given their chemical composition.\n\n\n\n\n\nCredit: Google\nRendering (Example: NeRFs)\nNeural radiance fields (or NeRFs for short) use neural networks to quickly approximate new views of a 3d scene without the need for traditional modeling and rendering."
  },
  {
    "objectID": "lecture1-background/notes-1.html#tabluar-data",
    "href": "lecture1-background/notes-1.html#tabluar-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Tabluar data",
    "text": "Tabluar data\nIf you’ve worked with Excel, SQL or even many physical records, you’re likely familiar with the concept of tabular data. Tabular data essentially refers to any data that we can easily represent in a table format. As this could mean a few different things, when we talk about tabular data in this class, we’ll specifically be refering to data in what is often called the tidy data format.\n\nTidy data\nWe’ll say that data is in in the “tidy” format if each observation is represented with a single row of our table and each feature is represented with a single column. An observation is an entity, such as a patient in a hospital, that we may want to make preditions about. A feature (or variable) represents some measureable property that every observation has. For the patients in our example the set of features might correspond to measurements like the heart rate, blood pressure or oxygen level of each patient, as well as properties like the patient’s name, age and gender. This organizaton makes it easy to find any given measurement for any given patient (just use the row and column coordinates in the table). For tabular data we’ll assume that the ordering of both rows and columns in our table has no special significance, so could change the ordering of either without altering what our table represents.\n\n\n\nAppendicitis dataset in the “tidy” format\n\n\nNote that how we organize a set of measurements into observations and features isn’t nessecarily fixed, and might change depending on our goals. For example, if our goal is to predict whether a patient has some given underlying condition, we might have one observation per patient. Alternatively, if a given patient visits the hospital several times and our goal is to predict whether a patient will be admitted overnight for a given visit, we might have one observation per visit.\n\n\nVariable types\nThe idea of tidy data should also be intuitive to programmers familiar with the object-oriented programming paradigm. There we organize our data in objects (observations) where each object has a common set of properies (features). Just as in object oriented programming, its important to consider the type of each feature, which defines what values it can take and what operations we can perform on it. We’ll consider a few useful general feature types and how we might map them to concrete types in code.\n\n\n\n\n\n\nQuantitative features\nQuantitative features are simply numbers like our patient’s blood pressure, heart rate etc. We can further subdivide this category into integer features, that we’d encode as integer types (e.g. int, uint) and real-valued features that we’d encode as floating point values (e.g. float).\n\n\nCategorical features\nCategorical features are features that can only take a few distinct, non-numerical values. For example this could be the department that a patient was admitted to ({ER, Neurology, Obstetrics, Dermatology, etc.}) or the patient’s gender identity ({female, male, non-binary, etc.}). These values might be best encoded through an enum type, but are typically encoded as either a string or int in practice.\nBoolean features are a special case of categorical features with only two possible values. They could be encoded as an bool or int type.\n\n\nOrdinal features\nOrdinal features are something of a middle-ground between quantitative and categorical features. They represent features where the possible values have a well-definded ordering (like numbers), but no concept of distance (like categorical values). For example our patients might be assigned a priority level that takes the values low, medium or high. In this case it’s well-defined to say that low &lt; medium &lt; high, but asking for the result of high - low is not defined. We might encode these features as int types as well.\n\n\nGeneral “nomial” features\nNon-numerical features that don’t have a fixed set of possible values is what we’d call nominal or unstructured data. While it’s common in many contexts to see such values within tabluar data, for neural networks we’ll generally treat them as their own data type, outside of the tidy, tablular data paradigm."
  },
  {
    "objectID": "lecture1-background/notes-1.html#image-data",
    "href": "lecture1-background/notes-1.html#image-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Image data",
    "text": "Image data"
  },
  {
    "objectID": "lecture1-background/notes-1.html#text-data",
    "href": "lecture1-background/notes-1.html#text-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Text data",
    "text": "Text data"
  },
  {
    "objectID": "lecture1-background/notes-1.html#multimodal-data",
    "href": "lecture1-background/notes-1.html#multimodal-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Multimodal data",
    "text": "Multimodal data"
  },
  {
    "objectID": "lecture1-background/notes-1.html#graph-data",
    "href": "lecture1-background/notes-1.html#graph-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Graph data",
    "text": "Graph data"
  },
  {
    "objectID": "lecture1-background/notes-1.html#section",
    "href": "lecture1-background/notes-1.html#section",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "",
    "text": "What is tabular data?\nIf you’ve worked with Excel, SQL or even many physical records, you’re likely familiar with the concept of tabular data. Tabular data essentially refers to any data that we can easily represent in a table format, but, as this could mean a few different things, when we talk about tabular data in this class, we’ll specifically be refering to data in what is often called the tidy data format.\n\n\nTidy data\nWe’ll say that data is in in the “tidy” format if each observation is represented with a single row of our table and each feature is represented with a single column. An observation is an entity, such as a patient in a hospital, that we may want to make preditions about. A feature (or variable) represents some measureable property that every observation has. For the patients in our example the set of features might correspond to measurements like the heart rate, blood pressure or oxygen level of each patient, as well as properties like the patient’s name, age and gender. This organizaton makes it easy to find any given measurement for any given patient (just use the row and column coordinates in the table). For tabular data we’ll assume that the ordering of both rows and columns in our table has no special significance, so could change the ordering of either without altering what our table represents.\nNote that how we organize a set of measurements into obsrevations and features isn’t nessecarily fixed, and might change depending on our goals. For example, if our goal is to predict whether a patient has some given underlying condition, we might have one observation per patient. Alternatively, if a given patient visits the hospital several times and our goal is to predict whether a patient will be admitted overnight for a given visit, we might have one observation per visit.\n\n\nVariable types\nThe idea of tidy data should also be intuitive to programmers familiar with the object-oriented programming paradigm. There we organize our data in objects (observations) where each object has a common set of properies (features). Just as in object oriented programming, its important to consider the type of each feature, which defines what values it can take and what operations we can perform on it. We’ll consider a few useful general feature types and how we might map them to concrete types in code.\n\nQuantitative features\nQuantitative features are simply numbers like our patient’s blood pressure, heart rate etc. We can further subdivide this category into integer features, that we’d encode as integer types (e.g. int, uint) and real-valued features that we’d encode as floating point values (e.g. float).\n\n\nCategorical features\nCategorical features are features that can only take a few distinct, non-numerical values. For example this could be the department that a patient was admitted to ({ER, Neurology, Obstetrics, Dermatology, etc.}) or the patient’s gender identity ({female, male, non-binary, etc.}). These values might be best encoded through an enum type, but are typically encoded as either a string or int in practice.\nBoolean features are a special case of categorical features with only two possible values. They could be encoded as an bool or int type.\n\n\nOrdinal features\nOrdinal features are something of a middle-ground between quantitative and categorical features. They represent features where the possible values have a well-definded ordering (like numbers), but no concept of distance (like categorical values). For example our patients might be assigned a priority level that takes the values low, medium or high. In this case it’s well-defined to say that low &lt; medium &lt; high, but asking for the result of high - low is not defined. We might encode these features as int types as well.\n\n\nGeneral “nomial” features\nNon-numerical features that don’t have a fixed set of possible values is what we’d call nominal or unstructured data. While it’s common in many contexts to see such values within tabluar data, for neural networks we’ll generally treat them as their own data type, outside of the tidy, tablular data paradigm.\n\n\n\nMatrix data\nWhile tables are useful for reading and understanding datasets, neural networks are fundamentally mathamatical functions of our data, so in order to work with them we’ll usually need to abstract away from the specifics of our data into a more convenient mathamatical form. In particular, as tablular data has 2 dimensions (observation rows and feature columns), the natural way to think about a dataset mathamatically is as a matrix. By convention, we’ll usually think about our data as an \\(N \\times d\\) matrix, where we have \\(N\\) observations and \\(d\\) features and we’ll typically call this matrix \\(\\mathbf{X}\\).\nUnder this convention, the first index into our matrix will denote the row or observation and the second, the column or feature. In code, we’ll use numpy arrays to represent matrices, which work similarly.\nWe can also think about each row as being a vector of length \\(d\\) representing a single observation.\nHere it’s worth pointing out a bit of a notational quirk that can get a little confusing. A vector is a 1-dimensional object; we can think of it as a 1-d array in code. However, when we do mathamatical operations involving both matrices and vectors, it’s often convenient to treat a vector as either a \\(d \\times 1\\) matrix, also known as a column vector, or as a \\(1 \\times d\\) matrix (row vector). By convention, in mathamatical expressions we’ll assume that by default, any vector we refer to will be treated as a column vector, even if the vector was a row in a matrix.\nIf we want to treat a vector as a row vector, we will explicitly transpose it. This can get confusing so it’s worth keeping this in your head as we move forward.\n\n\nEncoding categorical variables\nYou might be wondering at this point: if we’re treating everything as matrices and vectors, how do deal with features that aren’t real valued numbers?\nInteger values are straightforward; we can easily treat them as real numbers already and in code we can simply cast them.\nWe’ll talk (a lot) about unstructured text later in this course, so for now will just worry about categorical/ordinal features.\n\n\nData"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html",
    "href": "lecture7-pytorch/notebook copy.html",
    "title": "Lecture 7: PyTorch",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nimport tqdm\nfrom sklearn.inspection import DecisionBoundaryDisplay\n\ndef plot_boundary(model, X, y, alpha=1, title=''):\n    xrange = (-X[:, 0].min() + X[:, 0].max()) / 10\n    yrange = (-X[:, y].min() + X[:, y].max()) / 10\n    feature_1, feature_2 = np.meshgrid(\n        np.linspace(X[:, 0].min() - xrange, X[:, 0].max() + xrange, 250),\n        np.linspace(X[:, 1].min() - yrange, X[:, 1].max() + yrange, 250)\n    )\n    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n    y_pred = np.reshape(model.predict(torch.tensor(grid).float()).detach().numpy(), feature_1.shape)\n    display = DecisionBoundaryDisplay(\n        xx0=feature_1, xx1=feature_2, response=y_pred\n    )\n    display.plot()\n    display.ax_.scatter(\n        X[:, 0], X[:, 1], c=y, alpha=alpha, edgecolor=\"black\"\n    )\n    plt.title(title)\n    plt.show()"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#introduction-to-pytorch",
    "href": "lecture7-pytorch/notebook copy.html#introduction-to-pytorch",
    "title": "Lecture 7: PyTorch",
    "section": "Introduction to PyTorch",
    "text": "Introduction to PyTorch\nThe most basic object in PyTorch is a tensor. Tensor objects behave much like the AutogradValue objects we are creating in the homework! We can create a tensor object with a given value as follows\n\nx = torch.tensor(4.)\nx\n\ntensor(4.)\n\n\nPerforming basic operations on tensor objects gives tensor objects.\n\na = x ** 2 + 5\na\n\ntensor(21.)\n\n\ntensor objects also support reverse-mode automatic differentiation! To use this, we must specify that we will want to compute the derivative with respect to a given tensor. We can do this with the requires_grad argument.\n\nx = torch.tensor(4., requires_grad=True)\n\nOnce we have a tensor that requires_grad, we can perform operations on it to compute a loss.\n\na = x ** 2 + 5\nL = torch.log(a) # Functions like log must be called through torch\nL\n\ntensor(3.0445, grad_fn=&lt;LogBackward0&gt;)\n\n\nOnce we have a loss running the backward pass is done exactly as in the homework. First we call backward() on the loss tensor object, then we can access the derivative through the grad property of x.\n\nL.backward()\nx.grad\n\ntensor(0.3810)\n\n\nWe can also create tensor objects that wrap arrays.\n\nx = torch.tensor(np.array([3, 4, 5]))\nx\n\ntensor([3, 4, 5])\n\n\nWe can also just directly create tensors as we would numpy arrays\n\nx = torch.tensor([3, 4, 5])\nx\n\ntensor([3, 4, 5])\n\n\nIncluding convienience constructors.\n\nprint(torch.ones((5,)))\nprint(torch.zeros((2, 3)))\n\ntensor([1., 1., 1., 1., 1.])\ntensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\nAutomatic differentiation still works for arrays. In this case it gives use the gradient of the loss (hence the grad property).\n\nx = torch.tensor([3., 4., 5.], requires_grad=True)\nL = torch.sum(x ** 2)\nL\n\ntensor(50., grad_fn=&lt;SumBackward0&gt;)\n\n\n\nL.grad\n\n/var/folders/t9/fjsr8h1x7c7cg4vqw_xhjq2w0000gn/T/ipykernel_79454/323164392.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:491.)\n  L.grad\n\n\n\nL.backward()\nx.grad\n\ntensor([ 6.,  8., 10.])\n\n\nWe can convert tensor objects back to numpy by calling x.detach().numpy(). (detach removes the variable from any automatic differentiation computations)\n\nx.detach().numpy()\n\narray([3., 4., 5.], dtype=float32)\n\n\nAt this point it’s probably worth remarking on where the name tensor comes from.\nSo far we’ve discussed 3 kinds of array objects - Scalars: which are just single values (0-dimensional) - Vectors: 1-dimensional arrays of numbers - Matrices: 2-dimensional arrays of numbers\n\n\n\nAlt text\n\n\nA tensor is the generalization of a vector or matrix to any number of dimensions. For example, a 3-dimensional tensor can be seen in multiple ways.\n\n\n\nAlt text\n\n\nA tensor object can be created with any number of dimensions. For example, we could create a 2x2x2 tensor as:\n\nt = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nt\n\ntensor([[[1, 2],\n         [3, 4]],\n\n        [[5, 6],\n         [7, 8]]])\n\n\nOr we could create the tensor in the image using arange and reshape.\n\nt = torch.arange(30).reshape((3, 2, 5))\nt\n\ntensor([[[ 0,  1,  2,  3,  4],\n         [ 5,  6,  7,  8,  9]],\n\n        [[10, 11, 12, 13, 14],\n         [15, 16, 17, 18, 19]],\n\n        [[20, 21, 22, 23, 24],\n         [25, 26, 27, 28, 29]]])\n\n\n4-dimensional tensors can also be visualized\n\n\n\nAlt text\n\n\n\nt = torch.ones((3, 2, 4, 5))\nt.shape\n\ntorch.Size([3, 2, 4, 5])\n\n\nThere are some notable differences between torch and numpy when it comes to operations. The important one to watch out for at this point is matrix multiplation. In numpy we accomplished with with np.dot:\n\nx = np.ones((4, 5))\nw = np.ones((5, 2))\nnp.dot(x, w)\n\narray([[5., 5.],\n       [5., 5.],\n       [5., 5.],\n       [5., 5.]])\n\n\nIn PyTorch torch.dot only does vector dot products and thus only applies to 1-dimensional tensor objects:\n\nx = torch.ones((4, 5))\nw = torch.ones((5, 2))\ntorch.dot(x, w)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb Cell 40 line 3\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; x = torch.ones((4, 5))\n      &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; w = torch.ones((5, 2))\n----&gt; &lt;a href='vscode-notebook-cell:/Users/gabe/Documents/Courses/CS152-Neural-Networks-Fall-2023.github.io/lecture7-pytorch/notebook.ipynb#X55sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; torch.dot(x, w)\n\nRuntimeError: 1D tensors expected, but got 2D and 2D tensors\n\n\n\nInstead we use the torch.matmul function for this purpose\n\ntorch.matmul(x, w)\n\ntensor([[5., 5.],\n        [5., 5.],\n        [5., 5.],\n        [5., 5.]])\n\n\nPyTorch also has many handy built-in functions that numpy doesn’t have, such as sigmoid.\n\nx = torch.linspace(-5, 5, 50)\ns = torch.sigmoid(x)\nplt.plot(x, s)\n\n\n\n\n\n\n\n\nThis makes it very easy to implement something like logistic regression.\n\nclass LogisticRegression:\n    def __init__(self, dims):\n        self.weights = torch.ones((dims,), requires_grad=True)\n        self.bias = torch.zeros((), requires_grad=True)\n\n    def predict_probability(self, X):\n        f_X = torch.matmul(X, self.weights) + self.bias\n        return torch.sigmoid(f_X)\n\n    def predict(self, X):\n        return self.predict_probability(X) &gt; 0.5\n\nLet’s try loading a dataset, converting it to tensor and making predictions\n\nX, y = make_moons(noise=0.1)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\nmodel = LogisticRegression(2)\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nWhen working with PyTorch, it is convention to separate the loss function from the model, where the loss function will just take predictions and labels.\n\ndef NLL(pred, y):\n    LL = y * torch.log(pred) + (1. - y) * torch.log(1. - pred)\n    return -LL.sum()"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#gradient-descent",
    "href": "lecture7-pytorch/notebook copy.html#gradient-descent",
    "title": "Lecture 7: PyTorch",
    "section": "Gradient descent",
    "text": "Gradient descent\nGradient descent is also implemented in PyTorch in the optim module.\n\nfrom torch import optim\n\nGradient descent works a bit differently in PyTorch than what we’ve seen. We first need to construct a gradient descent object which specifies which values we’re optimizing and what the learning rate will be. We specify the values to optimize by simply passing a list of weights/parameters to the constructor.\nIn PyTorch, basic gradient descent is encapsulated in the optim.SGD class (SGD stands for stochastic gradient descent, we’ll talk about what stochastic means in this context next week.)\n\noptimizer = optim.SGD([model.weights, model.bias], lr=0.1)\n\nNotice that this object doesn’t even take in the function we’re trying to optimize, only the inputs. We need to call the function ourselves and run backward() to compute the gradients.\n\npredictions = model.predict_probability(X)\nloss = NLL(predictions, y)\nloss.backward()\n\nLet’s look at our model weights\n\nmodel.weights\nmodel.weights.grad\n\ntensor([-5.6526, 24.1355])\n\n\nWe can take a single step of gradient descent using the step method of the optimizer.\n\noptimizer.step()\nmodel.weights\n\ntensor([ 1.5653, -1.4135], requires_grad=True)\n\n\nWe see that this actually updates the weights themselves!\nIt’s important to note that in PyTorch, calling backward does not clear the value stored in grad. So computing the gradient multiple times will result in updates to the gradient.\n\nprint(model.weights.grad)\nNLL(model.predict_probability(X), y).backward()\nprint(model.weights.grad)\nNLL(model.predict_probability(X), y).backward()\nprint(model.weights.grad)\n\ntensor([-5.6526, 24.1355])\ntensor([-14.5242,  28.7704])\ntensor([-23.3958,  33.4053])\n\n\nWe can clear the stored gradients using the optimizer.\n\noptimizer.zero_grad()\nprint(model.weights.grad)\n\nNone\n\n\nSo far we’ve only taking a single step of gradient descent. In order to run many steps, we need to write a loop to do everything we just saw.\n\nfor i in range(10):\n    predictions = model.predict_probability(X)\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n45.934814453125\n40.60100555419922\n32.82542037963867\n30.3773136138916\n28.918834686279297\n28.118915557861328\n27.602989196777344\n27.248106002807617\n26.989551544189453\n26.794662475585938\n\n\nWe should now see that our model has been optimized!\n\nplot_boundary(model, X, y)"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#torch.nn",
    "href": "lecture7-pytorch/notebook copy.html#torch.nn",
    "title": "Lecture 7: PyTorch",
    "section": "torch.nn",
    "text": "torch.nn\nWhile PyTorch as a tool for automatic differentiation and optimization would be useful by itself. It actually gives us a lot more than that!\nOn of the most important features of PyTorch is its model-building tools in the torch.nn module. This gives us a lot of powerful features that we can use to build complex neural networks!\n\nfrom torch import nn\n\nLet’s start by building out logistic regression model in the torch.nn framwork. In order for a model to benefit from torch.nn our model class needs to inheret from nn.Module\n\nclass LogisticRegression(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.weights = nn.Parameter(torch.ones((dims,)))\n        self.bias = nn.Parameter(torch.zeros(()))\n\n    def forward(self, X):\n        return torch.sigmoid(torch.matmul(X, self.weights) + self.bias)\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\nThere are 2 changes to note here. The first is that we wrapped our weights and bias terms in nn.Parameter. This tells PyTorch that these are the parameters we will want to optimize. We don’t need to specify requires_grad for parameters, PyTorch will take care of that for us.\nThe second is that we moved the implmentation of predict_probability to forward. In PyTorch models the forward method is special, it defines the model as a function. If we call the model as a function forward will be called internally.\n\nmodel = LogisticRegression(2)\nmodel(X)\n\ntensor([0.5652, 0.7431, 0.8238, 0.5468, 0.8991, 0.5719, 0.8651, 0.7784, 0.6153,\n        0.7053, 0.7419, 0.3129, 0.4502, 0.5031, 0.4508, 0.7075, 0.7626, 0.4756,\n        0.4158, 0.4693, 0.7904, 0.7241, 0.2430, 0.5297, 0.7944, 0.8496, 0.6825,\n        0.6149, 0.6730, 0.5231, 0.6151, 0.6108, 0.5509, 0.7476, 0.6634, 0.8512,\n        0.8117, 0.7527, 0.5092, 0.7742, 0.8012, 0.7604, 0.6411, 0.3242, 0.2805,\n        0.4016, 0.6296, 0.3000, 0.7045, 0.7307, 0.7442, 0.8091, 0.5104, 0.8006,\n        0.6166, 0.5173, 0.6404, 0.5779, 0.8199, 0.9030, 0.7872, 0.6059, 0.8091,\n        0.9367, 0.5806, 0.7576, 0.8079, 0.3847, 0.4926, 0.4909, 0.8605, 0.6233,\n        0.5605, 0.5980, 0.3629, 0.6874, 0.8761, 0.7593, 0.8267, 0.7912, 0.7147,\n        0.4980, 0.4396, 0.9295, 0.8956, 0.5096, 0.7148, 0.7788, 0.7961, 0.2600,\n        0.4964, 0.6008, 0.5710, 0.7882, 0.9379, 0.8573, 0.7131, 0.8105, 0.6835,\n        0.5392], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\nThis means that we can use instances of nn.Module as parameterized functions. For example, we might create a general linear (technically affine) function in the same way.\n\\[f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{W}^T + \\mathbf{b},  \\quad f: \\mathbb{R}^i \\rightarrow \\mathbb{R}^o\\]\nNote that here we are not assuming an augmented representation of \\(\\mathbf{x}\\).\n\nclass Linear(nn.Module):\n    def __init__(self, inputs, outputs):\n        super().__init__()\n        self.weightsT = nn.Parameter(torch.ones((inputs, outputs)))\n        self.bias = nn.Parameter(torch.zeros((outputs,)))\n\n    def forward(self, X):\n        return torch.matmul(X, self.weightsT) + self.bias\n\nWe can use this module to implement out logistic regression model above.\n\nclass LogisticRegression(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.linear = Linear(dims, 1)                       # Dims input 1 output\n\n    def forward(self, X):\n        return torch.sigmoid(self.linear(X)).reshape((-1,)) # Turn output into a vector\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\n\nmodel = LogisticRegression(2)\nmodel(X)\n\ntensor([0.5652, 0.7431, 0.8238, 0.5468, 0.8991, 0.5719, 0.8651, 0.7784, 0.6153,\n        0.7053, 0.7419, 0.3129, 0.4502, 0.5031, 0.4508, 0.7075, 0.7626, 0.4756,\n        0.4158, 0.4693, 0.7904, 0.7241, 0.2430, 0.5297, 0.7944, 0.8496, 0.6825,\n        0.6149, 0.6730, 0.5231, 0.6151, 0.6108, 0.5509, 0.7476, 0.6634, 0.8512,\n        0.8117, 0.7527, 0.5092, 0.7742, 0.8012, 0.7604, 0.6411, 0.3242, 0.2805,\n        0.4016, 0.6296, 0.3000, 0.7045, 0.7307, 0.7442, 0.8091, 0.5104, 0.8006,\n        0.6166, 0.5173, 0.6404, 0.5779, 0.8199, 0.9030, 0.7872, 0.6059, 0.8091,\n        0.9367, 0.5806, 0.7576, 0.8079, 0.3847, 0.4926, 0.4909, 0.8605, 0.6233,\n        0.5605, 0.5980, 0.3629, 0.6874, 0.8761, 0.7593, 0.8267, 0.7912, 0.7147,\n        0.4980, 0.4396, 0.9295, 0.8956, 0.5096, 0.7148, 0.7788, 0.7961, 0.2600,\n        0.4964, 0.6008, 0.5710, 0.7882, 0.9379, 0.8573, 0.7131, 0.8105, 0.6835,\n        0.5392], grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\nThe power here is that because Linear is also an instance of nn.Module, PyTorch knows that it’s weights should also be considered part of our models weights. We can access the weights of a model using the parameters() method.\n\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[1.],\n         [1.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nThis lets us easily apply gradient descent:\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nfor i in range(10):\n    predictions = model(X)        # Now we can just call model!\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n76.53839111328125\n45.934814453125\n40.60100555419922\n32.82542037963867\n30.3773136138916\n28.918834686279297\n28.118915557861328\n27.602989196777344\n27.248106002807617\n26.989551544189453\n\n\n\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nPyTorch unsurprisingly also provides a built-in Linear module. As nn.Linear.\n\nnn.Linear(2, 1)\n\nLinear(in_features=2, out_features=1, bias=True)\n\n\nKnowing how to make a parameterized function in PyTorch, let’s consider making a neural network layer with a sigmoid activation function.\n\\[f(\\mathbf{x}) = \\sigma(\\mathbf{x}^T\\mathbf{W}^T + \\mathbf{b})\\]\n\nclass SigmoidLayer(nn.Module):\n    def __init__(self, inputs, outputs):\n        super().__init__()\n        self.linear = nn.Linear(inputs, outputs)\n\n    def forward(self, X):\n        return torch.sigmoid(self.linear(X))\n        \n\nLet’s create a layer with 10 neurons. (So \\(\\mathbf{W}:\\ (10 \\times 2)\\))\n\nlayer = SigmoidLayer(2, 10)\nprint(X.shape)\nlayer(X).shape\n\ntorch.Size([100, 2])\n\n\ntorch.Size([100, 10])\n\n\nLet’s use this to create a neural network class for binary classification!\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self, dims, hidden_size):\n        super().__init__()\n        self.layer = SigmoidLayer(dims, hidden_size)\n        self.linear = Linear(hidden_size, 1)                       \n\n    def forward(self, X):\n        hidden_neurons = self.layer(X)\n        output = self.linear(hidden_neurons)\n        return torch.sigmoid(output).reshape((-1,))\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5\n\nWe see that PyTorch recognizes both the parameters of the logistic regression and the parameters of our neural network feature transform:\n\nmodel = NeuralNetwork(2, 10)\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[-0.0632, -0.0324],\n         [-0.4227, -0.0076],\n         [ 0.5793, -0.4920],\n         [ 0.1640, -0.5442],\n         [ 0.2326,  0.3651],\n         [-0.0184,  0.6859],\n         [ 0.0893,  0.1236],\n         [-0.4774, -0.3702],\n         [-0.0048,  0.4830],\n         [-0.4720,  0.5458]], requires_grad=True),\n Parameter containing:\n tensor([-0.2695, -0.1038, -0.7001,  0.3398, -0.0591,  0.6680,  0.3601, -0.3093,\n          0.0831, -0.4315], requires_grad=True),\n Parameter containing:\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.]], requires_grad=True),\n Parameter containing:\n tensor([0.], requires_grad=True)]\n\n\nThis means that we can easily run our optimization as before.\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nfor i in range(100):\n    predictions = model(X)        # Now we can just call model!\n    loss = NLL(predictions, y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n251.74571228027344\n461.0118103027344\n62.689453125\n58.230892181396484\n51.833839416503906\n45.31672668457031\n42.269630432128906\n41.090309143066406\n42.59092712402344\n44.23348617553711\n51.76810073852539\n45.51247024536133\n48.5499267578125\n37.86709976196289\n36.245426177978516\n32.07354736328125\n30.741405487060547\n29.285472869873047\n28.51435089111328\n27.839073181152344\n27.37657928466797\n26.992008209228516\n26.69622802734375\n26.455289840698242\n26.262691497802734\n26.106895446777344\n25.978981018066406\n25.872283935546875\n25.78037452697754\n25.699132919311523\n25.625377655029297\n25.55675506591797\n25.492244720458984\n25.430410385131836\n25.371490478515625\n25.31437873840332\n25.260303497314453\n25.208097457885742\n25.160297393798828\n25.115331649780273\n25.07819175720215\n25.046260833740234\n25.029979705810547\n25.02396011352539\n25.0517578125\n25.099485397338867\n25.22385025024414\n25.381305694580078\n25.71344757080078\n26.064964294433594\n26.785503387451172\n27.31593894958496\n28.478464126586914\n28.659645080566406\n29.6827335357666\n28.770679473876953\n28.902992248535156\n27.449777603149414\n27.00601577758789\n25.92099380493164\n25.47977066040039\n24.875839233398438\n24.58094596862793\n24.25676918029785\n24.065155029296875\n23.871578216552734\n23.734432220458984\n23.599082946777344\n23.48827362060547\n23.378538131713867\n23.279327392578125\n23.17983627319336\n23.08414077758789\n22.986806869506836\n22.889585494995117\n22.789363861083984\n22.686796188354492\n22.579761505126953\n22.468294143676758\n22.35063362121582\n22.226394653320312\n22.093841552734375\n21.952234268188477\n21.799684524536133\n21.6351318359375\n21.456491470336914\n21.26246452331543\n21.05084991455078\n20.82036781311035\n20.568992614746094\n20.29586410522461\n19.999610900878906\n19.680295944213867\n19.337650299072266\n18.972978591918945\n18.587278366088867\n18.183042526245117\n17.762325286865234\n17.328487396240234\n16.884227752685547\n\n\n\nplot_boundary(model, X, y)\n\n\n\n\n\n\n\n\nPyTorch also gives us an easier (but less flexible) way to define a composition of modules like this. In PyTorch we can define this simple network using nn.Sequential\n\nmodel = nn.Sequential(\n    nn.Linear(2, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 1),\n    nn.Sigmoid(),\n)\nmodel(X).reshape((-1,))\n\ntensor([0.3653, 0.3638, 0.3685, 0.3575, 0.3788, 0.3567, 0.3749, 0.3824, 0.3716,\n        0.3777, 0.3612, 0.3494, 0.3608, 0.3496, 0.3610, 0.3802, 0.3737, 0.3504,\n        0.3581, 0.3621, 0.3859, 0.3814, 0.3410, 0.3605, 0.3768, 0.3890, 0.3599,\n        0.3586, 0.3567, 0.3529, 0.3723, 0.3711, 0.3682, 0.3644, 0.3774, 0.3742,\n        0.3804, 0.3808, 0.3526, 0.3757, 0.3669, 0.3735, 0.3731, 0.3516, 0.3461,\n        0.3566, 0.3558, 0.3496, 0.3594, 0.3775, 0.3755, 0.3808, 0.3586, 0.3792,\n        0.3543, 0.3657, 0.3559, 0.3642, 0.3848, 0.3816, 0.3824, 0.3546, 0.3808,\n        0.3906, 0.3661, 0.3723, 0.3823, 0.3552, 0.3561, 0.3543, 0.3730, 0.3723,\n        0.3523, 0.3669, 0.3531, 0.3590, 0.3764, 0.3702, 0.3680, 0.3841, 0.3798,\n        0.3555, 0.3480, 0.3861, 0.3814, 0.3495, 0.3793, 0.3814, 0.3839, 0.3427,\n        0.3540, 0.3623, 0.3700, 0.3661, 0.3915, 0.3718, 0.3660, 0.3685, 0.3601,\n        0.3597], grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\nHere nn.Sigmoid is a built-in module that just applies the sigmoid function. Its implementation would look like:\n\nclass SigmoidLayer(nn.Module):\n    def forward(self, X):\n        return torch.sigmoid(X)\n\nWe could use this to create a network with several hidden layers:\n\nmodel = nn.Sequential(\n    nn.Linear(2, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 10),\n    nn.Sigmoid(),\n    nn.Linear(10, 1),\n    nn.Sigmoid(),\n)\nmodel(X)\n\ntensor([[0.4041],\n        [0.4038],\n        [0.4038],\n        [0.4040],\n        [0.4038],\n        [0.4039],\n        [0.4038],\n        [0.4041],\n        [0.4042],\n        [0.4041],\n        [0.4038],\n        [0.4042],\n        [0.4042],\n        [0.4039],\n        [0.4042],\n        [0.4042],\n        [0.4040],\n        [0.4039],\n        [0.4042],\n        [0.4042],\n        [0.4042],\n        [0.4042],\n        [0.4041],\n        [0.4041],\n        [0.4040],\n        [0.4041],\n        [0.4039],\n        [0.4039],\n        [0.4038],\n        [0.4039],\n        [0.4042],\n        [0.4042],\n        [0.4042],\n        [0.4039],\n        [0.4042],\n        [0.4038],\n        [0.4040],\n        [0.4041],\n        [0.4039],\n        [0.4040],\n        [0.4038],\n        [0.4040],\n        [0.4042],\n        [0.4042],\n        [0.4041],\n        [0.4042],\n        [0.4039],\n        [0.4042],\n        [0.4038],\n        [0.4041],\n        [0.4040],\n        [0.4040],\n        [0.4041],\n        [0.4040],\n        [0.4038],\n        [0.4042],\n        [0.4038],\n        [0.4041],\n        [0.4041],\n        [0.4038],\n        [0.4041],\n        [0.4039],\n        [0.4040],\n        [0.4039],\n        [0.4041],\n        [0.4040],\n        [0.4041],\n        [0.4042],\n        [0.4040],\n        [0.4040],\n        [0.4038],\n        [0.4042],\n        [0.4039],\n        [0.4041],\n        [0.4042],\n        [0.4038],\n        [0.4038],\n        [0.4039],\n        [0.4038],\n        [0.4041],\n        [0.4042],\n        [0.4040],\n        [0.4039],\n        [0.4038],\n        [0.4039],\n        [0.4039],\n        [0.4042],\n        [0.4041],\n        [0.4041],\n        [0.4041],\n        [0.4040],\n        [0.4040],\n        [0.4042],\n        [0.4038],\n        [0.4039],\n        [0.4038],\n        [0.4039],\n        [0.4038],\n        [0.4039],\n        [0.4040]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\nPyTorch also provides built-in loss functions. The PyTorch function for the negative log-likelihood for logistic regression is called nn.functional.binary_cross_entropy. It has some sharp edges though.\nFor one, it expects y to be a float type. We can convert a PyTorch int tensor into a float one by calling the float method.\nWe also see that our sequential model returns a column vector, so y should match that as well.\n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nyfloat = y.float().reshape((-1, 1))\n\nfor i in range(100):\n    predictions = model(X)        # Now we can just call model!\n    loss = nn.functional.binary_cross_entropy(predictions, yfloat)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(loss.item())\n\n0.712141752243042\n0.7091044783592224\n0.7065528631210327\n0.7044107913970947\n0.7026132941246033\n0.7011056542396545\n0.6998415589332581\n0.6987819671630859\n0.6978939771652222\n0.6971497535705566\n0.696526288986206\n0.6960040330886841\n0.6955663561820984\n0.6951996684074402\n0.694892406463623\n0.6946350336074829\n0.6944191455841064\n0.6942383646965027\n0.6940867900848389\n0.6939594745635986\n0.6938527822494507\n0.6937631964683533\n0.6936879754066467\n0.69362473487854\n0.6935714483261108\n0.6935266852378845\n0.6934890151023865\n0.6934571266174316\n0.6934301853179932\n0.6934073567390442\n0.693388044834137\n0.693371593952179\n0.693357527256012\n0.6933454871177673\n0.6933351755142212\n0.6933264136314392\n0.6933186054229736\n0.6933119297027588\n0.693306028842926\n0.6933008432388306\n0.6932962536811829\n0.6932921409606934\n0.6932885050773621\n0.6932851672172546\n0.6932820081710815\n0.6932792067527771\n0.6932765245437622\n0.6932740807533264\n0.693271815776825\n0.6932694911956787\n0.6932673454284668\n0.6932653784751892\n0.6932634115219116\n0.6932615637779236\n0.6932596564292908\n0.6932578086853027\n0.6932560801506042\n0.693254292011261\n0.6932525634765625\n0.693250834941864\n0.6932492256164551\n0.6932475566864014\n0.6932458281517029\n0.6932441592216492\n0.6932425498962402\n0.6932408809661865\n0.6932392120361328\n0.6932376027107239\n0.6932359933853149\n0.693234384059906\n0.6932327747344971\n0.6932311058044434\n0.6932294964790344\n0.6932278275489807\n0.6932263374328613\n0.6932246685028076\n0.6932230591773987\n0.6932214498519897\n0.693219780921936\n0.6932182312011719\n0.6932166218757629\n0.693215012550354\n0.6932134032249451\n0.6932117938995361\n0.693210244178772\n0.6932085156440735\n0.6932069659233093\n0.6932052373886108\n0.6932037472724915\n0.6932021379470825\n0.6932004690170288\n0.6931988596916199\n0.6931973099708557\n0.693195641040802\n0.6931940317153931\n0.6931924223899841\n0.6931908130645752\n0.693189263343811\n0.6931875348091125\n0.6931860446929932\n\n\nFor convinience, let’s definie a wrapper class for our model.\n\nclass LogisticRegressionNeuralNetwork(nn.Module):\n    def __init__(self, network):\n        super().__init__()\n        self.network = network                   \n\n    def forward(self, X):\n        return self.network(X).reshape((-1,))\n\n    def predict_probability(self, X):\n        return self.forward(X)\n\n    def predict(self, X):\n        return self.forward(X) &gt; 0.5"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#evaluating-models",
    "href": "lecture7-pytorch/notebook copy.html#evaluating-models",
    "title": "Lecture 7: PyTorch",
    "section": "Evaluating models",
    "text": "Evaluating models\nWe see that we have a lot of options when designing a neural network. So far the choices we’ve seen are: - The number of layers - The number of neurons in each layer - The activation function - The learning rate for gradient descent\nAnd this is just the beginning! As we go on, we’ll learn about many more options that we have.\nLet’s take a look at how to make some of these choices. In many real cases, our data will not be a cleanly separated into 2 classes as we’ve seen. For instance, we can look at a noisier version of the dataset we saw before.\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\nplt.scatter(*X.T, c=y, edgecolor=\"black\")\n\n\n\n\n\n\n\n\nIn reality, this dataset was drawn from the distribution shown below! The optimal classifier would still have an “s-shaped” decision boundary\n\nX, y = make_moons(50000, noise=0.5)\nplt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.1)\npass\n\n\n\n\n\n\n\n\nLet’s split this into training and test sets as we’ve seen.\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXtest, ytest = X[inds[150:]], y[inds[150:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.legend()"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#underfittting",
    "href": "lecture7-pytorch/notebook copy.html#underfittting",
    "title": "Lecture 7: PyTorch",
    "section": "Underfittting",
    "text": "Underfittting\nWe’ll start by fitting a logistic regression model as we’ve seen. This time we’ll keep track of the loss on both the training data and the test data.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(2500)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.501: 100%|██████████| 2500/2500 [00:02&lt;00:00, 892.89it/s] \n\n\n\nplot_boundary(model, Xtrain, ytrain)\n\n\n\n\n\n\n\n\nLet’s compute the accuracy on both the training and the test data\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nprint('Training accuracy: %.3f, Test accuracy: %.3f' % (train_acc, test_acc))\n\nTraining accuracy: 0.793, Test accuracy: 0.793\n\n\nWe can also look at how the loss on both the training and test data changes as we run gradient descent.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nHere wee see that both the training loss/accuracy and the test loss/accuracy are quite poor! From our descision boundary plot we can see quite clearly that this is a consequence of our choice of a linear model for this classification problem. We call this problem underfitting, meaning that our model is not expressive enough to capture all the intricacies of our data. As we’ve already seen we can address this by adding neural network layers to increase the expressivity of our model."
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#overfitting",
    "href": "lecture7-pytorch/notebook copy.html#overfitting",
    "title": "Lecture 7: PyTorch",
    "section": "Overfitting",
    "text": "Overfitting\nLet’s try creating a much more complex model; one with several large neural network layers and fitting it to our data.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.073: 100%|██████████| 25000/25000 [00:41&lt;00:00, 602.24it/s]\n\n\nWe can view the descision boundary and accuracy for this classifier.\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\nWe see that our model is much more expressive and basically correctly classifies every observation in our training dataset. This is great! However the boundary is quite complex. Let’s see what happens when we evaluate on our test set.\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nThe accuracy is much worse. Rather than capturing the true distribution of classes, our model has captured the training set we happened to draw. This means if we draw a new dataset from the same distribution (like our test set), performance is poor. We call this issue overfitting.\nLet’s see how the training and test loss change over gradient descent.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nMuch of the rest of this class will focus on how to meet the deicate balance of overfitting vs. underfitting!\nIt’s worth noting the the best solution to overfitting is to get more data. If we train with enough data we can avoid overfitting entirely.\n\nX, y = make_moons(2000, noise=0.5)\nplt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.1)\n\n\n\n\n\n\n\n\n\nX, y = torch.tensor(X).float(), torch.tensor(y)\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(2500)\nfor i in pbar:\n    predictions = model(X)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, y.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n/var/folders/t9/fjsr8h1x7c7cg4vqw_xhjq2w0000gn/T/ipykernel_79454/2923296796.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X, y = torch.tensor(X).float(), torch.tensor(y)\nLoss: 0.390: 100%|██████████| 2500/2500 [00:16&lt;00:00, 151.68it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nUnfortunately, this often isn’t realistic. Data is hard to collect and more data means our model is slower and more expensive to train."
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#early-stopping",
    "href": "lecture7-pytorch/notebook copy.html#early-stopping",
    "title": "Lecture 7: PyTorch",
    "section": "Early stopping",
    "text": "Early stopping\nLet’s return to the original case\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXtest, ytest = X[inds[150:]], y[inds[150:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.legend()\n\n\n\n\n\n\n\n\nLet’s try a network somewhere in-between, with just a single hidden layer.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 100),\n    nn.ReLU(),\n    nn.Linear(100, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\nLoss: 0.366: 100%|██████████| 25000/25000 [00:28&lt;00:00, 870.32it/s] \n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nWe see that this network is more consistent between train and test, and now performs better on test data! Let’s take a look at the plot of training and test loss.\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\nWe still see that both drop quickly, but that test loss increases after a point. How might we use this to pick a better model?\nOne option would be to just use the model where the test loss is lowest. After all, that is our ultimate goal. There are different ways we can think about implementing this. One way to to have gradient descent stop when the test loss begins to increase. We call this approach early stopping\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 100),\n    nn.ReLU(),\n    nn.Linear(100, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n    if i &gt; 50 and test_loss.item() &gt; test_losses[-2]:\n        break\n\nLoss: 0.481:   1%|▏         | 346/25000 [00:00&lt;00:30, 810.31it/s]\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')\n\n\n\n\n\n\n\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\nHere we see that actually we do the best so far with this approach!\nWe could also try our early-stopping approach with our more complex network.\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, test_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    test_loss = torch.nn.functional.binary_cross_entropy(model(Xtest), ytest.flatten().float())\n    test_losses.append(test_loss.item())\n\n    if i &gt; 50 and test_loss.item() &gt; test_losses[-2]:\n        break\n\nLoss: 0.465:   2%|▏         | 382/25000 [00:00&lt;00:42, 574.88it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\nplt.plot(train_losses[:15000:100], label='Training loss')\nplt.plot(test_losses[:15000:100], label='Test loss')\nplt.legend()\nplt.title('Loss vs. training iteration')\n\nText(0.5, 1.0, 'Loss vs. training iteration')"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#train-validation-and-test",
    "href": "lecture7-pytorch/notebook copy.html#train-validation-and-test",
    "title": "Lecture 7: PyTorch",
    "section": "Train, validation and test",
    "text": "Train, validation and test\nThere is an issue here though! We’ve now used out test set to (indirectly) train our model. Both by using it to choose the number of layers and by using it to determine how long to run our optimization! This means that our model choice will be biased by our choice of test set, so how can we trust that our test loss or accuracy will actually be a good measure of the real-world performance of our model?\nTo deal with this issue we will typically split our data into 3 parts that we’ll call training, validation and test. We’ll use the validation portion as the portion to fit the model and the test set as the portion we use to estimate how well it will do in practice.\n\nX, y = make_moons(300, noise=0.5)\nX, y = torch.tensor(X).float(), torch.tensor(y)\n\ninds = np.arange(X.shape[0])\nnp.random.shuffle(inds)\nXtrain, ytrain = X[inds[:150]], y[inds[:150]]\nXvalid, yvalid = X[inds[150:225]], y[inds[150:225]]\nXtest, ytest = X[inds[225:]], y[inds[225:]]\n\n# We can plot training and test data on the same plot\nplt.scatter(*Xtrain.T, c=ytrain, edgecolor=\"black\", marker='o', label='training data')\nplt.scatter(*Xtest.T, c=ytest, edgecolor=\"black\", marker='^', label='test data')\nplt.scatter(*Xvalid.T, c=yvalid, edgecolor=\"black\", marker='*', label='valid data')\nplt.legend()\n\n\n\n\n\n\n\n\n\nnetwork = nn.Sequential(\n    nn.Linear(2, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 200),\n    nn.ReLU(),\n    nn.Linear(200, 1),\n    nn.Sigmoid(),\n)\nmodel = LogisticRegressionNeuralNetwork(network)   \n\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\ntrain_losses, valid_losses = [], []\npbar = tqdm.trange(25000)\nfor i in pbar:\n    predictions = model(Xtrain)        # Now we can just call model!\n    loss = torch.nn.functional.binary_cross_entropy(predictions, ytrain.flatten().float())\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    pbar.set_description('Loss: %.3f' % loss.item())\n\n    train_losses.append(loss.item())\n    valid_loss = torch.nn.functional.binary_cross_entropy(model(Xvalid), yvalid.flatten().float())\n    valid_losses.append(valid_loss.item())\n\n    if i &gt; 50 and valid_loss.item() &gt; valid_losses[-2]:\n        break\n\nLoss: 0.406:   4%|▍         | 1060/25000 [00:02&lt;00:46, 513.32it/s]\n\n\n\ntrain_acc = (model.predict(Xtrain) == ytrain).float().mean()\nplot_boundary(model, Xtrain, ytrain, title='Training accuracy: %.3f' % train_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xvalid) == yvalid).float().mean()\nplot_boundary(model, Xvalid, yvalid, title='Validation accuracy: %.3f' % test_acc)\n\n\n\n\n\n\n\n\n\ntest_acc = (model.predict(Xtest) == ytest).float().mean()\nplot_boundary(model, Xtest, ytest, title='Test accuracy: %.3f' % test_acc)"
  },
  {
    "objectID": "lecture7-pytorch/notebook copy.html#cross-validation",
    "href": "lecture7-pytorch/notebook copy.html#cross-validation",
    "title": "Lecture 7: PyTorch",
    "section": "Cross validation",
    "text": "Cross validation\nAnother important approach is cross validation. In this setting, rather than using a single validation set, we will split our training set many times!\n\n\n\nAlt text"
  },
  {
    "objectID": "lecture1-background/notes-1.html#matrix-data",
    "href": "lecture1-background/notes-1.html#matrix-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Matrix data",
    "text": "Matrix data\nWhile tables are useful for reading and understanding datasets, as we’ve seen, we want to think about neural networks as mathamatical functions of our data. Therefore, in order to work with them we’ll usually need to abstract away from the specifics of our data into a more convenient mathamatical form. In particular, as tablular data has 2 dimensions (observation rows and feature columns), the natural way to think about a dataset mathamatically is as a matrix. By convention, we’ll usually think about our data as an \\(N \\times d\\) matrix, where we have \\(N\\) observations and \\(d\\) features and we’ll typically call this matrix \\(\\mathbf{X}\\).\n\n\n\n\n\nUnder this convention, the first index into our matrix will denote the row or observation and the second, the column or feature. In code, we’ll use numpy arrays to represent matrices, which work similarly.\n\n\n\n\n\nWe can also think about each row as being a vector of length \\(d\\) representing a single observation. So we’ll say that each observation \\(\\mathbf{x}_i\\) is a \\(d\\)-dimension vector \\(\\mathbf{x}_i \\in \\mathbb{R}^d\\). This is why so far we’ve used the bold (\\(\\mathbf{x}\\)) notation.\nHere it’s worth pointing out a bit of a notational quirk that can get a little confusing. A vector is a 1-dimensional object; we can think of it as a 1-d array in code. However, when we do mathamatical operations involving both matrices and vectors, it’s often convenient to treat a vector as either a \\(d \\times 1\\) matrix, also known as a column vector, or as a \\(1 \\times d\\) matrix (row vector).\n\n\n\n\n\nBy convention, in mathamatical expressions we’ll assume that by default, any vector we refer to will be treated as a column vector, even if the vector was a row in a matrix. If we want to treat a vector as a row vector, we will explicitly transpose it. This can get confusing so it’s worth keeping this in your head as we move forward. Under this convention, we might think about our matrix of all observations as:\n\\[\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\mathbf{x}_3^T \\\\ \\vdots  \\end{bmatrix} = \\begin{bmatrix} x_{11} & x_{12} & x_{13} & \\dots \\\\ x_{21} & x_{22} & x_{23} & \\dots \\\\ x_{31} & x_{32} & x_{33} & \\dots\\\\ \\vdots & \\vdots & \\vdots & \\ddots  \\end{bmatrix}\\]\nThis will become relevant when reading mathematical expressions of matrices and vectors in this class. For example, consider the two vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\).\n\\[\n\\mathbf{a} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3\\\\ \\end{bmatrix},\\\\ \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 4 \\\\ 2\\\\ \\end{bmatrix}, \\\\\n\\]\nWe can write the dot product as:\n\\[\n\\mathbf{a}^T \\mathbf{b} = \\big{[} 2 \\ \\ \\ 1 \\ \\ \\ \\  3 \\big{]} \\begin{matrix} \\begin{bmatrix} 1 \\\\ 4 \\\\ 2\\\\ \\end{bmatrix} \\\\ \\\\ \\\\ \\end{matrix} =12\n\\]\nSimilarly we can write an outer product as:\n\\[\n\\mathbf{a} \\mathbf{b}^T =  \\begin{matrix} \\begin{bmatrix} 2 \\\\ 1 \\\\ 3\\\\ \\end{bmatrix} \\\\ \\\\ \\\\ \\end{matrix} \\big{[} 1 \\ \\ \\ 4 \\ \\ \\ \\  2 \\big{]}  = \\begin{matrix} \\begin{bmatrix} 2 & 8 & 4 \\\\ 1 & 4 & 2 \\\\ 3 & 12 & 6 \\end{bmatrix}\\\\ \\\\ \\\\ \\end{matrix}\n\\]\n\nEncoding non-quantitative features\nYou might be wondering at this point: if we’re treating everything as matrices and vectors, how do deal with features that aren’t inherently real-valued numbers? Generally the approach will be to convert them into real numbers in some way.\nInteger features are straightforward; we can easily treat them as real numbers already and in code we can simply cast them. We’ll typically map ordinal features to the first few non-negative integers, e.g. \\(\\{\\text{none},\\ \\text{low},\\ \\text{medium},\\  \\text{high} \\} \\rightarrow \\{ 0, \\ 1, \\ 2, \\ 3 \\}\\). Boolean features are usually mapped to either \\(\\{0, 1\\}\\) or to \\(\\{-1, 1\\}\\). Finally categorical values are typically first mapped to a set of boolean values. If a categorical feature as \\(c\\) possible values, then it will be mapped to \\(c\\) new boolean variables, each indicating whether the original feature had that value. This is often called one-hot encoding.\n\nWe’ll talk (a lot) about unstructured text later in this course, so for now will just worry about categorical/ordinal features."
  },
  {
    "objectID": "lecture1-background/notes.html#random-variables",
    "href": "lecture1-background/notes.html#random-variables",
    "title": "Prerequisites for neural networks",
    "section": "Random variables",
    "text": "Random variables\nA random variable represents an unknown or random value. This could be the outcome of a unpredictable event such as a coin flip, a dice roll, or the weather, but could also represent our beliefs about something we simply haven’t directly observed, such as a patient’s diagnosis.\nWe’ll typically denote a random variable with an upper-case letter and it’s instantiation with the same letter in lower-case"
  },
  {
    "objectID": "lecture1-background/notes.html#distributions",
    "href": "lecture1-background/notes.html#distributions",
    "title": "Prerequisites for neural networks",
    "section": "Distributions",
    "text": "Distributions"
  },
  {
    "objectID": "lecture1-background/notes.html#uniform-distribution",
    "href": "lecture1-background/notes.html#uniform-distribution",
    "title": "Prerequisites for neural networks",
    "section": "Uniform distribution",
    "text": "Uniform distribution"
  },
  {
    "objectID": "lecture1-background/notes.html#bernoulli-distribution",
    "href": "lecture1-background/notes.html#bernoulli-distribution",
    "title": "Prerequisites for neural networks",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution"
  },
  {
    "objectID": "lecture1-background/notes.html#categorical-distribution",
    "href": "lecture1-background/notes.html#categorical-distribution",
    "title": "Prerequisites for neural networks",
    "section": "Categorical distribution",
    "text": "Categorical distribution"
  },
  {
    "objectID": "lecture1-background/notes.html#normal-distribution",
    "href": "lecture1-background/notes.html#normal-distribution",
    "title": "Prerequisites for neural networks",
    "section": "Normal distribution",
    "text": "Normal distribution"
  },
  {
    "objectID": "lecture1-background/notes.html#expectation",
    "href": "lecture1-background/notes.html#expectation",
    "title": "Prerequisites for neural networks",
    "section": "Expectation",
    "text": "Expectation"
  },
  {
    "objectID": "lecture1-background/notes.html#variance",
    "href": "lecture1-background/notes.html#variance",
    "title": "Prerequisites for neural networks",
    "section": "Variance",
    "text": "Variance"
  },
  {
    "objectID": "lecture1-background/notes.html#standard-deviation",
    "href": "lecture1-background/notes.html#standard-deviation",
    "title": "Prerequisites for neural networks",
    "section": "Standard deviation",
    "text": "Standard deviation"
  },
  {
    "objectID": "lecture1-background/notes-1.html#other-types-of-data",
    "href": "lecture1-background/notes-1.html#other-types-of-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Other types of data",
    "text": "Other types of data\nWe’ll focus on tabular data for the first part of this course, but it’s far from the only type of data that we’ll consider. We won’t go into detail here about representing these types of data, we’ll leave that until we introduce the relevant neural network material.\n\nImage and field data\nImages are one of the most common inputs to neural networks for many real-world problems. A single image typically consists of thousands to millions of individual measurements making up the pixels of the image (each “pixel” represents the color or brightness of the image at a given location). In tabular data we generally assume each feature has a different interpretation and the order of the features isn’t inherently meaningful. In image data, our features all have the same interpretation (as pixels), and a specific configuration as a 2-dimensional grid.\nMore generally, we can think of image data as being a member of the larger category of field data. Field data refers to data where every point in a given space has a value or set of values associated with it. This includes image data (each pixel has a brightness or red, green and blue color values), as well as things like video (with a third, time dimension), audio (with only a time dimension), 3-d medical scans (with x, y and z spatial dimensions) and climate data (latitude and longitude coordinates) among others.\n\n\nText and sequence data\nText is another widely used application of neural networks. In this case our observation could be a sentence or paragraph of text. More generally, we can frame this as a variable-length sequence of categorical features (or tokens). Beyond text, we can also frame things like genetic data in this way.\n\n\nGraph/network data\nIn many cases our data might be defined not just by the features of each observation, but also by the relationships between observations. In this case we have what we’d call graph or network data. A classic example would be social networks, where the relationships between people (e.g. whether or not they are friends) is of upmost importance. Other examples include things like protein structures, where the configuration of atoms in a molecule is as important as the types of the atoms.\n\n\nMulti-modal data\nIn many cases it’s also common to consider more than one type of data at once. For example, a diagnosis system might take in an x-ray image, text of doctor notes and tabular test result data as inputs to its prediction function. We this multi-modal data, as it has multiple different types or modes in one (image, text and tabluar)."
  },
  {
    "objectID": "lecture1-background/notes-1.html#label-types",
    "href": "lecture1-background/notes-1.html#label-types",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Label types",
    "text": "Label types\nFor our discussion of prediction problems, we’ll assume that the label that we want to predict is just a single value, which is why we’ve used the scalar notation \\(y\\).\nIf our labels are real numbers \\(y \\in \\mathbb{R}\\), e.g. if we’re trying to predict the number of hours a patient will stay in the hospital, then we’ll say that we have a regression problem.\n\n\n\n\n\nAlternatively, if our labels are categorical values, e.g. we’re trying to predict whether or not a patient has appendicitis, \\(y \\in \\{\\textit{healthy}, \\textit{appendicitis}\\}\\), then we’ll say that we have a classification problem.\n\n\n\n\n\nIf we have a full dataset of \\(N\\) observations and labels, we could refer to the collection of \\(N\\) labels as a vector \\(\\mathbf{y} \\in \\mathbb{R}^N\\)."
  },
  {
    "objectID": "lecture1-background/data.html",
    "href": "lecture1-background/data.html",
    "title": "CS 152: Neural Networks",
    "section": "",
    "text": "import polars as pl\nimport pandas as pd\n\n\n#.loc[[627, 464, 600, 389, 603, 667, 180, 341, 704, 105, 502, 65, 324, 20]]\ndata = pd.read_csv('/Users/gabehope/Downloads/app_data.csv')[['Age', 'Appendix_Diameter', 'Migratory_Pain',  'RBC_Count', 'RBC_in_Urine', 'Peritonitis' ]].dropna().loc[[627, 464, 600, 217, 187, 185, 389, 603, 667, 180, 341, 704, 105, 502, 65, 324, 20]].sample(frac=1).reset_index()[['Age', 'Appendix_Diameter', 'Migratory_Pain',  'RBC_Count', 'RBC_in_Urine', 'Peritonitis']].replace(\n    'no appendicitis', 'healthy'\n    ).replace(\n    '+', 'low'\n    ).replace(\n    '++', 'medium'\n    ).replace(\n    '+++', 'high'\n    )#.to_csv('app_all.csv')\n\ndata['RBC_in_Urine'] = data['RBC_in_Urine'].replace(\n    'no', 'none'\n    )\ndata.to_csv('app_all.csv')\n\n\npd.read_csv('/Users/gabehope/Downloads/app_data.csv')\n\n\n\n\n\n\n\n\nAge\nBMI\nSex\nHeight\nWeight\nLength_of_Stay\nManagement\nSeverity\nDiagnosis_Presumptive\nDiagnosis\n...\nUnnamed: 59\nUnnamed: 60\nUnnamed: 61\nUnnamed: 62\nUnnamed: 63\nUnnamed: 64\nUnnamed: 65\nUnnamed: 66\nUnnamed: 67\nUnnamed: 68\n\n\n\n\n0\n12.68\n16.90\nfemale\n148.0\n37.0\n3.0\nconservative\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n14.10\n31.90\nmale\n147.0\n69.5\n2.0\nconservative\nuncomplicated\nappendicitis\nno appendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n14.14\n23.30\nfemale\n163.0\n62.0\n4.0\nconservative\nuncomplicated\nappendicitis\nno appendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n16.37\n20.60\nfemale\n165.0\n56.0\n3.0\nconservative\nuncomplicated\nappendicitis\nno appendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n11.08\n16.90\nfemale\n163.0\n45.0\n3.0\nconservative\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n777\n12.41\n25.25\nfemale\n166.5\n70.0\n4.0\nprimary surgical\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n778\n17.09\n20.43\nfemale\n158.0\n51.0\n6.0\nsecondary surgical\ncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n779\n14.99\n19.91\nfemale\n152.0\n46.0\n4.0\nprimary surgical\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n780\n7.20\n14.30\nmale\n129.3\n23.9\n5.0\nprimary surgical\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n781\n11.51\n18.17\nmale\n146.5\n39.0\n4.0\nprimary surgical\nuncomplicated\nappendicitis\nappendicitis\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n782 rows × 69 columns\n\n\n\n\nndata = pd.read_csv('/Users/gabehope/Downloads/app_data.csv')[['Age', 'Appendix_Diameter', 'Height', 'Weight',  'RBC_Count', 'Body_Temperature', 'WBC_Count', ]].dropna().loc[[627, 464, 600, 217, 187, 185, 389, 603, 667, 180, 341, 704, 105, 502, 65, 324, 20]].sample(frac=1).reset_index()[['Age', 'Appendix_Diameter', 'Height', 'Weight',  'RBC_Count', 'Body_Temperature', 'WBC_Count', ]].to_csv('app_numeric.csv')\n\n\nndata = pd.read_csv('app_numeric.csv')\n\n\ndel ndata['Unnamed: 0']\n\n\nndata.values\n\nimport numpy as np\n\ndef matrix_to_latex(matrix):\n    \"\"\"Converts a NumPy matrix to LaTeX.\"\"\"\n\n    latex_str = \"\\\\begin{pmatrix}\\n\"\n    for row in matrix:\n        latex_str += \" & \".join(map(str, row)) + \"\\\\\\\\\\n\"\n    latex_str += \"\\\\end{pmatrix}\"\n    return latex_str\n\nprint(matrix_to_latex(ndata.values))\n\n\\begin{pmatrix}\n16.66 & 9.0 & 174.0 & 65.0 & 5.31 & 36.6 & 6.6\\\\\n10.74 & 9.0 & 146.0 & 57.5 & 5.66 & 37.3 & 10.2\\\\\n9.04 & 5.3 & 134.0 & 29.4 & 4.92 & 36.0 & 5.1\\\\\n10.75 & 5.0 & 155.0 & 54.5 & 4.79 & 37.7 & 10.3\\\\\n7.3 & 6.2 & 123.0 & 23.5 & 4.64 & 37.4 & 21.1\\\\\n5.11 & 7.0 & 116.0 & 22.0 & 4.55 & 40.2 & 19.4\\\\\n14.36 & 9.0 & 163.0 & 50.0 & 4.84 & 37.5 & 14.3\\\\\n9.61 & 9.0 & 140.0 & 29.2 & 5.18 & 38.7 & 14.3\\\\\n15.83 & 12.0 & 153.0 & 59.0 & 4.33 & 36.7 & 12.8\\\\\n9.58 & 7.0 & 132.0 & 24.7 & 5.04 & 38.4 & 13.5\\\\\n10.37 & 5.5 & 156.0 & 39.0 & 4.8 & 37.4 & 5.6\\\\\n14.52 & 4.5 & 181.0 & 55.0 & 4.9 & 37.0 & 9.0\\\\\n12.41 & 3.7 & 150.5 & 42.5 & 5.49 & 37.2 & 9.1\\\\\n6.67 & 3.5 & 124.0 & 38.5 & 5.27 & 39.6 & 16.8\\\\\n15.21 & 8.5 & 155.0 & 85.0 & 4.62 & 36.8 & 12.4\\\\\n12.43 & 12.0 & 157.0 & 46.0 & 4.62 & 37.1 & 16.4\\\\\n10.51 & 9.0 & 134.5 & 27.0 & 5.03 & 37.4 & 12.8\\\\\n\\end{pmatrix}\n\n\n\\[\\\\begin{pmatrix}\\n16.66 & 9.0 & 174.0 & 65.0 & 5.31 & 36.6 & 6.6\\\\\\\\\\n10.74 & 9.0 & 146.0 & 57.5 & 5.66 & 37.3 & 10.2\\\\\\\\\\n9.04 & 5.3 & 134.0 & 29.4 & 4.92 & 36.0 & 5.1\\\\\\\\\\n10.75 & 5.0 & 155.0 & 54.5 & 4.79 & 37.7 & 10.3\\\\\\\\\\n7.3 & 6.2 & 123.0 & 23.5 & 4.64 & 37.4 & 21.1\\\\\\\\\\n5.11 & 7.0 & 116.0 & 22.0 & 4.55 & 40.2 & 19.4\\\\\\\\\\n14.36 & 9.0 & 163.0 & 50.0 & 4.84 & 37.5 & 14.3\\\\\\\\\\n9.61 & 9.0 & 140.0 & 29.2 & 5.18 & 38.7 & 14.3\\\\\\\\\\n15.83 & 12.0 & 153.0 & 59.0 & 4.33 & 36.7 & 12.8\\\\\\\\\\n9.58 & 7.0 & 132.0 & 24.7 & 5.04 & 38.4 & 13.5\\\\\\\\\\n10.37 & 5.5 & 156.0 & 39.0 & 4.8 & 37.4 & 5.6\\\\\\\\\\n14.52 & 4.5 & 181.0 & 55.0 & 4.9 & 37.0 & 9.0\\\\\\\\\\n12.41 & 3.7 & 150.5 & 42.5 & 5.49 & 37.2 & 9.1\\\\\\\\\\n6.67 & 3.5 & 124.0 & 38.5 & 5.27 & 39.6 & 16.8\\\\\\\\\\n15.21 & 8.5 & 155.0 & 85.0 & 4.62 & 36.8 & 12.4\\\\\\\\\\n12.43 & 12.0 & 157.0 & 46.0 & 4.62 & 37.1 & 16.4\\\\\\\\\\n10.51 & 9.0 & 134.5 & 27.0 & 5.03 & 37.4 & 12.8\\\\\\\\\\n\\\\end{pmatrix}\\]\nndata\n\nX = ndata.values\n\n\nX[7]\n\narray([  9.61,   9.  , 140.  ,  29.2 ,   5.18,  38.7 ,  14.3 ])\n\n\n\nX[7].shape\n\n(7,)\n\n\n\nX[7][:, None]\n\n[[  9.61]\n [  9.  ]\n [140.  ]\n [ 29.2 ]\n [  5.18]\n [ 38.7 ]\n [ 14.3 ]]\n\n\n\nX[7][:, None].shape\n\n(7, 1)\n\n\n\nX[7][None, :]\n\narray([[  9.61,   9.  , 140.  ,  29.2 ,   5.18,  38.7 ,  14.3 ]])\n\n\n\nX[7][None, :].shape\n\n(1, 7)\n\n\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass Patient:\n    age: float\n    pain: bool\n    rbc_count: float\n    rbc_urine: int"
  },
  {
    "objectID": "lecture1-background/notes.html#tabluar-data",
    "href": "lecture1-background/notes.html#tabluar-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Tabluar data",
    "text": "Tabluar data\nIf you’ve worked with Excel, SQL or even many physical records, you’re likely familiar with the concept of tabular data. Tabular data essentially refers to any data that we can easily represent in a table format. As this could mean a few different things, when we talk about tabular data in this class, we’ll specifically be refering to data in what is often called the tidy data format.\n\nTidy data\nWe’ll say that data is in in the “tidy” format if each observation is represented with a single row of our table and each feature is represented with a single column. An observation is an entity, such as a patient in a hospital, that we may want to make preditions about. A feature (or variable) represents some measureable property that every observation has. For the patients in our example the set of features might correspond to measurements like the heart rate, blood pressure or oxygen level of each patient, as well as properties like the patient’s name, age and gender. This organizaton makes it easy to find any given measurement for any given patient (just use the row and column coordinates in the table). For tabular data we’ll assume that the ordering of both rows and columns in our table has no special significance, so could change the ordering of either without altering what our table represents.\n\n\n\nAppendicitis dataset in the “tidy” format\n\n\nNote that how we organize a set of measurements into observations and features isn’t nessecarily fixed, and might change depending on our goals. For example, if our goal is to predict whether a patient has some given underlying condition, we might have one observation per patient. Alternatively, if a given patient visits the hospital several times and our goal is to predict whether a patient will be admitted overnight for a given visit, we might have one observation per visit.\n\n\nVariable types\nThe idea of tidy data should also be intuitive to programmers familiar with the object-oriented programming paradigm. There we organize our data in objects (observations) where each object has a common set of properies (features). Just as in object oriented programming, its important to consider the type of each feature, which defines what values it can take and what operations we can perform on it. We’ll consider a few useful general feature types and how we might map them to concrete types in code.\n\n\n\n\n\n\nQuantitative features\nQuantitative features are simply numbers like our patient’s blood pressure, heart rate etc. We can further subdivide this category into integer features, that we’d encode as integer types (e.g. int, uint) and real-valued features that we’d encode as floating point values (e.g. float).\n\n\nCategorical features\nCategorical features are features that can only take a few distinct, non-numerical values. For example this could be the department that a patient was admitted to ({ER, Neurology, Obstetrics, Dermatology, etc.}) or the patient’s gender identity ({female, male, non-binary, etc.}). These values might be best encoded through an enum type, but are typically encoded as either a string or int in practice.\nBoolean features are a special case of categorical features with only two possible values. They could be encoded as an bool or int type.\n\n\nOrdinal features\nOrdinal features are something of a middle-ground between quantitative and categorical features. They represent features where the possible values have a well-definded ordering (like numbers), but no concept of distance (like categorical values). For example our patients might be assigned a priority level that takes the values low, medium or high. In this case it’s well-defined to say that low &lt; medium &lt; high, but asking for the result of high - low is not defined. We might encode these features as int types as well.\n\n\nGeneral “nomial” features\nNon-numerical features that don’t have a fixed set of possible values is what we’d call nominal or unstructured data. While it’s common in many contexts to see such values within tabluar data, for neural networks we’ll generally treat them as their own data type, outside of the tidy, tablular data paradigm."
  },
  {
    "objectID": "lecture1-background/notes.html#matrix-data",
    "href": "lecture1-background/notes.html#matrix-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Matrix data",
    "text": "Matrix data\nWhile tables are useful for reading and understanding datasets, as we’ve seen, we want to think about neural networks as mathamatical functions of our data. Therefore, in order to work with them we’ll usually need to abstract away from the specifics of our data into a more convenient mathamatical form. In particular, as tablular data has 2 dimensions (observation rows and feature columns), the natural way to think about a dataset mathamatically is as a matrix. By convention, we’ll usually think about our data as an \\(N \\times d\\) matrix, where we have \\(N\\) observations and \\(d\\) features and we’ll typically call this matrix \\(\\mathbf{X}\\).\n\n\n\n\n\nUnder this convention, the first index into our matrix will denote the row or observation and the second, the column or feature. In code, we’ll use numpy arrays to represent matrices, which work similarly.\n\n\n\n\n\nWe can also think about each row as being a vector of length \\(d\\) representing a single observation. So we’ll say that each observation \\(\\mathbf{x}_i\\) is a \\(d\\)-dimension vector \\(\\mathbf{x}_i \\in \\mathbb{R}^d\\). This is why so far we’ve used the bold (\\(\\mathbf{x}\\)) notation.\nHere it’s worth pointing out a bit of a notational quirk that can get a little confusing. A vector is a 1-dimensional object; we can think of it as a 1-d array in code. However, when we do mathamatical operations involving both matrices and vectors, it’s often convenient to treat a vector as either a \\(d \\times 1\\) matrix, also known as a column vector, or as a \\(1 \\times d\\) matrix (row vector).\n\n\n\n\n\nBy convention, in mathamatical expressions we’ll assume that by default, any vector we refer to will be treated as a column vector, even if the vector was a row in a matrix. If we want to treat a vector as a row vector, we will explicitly transpose it. This can get confusing so it’s worth keeping this in your head as we move forward. Under this convention, we might think about our matrix of all observations as:\n\\[\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\mathbf{x}_3^T \\\\ \\vdots  \\end{bmatrix} = \\begin{bmatrix} x_{11} & x_{12} & x_{13} & \\dots \\\\ x_{21} & x_{22} & x_{23} & \\dots \\\\ x_{31} & x_{32} & x_{33} & \\dots\\\\ \\vdots & \\vdots & \\vdots & \\ddots  \\end{bmatrix}\\]\nThis will become relevant when reading mathematical expressions of matrices and vectors in this class. For example, consider the two vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\).\n\\[\n\\mathbf{a} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3\\\\ \\end{bmatrix},\\\\ \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 4 \\\\ 2\\\\ \\end{bmatrix}, \\\\\n\\]\nWe can write the dot product as:\n\\[\n\\mathbf{a}^T \\mathbf{b} = \\big{[} 2 \\ \\ \\ 1 \\ \\ \\ \\  3 \\big{]} \\begin{matrix} \\begin{bmatrix} 1 \\\\ 4 \\\\ 2\\\\ \\end{bmatrix} \\\\ \\\\ \\\\ \\end{matrix} =12\n\\]\nSimilarly we can write an outer product as:\n\\[\n\\mathbf{a} \\mathbf{b}^T =  \\begin{matrix} \\begin{bmatrix} 2 \\\\ 1 \\\\ 3\\\\ \\end{bmatrix} \\\\ \\\\ \\\\ \\end{matrix} \\big{[} 1 \\ \\ \\ 4 \\ \\ \\ \\  2 \\big{]}  = \\begin{matrix} \\begin{bmatrix} 2 & 8 & 4 \\\\ 1 & 4 & 2 \\\\ 3 & 12 & 6 \\end{bmatrix}\\\\ \\\\ \\\\ \\end{matrix}\n\\]\n\nEncoding non-quantitative features\nYou might be wondering at this point: if we’re treating everything as matrices and vectors, how do deal with features that aren’t inherently real-valued numbers? Generally the approach will be to convert them into real numbers in some way.\nInteger features are straightforward; we can easily treat them as real numbers already and in code we can simply cast them. We’ll typically map ordinal features to the first few non-negative integers, e.g. \\(\\{\\text{none},\\ \\text{low},\\ \\text{medium},\\  \\text{high} \\} \\rightarrow \\{ 0, \\ 1, \\ 2, \\ 3 \\}\\). Boolean features are usually mapped to either \\(\\{0, 1\\}\\) or to \\(\\{-1, 1\\}\\). Finally categorical values are typically first mapped to a set of boolean values. If a categorical feature as \\(c\\) possible values, then it will be mapped to \\(c\\) new boolean variables, each indicating whether the original feature had that value. This is often called one-hot encoding.\n\nWe’ll talk (a lot) about unstructured text later in this course, so for now will just worry about categorical/ordinal features."
  },
  {
    "objectID": "lecture1-background/notes.html#label-types",
    "href": "lecture1-background/notes.html#label-types",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Label types",
    "text": "Label types\nFor our discussion of prediction problems, we’ll assume that the label that we want to predict is just a single value, which is why we’ve used the scalar notation \\(y\\).\nIf our labels are real numbers \\(y \\in \\mathbb{R}\\), e.g. if we’re trying to predict the number of hours a patient will stay in the hospital, then we’ll say that we have a regression problem.\n\n\n\n\n\nAlternatively, if our labels are categorical values, e.g. we’re trying to predict whether or not a patient has appendicitis, \\(y \\in \\{\\textit{healthy}, \\textit{appendicitis}\\}\\), then we’ll say that we have a classification problem.\n\n\n\n\n\nIf we have a full dataset of \\(N\\) observations and labels, we could refer to the collection of \\(N\\) labels as a vector \\(\\mathbf{y} \\in \\mathbb{R}^N\\)."
  },
  {
    "objectID": "lecture1-background/notes.html#other-types-of-data",
    "href": "lecture1-background/notes.html#other-types-of-data",
    "title": "Lecture 1: Introduction to Neural Networks",
    "section": "Other types of data",
    "text": "Other types of data\nWe’ll focus on tabular data for the first part of this course, but it’s far from the only type of data that we’ll consider. We won’t go into detail here about representing these types of data, we’ll leave that until we introduce the relevant neural network material.\n\nImage and field data\nImages are one of the most common inputs to neural networks for many real-world problems. A single image typically consists of thousands to millions of individual measurements making up the pixels of the image (each “pixel” represents the color or brightness of the image at a given location). In tabular data we generally assume each feature has a different interpretation and the order of the features isn’t inherently meaningful. In image data, our features all have the same interpretation (as pixels), and a specific configuration as a 2-dimensional grid.\nMore generally, we can think of image data as being a member of the larger category of field data. Field data refers to data where every point in a given space has a value or set of values associated with it. This includes image data (each pixel has a brightness or red, green and blue color values), as well as things like video (with a third, time dimension), audio (with only a time dimension), 3-d medical scans (with x, y and z spatial dimensions) and climate data (latitude and longitude coordinates) among others.\n\n\nText and sequence data\nText is another widely used application of neural networks. In this case our observation could be a sentence or paragraph of text. More generally, we can frame this as a variable-length sequence of categorical features (or tokens). Beyond text, we can also frame things like genetic data in this way.\n\n\nGraph/network data\nIn many cases our data might be defined not just by the features of each observation, but also by the relationships between observations. In this case we have what we’d call graph or network data. A classic example would be social networks, where the relationships between people (e.g. whether or not they are friends) is of upmost importance. Other examples include things like protein structures, where the configuration of atoms in a molecule is as important as the types of the atoms.\n\n\nMulti-modal data\nIn many cases it’s also common to consider more than one type of data at once. For example, a diagnosis system might take in an x-ray image, text of doctor notes and tabular test result data as inputs to its prediction function. We this multi-modal data, as it has multiple different types or modes in one (image, text and tabluar)."
  }
]