{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uffeRdEKt5-S"
   },
   "source": [
    "# **Homework 10:** Language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "\n",
    "Please list anyone you discussed or collaborated on this assignment with below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST COLLABORATORS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course feedback\n",
    "\n",
    "Please submit this week's course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiPdgtSyiEeA"
   },
   "outputs": [],
   "source": [
    "# Uncomment for Colab\n",
    "# !yes | pip uninstall torch\n",
    "# !yes | pip uninstall torchtext\n",
    "# !yes | pip install torch==2.3.0\n",
    "# !yes | pip install torchtext==0.18\n",
    "# !wget https://cs152.github.io/assignments/homeworks/Homework%2010/hw10_support.py\n",
    "\n",
    "# Run me to get the data (should be included!)\n",
    "#!wget https://gist.githubusercontent.com/gabehope/286a065f3b7cc081af5f3e8d71502e63/raw/d31a233d8ade78ac5cbd8ecfa45f184017812c52/dataset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US5WseY1tm2D"
   },
   "source": [
    "This cell make take some time to run.\n",
    "\n",
    "**If you have issues running this cell on your own computer it may be an issue with the torch & torchtext versions, see [here](https://stackoverflow.com/questions/78933082/attributeerror-when-importing-torchtext-symbol-not-found-in-libc10-dylib)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTbMXq97fhVA"
   },
   "outputs": [],
   "source": [
    "from hw10_support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwopOBRYaXs2"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(data, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=lambda x: x)\n",
    "valid_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ4QG8DKczpC"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nKBnzVJdwu5"
   },
   "outputs": [],
   "source": [
    "def convertToText(x, vocab):\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Convert the first batch of validation data here\n",
    "x, y = next(iter(valid_loader))\n",
    "text = convertToText(x, data.eng_vocab)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBkjlsPyirKc"
   },
   "outputs": [],
   "source": [
    "print('Input 0: ', convertToText(x, data.eng_vocab)[0])\n",
    "print('Target 0: ', convertToText(y, data.eng_vocab)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu9kN-e20_-q"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK_qAQyjwGD3"
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "  def __init__(self, embedding_dimension):\n",
    "      super().__init__() # Needed for PyTorch!\n",
    "\n",
    "      # YOUR CODE HERE\n",
    "      self.embedding_matrix =\n",
    "\n",
    "  def forward(self, x):\n",
    "      # YOUR CODE HERE\n",
    "\n",
    "# Test output shape\n",
    "x, y = next(iter(valid_loader))\n",
    "assert Embedding(64)(x).shape == torch.Size([256, 26, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fQOPzE38U76"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKF-W9Pw4UQS"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-4zSuUL-H-P"
   },
   "outputs": [],
   "source": [
    "class RNNGenerator(nn.Module):\n",
    "  def __init__(self, vocab_size=1000, dimension=128):\n",
    "    super().__init__()\n",
    "    self.embedding = Embedding(dimension)\n",
    "    self.block1 = RNN(dimension, dimension)\n",
    "    self.block2 = RNN(dimension, dimension)\n",
    "    self.block3 = RNN(dimension, dimension)\n",
    "    self.output = nn.Linear(dimension, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.embedding(x)\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    x = self.block3(x)\n",
    "    return self.output(x)\n",
    "\n",
    "model = RNNGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiMtctdula2H"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CqEgVcai5Y5"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # Compute the softmax for each entry in a tensor\n",
    "    ex = torch.exp(x)\n",
    "    sum_ex = torch.sum(ex, dim=-1, keepdims=True)\n",
    "    return ex / sum_ex\n",
    "\n",
    "def autoregressive_loss(f, y):\n",
    "      # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUqLYTR6v596"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kohRdG5xwQw-"
   },
   "outputs": [],
   "source": [
    "def autoregressive_loss(f, y):\n",
    "      # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsLrZu2LUjCz"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2Z-ahdBdtPL"
   },
   "outputs": [],
   "source": [
    "# Use the GPUs if they are available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Do model creation here so that the model is recreated each time the cell is run\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Create the optimizer, just like we have with the built-in optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "# Information for plots\n",
    "train_losses = []\n",
    "\n",
    "for iteration, (train_X, train_Y) in enumerate(tqdm.tqdm(train_loader)):\n",
    "    # Grab the batch of data and send it to the correct device\n",
    "    train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
    "\n",
    "    # Compute the output, loss, and gradient and take a step of gradient descent\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    loss =\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    if iteration > 100:\n",
    "      break\n",
    "\n",
    "\n",
    "# Plot the loss over the first 100 iterations\n",
    "plt.plot(train_losses)\n",
    "plt.title('Loss vs. Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ib9yMQLIVyoC"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXTxTCp3W6gj"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BYM3jJWfv10"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        # Add any additional sub-modules here\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Computes the forward pass of an RNN\n",
    "\n",
    "        Inputs:\n",
    "            x: tensor (float), An N x L x D tensor of input data\n",
    "\n",
    "        Returns:\n",
    "            h: tensor (float), An N x L x H tensor of transformed features\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "# Create a model\n",
    "model = RNNGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsZOfXDqXpS-"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DG6IWV-Jd_9l"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def sample_categorical(probs):\n",
    "  assert torch.all(torch.isclose(p.sum(dim=-1), torch.tensor(1.)))\n",
    "  return torch.distributions.Categorical(probs=probs).sample()\n",
    "\n",
    "# 4 x 3 matrix of probabilities (each row sums to 1.)\n",
    "p = torch.tensor([[0.3, 0.2, 0.5],\n",
    "                  [0.0, 0.9, 0.1],\n",
    "                  [0.9, 0.0, 0.1],\n",
    "                  [0.3, 0.3, 0.4]])\n",
    "\n",
    "# Length 4 vector of samples\n",
    "print(sample_categorical(p))\n",
    "\n",
    "# 2 x 2 x 3 matrix of probabilities (each final dimension sums to 1.)\n",
    "p = torch.tensor([\n",
    "                  [\n",
    "                    [0.3, 0.2, 0.5],\n",
    "                    [0.0, 0.9, 0.1]],\n",
    "                  [\n",
    "                    [0.9, 0.0, 0.1],\n",
    "                    [0.3, 0.3, 0.4]\n",
    "                  ]\n",
    "                  ])\n",
    "\n",
    "# 2x2 matrix of samples\n",
    "print(sample_categorical(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_ZvIucjcEXg"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLlrCG9_X8Hg"
   },
   "outputs": [],
   "source": [
    "def sample(model, data, batch_size=1, max_length=50):\n",
    "  model.eval()\n",
    "\n",
    "  # Start with an N x 1 matrix where each entry is just the <start> token.\n",
    "  # After the first iteration this should be N x 2, then N x 3 ... until N x L.\n",
    "  sample = torch.ones((batch_size, 1)).int().to(device)\n",
    "  # YOUR CODE HERE\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "# Test sampling\n",
    "sample_sentence = sample(model, data)\n",
    "print('Tokens:', sample_sentence)\n",
    "print('Text:', convertToText(sample_sentence, data.eng_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QntmwrN10CTF"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEDr0Rnoda_t"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.query_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.key_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.value_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.d = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48sRBr8N5ftR"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbMo7t9V5FZB"
   },
   "outputs": [],
   "source": [
    "class MaskedAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.query_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.key_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.value_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.d = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdZH-pC9rgl0"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhhSUQof70pB"
   },
   "outputs": [],
   "source": [
    "class MaskedMultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.query_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.key_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.value_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.d = hidden_size // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkA7eu0vs-dT"
   },
   "source": [
    "There are no more questions in this homework, but if you'd like to try out training an actual language model using the code you wrote, feel free to experiment with the implementation below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIot_yRZ7P1w"
   },
   "outputs": [],
   "source": [
    "epsilon = 1e-7\n",
    "class LayerNorm(nn.Module):\n",
    "    '''\n",
    "        The same LayerNorm implementation we saw before.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xmean = x.mean(dim=(-1, -2), keepdims=True)\n",
    "        xvar = x.var(dim=(-1, -2), keepdims=True)\n",
    "        return (x - xmean) / torch.sqrt(xvar + epsilon)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''\n",
    "        A layer to add positional encodings to the input.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        pos = torch.arange(x.shape[-2]).unsqueeze(1)\n",
    "        i = torch.arange(x.shape[-1] // 2).unsqueeze(0)\n",
    "        embedding = torch.zeros_like(x)\n",
    "        embedding[..., ::2] = torch.sin(pos / 10000. ** (2 * i / x.shape[-1]))\n",
    "        embedding[..., 1::2] = torch.cos(pos / 10000. ** (2 * i / x.shape[-1]))\n",
    "        return x + embedding\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    '''\n",
    "        A block of a transformer decoder.\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.attention = MaskedMultiheadAttention(input_size, hidden_size, num_heads)\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.ln1 = LayerNorm()\n",
    "        self.ln2 = LayerNorm()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln1(self.attention(x) + x)\n",
    "        x = self.ln2(self.linear2(self.activation(self.linear1(x))) + x)\n",
    "        return x\n",
    "\n",
    "class TransformerGenerator(nn.Module):\n",
    "  '''\n",
    "      A full transformer decoder model.\n",
    "  '''\n",
    "  def __init__(self, vocab_size=1000, dimension=128, num_heads=8):\n",
    "    super().__init__()\n",
    "    self.embedding = Embedding(dimension)\n",
    "    self.positional_encoding = PositionalEncoding()\n",
    "    self.block1 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n",
    "    self.block2 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n",
    "    self.block3 = TransformerBlock(dimension, dimension, num_heads=num_heads)\n",
    "    self.output = nn.Linear(dimension, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.embedding(x)\n",
    "    x = self.positional_encoding(x)\n",
    "    x = self.block1(x)\n",
    "    x = self.block2(x)\n",
    "    x = self.block3(x)\n",
    "    return self.output(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsjDYrMusPOu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the GPUs if they are available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using '{device}' device.\")\n",
    "\n",
    "# Mini-Batch SGD hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "def gradient_descent(model, train_loader, valid_loader, optimizer=Adam, learning_rate=0.001, criterion=nn.CrossEntropyLoss(), num_epochs=10, batch_size=256):\n",
    "\n",
    "    # Do model creation here so that the model is recreated each time the cell is run\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    t = 0\n",
    "    # Create the optimizer, just like we have with the built-in optimizer\n",
    "    opt = optimizer(model.parameters(), learning_rate)\n",
    "\n",
    "    # A master bar for fancy output progress\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    # Information for plots\n",
    "    mb.names = [\"Train Loss\", \"Valid Loss\"]\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in mb:\n",
    "\n",
    "        #\n",
    "        # Training\n",
    "        #\n",
    "        model.train()\n",
    "\n",
    "        train_N = len(train_loader.dataset)\n",
    "        num_train_batches = len(train_loader)\n",
    "        train_dataiterator = iter(train_loader)\n",
    "\n",
    "        train_loss_mean = 0\n",
    "\n",
    "        for batch in progress_bar(range(num_train_batches), parent=mb):\n",
    "\n",
    "            # Grab the batch of data and send it to the correct device\n",
    "            train_X, train_Y = next(train_dataiterator)\n",
    "            train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
    "\n",
    "\n",
    "            # Compute the output\n",
    "            train_output = model(train_X)\n",
    "\n",
    "            # Compute loss\n",
    "            train_loss = criterion(train_output, train_Y)\n",
    "\n",
    "            num_in_batch = len(train_Y)\n",
    "            tloss = train_loss.item() * num_in_batch / train_N\n",
    "            train_loss_mean += tloss\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            # Compute gradient\n",
    "            model.zero_grad()\n",
    "            train_loss.backward()\n",
    "\n",
    "            # Take a step of gradient descent\n",
    "            t += 1\n",
    "            with torch.no_grad():\n",
    "                opt.step()\n",
    "\n",
    "        #\n",
    "        # Validation\n",
    "        #\n",
    "        model.eval()\n",
    "\n",
    "        valid_N = len(valid_loader.dataset)\n",
    "        num_valid_batches = len(valid_loader)\n",
    "\n",
    "        valid_loss_mean = 0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # valid_loader is probably just one large batch, so not using progress bar\n",
    "            for valid_X, valid_Y in valid_loader:\n",
    "\n",
    "                valid_X, valid_Y = valid_X.to(device), valid_Y.to(device)\n",
    "\n",
    "                valid_output = model(valid_X)\n",
    "\n",
    "                valid_loss = criterion(valid_output, valid_Y)\n",
    "\n",
    "                num_in_batch = len(valid_Y)\n",
    "                vloss = valid_loss.item() * num_in_batch / valid_N\n",
    "                valid_loss_mean += vloss\n",
    "                valid_losses.append(valid_loss.item())\n",
    "\n",
    "                # Convert network output into predictions (one-hot -> number)\n",
    "                predictions = valid_output.argmax(-1)\n",
    "\n",
    "                # Sum up total number that were correct\n",
    "                valid_correct += (predictions == valid_Y).type(torch.float).sum().item()\n",
    "                valid_total += torch.ones_like(predictions).type(torch.float).sum().item()\n",
    "\n",
    "        valid_accuracy = 100 * (valid_correct / valid_total)\n",
    "\n",
    "        # Report information\n",
    "        tloss = f\"Train Loss = {train_loss_mean:.4f}\"\n",
    "        vloss = f\"Valid Loss = {valid_loss_mean:.4f}\"\n",
    "        vaccu = f\"Valid Accuracy = {(valid_accuracy):>0.1f}%\"\n",
    "        mb.write(f\"[{epoch+1:>2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")\n",
    "\n",
    "        # Update plot data\n",
    "        max_loss = max(max(train_losses), max(valid_losses))\n",
    "        min_loss = min(min(train_losses), min(valid_losses))\n",
    "\n",
    "        x_margin = 0.2\n",
    "        x_bounds = [0 - x_margin, num_epochs + x_margin]\n",
    "\n",
    "        y_margin = 0.1\n",
    "        y_bounds = [min_loss - y_margin, max_loss + y_margin]\n",
    "\n",
    "        valid_Xaxis = torch.linspace(0, epoch + 1, len(train_losses))\n",
    "        valid_xaxis = torch.linspace(1, epoch + 1, len(valid_losses))\n",
    "        graph_data = [[valid_Xaxis, train_losses], [valid_xaxis, valid_losses]]\n",
    "\n",
    "        mb.update_graph(graph_data, x_bounds, y_bounds)\n",
    "\n",
    "    print(f\"[{epoch+1:>2}/{num_epochs}] {tloss}; {vloss}; {vaccu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2RPeR5MsfJu"
   },
   "outputs": [],
   "source": [
    "# Test out the model!\n",
    "model = TransformerGenerator()\n",
    "gradient_descent(model, train_loader, valid_loader, criterion=autoregressive_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
