<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.319">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CS 152: Neural Networks - Lecture 3: Logistic regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS 152: Neural Networks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../calendar/calendar.html" rel="" target="">
 <span class="menu-text">Calendar</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/repositories" rel="" target="">
 <span class="menu-text">Homeworks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://harveymuddcollege.instructure.com/courses/615/" rel="" target="">
 <span class="menu-text">Canvas</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/" rel="" target="">
 <span class="menu-text">Github</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#classification" id="toc-classification" class="nav-link active" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
  <li><a href="#categorical-outputs" id="toc-categorical-outputs" class="nav-link" data-scroll-target="#categorical-outputs">Categorical outputs</a></li>
  <li><a href="#binary-outputs" id="toc-binary-outputs" class="nav-link" data-scroll-target="#binary-outputs">Binary outputs</a></li>
  <li><a href="#visualizing-categorical-functions" id="toc-visualizing-categorical-functions" class="nav-link" data-scroll-target="#visualizing-categorical-functions">Visualizing categorical functions</a></li>
  <li><a href="#visualizing-categorical-functions-1" id="toc-visualizing-categorical-functions-1" class="nav-link" data-scroll-target="#visualizing-categorical-functions-1">Visualizing categorical functions</a></li>
  <li><a href="#visualizing-categorical-functions-2" id="toc-visualizing-categorical-functions-2" class="nav-link" data-scroll-target="#visualizing-categorical-functions-2">Visualizing categorical functions</a></li>
  <li><a href="#making-binary-predictions" id="toc-making-binary-predictions" class="nav-link" data-scroll-target="#making-binary-predictions">Making binary predictions</a></li>
  <li><a href="#making-binary-predictions-1" id="toc-making-binary-predictions-1" class="nav-link" data-scroll-target="#making-binary-predictions-1">Making binary predictions</a></li>
  <li><a href="#making-binary-predictions-2" id="toc-making-binary-predictions-2" class="nav-link" data-scroll-target="#making-binary-predictions-2">Making binary predictions</a></li>
  <li><a href="#making-binary-predictions-3" id="toc-making-binary-predictions-3" class="nav-link" data-scroll-target="#making-binary-predictions-3">Making binary predictions</a></li>
  <li><a href="#making-binary-predictions-4" id="toc-making-binary-predictions-4" class="nav-link" data-scroll-target="#making-binary-predictions-4">Making binary predictions</a></li>
  <li><a href="#descision-boundaries" id="toc-descision-boundaries" class="nav-link" data-scroll-target="#descision-boundaries">Descision boundaries</a></li>
  <li><a href="#descision-boundaries-1" id="toc-descision-boundaries-1" class="nav-link" data-scroll-target="#descision-boundaries-1">Descision boundaries</a></li>
  <li><a href="#measuring-error" id="toc-measuring-error" class="nav-link" data-scroll-target="#measuring-error">Measuring error</a></li>
  </ul></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#the-bernoulli-distribution" id="toc-the-bernoulli-distribution" class="nav-link" data-scroll-target="#the-bernoulli-distribution">The Bernoulli distribution</a></li>
  <li><a href="#a-probabilistic-model-for-binary-classification" id="toc-a-probabilistic-model-for-binary-classification" class="nav-link" data-scroll-target="#a-probabilistic-model-for-binary-classification">A probabilistic model for binary classification</a></li>
  <li><a href="#sigmoid-function" id="toc-sigmoid-function" class="nav-link" data-scroll-target="#sigmoid-function">Sigmoid function</a></li>
  <li><a href="#sigmoid-function-1" id="toc-sigmoid-function-1" class="nav-link" data-scroll-target="#sigmoid-function-1">Sigmoid function</a></li>
  <li><a href="#a-probabilistic-model-for-binary-classification-1" id="toc-a-probabilistic-model-for-binary-classification-1" class="nav-link" data-scroll-target="#a-probabilistic-model-for-binary-classification-1">A probabilistic model for binary classification</a></li>
  <li><a href="#a-probabilistic-model-for-binary-classification-2" id="toc-a-probabilistic-model-for-binary-classification-2" class="nav-link" data-scroll-target="#a-probabilistic-model-for-binary-classification-2">A probabilistic model for binary classification</a></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">Maximum likelihood estimation</a></li>
  <li><a href="#maximum-likelihood-estimation-1" id="toc-maximum-likelihood-estimation-1" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-1">Maximum likelihood estimation</a></li>
  <li><a href="#maximum-likelihood-estimation-2" id="toc-maximum-likelihood-estimation-2" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-2">Maximum likelihood estimation</a></li>
  <li><a href="#comparing-loss-functions" id="toc-comparing-loss-functions" class="nav-link" data-scroll-target="#comparing-loss-functions">Comparing loss functions</a></li>
  </ul></li>
  <li><a href="#multi-class-classification" id="toc-multi-class-classification" class="nav-link" data-scroll-target="#multi-class-classification">Multi-class classification</a>
  <ul class="collapse">
  <li><a href="#multi-class-prediction-functions" id="toc-multi-class-prediction-functions" class="nav-link" data-scroll-target="#multi-class-prediction-functions">Multi-class prediction functions</a></li>
  <li><a href="#multi-class-prediction-functions-1" id="toc-multi-class-prediction-functions-1" class="nav-link" data-scroll-target="#multi-class-prediction-functions-1">Multi-class prediction functions</a></li>
  <li><a href="#multi-class-prediction-functions-2" id="toc-multi-class-prediction-functions-2" class="nav-link" data-scroll-target="#multi-class-prediction-functions-2">Multi-class prediction functions</a></li>
  <li><a href="#multi-class-prediction-functions-3" id="toc-multi-class-prediction-functions-3" class="nav-link" data-scroll-target="#multi-class-prediction-functions-3">Multi-class prediction functions</a></li>
  <li><a href="#categorical-distribution" id="toc-categorical-distribution" class="nav-link" data-scroll-target="#categorical-distribution">Categorical distribution</a></li>
  <li><a href="#a-probabilistic-model-for-multi-class-classification" id="toc-a-probabilistic-model-for-multi-class-classification" class="nav-link" data-scroll-target="#a-probabilistic-model-for-multi-class-classification">A probabilistic model for multi-class classification</a></li>
  <li><a href="#softmax-function" id="toc-softmax-function" class="nav-link" data-scroll-target="#softmax-function">Softmax function</a></li>
  <li><a href="#a-probabilistic-model-for-multi-class-classification-1" id="toc-a-probabilistic-model-for-multi-class-classification-1" class="nav-link" data-scroll-target="#a-probabilistic-model-for-multi-class-classification-1">A probabilistic model for multi-class classification</a></li>
  <li><a href="#maximum-likelihood-estimation-3" id="toc-maximum-likelihood-estimation-3" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-3">Maximum likelihood estimation</a></li>
  <li><a href="#maximum-likelihood-estimation-4" id="toc-maximum-likelihood-estimation-4" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-4">Maximum likelihood estimation</a></li>
  </ul></li>
  <li><a href="#evaluating-models" id="toc-evaluating-models" class="nav-link" data-scroll-target="#evaluating-models">Evaluating models</a>
  <ul class="collapse">
  <li><a href="#training-and-test-datasets" id="toc-training-and-test-datasets" class="nav-link" data-scroll-target="#training-and-test-datasets">Training and test datasets</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 3: Logistic regression</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.17.3</span>

</pre>
</div>
</div>
<section id="classification" class="level1">
<h1>Classification</h1>
<section id="categorical-outputs" class="level2">
<h2 class="anchored" data-anchor-id="categorical-outputs">Categorical outputs</h2>
<p>In the last lecture we considered approximating functions of the form:</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in\mathbb{R}
\]</span></p>
<p>In many real-world problems, the output we want to model is not a continuous value, but a <em>categorical</em> value.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/catdogmouse.png" class="img-fluid figure-img" width="776"></p>
</figure>
</div>
</section>
<section id="binary-outputs" class="level2">
<h2 class="anchored" data-anchor-id="binary-outputs">Binary outputs</h2>
<p>In the simplest case there are two possible outputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/catdog.png" class="img-fluid figure-img" width="822"></p>
</figure>
</div>
<p>We use the set <span class="math inline">\(\{0, 1\}\)</span> to denote the possible outputs for a binary categorical function.</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in \{0, 1\}
\]</span></p>
<p>We might say that <span class="math inline">\(0 = \textbf{"cat"}\)</span> and <span class="math inline">\(1=\textbf{"dog"}\)</span>.</p>
<p>We call prediction of a categorical output <strong>classification</strong>.</p>
</section>
<section id="visualizing-categorical-functions" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-categorical-functions">Visualizing categorical functions</h2>
<p>Consider the fuel efficiency example from the previous lecture.</p>
<p><span class="math display">\[
\text{Input: } \mathbf{x}_i= \begin{bmatrix} \text{Weight} \\ \text{Horsepower} \\ \text{Displacement} \\ \text{0-60mph}  \end{bmatrix}, \quad \text{Output: } y_i = \begin{cases} 1: \text{Meets target } (MPG \geq 30) \\ 0:
\text{Fails to meet target } (MPG &lt; 30) \\  \end{cases}
\]</span></p>
<div class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-3-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="visualizing-categorical-functions-1" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-categorical-functions-1">Visualizing categorical functions</h2>
<p>With this new output definition our dataset will look like:</p>
<p><span class="math display">\[
\text{Honda Accord: } \begin{bmatrix} \text{Weight:} &amp; \text{2500 lbs} \\ \text{Horsepower:} &amp; \text{ 123 HP} \\ \text{Displacement:} &amp; \text{ 2.4 L} \\ \text{0-60mph:} &amp; \text{ 7.8 Sec} \end{bmatrix} \longrightarrow \text{1   (Meets target)}
\]</span></p>
<p><span class="math display">\[
\text{Dodge Aspen: } \begin{bmatrix} \text{Weight:} &amp; \text{3800 lbs} \\ \text{Horsepower:} &amp; \text{ 155 HP} \\ \text{Displacement:} &amp; \text{ 3.2 L} \\ \text{0-60mph:} &amp; \text{ 6.8 Sec} \end{bmatrix} \longrightarrow  \text{0   (Does not meet target)}
\]</span></p>
<p><span class="math display">\[
\vdots \quad \vdots
\]</span></p>
</section>
<section id="visualizing-categorical-functions-2" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-categorical-functions-2">Visualizing categorical functions</h2>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="making-binary-predictions" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions">Making binary predictions</h2>
<p>We could fit a linear regression model to our binary data, by simply treating the labels <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> as real-valued outputs.</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="making-binary-predictions-1" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions-1">Making binary predictions</h2>
<p>A more suitable prediction function would <em>only</em> output one of our two possible labels <span class="math inline">\(\{0, 1\}\)</span>. Using a <em>cutoff</em> (typically 0), as follows:</p>
<p><span class="math display">\[
f(\mathbf{x})=\mathbf{x}^T\mathbf{w} \quad \longrightarrow \quad f(\mathbf{x})=\begin{cases} 1\ \text{   if   }\ \mathbf{x}^T\mathbf{w} \geq 0 \\
0\ \text{   if   }\ \mathbf{x}^T\mathbf{w} &lt; 0\end{cases}
\]</span></p>
<p>We might also write this as:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \mathbb{I}(\mathbf{x}^T\mathbf{w} \geq 0)
\]</span></p>
<p>Where <span class="math inline">\(\mathbb{I}\)</span> is an <em>indicator function</em> that is simply <span class="math inline">\(1\)</span> if the boolean expression is true and <span class="math inline">\(0\)</span> otherwise.</p>
</section>
<section id="making-binary-predictions-2" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions-2">Making binary predictions</h2>
<p>This gives us a prediction function that looks like step function in 1 dimension:</p>
<div class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="making-binary-predictions-3" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions-3">Making binary predictions</h2>
<p>For our efficiency example, the binary prediction function can be written as:</p>
<p><span class="math display">\[
\text{Meets target} = f(\mathbf{x})=
\]</span></p>
<p><span class="math display">\[
\big((\text{weight})w_1 + (\text{horsepower})w_2 + (\text{displacement})w_3 + (\text{0-60mph})w_4 + b\big) \geq 0
\]</span></p>
<p>Or in matrix notation:</p>
<p><span class="math display">\[
f(\mathbf{x})= \left( \begin{bmatrix} \text{Weight} \\ \text{Horsepower} \\ \text{Displacement} \\ \text{0-60mph} \\ 1 \end{bmatrix} \cdot \begin{bmatrix} w_1 \\ w_2\\ w_3 \\ w_4\\ b\end{bmatrix} \geq  0\right)
\]</span></p>
<p>In this form we can see that the <em>sign</em> of each weight parameter determines whether the corresponding feature is more predictive of label <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span> and to what extent.</p>
</section>
<section id="making-binary-predictions-4" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions-4">Making binary predictions</h2>
<p>This has a geometric interpretation if we think of <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> as vectors. If the angle between <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> is in the range <span class="math inline">\([-\frac{\pi}{2}, \frac{\pi}{2}]\)</span> (or <span class="math inline">\([-90^o, 90^o]\)</span> in degrees), then the prediction will be <span class="math inline">\(1\)</span>.</p>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="descision-boundaries" class="level2">
<h2 class="anchored" data-anchor-id="descision-boundaries">Descision boundaries</h2>
<p>We can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.</p>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="descision-boundaries-1" class="level2">
<h2 class="anchored" data-anchor-id="descision-boundaries-1">Descision boundaries</h2>
<p>The <strong>decision boundary</strong> is the border between regions of the input space corresponding to each prediction. For a linear classification model the decision boundary is line or plane:</p>
<p><span class="math display">\[\mathbf{x}^T\mathbf{w}=0\]</span></p>
<div class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="measuring-error" class="level2">
<h2 class="anchored" data-anchor-id="measuring-error">Measuring error</h2>
<p>A natural measure for error for binary classifiers is <strong>accuracy</strong>. The <em>accuracy</em> of a prediction function is the fraction of observations where the prediction matches the true output:</p>
<p><span class="math display">\[
\textbf{Accuracy} = \frac{1}{N} \sum_{i=1}^N \mathbb{I}\big(f(\mathbf{x}_i) = y_i\big)
\]</span></p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>Model accuracy: 0.8291</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="logistic-regression" class="level1">
<h1>Logistic Regression</h1>
<section id="the-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-bernoulli-distribution">The Bernoulli distribution</h2>
<p>The <strong>Beroulli distribution</strong> is a distribution over binary outcomes (0 or 1). It is parameterized simply by <span class="math inline">\(q=p(y=1)\)</span></p>
<p><span class="math display">\[
p(y)=\begin{cases} q\quad\ \ \ \ \ \ \  \text{if }\ y=1\\
1-q\quad \text{if }\ y=0\\
\end{cases}\quad q\in[0,1],\ y\in\{0, 1\}
\]</span></p>
<p>We can also write this as:</p>
<p><span class="math display">\[
p(y) = q^y(1-q)^{1-y}
\]</span></p>
<p>The <em>log-probability</em> or <em>log-likelihood</em> is then:</p>
<p><span class="math display">\[
\log p(y) = y\log q + (1-y)\log(1-q)
\]</span></p>
</section>
<section id="a-probabilistic-model-for-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-binary-classification">A probabilistic model for binary classification</h2>
<p>Last lecture saw a probabilistic model for linear regression could be defined as:</p>
<p><span class="math display">\[
y_i \sim \mathcal{N}(\mathbf{x}^T\mathbf{w},\ \sigma^2)
\]</span></p>
<p>We’d ideally like to define a similar model for the case of binary outputs using the Bernoulli distribution. However we need to enforce that the Bernoulli parameter is in <span class="math inline">\([0,1]\)</span></p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{w}\notin [0, 1] \quad \longrightarrow \quad y_i \sim \mathbf{Bernoulli}(\mathbf{ q=? })\quad
\]</span></p>
<p>So we need a function that can map <span class="math inline">\(\mathbf{x}^T\mathbf{w}\)</span> to <span class="math inline">\([0,1]\)</span></p>
<p><span class="math display">\[
\textbf{Need }\ f(x):\ \mathbb{R} \longrightarrow [0,1]
\]</span></p>
<p><span class="math display">\[
\textbf{Input: } x \in \mathbb{R} \longrightarrow \textbf{Output: } y \in [0,1]
\]</span></p>
</section>
<section id="sigmoid-function" class="level2">
<h2 class="anchored" data-anchor-id="sigmoid-function">Sigmoid function</h2>
<p>The <strong>sigmoid</strong> (or logistic) function is a convenient choice</p>
<p><span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span></p>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="sigmoid-function-1" class="level2">
<h2 class="anchored" data-anchor-id="sigmoid-function-1">Sigmoid function</h2>
<p>The sigmoid function has some nice properties</p>
<p><span class="math display">\[
\sigma(0) = 0.5
\]</span></p>
<p><span class="math display">\[
1-\sigma(x) = \sigma(-x)
\]</span></p>
<p><span class="math display">\[
\frac{d}{dx}\sigma(x) = \sigma(x)\big(1-\sigma(x)\big)
\]</span></p>
<div class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="a-probabilistic-model-for-binary-classification-1" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-binary-classification-1">A probabilistic model for binary classification</h2>
<p>With the sigmoid function we can define our probabilistic model</p>
<p><span class="math display">\[
y_i \sim \mathbf{Bernoulli}\big(\mathbf{ \sigma(\mathbf{x}_i^T\mathbf{w} })\big)
\]</span></p>
<p><span class="math display">\[
p(y_i = 1) = \sigma(\mathbf{x}_i^T\mathbf{w}), \quad p(y_i=0)=1-\sigma(\mathbf{x}_i^T\mathbf{w})=\sigma(-\mathbf{x}_i^T\mathbf{w})
\]</span></p>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="a-probabilistic-model-for-binary-classification-2" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-binary-classification-2">A probabilistic model for binary classification</h2>
<p>We see that if we choose a probability cutoff of <span class="math inline">\(0.5\)</span>, our decision boundary doesn’t change!</p>
<p><span class="math display">\[
p(y_i=1)\geq 0.5 \quad \longrightarrow \quad \mathbf{x}^T\mathbf{w}\geq 0
\]</span></p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="maximum-likelihood-estimation" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation">Maximum likelihood estimation</h2>
<p>Let’s review how to find the parameters of a model using <strong>maximum likelihood estimation</strong></p>
<p><span class="math display">\[
\mathbf{w}^* = \underset{\mathbf{w}}{\text{argmax}} \ p(\mathbf{y} \mid \mathbf{X}, \mathbf{w}) =\underset{\mathbf{w}}{\text{argmax}} \ p(y_1,...,y_N \mid \mathbf{x}_1, ...,\mathbf{x}_N, \mathbf{w}) \]</span></p>
<p>Generally our model also assumes <em>conditional independence</em> across observations so:</p>
<p><span class="math display">\[
p(y_1,...,y_N \mid \mathbf{x}_1, ...,\mathbf{x}_N, \mathbf{w}) = \prod_{i=1}^N p(y_i\mid \mathbf{x}_i, \mathbf{w})
\]</span></p>
</section>
<section id="maximum-likelihood-estimation-1" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-1">Maximum likelihood estimation</h2>
<p>For convenience, it is typical to frame the optimal value in terms of the <em>negative log-likelihood</em> rather than the likelihood, but the two are equivalent.</p>
<p><span class="math display">\[
\underset{\mathbf{w}}{\text{argmax}} \prod_{i=1}^N p(y_i\mid \mathbf{x}_i, \mathbf{w}) = \underset{\mathbf{w}}{\text{argmin}} - \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{w}) = \textbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y})
\]</span></p>
<p>We see that the negative log-likelihood is a natural <em>loss function</em> to optimize to find <span class="math inline">\(\mathbf{w}^*\)</span>.</p>
<p><span class="math display">\[
\textbf{Loss}(\mathbf{w}) =\textbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y})=- \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{w})
\]</span></p>
</section>
<section id="maximum-likelihood-estimation-2" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-2">Maximum likelihood estimation</h2>
<p>We can now write the maximum likelihood loss for logistic regression.</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N y_i\log \sigma(\mathbf{x}^T\mathbf{w}) + (1-y_i)\log(1-\sigma(\mathbf{x}^T\mathbf{w}))
\]</span></p>
<p><span class="math display">\[
=-\sum_{i=1}^N y_i\log \sigma(\mathbf{x}^T\mathbf{w}) + (1-y_i)\log \sigma(-\mathbf{x}^T\mathbf{w})
\]</span></p>
<p><span class="math display">\[
\textbf{Ideally: }\ p(y_i\mid \mathbf{x}_i, \mathbf{w})=1,\ \forall (\mathbf{x}_i, y_i)\in \mathcal{D}
\]</span></p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\mathbf{y}^T\log \sigma(\mathbf{X}\mathbf{w})
\]</span></p>
</section>
<section id="comparing-loss-functions" class="level2">
<h2 class="anchored" data-anchor-id="comparing-loss-functions">Comparing loss functions</h2>
<p>Loss for <span class="math inline">\(y=0\)</span> as a function of <span class="math inline">\(z=\mathbf{x}^T\mathbf{w}\)</span></p>
<p><span class="math display">\[
\textbf{Let: }\ z=\mathbf{x}^T\mathbf{w}
\]</span></p>
<div class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="multi-class-classification" class="level1">
<h1>Multi-class classification</h1>
<section id="multi-class-prediction-functions" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-functions">Multi-class prediction functions</h2>
<p>We will typically use a set of integers <span class="math inline">\(\{0,1, 2,...,C\}\)</span> to denote the possible outputs for a general categorical function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/catdogmouse.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Therefore in general we are considering functions of the form:</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in \{0, 1, 2, ...,C\}
\]</span></p>
</section>
<section id="multi-class-prediction-functions-1" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-functions-1">Multi-class prediction functions</h2>
<p>It’s important to note that we are <em>not</em> assuming that the <em>ordering</em> of labels is meaningful For instance if we’re classifying images of animals we might set the labels such that:</p>
<p><span class="math display">\[
\textbf{0:  Cat},\quad
\textbf{1:  Dog},\quad
\textbf{2:  Mouse}
\]</span></p>
<p>But this is equally valid:</p>
<p><span class="math display">\[
\textbf{0:  Dog},\quad
\textbf{1:  Mouse},\quad
\textbf{2:  Cat}
\]</span></p>
</section>
<section id="multi-class-prediction-functions-2" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-functions-2">Multi-class prediction functions</h2>
<p>A simple prediction function for multiclass classification is:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{0...C\}}{\text{argmax}}\ \mathbf{x}^T\mathbf{w}_c
\]</span></p>
<p>Alternatively:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{0...C\}}{\text{argmax}}\ (\mathbf{x}^T\mathbf{W})_c, \quad \mathbf{W} \in \mathbb{R}^{d\times C}
\]</span></p>
<p><img src="images/paste-1.png" class="img-fluid"></p>
</section>
<section id="multi-class-prediction-functions-3" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-functions-3">Multi-class prediction functions</h2>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{0...C\}}{\text{argmax}}\ (\mathbf{x}^T\mathbf{W})_c, \quad \mathbf{W} \in \mathbb{R}^{d\times C}
\]</span></p>
<p>This function reduces to the same one we saw before for the case of <span class="math inline">\(C=2\)</span>:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{0,1\}}{\text{argmax}}\ (\mathbf{x}^T\mathbf{W})_c = \mathbb{I}(\mathbf{x}^T\mathbf{w}_1 - \mathbf{x}^T\mathbf{w}_0 \geq 0)
\]</span></p>
<p><span class="math display">\[
=\mathbb{I}(\mathbf{x}^T(\mathbf{w}_1 - \mathbf{w}_0) \geq 0) \quad \longrightarrow \quad \mathbb{I}(\mathbf{x}^T\mathbf{w} \geq 0), \quad \mathbf{w}=\mathbf{w}_1-\mathbf{w}_0
\]</span></p>
<p>This means the boundary between any two predictions is linear.</p>
<p><img src="images/paste-2.png" class="img-fluid"></p>
</section>
<section id="categorical-distribution" class="level2">
<h2 class="anchored" data-anchor-id="categorical-distribution">Categorical distribution</h2>
<p>The <strong>Categorical distribution</strong> is a distribution over several distinct (discrete) outcomes. It’s parameterized by a <em>vector</em> of probabilities for each outcome:</p>
<p><span class="math display">\[
p(y=c) = q_c, \quad y\in \{1...C\}
\]</span></p>
<p><span class="math display">\[
\mathbf{q} \in \mathbb{R}^C\quad q_c \geq 0\ \forall c\in \{1...C\}\quad \sum_{c=1}^C q_c=1
\]</span></p>
<p>It can also be written as:</p>
<p><span class="math display">\[
p(y)=\prod q_c^{\mathbb{I}(y=c)}
\]</span></p>
<p>The log-likelihood is then:</p>
<p><span class="math display">\[
\log p(y) = \sum_{c=1}^C \mathbb{I}(y=c)\log q_c = \log q_y
\]</span></p>
</section>
<section id="a-probabilistic-model-for-multi-class-classification" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-multi-class-classification">A probabilistic model for multi-class classification</h2>
<p>Once again we need to translate our linear function output into a valid parameter for this distribution:</p>
<p><span class="math display">\[
y_i\sim \mathbf{Categorical}(\mathbf{q}=?)
\]</span></p>
<p><span class="math display">\[
\mathbf{q}=\mathbf{x}^T\mathbf{W}?
\]</span></p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{W}\in \mathbb{R}^C,\quad  q_c \ngeq 0\ \forall c\in \{1...C\}, \quad \sum_{c=1}^C q_c\neq1
\]</span></p>
<p><span class="math display">\[
\textbf{Need }\ f(\mathbf{x}):\ \mathbb{R}^C \longrightarrow [0,\infty)^C,\ \sum_{i=1}^Cf(\mathbf{x})_c = 1
\]</span></p>
</section>
<section id="softmax-function" class="level2">
<h2 class="anchored" data-anchor-id="softmax-function">Softmax function</h2>
<p>Here we can use the softmax function!</p>
<p><span class="math display">\[
\text{softmax}(\mathbf{x})_c = \frac{e^{x_c}}{\sum_{j=1}^Ce^{x_j}}
\]</span></p>
</section>
<section id="a-probabilistic-model-for-multi-class-classification-1" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-multi-class-classification-1">A probabilistic model for multi-class classification</h2>
<p>Now we can define our probabilistic model as:</p>
<p><span class="math display">\[
y_i\sim \mathbf{Categorical}\big(\text{softmax}(\mathbf{x}^T\mathbf{W})\big)
\]</span></p>
<p><span class="math display">\[
p(y_i=c) = \text{softmax}(\mathbf{x}^T\mathbf{W})_c=\frac{e^{\mathbf{x}^T\mathbf{w}_c}}{\sum_{j=1}^Ce^{\mathbf{x}^T\mathbf{w}_j}}
\]</span></p>
</section>
<section id="maximum-likelihood-estimation-3" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-3">Maximum likelihood estimation</h2>
<p><span class="math display">\[
\textbf{Loss}(\mathbf{W}) =\textbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})=- \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{W})
\]</span></p>
<p><span class="math display">\[
= \sum_{i=1}^N \log\ \text{softmax}(\mathbf{x}_i^T\mathbf{W})_{y_i} = \sum_{i=1}^N  \log \frac{e^{\mathbf{x}_i^T\mathbf{w}_{y_i}}}{\sum_{j=1}^Ce^{\mathbf{x}_i^T\mathbf{w}_{j}}}
\]</span></p>
<p><span class="math display">\[
=\sum_{i=1}^N \bigg(\mathbf{x}_i^T\mathbf{w}_{y_i}- \log\sum_{j=1}^Ce^{\mathbf{x}_i^T\mathbf{w}_{j}}\bigg)
\]</span></p>
</section>
<section id="maximum-likelihood-estimation-4" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-4">Maximum likelihood estimation</h2>
<p>In this case our parameters are a matrix</p>
<p><span class="math display">\[
\nabla_{\mathbf{W}} \mathbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})= \begin{bmatrix} \frac{\partial \mathbf{NLL}}{\partial W_{11}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{12}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{1C}} \\
\frac{\partial \mathbf{NLL}}{\partial W_{21}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{22}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{2C}} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\frac{\partial \mathbf{NLL}}{\partial W_{d1}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{d2}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{dC}}
\end{bmatrix}
\]</span></p>
<p>We can still perform gradient descent as before.</p>
<p><span class="math display">\[
\mathbf{W}^{(i+1)} \leftarrow \mathbf{W}^{(i)} - \alpha \nabla_{\mathbf{W}} \mathbf{NLL}(\mathbf{W}^{(i)}, \mathbf{X}, \mathbf{y})
\]</span></p>
</section>
</section>
<section id="evaluating-models" class="level1">
<h1>Evaluating models</h1>
<section id="training-and-test-datasets" class="level2">
<h2 class="anchored" data-anchor-id="training-and-test-datasets">Training and test datasets</h2>
<p>In machine learning we are typically less interested in how our model predicts the data we’ve already seen than we are in how well it makes predictions for <em>new</em> data. One way to estimate how well our model our model will generalize to new data is to <em>hold out</em> data while fitting our model. To do this we will split our dataset into two smaller datasets: a <em>training dataset</em> that we will use to fit our model, and a <em>test</em> or <em>held-out</em> dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.</p>
<p><span class="math display">\[\mathcal{D} = \{ (\mathbf{x}_1, y_1),\ (\mathbf{x}_2, y_2),\ ... \,(\mathbf{x}_N, y_N) \}\quad \longrightarrow \quad
\]</span></p>
<p><span class="math display">\[
\mathcal{D}_{train} = \{ (\mathbf{x}_1, y_1),\ (\mathbf{x}_2, y_2),\ ... \,(\mathbf{x}_{Ntrain}, y_{Ntrain}) \},\  
\mathcal{D}_{test} = \{ (\mathbf{x}_1, y_1),\ (\mathbf{x}_2, y_2),\ ... \,(\mathbf{x}_{Ntest}, y_{Ntest}) \}
\]</span></p>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display">
<p><img src="slides_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>