<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.319">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CS 152: Neural Networks - Lecture 8: Regularization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS 152: Neural Networks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../calendar/calendar.html" rel="" target="">
 <span class="menu-text">Calendar</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/repositories" rel="" target="">
 <span class="menu-text">Homeworks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://harveymuddcollege.instructure.com/courses/615/" rel="" target="">
 <span class="menu-text">Canvas</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152-Neural-Networks-Fall-2023/" rel="" target="">
 <span class="menu-text">Github</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#playground" id="toc-playground" class="nav-link active" data-scroll-target="#playground">Playground</a></li>
  <li><a href="#choosing-hyperparameters" id="toc-choosing-hyperparameters" class="nav-link" data-scroll-target="#choosing-hyperparameters">Choosing Hyperparameters</a>
  <ul class="collapse">
  <li><a href="#train-test-splits" id="toc-train-test-splits" class="nav-link" data-scroll-target="#train-test-splits">Train-test splits</a></li>
  <li><a href="#train-validation-test-splits" id="toc-train-validation-test-splits" class="nav-link" data-scroll-target="#train-validation-test-splits">Train-validation-test splits</a></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation">Cross-validation</a></li>
  <li><a href="#overfitting-and-underfitting" id="toc-overfitting-and-underfitting" class="nav-link" data-scroll-target="#overfitting-and-underfitting">Overfitting and underfitting</a></li>
  </ul></li>
  <li><a href="#early-stopping" id="toc-early-stopping" class="nav-link" data-scroll-target="#early-stopping">Early Stopping</a>
  <ul class="collapse">
  <li><a href="#tracking-validation-loss" id="toc-tracking-validation-loss" class="nav-link" data-scroll-target="#tracking-validation-loss">Tracking validation loss</a></li>
  <li><a href="#early-stopping-1" id="toc-early-stopping-1" class="nav-link" data-scroll-target="#early-stopping-1">Early stopping</a></li>
  </ul></li>
  <li><a href="#loss-based-regularization" id="toc-loss-based-regularization" class="nav-link" data-scroll-target="#loss-based-regularization">Loss-based regularization</a>
  <ul class="collapse">
  <li><a href="#l2-regularization" id="toc-l2-regularization" class="nav-link" data-scroll-target="#l2-regularization">L2 Regularization</a></li>
  <li><a href="#l2-regularization-for-neural-networks" id="toc-l2-regularization-for-neural-networks" class="nav-link" data-scroll-target="#l2-regularization-for-neural-networks">L2 Regularization for neural networks</a></li>
  <li><a href="#l2-regularization-in-pytorch" id="toc-l2-regularization-in-pytorch" class="nav-link" data-scroll-target="#l2-regularization-in-pytorch">L2 Regularization in PyTorch</a></li>
  <li><a href="#l1-regularization" id="toc-l1-regularization" class="nav-link" data-scroll-target="#l1-regularization">L1 Regularization</a></li>
  </ul></li>
  <li><a href="#dropout-regularization" id="toc-dropout-regularization" class="nav-link" data-scroll-target="#dropout-regularization">Dropout Regularization</a>
  <ul class="collapse">
  <li><a href="#dropout" id="toc-dropout" class="nav-link" data-scroll-target="#dropout">Dropout</a></li>
  <li><a href="#dropout-at-evaluation-time" id="toc-dropout-at-evaluation-time" class="nav-link" data-scroll-target="#dropout-at-evaluation-time">Dropout at evaluation time</a></li>
  <li><a href="#dropout-in-pytorch" id="toc-dropout-in-pytorch" class="nav-link" data-scroll-target="#dropout-in-pytorch">Dropout in PyTorch</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 8: Regularization</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="playground" class="level1">
<h1>Playground</h1>
<p>Try out the concepts from this lecture in the <a href="https://cs152-neural-networks-fall-2023.github.io/playground">Neural Network Playground!</a></p>
</section>
<section id="choosing-hyperparameters" class="level1">
<h1>Choosing Hyperparameters</h1>
<p>In the last lecture we looked at how to make choices about our network such as: <em>the number of layers</em>, <em>the number of neurons in each layer</em> and the <em>learning rate</em>. We’ve seen that we can use the gradient descent algorithm to choose the values of the low-level parameters of our model ( e.g.&nbsp;<span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> ). We call high level choices like the number of layers and learning rate <strong>hyperparameters</strong>. There isn’t strictly an algorithm for making these choices, typically we need to make some reasonable choices, train the model with gradient descent and then <em>evaluate</em> the performance of our model.</p>
<section id="train-test-splits" class="level2">
<h2 class="anchored" data-anchor-id="train-test-splits">Train-test splits</h2>
<p>As we’ve seen previously to get an unbiased estimate of how well our model will perform on new data, it is good practice to hold-out a <strong>test set</strong> of data that we will not use to train our model with gradient descent. Instead we will fit our model on the remaining data (the <strong>training set</strong>) and then compute the loss (or other metrics like accuracy) on the test set, using this as an estimate of the performance of our model.</p>
<p><img src="images/paste-23.png" class="img-fluid"></p>
</section>
<section id="train-validation-test-splits" class="level2">
<h2 class="anchored" data-anchor-id="train-validation-test-splits">Train-validation-test splits</h2>
<p>If our test loss isn’t very good we may decide that we want to change our hyperparameters and train the model again. We could keep doing this over and over until we get a test loss that we’re satisfied with. However, as soon as we use the test data to make choices about our model, the test loss we’ll no longer be an unbiased estimate of the performance of our model on new data! After all, we’ve now used it to fit our model. This isn’t ideal as we will no longer have a reliable estimate for the true performance of our model.</p>
<p>A simple approach to addressing this is to split our data into 3 parts: a <strong>training set</strong> that we’ll use for gradient descent, a <strong>test set</strong> that we’ll use for evaluating our model, and a <strong>validation set</strong> that we’ll use for choosing hyperparameters. When we run gradient descent, we can hold out both the test and validation sets, but we’ll allow ourselves to use the performance on the validation set (the <em>validation loss</em>) to choose hyperparameters. The test set we’ll reserve for the very end, when we’ve definitively chosen our model and need to estimate how well it will do. At a high-level the process looks like this:</p>
<div class="columns">
<div class="column" style="width:35%;">
<p><img src="images/paste-24.png" class="img-fluid"></p>
</div><div class="column" style="width:65%;">
<p><img src="images/paste-25.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="cross-validation">Cross-validation</h2>
<p>An alternative approach is multiple splits of the same training data. Rather than partitioning our training set into distinct training and validation sets, we can divide our training set into <span class="math inline">\(K\)</span> groups called <em>folds</em>.</p>
<p>To evaluate the performance of a given hyperparameter setting we can train our model multiple times, each time holding out a different group as the validation set. This gives us <span class="math inline">\(K\)</span> estimates of the performance of a given choice of hyperparameters.</p>
<div class="columns">
<div class="column" style="width:35%;">
<p><img src="images/paste-26.png" class="img-fluid"></p>
</div><div class="column" style="width:65%;">
<p><img src="images/paste-27.png" class="img-fluid"></p>
</div>
</div>
<p>Cross-validation can be a more reliable way to choose hyperparameters at the expense of needing to retrain to model <span class="math inline">\(K\)</span> times, which can be computationally expensive.</p>
</section>
<section id="overfitting-and-underfitting" class="level2">
<h2 class="anchored" data-anchor-id="overfitting-and-underfitting">Overfitting and underfitting</h2>
<p>There’s two possible reasons that a model might perform poorly on validation or test data (assuming gradient descent works well).</p>
<p><img src="images/paste-36.png" class="img-fluid"></p>
<ul>
<li><p><strong>Underfitting</strong> occurs when our model is too simple to capture the data we’re trying to model. For example, if we try to fit a linear model to U-shaped data we see that the model can never fit the data well. We can identify underfitting when <em>both the training and validation/test loss will be poor</em>.</p></li>
<li><p><strong>Overfitting</strong> occurs when our prediction function is too complex. In this case the model may capture all of the small variations present in the training data even when these variations are simply due to noise or poor measurements, thus may not be reflected in held-out data. A better approach would be to model these variations as <em>uncertainty</em> rather than variations in the prediction function. We can identify overfitting when the <em>training loss is good, but the validation/loss is poor</em>.</p></li>
</ul>
<p>If we think about plotting our training and validation loss as a function of the complexity of our model, we might see underfitting when the model is very simple and overfitting when the model is very complex. The idea model would be right in the middle when the validation loss is at its minimum.</p>
<p><img src="images/paste-35.png" class="img-fluid"></p>
<p>In this case model complexity could mean several different things:</p>
<ul>
<li><p>Number of layers</p></li>
<li><p>Number of neurons per layer</p></li>
<li><p>Activation functions</p></li>
<li><p>Explicit feature transforms applied</p></li>
</ul>
<p>Let’s look at a specific example where we’ll fit 3 neural networks of different levels of complexity on the same data:</p>
<section id="underfit-model" class="level4">
<h4 class="anchored" data-anchor-id="underfit-model">Underfit model</h4>
<p><img src="images/paste-31.png" class="img-fluid"></p>
</section>
<section id="well-fit-model" class="level4">
<h4 class="anchored" data-anchor-id="well-fit-model">Well-fit model</h4>
<p><img src="images/paste-32.png" class="img-fluid" width="1452"></p>
</section>
<section id="overfit-model" class="level4">
<h4 class="anchored" data-anchor-id="overfit-model">Overfit model</h4>
<p><img src="images/paste-28.png" class="img-fluid" width="1100"></p>
<p>If we take a closer look at the overfit model, we can see that it actually fits the training data almost perfectly, but if we add more data from the same dataset, the performance looks much worse.</p>
<div class="columns">
<div class="column" style="width:45%;">
<p><img src="images/paste-29.png" class="img-fluid"></p>
</div><div class="column" style="width:10%;">

</div><div class="column" style="width:45%;">
<p><img src="images/paste-30.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
</section>
<section id="early-stopping" class="level1">
<h1>Early Stopping</h1>
<section id="tracking-validation-loss" class="level2">
<h2 class="anchored" data-anchor-id="tracking-validation-loss">Tracking validation loss</h2>
<p>A common tool for quickly identifying poor performance is to track both the training <em>and</em> validation loss as we perform gradient descent. Doing this can let us see in real time if our model is underfitting or overfitting.</p>
<p>If we take a look a this type of plot from real neural network we see something interesting: the plot looks almost exactly like the model complexity plot we saw above.</p>
<div class="columns">
<div class="column" style="width:40%;">
<p><img src="images/paste-37.png" class="img-fluid" width="556"></p>
</div><div class="column" style="width:60%;">
<p><img src="images/paste-35.png" class="img-fluid"></p>
</div>
</div>
<p>Early in training both the training both the training and validation loss are improving, suggesting that at first the model is underfitting. After a while the training loss continues to improve, but the validation loss starts to get worse, suggesting that the model is beginning to overfit.</p>
</section>
<section id="early-stopping-1" class="level2">
<h2 class="anchored" data-anchor-id="early-stopping-1">Early stopping</h2>
<p>The plot above suggests a simple strategy for preventing overfitting: simply stop gradient descent when the validation loss begins to increase! We call this approach <strong>early stopping</strong>.</p>
<p><img src="images/paste-38.png" class="img-fluid"></p>
<p>We saw a simple way to implement this in the previous lecture: if the current validation loss is larger than the previous one, stop training.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(model, training_data)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    valid_loss <span class="op">=</span> compute_loss(model, training_data)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> valid_loss <span class="op">&gt;</span> valid_losses[<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    valid_losses.append(valid_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the real world, the loss can be noisy:</p>
<p><img src="images/paste-39.png" class="img-fluid" width="503"></p>
<p>So it may not make sense to stop the first time the validation loss increases. A common strategy to apply a more <em>patient</em> form of early stopping. In the case we stop if the validation loss hasn’t improved for some specified number of steps:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>patience <span class="op">=</span> <span class="dv">5</span>                    <span class="co"># Number of steps to wait before stopping</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>steps_since_improvement <span class="op">=</span> <span class="dv">0</span>     <span class="co"># Steps since validation loss improved</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>min_loss <span class="op">=</span> <span class="fl">1e8</span>                  <span class="co"># Minimum loss seen so far (start large)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    valid_loss <span class="op">=</span> compute_loss(model, training_data)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the validation loss improves reset the counter</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> valid_loss <span class="op">&lt;</span> min_loss:</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        steps_since_improvement <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        min_loss <span class="op">=</span> valid_loss</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Otherwise increment the counter</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        steps_since_improvement <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If its been patience steps since the last improvement, stop</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> steps_since_improvement <span class="op">==</span> patience:</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="loss-based-regularization" class="level1">
<h1>Loss-based regularization</h1>
<p>Thus far we have thought about combating overfitting by either restricting our prediction function or reducing the number of gradient descent steps we use to optimize the loss. In principal though, neither of these choices <em>should</em> be a problem. After all, while a simple function cannot approximate a complex function, a complex function should easily be able to approximate a simple one.</p>
<p>This raises the question: if the answer we’re looking for isn’t actually the one that minimizes our loss, are we actually minimizing the right loss?</p>
<section id="l2-regularization" class="level2">
<h2 class="anchored" data-anchor-id="l2-regularization">L2 Regularization</h2>
<p>One way that overfitting can manifest is as a prediction function that is overly sensitive to small changes in the input. We can see this in examples like the one below.</p>
<p><img src="images/Screenshot 2023-10-18 at 7.40.46 AM.png" class="img-fluid"></p>
<p>Here in the overfit case, our prediction function is trying to capture the noise of the data rather than just the overall trend. This is explicitly encouraged by losses like the mean squared-error loss, as the loss says fit every observation as closely as possible:</p>
<p><span class="math display">\[\textbf{MSE}(\mathbf{X}, \mathbf{y}, \mathbf{w}) = \frac{1}{N} \sum_{i=1}^N ((f(\mathbf{x}_i, \mathbf{w}) - y_i)^2)\]</span></p>
<p>When our prediction function <span class="math inline">\(f\)</span> is complex enough, it can exactly capture variations due to noise in the training data. As we can see, this means that the function must be very <em>non-smooth</em>, small changes in the input correspond to big changes in the output as we can clearly see in the marked region. This means that the function in this region has a very large <em>slope</em>.</p>
<p>How does this observation help us think about regularization? Well, we know that the <em>weights</em> of our model control the slope of the function; large weights correspond to large slopes. Therefore if we want to ensure our prediction function is smooth, we need to make sure that the weights are not too large.</p>
<div class="columns">
<div class="column" style="width:45%;">
<p><img src="images/paste-10.png" class="img-fluid" width="974"></p>
<p>An overfit network will have large weights to encode large slopes.</p>
</div><div class="column" style="width:10%;">

</div><div class="column" style="width:45%;">
<p><img src="images/paste-13.png" class="img-fluid" width="974"></p>
<p>A regularized network will have smaller weights encoding a smooth function.</p>
</div>
</div>
<p>We can account for this in our loss function by adding a loss that encourages our weights to be close to 0. One such loss is the <strong>L2</strong> loss. For a given weight vector <span class="math inline">\(\mathbf{w}\)</span> the <strong>L2</strong> loss is simply the squared 2-norm of the vector: <span class="math display">\[\textbf{L}_2(\mathbf{w}) = \|\mathbf{w}\|_2^2 = \sum_{i=1}^d w_i^2\]</span></p>
<p>If we have a weight <em>matrix</em> <span class="math inline">\(\mathbf{W}\)</span> as in neural networks or multinomial logistic regression the L2 loss is just the squared matrix 2-norm, which is again simply the sum of every element squared. For a <span class="math inline">\(d \times e\)</span> weight matrix <span class="math inline">\(\mathbf{W}\)</span> the L2 loss is:</p>
<p><span class="math display">\[\textbf{L}_2(\mathbf{W}) = \|\mathbf{W}\|_2^2 = \sum_{i=1}^d\sum_{j=1}^e w_{ij}^2\]</span></p>
<p>We can then train our model with a combination of losses. For example, if we’re training a regression model we could use:</p>
<p><span class="math display">\[\textbf{Loss}(\mathbf{X}, \mathbf{y}, \mathbf{w}) = \textbf{MSE}(\mathbf{X}, \mathbf{y}, \mathbf{w}) + \lambda \textbf{L}_2(\mathbf{w})\]</span></p>
<p>Here <span class="math inline">\(\lambda\)</span> is a value that we can choose to trade off between these two losses. Too high a value for <span class="math inline">\(\lambda\)</span> and we might end up with a value that is <em>too</em> smooth or just flat, too low and or L2 loss might not affect our result at all.</p>
</section>
<section id="l2-regularization-for-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="l2-regularization-for-neural-networks">L2 Regularization for neural networks</h2>
<p>If we are dealing with a neural network model, we may actually have many weight vectors and matrices. For example in a 4 hidden-layer network with sigmoid activations we have a prediction function that looks like: <span class="math display">\[f(\mathbf{x}, \mathbf{w}_0,...) = \sigma( \sigma( \sigma( \sigma( \mathbf{x^T} \mathbf{W}_4)^T  \mathbf{W}_3)^T  \mathbf{W}_2)^T \mathbf{W}_1)^T \mathbf{w}_0\]</span></p>
<p><img src="images/paste-1.png" class="img-fluid" width="600"></p>
<p>In this case, we can simply add up the L2 loss for every weight. For a network with <span class="math inline">\(L\)</span> hidden layers the L2 loss would simply be: <span class="math display">\[\textbf{L}_2(\mathbf{w}_0, \mathbf{W}_1,...,\mathbf{W}_L) = \sum_{l=0}^L\|\mathbf{W}_l\|_2^2\]</span></p>
<p>In practice most networks also incorporate bias terms, so each linear function in our network can be written as:</p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{W} + \mathbf{b}
\]</span></p>
<p>And the full prediction function for a sigmoid-activation network might be:</p>
<p><span class="math display">\[f(\mathbf{x}, \mathbf{w}_0,...) = \sigma( \sigma( \sigma( \sigma( \mathbf{x^T} \mathbf{W}_4 + \mathbf{b}_4)^T  \mathbf{W}_3 + \mathbf{b}_3)^T  \mathbf{W}_2 + \mathbf{b}_2)^T \mathbf{W}_1 + \mathbf{b}_1)^T \mathbf{w}_0 + \mathbf{b}_0\]</span></p>
<p>Each of these biases is a constant offset and <strong>does not</strong> affect the slope of the function or how quickly the output changes with small changes in the input. This means that the bias terms do not contribute to overfitting, therefore we do not need to regularize them!</p>
</section>
<section id="l2-regularization-in-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="l2-regularization-in-pytorch">L2 Regularization in PyTorch</h2>
<p>In PyTorch, L2 regularization is actually handled by the optimizer and is known as <strong>weight decay</strong>. This name comes from the fact that regularization encourages unimportant weights to <em>decay</em> to 0. When creating a PyTorch optimizer, we can specify how much L2 regularization to add to our loss by setting the <code>weight_decay</code> option to our desired L2 weight ( <span class="math inline">\(\lambda\)</span> in our notation).</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.1</span>, weight_decay<span class="op">=</span><span class="fl">0.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="l1-regularization" class="level2">
<h2 class="anchored" data-anchor-id="l1-regularization">L1 Regularization</h2>
<p>A natural alternative to L2 regularization, where we minimized the square of each weight is to simply minimize the <em>absolute value</em> of each weight, which should have a similar effect of encouraging our weights to be close to 0.</p>
<p><span class="math display">\[\text{Vector: }\textbf{L}_1(\mathbf{w}) = \|\mathbf{w}\|_1 = \sum_{i=1}^d |w_i|, \quad \text{Matrix: }\textbf{L}_1(\mathbf{W}) = \|\mathbf{W}\|_1 = \sum_{i=1}^d\sum_{j=1}^e |w_{ij}|\]</span></p>
<p>We call this <strong>L1</strong> regularization, as it is equivalent to minimizing the L1 norm <span class="math inline">\((\|\cdot\|_1)\)</span> of each weight vector/matrix.</p>
<p>If we plot the L2 and L1 losses for a single weight <span class="math inline">\(w\)</span>, we can get a sense of the differences between these two approaches.</p>
<p><img src="images/paste-2.png" class="img-fluid" width="711"></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img src="images/paste-3.png" class="img-fluid" width="674"></p>
</div><div class="column" style="width:50%;">
<p><img src="images/paste-4.png" class="img-fluid"></p>
</div>
</div>
<p>We see that the L2 loss <em>strongly</em> penalizes weights far from 0 compared to the L1 loss. However, this penalty decays quadratically towards 0, so weights close to 0 incur very little loss. The L1 loss decays <em>linearly</em> and thus more strongly penalizes weights that are already close to 0. Intuitively, this means that the L1 loss focuses on decreasing weights already close to 0 just as much as weights that are far from 0. This has the effect of encouraging <em>sparsity</em>, as the L1 loss can trade-off allowing some weights to be large if others go to exactly 0. The L2 loss encourages all weights to be reasonably small.</p>
<p>We can see the same distinction if we plot the L2 and L2 losses as a function of 2 weights:</p>
<p><img src="images/paste-5.png" class="img-fluid" width="986"></p>
<p>If we overlay a hypothetical MSE loss as a function of the two weights, we can get a sense of <em>why</em> the L1 loss encourages sparsity. For most curves of constant MSE, the point that minimizes the L1 loss falls at a point where one of the weights is <em>exactly</em> 0. If our L1 weight <span class="math inline">\((\lambda)\)</span> is high enough, our overall minimum would fall at one of these points.</p>
<p><img src="images/paste-7.png" class="img-fluid" width="891"></p>
<p>We can see the effect these two forms of regularization have on a real network.</p>
<div class="columns">
<div class="column" style="width:45%;">
<p><img src="images/paste-13.png" class="img-fluid" width="974"></p>
<p>L2 Regularization encourages all weights to be small.</p>
</div><div class="column" style="width:10%;">

</div><div class="column" style="width:45%;">
<p><img src="images/paste-14.png" class="img-fluid"></p>
<p>L1 Regularization encourages all but the most relevant weights to go to 0.</p>
</div>
</div>
</section>
</section>
<section id="dropout-regularization" class="level1">
<h1>Dropout Regularization</h1>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout">Dropout</h2>
<p>Another way to think about overfitting is through <em>Interdependency</em>. In order to capture small scale variations in our data, our network needs to dedicate many complex connections to capturing these specific variations. Another effective and popular form of regularization is <strong>dropout</strong> which purposefully breaks connections at training training time in order to encourage the network to learn reduce reliance on single specialized neurons and create redundancy.</p>
<p>As shown in this figure from the original dropout paper, dropout randomly removes neurons from the network at each step of training, performing the update with respect to this new randomized network.</p>
<p><img src="images/paste-15.png" class="img-fluid" width="993"></p>
<p>The probability that any given neuron is removed is called the <strong>dropout rate</strong> <span class="math inline">\(r\)</span>. Mathematically, we can view dropout as a randomized function that is applied to the input of each layer. This function performs an element-wise multiplication <span class="math inline">\((\odot)\)</span> of the input <span class="math inline">\(\mathbf{X}\)</span> with a random matrix <span class="math inline">\(\mathbf{D}\)</span> of 1’s and 0’s, where <span class="math inline">\(p(d_{ij}=0)=r\)</span>.</p>
<p><span class="math display">\[\text{Dropout}(\mathbf{X}, r) = \mathbf{D} \odot \mathbf{X}, \quad \mathbf{D} =
\begin{bmatrix}
d_{11} &amp; d_{12} &amp; \dots &amp; d_{1n} \\
d_{21} &amp; d_{22} &amp; \dots &amp; d_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
d_{m1} &amp; d_{m2} &amp; \dots &amp;  d_{mn}
\end{bmatrix},\ d_{ij} \sim \text{Bernoulli}(1-r)\]</span><br>
We can shorten <span class="math inline">\(\text{Dropout}(\mathbf{X}, r)\)</span> to <span class="math inline">\(\text{DO}_r(\mathbf{X})\)</span>. With this we can write a network layer with sigmoid activation and dropout as:</p>
<p><span class="math display">\[
\phi(\mathbf{x}) = \sigma(\text{DO}_r(\mathbf{x})^T\mathbf{W} + \mathbf{b})
\]</span></p>
<p>A network with several dropout layers would have a prediction function defined as:</p>
<p><span class="math display">\[f(\mathbf{x}, \mathbf{w}_0,...) = \text{DO}_r(\sigma( \text{DO}_r(\sigma( \text{DO}_r(\sigma(\text{DO}_r( \mathbf{x})^T  \mathbf{W}_2 + \mathbf{b}_2))^T \mathbf{W}_1 + \mathbf{b}_1))^T \mathbf{w}_0 + \mathbf{b}_0\]</span></p>
<p>Or more simply as a sequence of operations:</p>
<p><span class="math display">\[
\mathbf{a} = \sigma(\text{DO}_r(\mathbf{x})^T\mathbf{W}_2 + \mathbf{b}_2)
\]</span></p>
<p><span class="math display">\[
\mathbf{b} = \sigma(\text{DO}_r(\mathbf{a})^T\mathbf{W}_1 + \mathbf{b}_1)
\]</span><br>
<span class="math display">\[
\mathbf{f} = \text{DO}_r(\mathbf{b})^T\mathbf{w}_0 + b_0
\]</span></p>
<p>The randomness introduced by dropout will cause our prediction function to be noisy. By dropping out different neurons at each step, we get different prediction functions from the same weights:</p>
<div class="columns">
<div class="column" style="width:33%;">
<p><img src="images/paste-19.png" class="img-fluid"></p>
</div><div class="column" style="width:33%;">
<p><img src="images/paste-20.png" class="img-fluid"></p>
</div><div class="column" style="width:33%;">
<p><img src="images/paste-21.png" class="img-fluid"></p>
</div>
</div>
<p>If we average all these networks however, we get something quite smooth, with redundancies in the predictions made by each neuron:</p>
<p><img src="images/paste-22.png" class="img-fluid"></p>
<p>We can see from this example that unlike L2 and L1 regularization, dropout doesn’t enforce that weights should be small. Rather it encourages redundancy in the network, preventing neurons from becoming co-dependent.</p>
</section>
<section id="dropout-at-evaluation-time" class="level2">
<h2 class="anchored" data-anchor-id="dropout-at-evaluation-time">Dropout at evaluation time</h2>
<p>When we’re evaluating our model or trying to make predictions on new data, we likely don’t want our prediction function to be noisy. As we can see in the examples above, applying dropout can lead to poor predictions if we’re unlucky. A simple approach might just remove the dropout functions at evaluation time:</p>
<p><span class="math display">\[
\phi(\mathbf{x})_{train} = \sigma(\text{DO}_r(\mathbf{x})^T\mathbf{W} + \mathbf{b}) \quad \rightarrow \quad \phi(\mathbf{x})_{eval} = \sigma(\mathbf{x}^T\mathbf{W} + \mathbf{b})
\]</span></p>
<p>However this has a problem! To see why consider the <strong>expected value</strong> of a linear function with dropout:</p>
<p><span class="math display">\[
\mathbb{E}[ \text{DO}_r(\mathbf{x})^T\mathbf{w}] = \sum_i d_i x_i w_i, \quad d_i \sim \text{Bernoulli}(1-r)
\]</span></p>
<p><span class="math display">\[
= \sum_i p(d_i=1) x_i w_i = (1-r)\sum_i  x_i w_i &lt;  \sum_i  x_i w_i
\]</span></p>
<p>If <span class="math inline">\(r=0.5\)</span> (the value suggested by the original dropout inventors), then on average the output of our function with dropout will only be half as large as the function without dropout! If we simply get rid of the dropout functions, the scale of our predictions will be way off.</p>
<p>A simple solution is to simply define dropout at evaluation time to <em>scale</em> the output according to the dropout rate. So at evaluation time dropout is defined as:</p>
<p><span class="math display">\[
\text{Dropout}_{eval}(\mathbf{X}, r) = (1-r) \mathbf{X}
\]</span></p>
<p>This gives use the smooth prediction function we’re looking for:</p>
<p><img src="images/paste-22.png" class="img-fluid"></p>
</section>
<section id="dropout-in-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="dropout-in-pytorch">Dropout in PyTorch</h2>
<p>In Pytorch, dropout is implemented as a module (or layer) as with the linear and activation layers we’ve seen previously. We can define a network with dropout very simply using the <code>nn.Dropout</code> module:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2 Hidden-layer network with dropout</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(nn.Dropout(<span class="fl">0.5</span>), nn.Linear(<span class="dv">2</span>, <span class="dv">10</span>), nn.ReLU(), </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                      nn.Dropout(<span class="fl">0.5</span>), nn.Linear(<span class="dv">10</span>, <span class="dv">10</span>), nn.ReLU(), </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                      nn.Dropout(<span class="fl">0.5</span>), nn.Linear(<span class="dv">10</span>, <span class="dv">1</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                     )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>