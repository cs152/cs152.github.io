<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lecture 3: Logistic regression – CS 152: Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS 152: Neural Networks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../calendar/calendar.html"> 
<span class="menu-text">Calendar</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../assignments/homeworks/homeworks.html"> 
<span class="menu-text">Homeworks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../assignments/final-project/outline.html"> 
<span class="menu-text">Project</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="https://probml.github.io/pml-book/book1.html">
 <span class="dropdown-text">Textbook</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://blank-app-ufu2uvdeosc.streamlit.app/">
 <span class="dropdown-text">Notebook conversion</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.gradescope.com/courses/960105">
 <span class="dropdown-text">Gradescope</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-solutions" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Solutions</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-solutions">    
        <li class="dropdown-header">Homework 1 Solutions</li>
        <li class="dropdown-header">Homework 2 Solutions</li>
        <li class="dropdown-header">Homework 3 Solutions</li>
        <li class="dropdown-header">Homework 4 Solutions</li>
        <li class="dropdown-header">Homework 5 Solutions</li>
        <li class="dropdown-header">Homework 6 Solutions</li>
        <li class="dropdown-header">Homework 7 Solutions</li>
        <li class="dropdown-header">Homework 8 Solutions</li>
        <li class="dropdown-header">Homework 9 Solutions</li>
        <li class="dropdown-header">Homework 10 Solutions</li>
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#classification" id="toc-classification" class="nav-link active" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
  <li><a href="#functions-with-categorical-outputs" id="toc-functions-with-categorical-outputs" class="nav-link" data-scroll-target="#functions-with-categorical-outputs">Functions with categorical outputs</a></li>
  <li><a href="#binary-outputs" id="toc-binary-outputs" class="nav-link" data-scroll-target="#binary-outputs">Binary outputs</a></li>
  <li><a href="#visualizing-categorical-outputs" id="toc-visualizing-categorical-outputs" class="nav-link" data-scroll-target="#visualizing-categorical-outputs">Visualizing categorical outputs</a></li>
  <li><a href="#making-binary-predictions" id="toc-making-binary-predictions" class="nav-link" data-scroll-target="#making-binary-predictions">Making binary predictions</a></li>
  <li><a href="#interpreting-parameters" id="toc-interpreting-parameters" class="nav-link" data-scroll-target="#interpreting-parameters">Interpreting parameters</a></li>
  <li><a href="#geometric-interpretation-of-predictions" id="toc-geometric-interpretation-of-predictions" class="nav-link" data-scroll-target="#geometric-interpretation-of-predictions">Geometric interpretation of predictions</a></li>
  <li><a href="#decision-boundaries" id="toc-decision-boundaries" class="nav-link" data-scroll-target="#decision-boundaries">Decision boundaries</a></li>
  <li><a href="#measuring-error" id="toc-measuring-error" class="nav-link" data-scroll-target="#measuring-error">Measuring error</a></li>
  <li><a href="#defining-a-loss-function" id="toc-defining-a-loss-function" class="nav-link" data-scroll-target="#defining-a-loss-function">Defining a loss function</a></li>
  </ul></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#the-bernoulli-distribution" id="toc-the-bernoulli-distribution" class="nav-link" data-scroll-target="#the-bernoulli-distribution">The Bernoulli distribution</a></li>
  <li><a href="#a-probabilistic-model-for-binary-classification" id="toc-a-probabilistic-model-for-binary-classification" class="nav-link" data-scroll-target="#a-probabilistic-model-for-binary-classification">A probabilistic model for binary classification</a></li>
  <li><a href="#sigmoid-function" id="toc-sigmoid-function" class="nav-link" data-scroll-target="#sigmoid-function">Sigmoid function</a></li>
  <li><a href="#a-probabilistic-model-for-binary-classification-1" id="toc-a-probabilistic-model-for-binary-classification-1" class="nav-link" data-scroll-target="#a-probabilistic-model-for-binary-classification-1">A probabilistic model for binary classification</a></li>
  <li><a href="#logistic-regression-decision-boundary" id="toc-logistic-regression-decision-boundary" class="nav-link" data-scroll-target="#logistic-regression-decision-boundary">Logistic regression decision boundary</a></li>
  <li><a href="#maximum-likelihood-estimation-review" id="toc-maximum-likelihood-estimation-review" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-review">Maximum likelihood estimation review</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  <li><a href="#maximum-likelihood-for-logistic-regression" id="toc-maximum-likelihood-for-logistic-regression" class="nav-link" data-scroll-target="#maximum-likelihood-for-logistic-regression">Maximum likelihood for logistic regression</a></li>
  <li><a href="#optimizing-logistic-regression" id="toc-optimizing-logistic-regression" class="nav-link" data-scroll-target="#optimizing-logistic-regression">Optimizing logistic regression</a></li>
  <li><a href="#comparing-loss-functions" id="toc-comparing-loss-functions" class="nav-link" data-scroll-target="#comparing-loss-functions">Comparing loss functions</a></li>
  </ul></li>
  <li><a href="#multinomial-logistic-regression" id="toc-multinomial-logistic-regression" class="nav-link" data-scroll-target="#multinomial-logistic-regression">Multinomial logistic regression</a>
  <ul class="collapse">
  <li><a href="#multi-class-classification" id="toc-multi-class-classification" class="nav-link" data-scroll-target="#multi-class-classification">Multi-class classification</a></li>
  <li><a href="#multi-class-prediction-functions" id="toc-multi-class-prediction-functions" class="nav-link" data-scroll-target="#multi-class-prediction-functions">Multi-class prediction functions</a></li>
  <li><a href="#multi-class-decision-boundaries" id="toc-multi-class-decision-boundaries" class="nav-link" data-scroll-target="#multi-class-decision-boundaries">Multi-class decision boundaries</a></li>
  <li><a href="#categorical-distribution" id="toc-categorical-distribution" class="nav-link" data-scroll-target="#categorical-distribution">Categorical distribution</a></li>
  <li><a href="#a-probabilistic-model-for-multi-class-classification" id="toc-a-probabilistic-model-for-multi-class-classification" class="nav-link" data-scroll-target="#a-probabilistic-model-for-multi-class-classification">A probabilistic model for multi-class classification</a></li>
  <li><a href="#softmax-function" id="toc-softmax-function" class="nav-link" data-scroll-target="#softmax-function">Softmax function</a></li>
  <li><a href="#multonomial-logistic-regression" id="toc-multonomial-logistic-regression" class="nav-link" data-scroll-target="#multonomial-logistic-regression">Multonomial logistic regression</a></li>
  <li><a href="#maximum-likelihood-estimation-for-multinomial-logistic-regression" id="toc-maximum-likelihood-estimation-for-multinomial-logistic-regression" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-for-multinomial-logistic-regression">Maximum likelihood estimation for multinomial logistic regression</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient descent</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 3: Logistic regression</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="classification" class="level1">
<h1>Classification</h1>
<p><strong>Interactive visualization for this lecture available <a href="../lecture3-logistic-regression/viz-v2.html">here</a></strong></p>
<section id="functions-with-categorical-outputs" class="level2">
<h2 class="anchored" data-anchor-id="functions-with-categorical-outputs">Functions with categorical outputs</h2>
<p>In the last lecture we considered approximating functions of the form:</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in\mathbb{R}
\]</span></p>
<p>In that setup our function takes in a vector and produces a real number as an output (for example a miles per gallon rating).</p>
<p>In many real-world problems, the output we want to model is not a continuous value, but a <em>categorical</em> value, meaning the function produces one choice from an unordered of possible outputs. A well-studied example of this kind of prediction is labeling; we might want to assign a label to an image based on the image’s content.</p>
<p><img src="pictures/catdogmouse.png" class="img-fluid"></p>
<p>We call the prediction of categorical outputs <strong>classification</strong>. The output is often also called the <em>class</em> of the observation.</p>
</section>
<section id="binary-outputs" class="level2">
<h2 class="anchored" data-anchor-id="binary-outputs">Binary outputs</h2>
<p>In the simplest <em>binary</em> case our function produces one of two possible outputs.</p>
<p>For example: consider the problem of labeling images as containing either cats or dogs. Conceptually we would like a function that maps images to either a cat label or a dog label:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/catdog.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>For convenience and generality, we will typically use the set <span class="math inline">\(\{0, 1\}\)</span> to denote the possible outputs for a binary classification function. Therefore in general we are considering functions of the form:</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in \{0, 1\}
\]</span></p>
<p>We can assign these outputs to correspond to our actual target labels. For instance we might say that <span class="math inline">\(0 = \textbf{"cat"}\)</span> and <span class="math inline">\(1=\textbf{"dog"}\)</span>.</p>
</section>
<section id="visualizing-categorical-outputs" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-categorical-outputs">Visualizing categorical outputs</h2>
<p>As a simpler example, let’s again consider the fuel efficiency example from the previous lecture. Perhaps our company has set a target fuel efficiency of 30 miles per gallon for our new model and we want to predict whether our design will meet that target. In this case our inputs will be the same as before, but our output will become a binary label:</p>
<p><span class="math display">\[
\text{Input: } \mathbf{x}_i= \begin{bmatrix} \text{Weight} \\ \text{Horsepower} \\ \text{Displacement} \\ \text{0-60mph}  \end{bmatrix}, \quad \text{Output: } y_i = \begin{cases} 1: \text{Meets target } (MPG \geq 30) \\ 0:
\text{Fails to meet target } (MPG &lt; 30) \\  \end{cases}
\]</span></p>
<p>We can visualize which observations meet our target efficiency by again plotting weight against MPG and using colors to distinguish observations would have label <span class="math inline">\(1\)</span> vs.&nbsp;label <span class="math inline">\(0\)</span>.</p>
<div id="fd11710a" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>With this new output definition our dataset will look like:</p>
<p><span class="math display">\[
\text{Honda Accord: } \begin{bmatrix} \text{Weight:} &amp; \text{2500 lbs} \\ \text{Horsepower:} &amp; \text{ 123 HP} \\ \text{Displacement:} &amp; \text{ 2.4 L} \\ \text{0-60mph:} &amp; \text{ 7.8 Sec} \end{bmatrix} \longrightarrow \text{1   (Meets target)}
\]</span></p>
<p><span class="math display">\[
\text{Dodge Aspen: } \begin{bmatrix} \text{Weight:} &amp; \text{3800 lbs} \\ \text{Horsepower:} &amp; \text{ 155 HP} \\ \text{Displacement:} &amp; \text{ 3.2 L} \\ \text{0-60mph:} &amp; \text{ 6.8 Sec} \end{bmatrix} \longrightarrow  \text{0   (Does not meet target)}
\]</span></p>
<p><span class="math display">\[
\vdots \quad \vdots
\]</span></p>
<p>In this case, we’ve gotten rid of the <span class="math inline">\(MPG\)</span> output variable and replaced it with a binary output <span class="math inline">\(y_i \in \{0, 1\}\)</span>. If we plot this version of the data, we can see more directly how this <em>classification</em> task differs from the <em>regression</em> task we saw in the last lecture.</p>
<div id="e7a2a3be" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="making-binary-predictions" class="level2">
<h2 class="anchored" data-anchor-id="making-binary-predictions">Making binary predictions</h2>
<p>We could fit a linear regression model to our binary data, by simply treating the labels <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> as real-valued outputs. For our fuel economy example, such a model would look like this:</p>
<div id="3e97c6f5" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>However, this doesn’t really address our problem. How do we interpret a prediction of <span class="math inline">\(-1\)</span> or <span class="math inline">\(10\)</span> or <span class="math inline">\(0.5\)</span>?</p>
<p>A more suitable prediction function would <em>only</em> output one of our two possible labels <span class="math inline">\(\{0, 1\}\)</span>. Fortunately, we can adapt our linear regression function in this way by defining a <em>cutoff</em> (typically 0), as follows:</p>
<p><span class="math display">\[
f(\mathbf{x})=\mathbf{x}^T\mathbf{w} \quad \longrightarrow \quad f(\mathbf{x})=\begin{cases} 1\ \text{   if   }\ \mathbf{x}^T\mathbf{w} \geq 0 \\
0\ \text{   if   }\ \mathbf{x}^T\mathbf{w} &lt; 0\end{cases}
\]</span></p>
<p>We might also write this as:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \mathbb{I}(\mathbf{x}^T\mathbf{w} \geq 0)
\]</span></p>
<p>Where <span class="math inline">\(\mathbb{I}\)</span> is an <em>indicator function</em> that is <span class="math inline">\(1\)</span> if the boolean expression is true and <span class="math inline">\(0\)</span> otherwise.</p>
<p>This gives us a prediction function that looks like step function in 1 dimension:</p>
<div id="8c5c5b9b" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-6-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="interpreting-parameters" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-parameters">Interpreting parameters</h2>
<p>For our efficiency example, the binary prediction function can be written as:</p>
<p><span class="math display">\[
\text{Meets target} = f(\mathbf{x})=
\]</span></p>
<p><span class="math display">\[
\big((\text{weight})w_1 + (\text{horsepower})w_2 + (\text{displacement})w_3 + (\text{0-60mph})w_4 + b\big) \geq 0
\]</span></p>
<p>Or in matrix notation:</p>
<p><span class="math display">\[
f(\mathbf{x})= \left( \begin{bmatrix} \text{Weight} \\ \text{Horsepower} \\ \text{Displacement} \\ \text{0-60mph} \\ 1 \end{bmatrix} \cdot \begin{bmatrix} w_1 \\ w_2\\ w_3 \\ w_4\\ b\end{bmatrix} \geq  0\right)
\]</span></p>
<p>In this form we can see that the <em>sign</em> of each weight parameter determines whether the corresponding feature is more predictive of label <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span> and to what extent. For instance, large positive weights indicate features that are very predictive of <span class="math inline">\(1\)</span>.</p>
</section>
<section id="geometric-interpretation-of-predictions" class="level2">
<h2 class="anchored" data-anchor-id="geometric-interpretation-of-predictions">Geometric interpretation of predictions</h2>
<p>Our binary prediction function also has a geometric interpretation if we think of <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> as vectors. Reall that the dot product between the vectors <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> can be written as:</p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{w} = ||\mathbf{x}||_2 ||\mathbf{w}||_2 \cos \theta
\]</span></p>
<p>Where <span class="math inline">\(\theta\)</span> is the angle between the two vectors. If the angle between <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> is in the range <span class="math inline">\([-\frac{\pi}{2}, \frac{\pi}{2}]\)</span> (or <span class="math inline">\([-90^o, 90^o]\)</span> in degrees), then the prediction will be <span class="math inline">\(1\)</span>, otherwise it will be 0.</p>
<div id="4e8b72b5" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The blue line in the figure above is the set of points such that:</p>
<p><span class="math display">\[
\mathbf{x}^T \mathbf{w} = 0
\]</span></p>
<p>thus it represents the boundary between the regions where <span class="math inline">\(1\)</span> and <span class="math inline">\(0\)</span> predictions are made. By definition, it is <em>perpendicular</em> to the direction of <span class="math inline">\(\mathbf{w}\)</span>.</p>
</section>
<section id="decision-boundaries" class="level2">
<h2 class="anchored" data-anchor-id="decision-boundaries">Decision boundaries</h2>
<p>We can visualize a classification dataset as a function of two variables using color to distinguish between observations with each label. In this example we’ll look at weight and engine displacement.</p>
<div id="1dbfb33f" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>For a binary classification model the <strong>decision boundary</strong> is the border between regions of the input space corresponding to each prediction that we saw in the previous section. For a linear classification model the decision boundary is line or plane:</p>
<p><span class="math display">\[\mathbf{x}^T\mathbf{w}=0\]</span></p>
<p>Here we’ll plot the decision boundary in the input space and color code observations by the <em>predicted</em> label.</p>
<div id="61b92b4d" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="measuring-error" class="level2">
<h2 class="anchored" data-anchor-id="measuring-error">Measuring error</h2>
<p>A natural measure for error for binary classifiers is <strong>accuracy</strong>. The <em>accuracy</em> of a prediction function is the fraction of observations where the prediction matches the true output:</p>
<p><span class="math display">\[
\textbf{Accuracy: }\quad \frac{\text{\# of correct predictions}}{\text{Total predictions}}
\]</span></p>
<p>We can write this in terms of our prediction function as:</p>
<p><span class="math display">\[
\textbf{Accuracy} = \frac{1}{N} \sum_{i=1}^N \mathbb{I}\big(f(\mathbf{x}_i) = y_i\big)
\]</span></p>
<p>Below we can plot the decision boundary compared to the <em>true</em> outputs and calculate the accuracy of our predictions.</p>
<div id="15de17ef" class="cell" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8291</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-10-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="defining-a-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="defining-a-loss-function">Defining a loss function</h2>
<p>In the last lecture we saw that we can find an optimal choice of parameters <span class="math inline">\(\mathbf{w}\)</span> for a linear regression model by defining a measure of <em>error</em> or <em>loss</em> for our approximation on our dataset and minimizing that error as a function of <span class="math inline">\(\mathbf{w}\)</span>, either directly or with gradient descent.</p>
<p><span class="math display">\[
\mathbf{w}^* = \underset{\mathbf{w}}{\text{argmin}} \ \mathbf{Loss}(\mathbf{w})
\]</span></p>
<p>Gradient descent update:</p>
<p><span class="math display">\[
\mathbf{w}^{(k+1)} \quad \longleftarrow \quad \mathbf{w}^{(k)} - \alpha \nabla_{\mathbf{w}} \mathbf{Loss}(\mathbf{w})
\]</span></p>
<p>We might consider using (negative) accuracy as a loss function or the same mean squared error that we used for linear regression. However, if we tried to minimize one of these losses with gradient descent, we would run into a fundamental problem: the derivative of the indicator function is always <span class="math inline">\(0\)</span>, meaning gradient descent will never update our model.</p>
<p>To get around this problem, we need to turn back to our <em>maximum likelihood estimation</em> approach.</p>
</section>
</section>
<section id="logistic-regression" class="level1 page-columns page-full">
<h1>Logistic Regression</h1>
<section id="the-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-bernoulli-distribution">The Bernoulli distribution</h2>
<p>The <strong>Bernoulli</strong> distribution is a probability distribution over two possible outcomes. It is often thought of as the distribution of a coin flip, where the probability of heads is defined by a <em>parameter</em> <span class="math inline">\(q\)</span> in the range <span class="math inline">\([0,1]\)</span>.</p>
<p><span class="math display">\[
\text{Probability of }\textbf{heads: } \ \ q, \quad \text{Probability of }\textbf{tails: } 1-q
\]</span></p>
<p>Again we typically use <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> to denote the two possible outcomes, so we can write the <em>probability mass function</em> (or <em>likelihood</em>) of the Bernoulli distribution as:</p>
<p><span class="math display">\[
p(y)=\begin{cases} q\quad\ \ \ \ \ \ \  \text{if }\ y=1\\
1-q\quad \text{if }\ y=0\\
\end{cases}\quad q\in[0,1],\ y\in\{0, 1\}
\]</span></p>
<p>Using the fact that <span class="math inline">\(y\)</span> can only be <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>, we can write this more compactly as:</p>
<p><span class="math display">\[
p(y) = q^y(1-q)^{1-y}
\]</span></p>
<p>Recall that the probability mass function tells us the probability of any outcome under our distribution. We can write the log probability mass function as:</p>
<p><span class="math display">\[
\log p(y) = y\log q + (1-y)\log(1-q)
\]</span></p>
</section>
<section id="a-probabilistic-model-for-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-binary-classification">A probabilistic model for binary classification</h2>
<p>In the previous lecture we saw that we could define a <em>probabilistic model</em> for outcomes given inputs by making an strong assumption about how the observed outputs were generated. In particular, we assumed that each <span class="math inline">\(y_i\)</span> was sampled from a Normal distribution where the mean was a linear function of the input <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
<p><span class="math display">\[
y_i \sim \mathcal{N}(\mathbf{x}_i^T\mathbf{w},\ \sigma^2)
\]</span></p>
<p>Given everything we’ve seen, we might want to do the same for binary outputs by defining a probabilistic model where each binary label $y$_i$ is drawn from a Bernoulli where <span class="math inline">\(q\)</span> is a linear function of <span class="math inline">\(\mathbf{x}_i\)</span>. Unfortunately <span class="math inline">\(q\)</span> needs to be restricted to the interval <span class="math inline">\([0,1]\)</span> and a linear function can make no such guarantee about its output.</p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{w}\notin [0, 1] \quad \longrightarrow \quad y_i \sim \mathbf{Bernoulli}(\mathbf{ q=? })\quad
\]</span></p>
<p>However, if we had a way to map the outputs of our linear function into the range <span class="math inline">\([0,1]\)</span>, we could define such a model. This means we need a <em>function</em> of the form:</p>
<p><span class="math display">\[
\textbf{Need }\ g(x):\ \mathbb{R} \longrightarrow [0,1]
\]</span></p>
<p><span class="math display">\[
\textbf{Input: } x \in \mathbb{R} \longrightarrow \textbf{Output: } y \in [0,1]
\]</span></p>
</section>
<section id="sigmoid-function" class="level2">
<h2 class="anchored" data-anchor-id="sigmoid-function">Sigmoid function</h2>
<p>The <strong>sigmoid</strong> (or <strong>logistic</strong>) function is exactly such a function.</p>
<p><span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span></p>
<div id="3eb57f24" class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This “S”-shaped function <em>squashes</em> any real number into the range <span class="math inline">\([0,1]\)</span>. The sigmoid function has a number of other nice properties. It is <em>smooth</em>, <em>monotonic</em> and <em>differentiable</em>. It’s derivative has a convenient form that can be written in terms of the sigmoid function itself.</p>
<p><span class="math display">\[
\frac{d}{dx}\sigma(x) = \sigma(x)\big(1-\sigma(x)\big)
\]</span></p>
<div id="6ab56f9e" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It’s particularly useful for modeling probabilities because:</p>
<p><span class="math display">\[
\sigma(0) = 0.5
\]</span></p>
<p>and</p>
<p><span class="math display">\[
1-\sigma(x) = \sigma(-x)
\]</span></p>
</section>
<section id="a-probabilistic-model-for-binary-classification-1" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-binary-classification-1">A probabilistic model for binary classification</h2>
<p>With the sigmoid as our mapping function, we can now define our linear probabilistic model for binary classification as:</p>
<p><span class="math display">\[
y_i \sim \mathbf{Bernoulli}\big(\mathbf{ \sigma(\mathbf{x}_i^T\mathbf{w} })\big)
\]</span></p>
<p>Using this definition, we can easily write out the probability of each output given the input <span class="math inline">\((\mathbf{x}_i)\)</span> and model parameters <span class="math inline">\((\mathbf{w})\)</span>.</p>
<p><span class="math display">\[
p(y_i = 1\mid \mathbf{x}_i, \mathbf{w}) = \sigma(\mathbf{x}_i^T\mathbf{w}), \quad p(y_i=0\mid \mathbf{x}_i, \mathbf{w})=1-\sigma(\mathbf{x}_i^T\mathbf{w})=\sigma(-\mathbf{x}_i^T\mathbf{w})
\]</span></p>
<p>For our fuel efficiency example, we can plot the predicted probability that our target is met, <span class="math inline">\(p(y=1\mid \mathbf{x}, \mathbf{w})\)</span> under our model as a function of the input (in this case <code>weight</code>). We see that the result is again an s-curve.</p>
<div id="66ed5469" class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We call this probabilistic model for binary outputs: <strong>logistic regression</strong>.</p>
</section>
<section id="logistic-regression-decision-boundary" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-decision-boundary">Logistic regression decision boundary</h2>
<p>When we’re making predictions we typically don’t want to sample an output, we want to make a definite prediction. In this case either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. A reasonable way to do this is to simply predict the output that is most likely under our model:</p>
<p><span class="math display">\[
\textbf{Prediction function: } f(\mathbf{x}) = \begin{cases}1 \ \text{if } p(y=1\mid\mathbf{x}, \mathbf{w}) \geq p(y=0\mid\mathbf{x}, \mathbf{w}) \\
0 \text{ otherwise} \end{cases}
\]</span></p>
<p>Since there’s only two possible outcomes, this is equivalent to checking if the probability of class <span class="math inline">\(1\)</span> is greater than 50%. <span class="math display">\[p(y=1\mid \mathbf{x}, \mathbf{w}) =\sigma(\mathbf{x}^T\mathbf{w})\geq 0.5\]</span></p>
<p>Since <span class="math inline">\(\sigma(0) =0.5\)</span>, we see that this is equivalent to the decision rule for classification we defined earlier!</p>
<p><span class="math display">\[
p(y_i=1)\geq 0.5 \quad \longrightarrow \quad \mathbf{x}^T\mathbf{w}\geq 0
\]</span></p>
</section>
<section id="maximum-likelihood-estimation-review" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-review">Maximum likelihood estimation review</h2>
<p>Now that we’ve setup our model, we can look at how to find the optimal <span class="math inline">\(\mathbf{w}\)</span> using the principle of <em>maximum likelihood estimation</em>.</p>
<div id="362d7776" class="cell" data-execution_count="13">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-14-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section"></h2>
<p>Recall that the <em>maximum likelihood estimate</em> of our parameter <span class="math inline">\(\mathbf{w}\)</span> is the choice of <span class="math inline">\(\mathbf{w}\)</span> that maximizes the (conditional) probability of the data we observed under our model</p>
<p><span class="math display">\[
\mathbf{w}^* = \underset{\mathbf{w}}{\text{argmax}} \ p(\mathbf{y} \mid \mathbf{X}, \mathbf{w}) =\underset{\mathbf{w}}{\text{argmax}} \ p(y_1,...,y_N \mid \mathbf{x}_1, ...,\mathbf{x}_N, \mathbf{w}) \]</span></p>
<p>Again, our model also assumes <em>conditional independence</em> across observations so:</p>
<p><span class="math display">\[
p(y_1,...,y_N \mid \mathbf{x}_1, ...,\mathbf{x}_N, \mathbf{w}) = \prod_{i=1}^N p(y_i\mid \mathbf{x}_i, \mathbf{w})
\]</span></p>
<p>For convenience, it is typical to frame the optimal value in terms of the <em>negative log-likelihood</em> rather than the likelihood, but the two are equivalent.</p>
<p><span class="math display">\[
\underset{\mathbf{w}}{\text{argmax}} \prod_{i=1}^N p(y_i\mid \mathbf{x}_i, \mathbf{w}) = \underset{\mathbf{w}}{\text{argmin}} - \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{w}) = \textbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y})
\]</span></p>
<p>Thus, the negative log-likelihood is a natural <em>loss function</em> to optimize to find <span class="math inline">\(\mathbf{w}^*\)</span>.</p>
<p><span class="math display">\[
\textbf{Loss}(\mathbf{w}) =\textbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y})=- \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{w})
\]</span></p>
</section>
<section id="maximum-likelihood-for-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-for-logistic-regression">Maximum likelihood for logistic regression</h2>
<p>We can now write out the negative log-likelihood for our logistic regression model using the Bernoulli PMF we defined above</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N \bigg[ y_i\log \sigma(\mathbf{x}_i^T\mathbf{w}) + (1-y_i)\log(1-\sigma(\mathbf{x}_i^T\mathbf{w})) \bigg]
\]</span></p>
<p>Using our knowledge of the sigmoid function, we can write this even more compactly:</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) =-\sum_{i=1}^N \bigg[ y_i\log \sigma(\mathbf{x}_i^T\mathbf{w}) + (1-y_i)\log \sigma(-\mathbf{x}_i^T\mathbf{w}) \bigg]
\]</span></p>
<p><span class="math display">\[
= -\sum_{i=1}^N \log\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>Note that <span class="math inline">\(2y_i-1\)</span> is <span class="math inline">\(1\)</span> if <span class="math inline">\(y_i=1\)</span> and is <span class="math inline">\(-1\)</span> if <span class="math inline">\(y_i=0\)</span>.</p>
<p>For our logistic regression model, maximum likelihood is intuitive. In the ideal case our model would always predict the correct class with probability 1.</p>
<p><span class="math display">\[
\textbf{Best case scenerio: } p(y_i\mid \mathbf{x}_i, \mathbf{w})=1, \quad \forall i \in \{1,...,N\}
\]</span></p>
<p>This is generally not possible though due to the constraints of our linear function.</p>
<p>We can also write the negative log-likelihood compactly using matrix-vector notation.</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\mathbf{y}^T\log \sigma(\mathbf{X}\mathbf{w}) - (1-\mathbf{y})^T\log \sigma(-\mathbf{X}\mathbf{w})
\]</span></p>
<p>It’s worth noting that in neural network literature, this loss is often called the <strong>binary cross-entropy loss</strong>.</p>
</section>
<section id="optimizing-logistic-regression" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="optimizing-logistic-regression">Optimizing logistic regression</h2>
<p>As we saw with linear regression, we can find the optimal paramters <span class="math inline">\(\mathbf{w}^*\)</span> under this loss function using gradient descent:<br>
<span class="math display">\[
\mathbf{w}^{(i+1)} \leftarrow \mathbf{w}^{(i)} - \alpha \nabla_{\mathbf{w}} \mathbf{NLL}(\mathbf{w}^{(i)}, \mathbf{X}, \mathbf{y})
\]</span></p>
<p>To use this, we first need to derive the gradient of the negative log-likelihood with respect to <span class="math inline">\(\mathbf{w}\)</span>. We’ll start by writing out the simplest version of the NLL that we saw above:</p>
<p><span class="math display">\[
\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N \log\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p><span class="math display">\[
\nabla_{\mathbf{w}}\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = \frac{d}{d\mathbf{w}}-\sum_{i=1}^N \log\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>As a first step, recall that the addition rule tells us that the derivative of a sum is a sum of derivatives:</p>
<p><span class="math display">\[
= -\sum_{i=1}^N \frac{d}{d\mathbf{w}} \log\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>Next we’ll apply the chain rule to the <span class="math inline">\(\log\)</span> function, remembering that <span class="math inline">\(\frac{d}{dx} \log x = \frac{1}{x}\)</span>:</p>
<p><span class="math display">\[
= -\sum_{i=1}^N \bigg(\frac{1}{ \sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big) }\bigg)\frac{d}{d\mathbf{w}} \sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>Then we can apply the chain rule to the sigmoid function, using the fact that <span class="math inline">\(\frac{d}{dx} \sigma(x)=\sigma(x)(1-\sigma(x))\)</span>:</p>
<p><span class="math display">\[
= -\sum_{i=1}^N \bigg(\frac{1}{ \sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big) } \bigg)
\bigg(\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)\bigg) \bigg(1-\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)  \bigg)
\frac{d}{d\mathbf{w}}\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>We now see that the first 2 terms cancel!</p>
<p><span class="math display">\[
= -\sum_{i=1}^N  \bigg(1-\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)  \bigg)
\frac{d}{d\mathbf{w}}\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)
\]</span></p>
<p>Finally we’re left with the gradient of a linear function, which is just:</p>
<p><span class="math display">\[\frac{d}{d\mathbf{w}}\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)=(2y_i-1)\mathbf{x}_i\]</span></p>
<p>Note that the transpose is irrelevant as we’re no longer signifying a dot-product and <span class="math inline">\(\mathbf{x}_i\)</span> is just a vector. So finally we’re left with</p>
<p><span class="math display">\[
\nabla_{\mathbf{w}}\mathbf{NLL}(\mathbf{w}, \mathbf{X}, \mathbf{y}) = -\sum_{i=1}^N  \bigg(1-\sigma\big((2y_i-1)\mathbf{x}_i^T\mathbf{w}\big)  \bigg)
\bigg((2y_i-1)\mathbf{x}_i \bigg)
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb2" data-startfrom="2" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 1;"><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>MathJax <span class="op">=</span> {</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> MathJax <span class="op">=</span> <span class="cf">await</span> <span class="pp">require</span>(<span class="st">'mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> <span class="bu">window</span><span class="op">.</span><span class="at">MathJax</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">// configure MathJax</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  MathJax<span class="op">.</span><span class="at">Hub</span><span class="op">.</span><span class="fu">Config</span>({</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">tex2jax</span><span class="op">:</span> {<span class="dt">inlineMath</span><span class="op">:</span> [[<span class="st">'$'</span><span class="op">,</span><span class="st">'$'</span>]<span class="op">,</span> [<span class="st">'</span><span class="sc">\\</span><span class="st">('</span><span class="op">,</span><span class="st">'</span><span class="sc">\\</span><span class="st">)'</span>]]}<span class="op">,</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">displayMath</span><span class="op">:</span> [ [<span class="st">'$$'</span><span class="op">,</span><span class="st">'$$'</span>]<span class="op">,</span> [<span class="st">"</span><span class="sc">\\</span><span class="st">["</span><span class="op">,</span><span class="st">"</span><span class="sc">\\</span><span class="st">]"</span>] ]<span class="op">,</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">processEscapes</span><span class="op">:</span> <span class="kw">true</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  })  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> MathJax</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>Plotly <span class="op">=</span> <span class="pp">require</span>(<span class="st">"https://cdn.plot.ly/plotly-latest.min.js"</span>)<span class="op">;</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>tfbase <span class="op">=</span> <span class="pp">require</span>(<span class="st">'@tensorflow/tfjs@4.11.0'</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>pyodide <span class="op">=</span> {</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> p <span class="op">=</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> <span class="pp">require</span>(<span class="st">"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js"</span>)<span class="op">;</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="bu">console</span><span class="op">.</span><span class="fu">log</span>(p)<span class="op">;</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> p<span class="op">.</span><span class="fu">loadPyodide</span>()<span class="op">;</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>PyScope <span class="op">=</span> <span class="kw">function</span>() {</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> scope <span class="op">=</span> pyodide<span class="op">.</span><span class="fu">toPy</span>({})<span class="op">;</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> py <span class="op">=</span> <span class="kw">async</span> (strings<span class="op">,</span> <span class="op">...</span>expressions) <span class="kw">=&gt;</span> {</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> globals <span class="op">=</span> {}<span class="op">;</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> code <span class="op">=</span> strings<span class="op">.</span><span class="fu">reduce</span>((result<span class="op">,</span> string<span class="op">,</span> index) <span class="kw">=&gt;</span> {</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (expressions[index]) {</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> name <span class="op">=</span> <span class="vs">`x</span><span class="sc">${</span>index<span class="sc">}</span><span class="vs">`</span><span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        globals[name] <span class="op">=</span> expressions[index]<span class="op">;</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result <span class="op">+</span> string <span class="op">+</span> name<span class="op">;</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> result <span class="op">+</span> string<span class="op">;</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    }<span class="op">,</span> <span class="st">''</span>)<span class="op">;</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">loadPackagesFromImports</span>(code)<span class="op">;</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    scope<span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="at">globals</span>)<span class="op">;</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> result <span class="op">=</span> <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">runPythonAsync</span>(</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>      code<span class="op">,</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        <span class="dt">globals</span><span class="op">:</span> scope</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">t2Js</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">t2Js</span>()<span class="op">;</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">toJs</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">toJs</span>()<span class="op">;</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result<span class="op">;</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> py<span class="op">;</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>py <span class="op">=</span> {</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> testscope <span class="op">=</span> <span class="fu">PyScope</span>()<span class="op">;</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> py <span class="op">=</span> <span class="kw">async</span> (strings<span class="op">,</span> <span class="op">...</span>expressions) <span class="kw">=&gt;</span> {</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> globals <span class="op">=</span> {}<span class="op">;</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> code <span class="op">=</span> strings<span class="op">.</span><span class="fu">reduce</span>((result<span class="op">,</span> string<span class="op">,</span> index) <span class="kw">=&gt;</span> {</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (expressions[index]) {</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> name <span class="op">=</span> <span class="vs">`x</span><span class="sc">${</span>index<span class="sc">}</span><span class="vs">`</span><span class="op">;</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        globals[name] <span class="op">=</span> expressions[index]<span class="op">;</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result <span class="op">+</span> string <span class="op">+</span> name<span class="op">;</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> result <span class="op">+</span> string<span class="op">;</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>    }<span class="op">,</span> <span class="st">''</span>)<span class="op">;</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">loadPackagesFromImports</span>(code)<span class="op">;</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    pyodide<span class="op">.</span><span class="at">globals</span><span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="fu">toPy</span>(globals))</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> result <span class="op">=</span> <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">runPythonAsync</span>(</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>      code<span class="op">,</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>      {<span class="dt">globals</span><span class="op">:</span> pyodide<span class="op">.</span><span class="at">globals</span>}</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">t2Js</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">t2Js</span>()<span class="op">;</span></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">toJs</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">toJs</span>()<span class="op">;</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result<span class="op">;</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> sigmoidGradConfig  <span class="op">=</span> {</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Sigmoid</span><span class="op">,</span></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">sigmoid</span>(x)<span class="op">;</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(dy<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">mul</span>(y<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">sub</span>(tfbase<span class="op">.</span><span class="fu">scalar</span>(<span class="dv">1</span>)<span class="op">,</span> y)))}<span class="op">;</span></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(sigmoidGradConfig)<span class="op">;</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> tanhGradConfig <span class="op">=</span> {</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Tanh</span><span class="op">,</span></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">tanh</span>(x)<span class="op">;</span></span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(tfbase<span class="op">.</span><span class="fu">sub</span>(tfbase<span class="op">.</span><span class="fu">scalar</span>(<span class="dv">1</span>)<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">square</span>(y))<span class="op">,</span> dy)}<span class="op">;</span></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(tanhGradConfig)<span class="op">;</span></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>   <span class="kw">const</span> expGradConfig <span class="op">=</span> {</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Exp</span><span class="op">,</span></span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">exp</span>(x)<span class="op">;</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(dy<span class="op">,</span> y)}<span class="op">;</span></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span> </span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(expGradConfig)<span class="op">;</span></span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">dispatchEvent</span>(element){</span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>    element<span class="op">.</span><span class="fu">dispatchEvent</span>(<span class="kw">new</span> <span class="bu">Event</span>(<span class="st">"input"</span><span class="op">,</span> {<span class="dt">bubbles</span><span class="op">:</span> <span class="kw">true</span>}))<span class="op">;</span></span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>  pyodide<span class="op">.</span><span class="at">globals</span><span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="fu">toPy</span>({<span class="dt">Plotbase</span><span class="op">:</span> Plot<span class="op">,</span> <span class="dt">tfbase</span><span class="op">:</span> tfbase<span class="op">,</span> <span class="dt">Plotlybase</span><span class="op">:</span> Plotly<span class="op">,</span> <span class="dt">dispatchEvent</span><span class="op">:</span> dispatchEvent<span class="op">,</span> <span class="dt">d3base</span><span class="op">:</span> d3}))</span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a><span class="cf">await</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a><span class="vs">from pyodide.ffi import create_once_callable</span></span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a><span class="vs">from types import SimpleNamespace</span></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a><span class="vs">from pyodide.ffi import to_js</span></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a><span class="vs">from js import Object, document</span></span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a><span class="vs">import pandas</span></span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a><span class="vs">import numpy as np</span></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a><span class="vs">tfbase = SimpleNamespace(**tfbase)</span></span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_tensor(a, *args):</span></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Parameter):</span></span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value.value</span></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Tensor):</span></span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value</span></span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, np.ndarray):</span></span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.tolist()</span></span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a)</span></span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert(a):</span></span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Parameter):</span></span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value.value</span></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Tensor):</span></span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value</span></span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, np.ndarray):</span></span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.tolist()</span></span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)</span></span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_start(shape, start):</span></span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = start or 0</span></span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a><span class="vs">  if start &lt; 0:</span></span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a><span class="vs">    start = shape + start</span></span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = min(start, shape - 1)</span></span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a><span class="vs">  return start</span></span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_end(shape, start, end): </span></span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = convert_start(shape, start)</span></span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a><span class="vs">  if end is None:</span></span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a><span class="vs">    end = shape</span></span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a><span class="vs">    end = convert_start(shape, end)</span></span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a><span class="vs">  return end - start</span></span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a><span class="vs">class Tensor:</span></span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a><span class="vs">  keepall = False</span></span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a><span class="vs">  class Keep:</span></span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __enter__(self):</span></span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.value = Tensor.keepall</span></span>
<span id="cb2-162"><a href="#cb2-162" aria-hidden="true" tabindex="-1"></a><span class="vs">        Tensor.keepall = True</span></span>
<span id="cb2-163"><a href="#cb2-163" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-164"><a href="#cb2-164" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __exit__(self, *args):</span></span>
<span id="cb2-165"><a href="#cb2-165" aria-hidden="true" tabindex="-1"></a><span class="vs">        Tensor.keepall = self.value</span></span>
<span id="cb2-166"><a href="#cb2-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-167"><a href="#cb2-167" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, *args, value=None, keep=None, **kwargs):</span></span>
<span id="cb2-168"><a href="#cb2-168" aria-hidden="true" tabindex="-1"></a><span class="vs">    if keep is None:</span></span>
<span id="cb2-169"><a href="#cb2-169" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.keep = Tensor.keepall</span></span>
<span id="cb2-170"><a href="#cb2-170" aria-hidden="true" tabindex="-1"></a><span class="vs">    else:</span></span>
<span id="cb2-171"><a href="#cb2-171" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.keep = keep</span></span>
<span id="cb2-172"><a href="#cb2-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-173"><a href="#cb2-173" aria-hidden="true" tabindex="-1"></a><span class="vs">    if not (value is None):</span></span>
<span id="cb2-174"><a href="#cb2-174" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = value</span></span>
<span id="cb2-175"><a href="#cb2-175" aria-hidden="true" tabindex="-1"></a><span class="vs">    elif len(args) and isinstance(args[0], Tensor):</span></span>
<span id="cb2-176"><a href="#cb2-176" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.add(args[0].value, 0)</span></span>
<span id="cb2-177"><a href="#cb2-177" aria-hidden="true" tabindex="-1"></a><span class="vs">    elif len(args) and args[0] is None:</span></span>
<span id="cb2-178"><a href="#cb2-178" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.tensor(0.)</span></span>
<span id="cb2-179"><a href="#cb2-179" aria-hidden="true" tabindex="-1"></a><span class="vs">    else:</span></span>
<span id="cb2-180"><a href="#cb2-180" aria-hidden="true" tabindex="-1"></a><span class="vs">      args = [convert(a) for a in args]</span></span>
<span id="cb2-181"><a href="#cb2-181" aria-hidden="true" tabindex="-1"></a><span class="vs">      kwargs = {k: convert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb2-182"><a href="#cb2-182" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.tensor(*args, **kwargs)</span></span>
<span id="cb2-183"><a href="#cb2-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-184"><a href="#cb2-184" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getattr__(self, name):</span></span>
<span id="cb2-185"><a href="#cb2-185" aria-hidden="true" tabindex="-1"></a><span class="vs">    if name == 'T':</span></span>
<span id="cb2-186"><a href="#cb2-186" aria-hidden="true" tabindex="-1"></a><span class="vs">      return self.transpose()</span></span>
<span id="cb2-187"><a href="#cb2-187" aria-hidden="true" tabindex="-1"></a><span class="vs">    attr = getattr(self.value, name)</span></span>
<span id="cb2-188"><a href="#cb2-188" aria-hidden="true" tabindex="-1"></a><span class="vs">    if callable(attr):</span></span>
<span id="cb2-189"><a href="#cb2-189" aria-hidden="true" tabindex="-1"></a><span class="vs">      def run(*args, **kwargs):</span></span>
<span id="cb2-190"><a href="#cb2-190" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = [convert(a) for a in args]</span></span>
<span id="cb2-191"><a href="#cb2-191" aria-hidden="true" tabindex="-1"></a><span class="vs">        kwargs = {k: convert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb2-192"><a href="#cb2-192" aria-hidden="true" tabindex="-1"></a><span class="vs">        output = attr(*args, **kwargs)</span></span>
<span id="cb2-193"><a href="#cb2-193" aria-hidden="true" tabindex="-1"></a><span class="vs">        return Tensor(value=output)</span></span>
<span id="cb2-194"><a href="#cb2-194" aria-hidden="true" tabindex="-1"></a><span class="vs">      # Prevent premature garbage collection</span></span>
<span id="cb2-195"><a href="#cb2-195" aria-hidden="true" tabindex="-1"></a><span class="vs">      run._ref = self</span></span>
<span id="cb2-196"><a href="#cb2-196" aria-hidden="true" tabindex="-1"></a><span class="vs">      return run</span></span>
<span id="cb2-197"><a href="#cb2-197" aria-hidden="true" tabindex="-1"></a><span class="vs">    return attr</span></span>
<span id="cb2-198"><a href="#cb2-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-199"><a href="#cb2-199" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __add__(a, b):</span></span>
<span id="cb2-200"><a href="#cb2-200" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.add(convert(a), convert(b)))</span></span>
<span id="cb2-201"><a href="#cb2-201" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __radd__(a, b):</span></span>
<span id="cb2-202"><a href="#cb2-202" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.add(convert(b), convert(a)))</span></span>
<span id="cb2-203"><a href="#cb2-203" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __sub__(a, b):</span></span>
<span id="cb2-204"><a href="#cb2-204" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.sub(convert(a), convert(b)))</span></span>
<span id="cb2-205"><a href="#cb2-205" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rsub__(a, b):</span></span>
<span id="cb2-206"><a href="#cb2-206" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.sub(convert(b), convert(a)))</span></span>
<span id="cb2-207"><a href="#cb2-207" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __mul__(a, b):</span></span>
<span id="cb2-208"><a href="#cb2-208" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.mul(convert(a), convert(b)))</span></span>
<span id="cb2-209"><a href="#cb2-209" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rmul__(a, b):</span></span>
<span id="cb2-210"><a href="#cb2-210" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.mul(convert(b), convert(a)))</span></span>
<span id="cb2-211"><a href="#cb2-211" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __truediv__(a, b):</span></span>
<span id="cb2-212"><a href="#cb2-212" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.div(convert(a), convert(b)))</span></span>
<span id="cb2-213"><a href="#cb2-213" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rtruediv__(a, b):</span></span>
<span id="cb2-214"><a href="#cb2-214" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.div(convert(b), convert(a)))</span></span>
<span id="cb2-215"><a href="#cb2-215" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __floordiv__(a, b):</span></span>
<span id="cb2-216"><a href="#cb2-216" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))</span></span>
<span id="cb2-217"><a href="#cb2-217" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rfloordiv__(a, b):</span></span>
<span id="cb2-218"><a href="#cb2-218" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))</span></span>
<span id="cb2-219"><a href="#cb2-219" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __pow__(a, b):</span></span>
<span id="cb2-220"><a href="#cb2-220" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.pow(convert(a), convert(b)))</span></span>
<span id="cb2-221"><a href="#cb2-221" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rpow__(a, b):</span></span>
<span id="cb2-222"><a href="#cb2-222" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.pow(convert(b), convert(a)))</span></span>
<span id="cb2-223"><a href="#cb2-223" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __neg__(a):</span></span>
<span id="cb2-224"><a href="#cb2-224" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.neg(convert(a)))</span></span>
<span id="cb2-225"><a href="#cb2-225" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __eq__(a, b):</span></span>
<span id="cb2-226"><a href="#cb2-226" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.equal(convert(a), convert(b)))</span></span>
<span id="cb2-227"><a href="#cb2-227" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __neq__(a, b):</span></span>
<span id="cb2-228"><a href="#cb2-228" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))</span></span>
<span id="cb2-229"><a href="#cb2-229" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __lt__(a, b):</span></span>
<span id="cb2-230"><a href="#cb2-230" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.less(convert(a), convert(b)))</span></span>
<span id="cb2-231"><a href="#cb2-231" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __gt__(a, b):</span></span>
<span id="cb2-232"><a href="#cb2-232" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.greater(convert(a), convert(b)))</span></span>
<span id="cb2-233"><a href="#cb2-233" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __leq__(a, b):</span></span>
<span id="cb2-234"><a href="#cb2-234" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))</span></span>
<span id="cb2-235"><a href="#cb2-235" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __geq__(a, b):</span></span>
<span id="cb2-236"><a href="#cb2-236" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))</span></span>
<span id="cb2-237"><a href="#cb2-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-238"><a href="#cb2-238" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __del__(self):</span></span>
<span id="cb2-239"><a href="#cb2-239" aria-hidden="true" tabindex="-1"></a><span class="vs">    if hasattr(self.value, 'dispose') and not self.keep:</span></span>
<span id="cb2-240"><a href="#cb2-240" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value.dispose()</span></span>
<span id="cb2-241"><a href="#cb2-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-242"><a href="#cb2-242" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __iter__(self):</span></span>
<span id="cb2-243"><a href="#cb2-243" aria-hidden="true" tabindex="-1"></a><span class="vs">    for x in self.value.arraySync():</span></span>
<span id="cb2-244"><a href="#cb2-244" aria-hidden="true" tabindex="-1"></a><span class="vs">        yield Tensor(x)</span></span>
<span id="cb2-245"><a href="#cb2-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-246"><a href="#cb2-246" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getitem__(self, args):</span></span>
<span id="cb2-247"><a href="#cb2-247" aria-hidden="true" tabindex="-1"></a><span class="vs">    tosqueeze = []</span></span>
<span id="cb2-248"><a href="#cb2-248" aria-hidden="true" tabindex="-1"></a><span class="vs">    starts, ends, steps = [], [], []</span></span>
<span id="cb2-249"><a href="#cb2-249" aria-hidden="true" tabindex="-1"></a><span class="vs">    value = self</span></span>
<span id="cb2-250"><a href="#cb2-250" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-251"><a href="#cb2-251" aria-hidden="true" tabindex="-1"></a><span class="vs">    if not (type(args) is tuple):</span></span>
<span id="cb2-252"><a href="#cb2-252" aria-hidden="true" tabindex="-1"></a><span class="vs">      args = (args,)</span></span>
<span id="cb2-253"><a href="#cb2-253" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-254"><a href="#cb2-254" aria-hidden="true" tabindex="-1"></a><span class="vs">    for ind in range(len(args)):</span></span>
<span id="cb2-255"><a href="#cb2-255" aria-hidden="true" tabindex="-1"></a><span class="vs">      if args[ind] is Ellipsis:</span></span>
<span id="cb2-256"><a href="#cb2-256" aria-hidden="true" tabindex="-1"></a><span class="vs">        start = args[:ind]</span></span>
<span id="cb2-257"><a href="#cb2-257" aria-hidden="true" tabindex="-1"></a><span class="vs">        rest = args[(ind + 1):]</span></span>
<span id="cb2-258"><a href="#cb2-258" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest</span></span>
<span id="cb2-259"><a href="#cb2-259" aria-hidden="true" tabindex="-1"></a><span class="vs">        break</span></span>
<span id="cb2-260"><a href="#cb2-260" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-261"><a href="#cb2-261" aria-hidden="true" tabindex="-1"></a><span class="vs">    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):</span></span>
<span id="cb2-262"><a href="#cb2-262" aria-hidden="true" tabindex="-1"></a><span class="vs">      if isinstance(dim, slice):</span></span>
<span id="cb2-263"><a href="#cb2-263" aria-hidden="true" tabindex="-1"></a><span class="vs">        starts.append(dim.start or 0)</span></span>
<span id="cb2-264"><a href="#cb2-264" aria-hidden="true" tabindex="-1"></a><span class="vs">        ends.append(dim.stop or shape)</span></span>
<span id="cb2-265"><a href="#cb2-265" aria-hidden="true" tabindex="-1"></a><span class="vs">        steps.append(dim.step or 1)</span></span>
<span id="cb2-266"><a href="#cb2-266" aria-hidden="true" tabindex="-1"></a><span class="vs">      elif Tensor(dim).shape:</span></span>
<span id="cb2-267"><a href="#cb2-267" aria-hidden="true" tabindex="-1"></a><span class="vs">        t = Tensor(dim)</span></span>
<span id="cb2-268"><a href="#cb2-268" aria-hidden="true" tabindex="-1"></a><span class="vs">        if t.value.dtype == 'bool':</span></span>
<span id="cb2-269"><a href="#cb2-269" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]</span></span>
<span id="cb2-270"><a href="#cb2-270" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')</span></span>
<span id="cb2-271"><a href="#cb2-271" aria-hidden="true" tabindex="-1"></a><span class="vs">          value = tf.gather(value, inds, i)</span></span>
<span id="cb2-272"><a href="#cb2-272" aria-hidden="true" tabindex="-1"></a><span class="vs">        else:</span></span>
<span id="cb2-273"><a href="#cb2-273" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = tf.cast(tf.reshape(t, [-1]), 'int32')</span></span>
<span id="cb2-274"><a href="#cb2-274" aria-hidden="true" tabindex="-1"></a><span class="vs">          value = tf.gather(value, inds, i)</span></span>
<span id="cb2-275"><a href="#cb2-275" aria-hidden="true" tabindex="-1"></a><span class="vs">      else:</span></span>
<span id="cb2-276"><a href="#cb2-276" aria-hidden="true" tabindex="-1"></a><span class="vs">        starts.append(dim)</span></span>
<span id="cb2-277"><a href="#cb2-277" aria-hidden="true" tabindex="-1"></a><span class="vs">        ends.append(dim + 1)</span></span>
<span id="cb2-278"><a href="#cb2-278" aria-hidden="true" tabindex="-1"></a><span class="vs">        steps.append(1)</span></span>
<span id="cb2-279"><a href="#cb2-279" aria-hidden="true" tabindex="-1"></a><span class="vs">        tosqueeze.append(i)</span></span>
<span id="cb2-280"><a href="#cb2-280" aria-hidden="true" tabindex="-1"></a><span class="vs">    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))</span></span>
<span id="cb2-281"><a href="#cb2-281" aria-hidden="true" tabindex="-1"></a><span class="vs">    if len(tosqueeze) &gt; 0:</span></span>
<span id="cb2-282"><a href="#cb2-282" aria-hidden="true" tabindex="-1"></a><span class="vs">      value = tf.squeeze(value, tosqueeze)</span></span>
<span id="cb2-283"><a href="#cb2-283" aria-hidden="true" tabindex="-1"></a><span class="vs">    return value</span></span>
<span id="cb2-284"><a href="#cb2-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-285"><a href="#cb2-285" aria-hidden="true" tabindex="-1"></a><span class="vs">  def t2Js(self):</span></span>
<span id="cb2-286"><a href="#cb2-286" aria-hidden="true" tabindex="-1"></a><span class="vs">    return to_js(self.value.arraySync())</span></span>
<span id="cb2-287"><a href="#cb2-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-288"><a href="#cb2-288" aria-hidden="true" tabindex="-1"></a><span class="vs">class wrapper:</span></span>
<span id="cb2-289"><a href="#cb2-289" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb2-290"><a href="#cb2-290" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb2-291"><a href="#cb2-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-292"><a href="#cb2-292" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, x, *args, **kwargs):</span></span>
<span id="cb2-293"><a href="#cb2-293" aria-hidden="true" tabindex="-1"></a><span class="vs">    with Tensor.Keep():</span></span>
<span id="cb2-294"><a href="#cb2-294" aria-hidden="true" tabindex="-1"></a><span class="vs">      return convert(self.f(Tensor(value=x), *args, **kwargs))</span></span>
<span id="cb2-295"><a href="#cb2-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-296"><a href="#cb2-296" aria-hidden="true" tabindex="-1"></a><span class="vs">class grad:</span></span>
<span id="cb2-297"><a href="#cb2-297" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb2-298"><a href="#cb2-298" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb2-299"><a href="#cb2-299" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.wrapper = wrapper(f)</span></span>
<span id="cb2-300"><a href="#cb2-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-301"><a href="#cb2-301" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, x, *args, **kwargs):</span></span>
<span id="cb2-302"><a href="#cb2-302" aria-hidden="true" tabindex="-1"></a><span class="vs">    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)</span></span>
<span id="cb2-303"><a href="#cb2-303" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=output)</span></span>
<span id="cb2-304"><a href="#cb2-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-305"><a href="#cb2-305" aria-hidden="true" tabindex="-1"></a><span class="vs">class wrappers:</span></span>
<span id="cb2-306"><a href="#cb2-306" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb2-307"><a href="#cb2-307" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb2-308"><a href="#cb2-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-309"><a href="#cb2-309" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, *args):</span></span>
<span id="cb2-310"><a href="#cb2-310" aria-hidden="true" tabindex="-1"></a><span class="vs">    with Tensor.Keep():</span></span>
<span id="cb2-311"><a href="#cb2-311" aria-hidden="true" tabindex="-1"></a><span class="vs">      wrapped_args = [Tensor(value=x) for x in args]</span></span>
<span id="cb2-312"><a href="#cb2-312" aria-hidden="true" tabindex="-1"></a><span class="vs">      return convert(self.f(*wrapped_args))</span></span>
<span id="cb2-313"><a href="#cb2-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-314"><a href="#cb2-314" aria-hidden="true" tabindex="-1"></a><span class="vs">class grads:</span></span>
<span id="cb2-315"><a href="#cb2-315" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb2-316"><a href="#cb2-316" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb2-317"><a href="#cb2-317" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.wrapper = wrappers(f)</span></span>
<span id="cb2-318"><a href="#cb2-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-319"><a href="#cb2-319" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, *args):</span></span>
<span id="cb2-320"><a href="#cb2-320" aria-hidden="true" tabindex="-1"></a><span class="vs">    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))</span></span>
<span id="cb2-321"><a href="#cb2-321" aria-hidden="true" tabindex="-1"></a><span class="vs">    return [Tensor(value=x) for x in output]</span></span>
<span id="cb2-322"><a href="#cb2-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-323"><a href="#cb2-323" aria-hidden="true" tabindex="-1"></a><span class="vs">tf = Tensor(value=tfbase)</span></span>
<span id="cb2-324"><a href="#cb2-324" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotbase = SimpleNamespace(**Plotbase)</span></span>
<span id="cb2-325"><a href="#cb2-325" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotlybase = SimpleNamespace(**Plotlybase)</span></span>
<span id="cb2-326"><a href="#cb2-326" aria-hidden="true" tabindex="-1"></a><span class="vs">d3base = SimpleNamespace(**d3base)</span></span>
<span id="cb2-327"><a href="#cb2-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-328"><a href="#cb2-328" aria-hidden="true" tabindex="-1"></a><span class="vs">def meshgrid(*args):</span></span>
<span id="cb2-329"><a href="#cb2-329" aria-hidden="true" tabindex="-1"></a><span class="vs">  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])</span></span>
<span id="cb2-330"><a href="#cb2-330" aria-hidden="true" tabindex="-1"></a><span class="vs">tf.meshgrid = meshgrid</span></span>
<span id="cb2-331"><a href="#cb2-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-332"><a href="#cb2-332" aria-hidden="true" tabindex="-1"></a><span class="vs">def default_convert(obj, default_f, other):</span></span>
<span id="cb2-333"><a href="#cb2-333" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(obj, Tensor):</span></span>
<span id="cb2-334"><a href="#cb2-334" aria-hidden="true" tabindex="-1"></a><span class="vs">    obj = obj.t2Js()</span></span>
<span id="cb2-335"><a href="#cb2-335" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(obj, pandas.DataFrame):</span></span>
<span id="cb2-336"><a href="#cb2-336" aria-hidden="true" tabindex="-1"></a><span class="vs">    obj = obj.to_dict('records') </span></span>
<span id="cb2-337"><a href="#cb2-337" aria-hidden="true" tabindex="-1"></a><span class="vs">  return default_f(obj)</span></span>
<span id="cb2-338"><a href="#cb2-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-339"><a href="#cb2-339" aria-hidden="true" tabindex="-1"></a><span class="vs">def plotconvert(a):</span></span>
<span id="cb2-340"><a href="#cb2-340" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)</span></span>
<span id="cb2-341"><a href="#cb2-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-342"><a href="#cb2-342" aria-hidden="true" tabindex="-1"></a><span class="vs">class PlotWrapper:</span></span>
<span id="cb2-343"><a href="#cb2-343" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, base=None):</span></span>
<span id="cb2-344"><a href="#cb2-344" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.base = base</span></span>
<span id="cb2-345"><a href="#cb2-345" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-346"><a href="#cb2-346" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getattr__(self, name):</span></span>
<span id="cb2-347"><a href="#cb2-347" aria-hidden="true" tabindex="-1"></a><span class="vs">    attr = getattr(self.base, name)</span></span>
<span id="cb2-348"><a href="#cb2-348" aria-hidden="true" tabindex="-1"></a><span class="vs">    if callable(attr):</span></span>
<span id="cb2-349"><a href="#cb2-349" aria-hidden="true" tabindex="-1"></a><span class="vs">      def run(*args, **kwargs):</span></span>
<span id="cb2-350"><a href="#cb2-350" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = [plotconvert(a) for a in args]</span></span>
<span id="cb2-351"><a href="#cb2-351" aria-hidden="true" tabindex="-1"></a><span class="vs">        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb2-352"><a href="#cb2-352" aria-hidden="true" tabindex="-1"></a><span class="vs">        return attr(*args, **kwargs)</span></span>
<span id="cb2-353"><a href="#cb2-353" aria-hidden="true" tabindex="-1"></a><span class="vs">      return run</span></span>
<span id="cb2-354"><a href="#cb2-354" aria-hidden="true" tabindex="-1"></a><span class="vs">    return attr</span></span>
<span id="cb2-355"><a href="#cb2-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-356"><a href="#cb2-356" aria-hidden="true" tabindex="-1"></a><span class="vs">Plot = PlotWrapper(Plotbase)</span></span>
<span id="cb2-357"><a href="#cb2-357" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotly = PlotWrapper(Plotlybase)</span></span>
<span id="cb2-358"><a href="#cb2-358" aria-hidden="true" tabindex="-1"></a><span class="vs">d3 = PlotWrapper(d3base)</span></span>
<span id="cb2-359"><a href="#cb2-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-360"><a href="#cb2-360" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):</span></span>
<span id="cb2-361"><a href="#cb2-361" aria-hidden="true" tabindex="-1"></a><span class="vs">  if height is None:</span></span>
<span id="cb2-362"><a href="#cb2-362" aria-hidden="true" tabindex="-1"></a><span class="vs">    height = 0.75 * width</span></span>
<span id="cb2-363"><a href="#cb2-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-364"><a href="#cb2-364" aria-hidden="true" tabindex="-1"></a><span class="vs">  width, height = int(width), int(height)</span></span>
<span id="cb2-365"><a href="#cb2-365" aria-hidden="true" tabindex="-1"></a><span class="vs">  container = document.createElement('div')</span></span>
<span id="cb2-366"><a href="#cb2-366" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.style.width = str(width) + 'px'</span></span>
<span id="cb2-367"><a href="#cb2-367" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.style.height = str(height) + 'px'</span></span>
<span id="cb2-368"><a href="#cb2-368" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb2-369"><a href="#cb2-369" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot = document.createElement('div')</span></span>
<span id="cb2-370"><a href="#cb2-370" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot.classList.add("plotlydiv")</span></span>
<span id="cb2-371"><a href="#cb2-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-372"><a href="#cb2-372" aria-hidden="true" tabindex="-1"></a><span class="vs">  if hide_toolbar:</span></span>
<span id="cb2-373"><a href="#cb2-373" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.classList.add("hidetoolbar")</span></span>
<span id="cb2-374"><a href="#cb2-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-375"><a href="#cb2-375" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.append(lineplot)</span></span>
<span id="cb2-376"><a href="#cb2-376" aria-hidden="true" tabindex="-1"></a><span class="vs">  if overlay:</span></span>
<span id="cb2-377"><a href="#cb2-377" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay = document.createElement('div')</span></span>
<span id="cb2-378"><a href="#cb2-378" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.classList.add("plotlyoverlay")</span></span>
<span id="cb2-379"><a href="#cb2-379" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-380"><a href="#cb2-380" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.append(overlay)</span></span>
<span id="cb2-381"><a href="#cb2-381" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-382"><a href="#cb2-382" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.style.position = 'relative'</span></span>
<span id="cb2-383"><a href="#cb2-383" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.top = '0'</span></span>
<span id="cb2-384"><a href="#cb2-384" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.bottom = '0'</span></span>
<span id="cb2-385"><a href="#cb2-385" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.width = '100%'</span></span>
<span id="cb2-386"><a href="#cb2-386" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.position = 'absolute'</span></span>
<span id="cb2-387"><a href="#cb2-387" aria-hidden="true" tabindex="-1"></a><span class="vs">  return container</span></span>
<span id="cb2-388"><a href="#cb2-388" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb2-389"><a href="#cb2-389" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):</span></span>
<span id="cb2-390"><a href="#cb2-390" aria-hidden="true" tabindex="-1"></a><span class="vs">  container = PlotlyFigure(width, height, hide_toolbar)</span></span>
<span id="cb2-391"><a href="#cb2-391" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot, overlay = container.childNodes[0], container.childNodes[1]</span></span>
<span id="cb2-392"><a href="#cb2-392" aria-hidden="true" tabindex="-1"></a><span class="vs">  if sync is None:</span></span>
<span id="cb2-393"><a href="#cb2-393" aria-hidden="true" tabindex="-1"></a><span class="vs">    sync = container</span></span>
<span id="cb2-394"><a href="#cb2-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-395"><a href="#cb2-395" aria-hidden="true" tabindex="-1"></a><span class="vs">  class mover:</span></span>
<span id="cb2-396"><a href="#cb2-396" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self):</span></span>
<span id="cb2-397"><a href="#cb2-397" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.mousedown = False</span></span>
<span id="cb2-398"><a href="#cb2-398" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-399"><a href="#cb2-399" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __call__(self, event):</span></span>
<span id="cb2-400"><a href="#cb2-400" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mousedown':</span></span>
<span id="cb2-401"><a href="#cb2-401" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = True</span></span>
<span id="cb2-402"><a href="#cb2-402" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mouseleave':</span></span>
<span id="cb2-403"><a href="#cb2-403" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = False</span></span>
<span id="cb2-404"><a href="#cb2-404" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mouseup':</span></span>
<span id="cb2-405"><a href="#cb2-405" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = False</span></span>
<span id="cb2-406"><a href="#cb2-406" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb2-407"><a href="#cb2-407" aria-hidden="true" tabindex="-1"></a><span class="vs">      if self.mousedown:</span></span>
<span id="cb2-408"><a href="#cb2-408" aria-hidden="true" tabindex="-1"></a><span class="vs">        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))</span></span>
<span id="cb2-409"><a href="#cb2-409" aria-hidden="true" tabindex="-1"></a><span class="vs">        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))</span></span>
<span id="cb2-410"><a href="#cb2-410" aria-hidden="true" tabindex="-1"></a><span class="vs">        sync.value = to_js([x, y])</span></span>
<span id="cb2-411"><a href="#cb2-411" aria-hidden="true" tabindex="-1"></a><span class="vs">        dispatchEvent(sync)</span></span>
<span id="cb2-412"><a href="#cb2-412" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb2-413"><a href="#cb2-413" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb2-414"><a href="#cb2-414" aria-hidden="true" tabindex="-1"></a><span class="vs">  e = mover()</span></span>
<span id="cb2-415"><a href="#cb2-415" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mousemove', to_js(e))</span></span>
<span id="cb2-416"><a href="#cb2-416" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mousedown', to_js(e))</span></span>
<span id="cb2-417"><a href="#cb2-417" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mouseup', to_js(e))</span></span>
<span id="cb2-418"><a href="#cb2-418" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mouseleave', to_js(e))</span></span>
<span id="cb2-419"><a href="#cb2-419" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.value = to_js([0., 0.])</span></span>
<span id="cb2-420"><a href="#cb2-420" aria-hidden="true" tabindex="-1"></a><span class="vs">  return container</span></span>
<span id="cb2-421"><a href="#cb2-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-422"><a href="#cb2-422" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyReactive(container, traces=[], layout={}, options={}):</span></span>
<span id="cb2-423"><a href="#cb2-423" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))</span></span>
<span id="cb2-424"><a href="#cb2-424" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_layout.update(layout)</span></span>
<span id="cb2-425"><a href="#cb2-425" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}</span></span>
<span id="cb2-426"><a href="#cb2-426" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_options.update(options)</span></span>
<span id="cb2-427"><a href="#cb2-427" aria-hidden="true" tabindex="-1"></a><span class="vs">  plot = container.childNodes[0]</span></span>
<span id="cb2-428"><a href="#cb2-428" aria-hidden="true" tabindex="-1"></a><span class="vs">  Plotly.react(plot, traces, full_layout, full_options)</span></span>
<span id="cb2-429"><a href="#cb2-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-430"><a href="#cb2-430" aria-hidden="true" tabindex="-1"></a><span class="vs">def colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):</span></span>
<span id="cb2-431"><a href="#cb2-431" aria-hidden="true" tabindex="-1"></a><span class="vs">  import matplotlib.cm as cm</span></span>
<span id="cb2-432"><a href="#cb2-432" aria-hidden="true" tabindex="-1"></a><span class="vs">  if cmin is None:</span></span>
<span id="cb2-433"><a href="#cb2-433" aria-hidden="true" tabindex="-1"></a><span class="vs">    cmin = tf.min(t)</span></span>
<span id="cb2-434"><a href="#cb2-434" aria-hidden="true" tabindex="-1"></a><span class="vs">  if cmax is None:</span></span>
<span id="cb2-435"><a href="#cb2-435" aria-hidden="true" tabindex="-1"></a><span class="vs">    cmax = tf.max(t)</span></span>
<span id="cb2-436"><a href="#cb2-436" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb2-437"><a href="#cb2-437" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = (t - cmin) / (cmax - cmin)</span></span>
<span id="cb2-438"><a href="#cb2-438" aria-hidden="true" tabindex="-1"></a><span class="vs">  if scale == 'log':</span></span>
<span id="cb2-439"><a href="#cb2-439" aria-hidden="true" tabindex="-1"></a><span class="vs">    e = tf.exp(1)</span></span>
<span id="cb2-440"><a href="#cb2-440" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = t * (e - 1) + 1</span></span>
<span id="cb2-441"><a href="#cb2-441" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tf.log(t)</span></span>
<span id="cb2-442"><a href="#cb2-442" aria-hidden="true" tabindex="-1"></a><span class="vs">  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))</span></span>
<span id="cb2-443"><a href="#cb2-443" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = t * res</span></span>
<span id="cb2-444"><a href="#cb2-444" aria-hidden="true" tabindex="-1"></a><span class="vs">  shape = t.shape</span></span>
<span id="cb2-445"><a href="#cb2-445" aria-hidden="true" tabindex="-1"></a><span class="vs">  tflat = tf.reshape(t, [-1])</span></span>
<span id="cb2-446"><a href="#cb2-446" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))</span></span>
<span id="cb2-447"><a href="#cb2-447" aria-hidden="true" tabindex="-1"></a><span class="vs">  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))</span></span>
<span id="cb2-448"><a href="#cb2-448" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])</span></span>
<span id="cb2-449"><a href="#cb2-449" aria-hidden="true" tabindex="-1"></a><span class="vs">  tflat = tfrac * tceil + (1. - tfrac) * tfloor</span></span>
<span id="cb2-450"><a href="#cb2-450" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = tf.reshape(tflat, list(shape) + [4])</span></span>
<span id="cb2-451"><a href="#cb2-451" aria-hidden="true" tabindex="-1"></a><span class="vs">  return t</span></span>
<span id="cb2-452"><a href="#cb2-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-453"><a href="#cb2-453" aria-hidden="true" tabindex="-1"></a><span class="vs">def plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):</span></span>
<span id="cb2-454"><a href="#cb2-454" aria-hidden="true" tabindex="-1"></a><span class="vs">  if not (cmap is None):</span></span>
<span id="cb2-455"><a href="#cb2-455" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = colorMap(t, cmap, **kwargs)</span></span>
<span id="cb2-456"><a href="#cb2-456" aria-hidden="true" tabindex="-1"></a><span class="vs">  if size is None:</span></span>
<span id="cb2-457"><a href="#cb2-457" aria-hidden="true" tabindex="-1"></a><span class="vs">    size = (canvas.height, canvas.width)</span></span>
<span id="cb2-458"><a href="#cb2-458" aria-hidden="true" tabindex="-1"></a><span class="vs">  if interpolation == 'bilinear':</span></span>
<span id="cb2-459"><a href="#cb2-459" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tfbase.image['resizeBilinear'](t.value, list(size))</span></span>
<span id="cb2-460"><a href="#cb2-460" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb2-461"><a href="#cb2-461" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))</span></span>
<span id="cb2-462"><a href="#cb2-462" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfbase.browser['toPixels'](t, canvas)</span></span>
<span id="cb2-463"><a href="#cb2-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-464"><a href="#cb2-464" aria-hidden="true" tabindex="-1"></a><span class="vs">from itertools import chain</span></span>
<span id="cb2-465"><a href="#cb2-465" aria-hidden="true" tabindex="-1"></a><span class="vs">import math</span></span>
<span id="cb2-466"><a href="#cb2-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-467"><a href="#cb2-467" aria-hidden="true" tabindex="-1"></a><span class="vs">class Module:</span></span>
<span id="cb2-468"><a href="#cb2-468" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self):</span></span>
<span id="cb2-469"><a href="#cb2-469" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._submodules = dict()</span></span>
<span id="cb2-470"><a href="#cb2-470" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = False</span></span>
<span id="cb2-471"><a href="#cb2-471" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._store = False</span></span>
<span id="cb2-472"><a href="#cb2-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-473"><a href="#cb2-473" aria-hidden="true" tabindex="-1"></a><span class="vs">    def parameters(self):</span></span>
<span id="cb2-474"><a href="#cb2-474" aria-hidden="true" tabindex="-1"></a><span class="vs">        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))</span></span>
<span id="cb2-475"><a href="#cb2-475" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-476"><a href="#cb2-476" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __setattr__(self, name, value):</span></span>
<span id="cb2-477"><a href="#cb2-477" aria-hidden="true" tabindex="-1"></a><span class="vs">        if isinstance(value, Module):</span></span>
<span id="cb2-478"><a href="#cb2-478" aria-hidden="true" tabindex="-1"></a><span class="vs">            self._submodules[name] = value</span></span>
<span id="cb2-479"><a href="#cb2-479" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__setattr__(name, value)</span></span>
<span id="cb2-480"><a href="#cb2-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-481"><a href="#cb2-481" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __call__(self, *args, **kwargs):</span></span>
<span id="cb2-482"><a href="#cb2-482" aria-hidden="true" tabindex="-1"></a><span class="vs">        value = self.forward(*args, **kwargs)</span></span>
<span id="cb2-483"><a href="#cb2-483" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._store = False</span></span>
<span id="cb2-484"><a href="#cb2-484" aria-hidden="true" tabindex="-1"></a><span class="vs">        return value</span></span>
<span id="cb2-485"><a href="#cb2-485" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-486"><a href="#cb2-486" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self):</span></span>
<span id="cb2-487"><a href="#cb2-487" aria-hidden="true" tabindex="-1"></a><span class="vs">        raise NotImplementedError()</span></span>
<span id="cb2-488"><a href="#cb2-488" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-489"><a href="#cb2-489" aria-hidden="true" tabindex="-1"></a><span class="vs">    def train(self):</span></span>
<span id="cb2-490"><a href="#cb2-490" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = False</span></span>
<span id="cb2-491"><a href="#cb2-491" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb2-492"><a href="#cb2-492" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.train()</span></span>
<span id="cb2-493"><a href="#cb2-493" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-494"><a href="#cb2-494" aria-hidden="true" tabindex="-1"></a><span class="vs">    def eval(self):</span></span>
<span id="cb2-495"><a href="#cb2-495" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = True</span></span>
<span id="cb2-496"><a href="#cb2-496" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb2-497"><a href="#cb2-497" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.eval()</span></span>
<span id="cb2-498"><a href="#cb2-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-499"><a href="#cb2-499" aria-hidden="true" tabindex="-1"></a><span class="vs">    def store(self):</span></span>
<span id="cb2-500"><a href="#cb2-500" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.store = True</span></span>
<span id="cb2-501"><a href="#cb2-501" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb2-502"><a href="#cb2-502" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.eval()</span></span>
<span id="cb2-503"><a href="#cb2-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-504"><a href="#cb2-504" aria-hidden="true" tabindex="-1"></a><span class="vs">class Parameter(Module):</span></span>
<span id="cb2-505"><a href="#cb2-505" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, value):</span></span>
<span id="cb2-506"><a href="#cb2-506" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb2-507"><a href="#cb2-507" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.value = value</span></span>
<span id="cb2-508"><a href="#cb2-508" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.temp = None</span></span>
<span id="cb2-509"><a href="#cb2-509" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.grad = None</span></span>
<span id="cb2-510"><a href="#cb2-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-511"><a href="#cb2-511" aria-hidden="true" tabindex="-1"></a><span class="vs">    def parameters(self):</span></span>
<span id="cb2-512"><a href="#cb2-512" aria-hidden="true" tabindex="-1"></a><span class="vs">        return [self]</span></span>
<span id="cb2-513"><a href="#cb2-513" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-514"><a href="#cb2-514" aria-hidden="true" tabindex="-1"></a><span class="vs">class Sequential(Module):</span></span>
<span id="cb2-515"><a href="#cb2-515" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, *args):</span></span>
<span id="cb2-516"><a href="#cb2-516" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb2-517"><a href="#cb2-517" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.sequence = []</span></span>
<span id="cb2-518"><a href="#cb2-518" aria-hidden="true" tabindex="-1"></a><span class="vs">        for arg in args:</span></span>
<span id="cb2-519"><a href="#cb2-519" aria-hidden="true" tabindex="-1"></a><span class="vs">            if isinstance(arg, Module):</span></span>
<span id="cb2-520"><a href="#cb2-520" aria-hidden="true" tabindex="-1"></a><span class="vs">                self.sequence.append(arg)</span></span>
<span id="cb2-521"><a href="#cb2-521" aria-hidden="true" tabindex="-1"></a><span class="vs">            else:</span></span>
<span id="cb2-522"><a href="#cb2-522" aria-hidden="true" tabindex="-1"></a><span class="vs">                self.sequence.extend(arg)</span></span>
<span id="cb2-523"><a href="#cb2-523" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb2-524"><a href="#cb2-524" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}</span></span>
<span id="cb2-525"><a href="#cb2-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-526"><a href="#cb2-526" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __getitem__(self, index):</span></span>
<span id="cb2-527"><a href="#cb2-527" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self.sequence[index]</span></span>
<span id="cb2-528"><a href="#cb2-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-529"><a href="#cb2-529" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb2-530"><a href="#cb2-530" aria-hidden="true" tabindex="-1"></a><span class="vs">        for m in self.sequence:</span></span>
<span id="cb2-531"><a href="#cb2-531" aria-hidden="true" tabindex="-1"></a><span class="vs">            X = m(X)</span></span>
<span id="cb2-532"><a href="#cb2-532" aria-hidden="true" tabindex="-1"></a><span class="vs">        return X</span></span>
<span id="cb2-533"><a href="#cb2-533" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-534"><a href="#cb2-534" aria-hidden="true" tabindex="-1"></a><span class="vs">ModuleList = Sequential</span></span>
<span id="cb2-535"><a href="#cb2-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-536"><a href="#cb2-536" aria-hidden="true" tabindex="-1"></a><span class="vs">class Sigmoid(Module):</span></span>
<span id="cb2-537"><a href="#cb2-537" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb2-538"><a href="#cb2-538" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.sigmoid(X)</span></span>
<span id="cb2-539"><a href="#cb2-539" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-540"><a href="#cb2-540" aria-hidden="true" tabindex="-1"></a><span class="vs">class ReLU(Module):</span></span>
<span id="cb2-541"><a href="#cb2-541" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb2-542"><a href="#cb2-542" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.relu(X)</span></span>
<span id="cb2-543"><a href="#cb2-543" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-544"><a href="#cb2-544" aria-hidden="true" tabindex="-1"></a><span class="vs">class Tanh(Module):</span></span>
<span id="cb2-545"><a href="#cb2-545" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb2-546"><a href="#cb2-546" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.tanh(X)</span></span>
<span id="cb2-547"><a href="#cb2-547" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-548"><a href="#cb2-548" aria-hidden="true" tabindex="-1"></a><span class="vs">class Linear(Module):</span></span>
<span id="cb2-549"><a href="#cb2-549" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, in_features, out_features):</span></span>
<span id="cb2-550"><a href="#cb2-550" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb2-551"><a href="#cb2-551" aria-hidden="true" tabindex="-1"></a><span class="vs">        # Kaiming He initialization</span></span>
<span id="cb2-552"><a href="#cb2-552" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))</span></span>
<span id="cb2-553"><a href="#cb2-553" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))</span></span>
<span id="cb2-554"><a href="#cb2-554" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.input = None</span></span>
<span id="cb2-555"><a href="#cb2-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-556"><a href="#cb2-556" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, x):</span></span>
<span id="cb2-557"><a href="#cb2-557" aria-hidden="true" tabindex="-1"></a><span class="vs">        # Returns a new Matrix</span></span>
<span id="cb2-558"><a href="#cb2-558" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.input = None</span></span>
<span id="cb2-559"><a href="#cb2-559" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.dot(x, self.W) + self.b</span></span>
<span id="cb2-560"><a href="#cb2-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-561"><a href="#cb2-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-562"><a href="#cb2-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-563"><a href="#cb2-563" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb2-564"><a href="#cb2-564" aria-hidden="true" tabindex="-1"></a><span class="vs">class Optimizer:</span></span>
<span id="cb2-565"><a href="#cb2-565" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, model, loss=None, store=False):</span></span>
<span id="cb2-566"><a href="#cb2-566" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.parameters = list(model.parameters())</span></span>
<span id="cb2-567"><a href="#cb2-567" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.model = model</span></span>
<span id="cb2-568"><a href="#cb2-568" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.loss = loss</span></span>
<span id="cb2-569"><a href="#cb2-569" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.store = store</span></span>
<span id="cb2-570"><a href="#cb2-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-571"><a href="#cb2-571" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _grads(self, loss, *args, **kwargs):</span></span>
<span id="cb2-572"><a href="#cb2-572" aria-hidden="true" tabindex="-1"></a><span class="vs">        def loss_internal(*params):</span></span>
<span id="cb2-573"><a href="#cb2-573" aria-hidden="true" tabindex="-1"></a><span class="vs">            for val, param in zip(params, self.parameters):</span></span>
<span id="cb2-574"><a href="#cb2-574" aria-hidden="true" tabindex="-1"></a><span class="vs">                param.temp = param.value</span></span>
<span id="cb2-575"><a href="#cb2-575" aria-hidden="true" tabindex="-1"></a><span class="vs">                param.value = val</span></span>
<span id="cb2-576"><a href="#cb2-576" aria-hidden="true" tabindex="-1"></a><span class="vs">            try:</span></span>
<span id="cb2-577"><a href="#cb2-577" aria-hidden="true" tabindex="-1"></a><span class="vs">                l = loss(self.model, *args, **kwargs)</span></span>
<span id="cb2-578"><a href="#cb2-578" aria-hidden="true" tabindex="-1"></a><span class="vs">            finally:</span></span>
<span id="cb2-579"><a href="#cb2-579" aria-hidden="true" tabindex="-1"></a><span class="vs">                for param in self.parameters:</span></span>
<span id="cb2-580"><a href="#cb2-580" aria-hidden="true" tabindex="-1"></a><span class="vs">                    param.value = param.temp</span></span>
<span id="cb2-581"><a href="#cb2-581" aria-hidden="true" tabindex="-1"></a><span class="vs">                    param.temp = None</span></span>
<span id="cb2-582"><a href="#cb2-582" aria-hidden="true" tabindex="-1"></a><span class="vs">            return l</span></span>
<span id="cb2-583"><a href="#cb2-583" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb2-584"><a href="#cb2-584" aria-hidden="true" tabindex="-1"></a><span class="vs">        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))</span></span>
<span id="cb2-585"><a href="#cb2-585" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-586"><a href="#cb2-586" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _step(self, grads):</span></span>
<span id="cb2-587"><a href="#cb2-587" aria-hidden="true" tabindex="-1"></a><span class="vs">        raise NotImplementedError()</span></span>
<span id="cb2-588"><a href="#cb2-588" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-589"><a href="#cb2-589" aria-hidden="true" tabindex="-1"></a><span class="vs">    def step(self, *args, **kwargs):</span></span>
<span id="cb2-590"><a href="#cb2-590" aria-hidden="true" tabindex="-1"></a><span class="vs">        grads = self._grads(self.loss, *args, **kwargs)</span></span>
<span id="cb2-591"><a href="#cb2-591" aria-hidden="true" tabindex="-1"></a><span class="vs">        if self.store:</span></span>
<span id="cb2-592"><a href="#cb2-592" aria-hidden="true" tabindex="-1"></a><span class="vs">          for grad, param in zip(grads, self.parameters):</span></span>
<span id="cb2-593"><a href="#cb2-593" aria-hidden="true" tabindex="-1"></a><span class="vs">            param.grad = grad</span></span>
<span id="cb2-594"><a href="#cb2-594" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self._step(grads)</span></span>
<span id="cb2-595"><a href="#cb2-595" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-596"><a href="#cb2-596" aria-hidden="true" tabindex="-1"></a><span class="vs">    def stepWithLoss(self, loss, *args, **kwargs):</span></span>
<span id="cb2-597"><a href="#cb2-597" aria-hidden="true" tabindex="-1"></a><span class="vs">        grads = self._grads(loss, *args, **kwargs)</span></span>
<span id="cb2-598"><a href="#cb2-598" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self._step(grads)</span></span>
<span id="cb2-599"><a href="#cb2-599" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb2-600"><a href="#cb2-600" aria-hidden="true" tabindex="-1"></a><span class="vs">class SGD(Optimizer):</span></span>
<span id="cb2-601"><a href="#cb2-601" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, model, loss, lr=0.001, store=False):</span></span>
<span id="cb2-602"><a href="#cb2-602" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__(model, loss, store)</span></span>
<span id="cb2-603"><a href="#cb2-603" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.lr = lr</span></span>
<span id="cb2-604"><a href="#cb2-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-605"><a href="#cb2-605" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _step(self, grads):</span></span>
<span id="cb2-606"><a href="#cb2-606" aria-hidden="true" tabindex="-1"></a><span class="vs">        for grad, param in zip(grads, self.parameters):</span></span>
<span id="cb2-607"><a href="#cb2-607" aria-hidden="true" tabindex="-1"></a><span class="vs">            param.value = param.value - self.lr * grad</span></span>
<span id="cb2-608"><a href="#cb2-608" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb2-609"><a href="#cb2-609" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-610"><a href="#cb2-610" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> py<span class="op">;</span></span>
<span id="cb2-611"><a href="#cb2-611" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb3" data-startfrom="0" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line -1;"><span id="cb3-0"><a href="#cb3-0" aria-hidden="true" tabindex="-1"></a>mpg <span class="op">=</span> <span class="fu">FileAttachment</span>(<span class="st">"auto-mpg.csv"</span>)<span class="op">.</span><span class="fu">csv</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell hidden">
<div class="sourceCode cell-code hidden" id="cb4" data-startfrom="2" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 1;"><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="vs"># Setup the data and prediction functions</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="vs">import pandas as pd</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="vs">df = pd.DataFrame(</span><span class="sc">${</span>mpg<span class="sc">}</span><span class="vs">)[['weight', 'mpg']]</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="vs">df = df.astype(float).dropna().values</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="vs">x, y = df[:, :1], df[:, 1:]</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="vs">x = Tensor((x - x.mean()) / x.std())</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="vs">y = Tensor((y - y.mean()) / y.std()) &gt; -0</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="vs">def get_batch(batchsize, x, y):</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="vs">  return x, y</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="vs">scale = Tensor([[1., 1.]])</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="vs">def predict(w, x, y=None):</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="vs">  w = w.reshape((-1, 2)) * scale</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="vs">  x = x.reshape((-1, 1))</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="vs">  x = tf.concat([x, tf.onesLike(x)], 1)</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="vs">  if y is None:</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="vs">    return tf.sigmoid(tf.dot(x, w.T))</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="vs">    y = y.reshape((-1, 1))</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="vs">    z = tf.dot(x, w.T)</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="vs">    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) </span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="vs">wrange = tf.linspace(-15, 5, 25)</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="vs">brange = tf.linspace(-10, 10, 25)</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="vs">ww, bb = tf.meshgrid(wrange, brange)</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="vs">paramgrid = tf.stack([ww.flatten(), bb.flatten()]).T</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="vs">eyetheta = 0</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="vs">(x, y)</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>surfaces <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>batch<span class="sc">}</span><span class="vs"> </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="vs"># Plot the loss surface</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="vs">l1weight = 0.</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="vs">l2weight = 0.</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="vs">def loss(w, x, y):</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="vs">  w = w.reshape((-1, 2))</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="vs">  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) </span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="vs">lossgrid = loss(paramgrid, x, y).reshape(ww.shape)</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="vs">losscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="vs">losssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="fu">py</span><span class="vs">`</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>surfaces<span class="sc">}</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="vs">cweights = </span><span class="sc">${</span>weights<span class="sc">}</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="vs">startpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))</span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a><span class="vs">fullweightlist = [Tensor(cweights)]</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="vs">batchweightlist = [Tensor(cweights)]</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="vs">steps = int(</span><span class="sc">${</span>steps<span class="sc">}</span><span class="vs">)</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a><span class="vs">lr = float(</span><span class="sc">${</span>learningrate<span class="sc">}</span><span class="vs">) if steps &gt; 0 else 0.</span></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a><span class="vs">momentum = 0.</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a><span class="vs">nxbatch, nybatch = batches[0]</span></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a><span class="vs">batchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])</span></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a><span class="vs">beta = 0.</span></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a><span class="vs">velocity = batchgrad</span></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a><span class="vs">magnitude = batchgrad ** 2</span></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a><span class="vs">if beta &gt; 0:</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)</span></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="vs">for i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a><span class="vs">  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a><span class="vs">  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="vs">  velocity = momentum * velocity + (1 - momentum) * bgrad</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span class="vs">  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchgrad = velocity</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a><span class="vs">  if beta &gt; 0:</span></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a><span class="vs">    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)</span></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a><span class="vs">  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())</span></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())</span></span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a><span class="vs">fullweights = tf.stack(fullweightlist)</span></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a><span class="vs">batchweights = tf.stack(batchweightlist)</span></span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a><span class="vs">gradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))</span></span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a><span class="vs">batchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))</span></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a><span class="vs">zloss = loss(fullweights, x, y)</span></span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a><span class="vs">batchzloss = loss(batchweights, x, y)</span></span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a><span class="vs">threedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')</span></span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a><span class="vs">threedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')</span></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a><span class="vs">finalloss = zloss[0].t2Js()</span></span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a><span class="vs">PlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {</span></span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a><span class="vs">      'text': 'Bias (b)'</span></span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a><span class="vs">    }}})</span></span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-3" data-nodetype="expression">

</div>
</div>
</div>
<div class="sourceCode cell-code hidden" id="cb5" data-startfrom="110" data-source-offset="-3585"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 109;"><span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>batch<span class="sc">}</span></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a><span class="vs"># Plot the data scatterplot and prediction function</span></span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a><span class="vs">inweights = </span><span class="sc">${</span>weights<span class="sc">}</span></span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a><span class="vs">cweights = Tensor(inweights)</span></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a><span class="vs">errors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())</span></span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a><span class="vs">losses = (errors)</span></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a><span class="vs">batchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))</span></span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a><span class="vs">xrange = tf.linspace(-2, 3, 50)</span></span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a><span class="vs">pfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))</span></span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a><span class="vs">PlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = σ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})</span></span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a><span class="vs">histdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))</span></span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a><span class="vs">losses.mean()</span></span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>data<span class="sc">}</span></span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a><span class="vs">batchsize = 0</span></span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a><span class="vs">batches = [get_batch(batchsize, x, y) for i in range(max(1, int(</span><span class="sc">${</span>steps<span class="sc">}</span><span class="vs">)))]</span></span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a><span class="vs">xbatch, ybatch = batches[0]</span></span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-5" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="column-screen columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb6" data-startfrom="0" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line -1;"><span id="cb6-0"><a href="#cb6-0" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="vs"># Scatterplot figure</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="vs">scatterfig = PlotlyFigure(width=500, height=500)</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="vs">scatterfig</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb7" data-startfrom="0" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line -1;"><span id="cb7-0"><a href="#cb7-0" aria-hidden="true" tabindex="-1"></a>viewof learningrate <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="fl">0.01</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">" Learning rate"</span>})</span>
<span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">//learningrate = 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-5" data-nodetype="declaration">

</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb8" data-startfrom="2" data-source-offset="-1"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 1;"><span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plots <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="vs">lossplot = PlotlyInput(width=500, height=500)</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>viewof weights <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="vs">lossplot</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-6-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-6-2" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb9" data-startfrom="0" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line -1;"><span id="cb9-0"><a href="#cb9-0" aria-hidden="true" tabindex="-1"></a>viewof steps <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">10</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">0</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"  Steps"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-7" data-nodetype="declaration">

</div>
</div>
</div>
</div>
</div>
</section>
<section id="comparing-loss-functions" class="level2">
<h2 class="anchored" data-anchor-id="comparing-loss-functions">Comparing loss functions</h2>
<p>Let’s look at how this loss function compares to the mean squared error loss we derived for logistic regression. One way to do this is to visualize the loss for a single observation as a function of the output of <span class="math inline">\(\mathbf{x}^T\mathbf{w}\)</span>. Here we’ll look at the loss for different models trying to predict an output of <span class="math inline">\(y=0\)</span>:</p>
<p><span class="math display">\[
\textbf{Let: }\ y=0, \quad z=\mathbf{x}^T\mathbf{w}
\]</span></p>
<div id="3389516a" class="cell" data-execution_count="14">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="notes_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We see that the squared error loss is best when the output is exactly 0, while the logistic regression NLL wants the output of <span class="math inline">\(\mathbf{x}^T\mathbf{w}\)</span> to be a negative as possible so that <span class="math inline">\(p(y=0\mid \mathbf{x}, \mathbf{w}) \longrightarrow 1\)</span>. Meanwhile the “accuracy” loss has no slope, making it impossible to optimize with gradient descent.</p>
</section>
</section>
<section id="multinomial-logistic-regression" class="level1">
<h1>Multinomial logistic regression</h1>
<section id="multi-class-classification" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-classification">Multi-class classification</h2>
<p>We’ve now seen a useful model for binary classification, but in many cases we want to predict between many different classes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pictures/catdogmouse.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We will typically use a set of integers <span class="math inline">\(\{1, 2,...,C\}\)</span> to denote the possible outputs for a general categorical function. Therefore we are considering functions of the form:</p>
<p><span class="math display">\[
y=f(\mathbf{x}), \quad \text{Input: } \mathbf{x} \in\mathbb{R}^n \longrightarrow \text{ Output: }y \in \{1, 2, ...,C\}
\]</span></p>
<p>It’s important to note that we do <em>not</em> want to assume that the <em>ordering</em> of labels is meaningful. For instance if we’re classifying images of animals we might set the labels such that:</p>
<p><span class="math display">\[
\textbf{1:  Cat},\quad
\textbf{2:  Dog},\quad
\textbf{3:  Mouse}
\]</span></p>
<p>But this shouldn’t lead to different results to the case where we assign the labels as:</p>
<p><span class="math display">\[
\textbf{1:  Dog},\quad
\textbf{2:  Mouse},\quad
\textbf{3:  Cat}
\]</span></p>
<p>We call prediction of a categorical output with more than two possibilities <strong>multi-class</strong> <strong>classification</strong>.</p>
</section>
<section id="multi-class-prediction-functions" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-functions">Multi-class prediction functions</h2>
<p>A symmetric approach to defining a prediction function for multi-class classification is to define a <em>separate</em> linear function for each class and choose the class whose function gives the largest output.</p>
<p>If <span class="math inline">\(C\)</span> is the number of possible classes, we will therefore have <span class="math inline">\(C\)</span> different parameter vectors <span class="math inline">\(\mathbf{w}_1,…,\mathbf{w}_C\)</span> and our prediction function will be defined as:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{1...C\}}{\text{argmax}}\ \mathbf{x}^T\mathbf{w}_c
\]</span></p>
<p>For convenience, we can also define a matrix that contains all <span class="math inline">\(C\)</span> parameter vectors:</p>
<p><span class="math display">\[
\mathbf{W} = \begin{bmatrix} \mathbf{w}_1^T \\ \mathbf{w}_2^T \\ \vdots \\ \mathbf{w}_C^T\end{bmatrix} = \begin{bmatrix} W_{11} &amp; W_{12} &amp; \dots &amp; W_{1d} \\
W_{21} &amp; W_{22} &amp; \dots &amp; W_{2d} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{C1} &amp; W_{C2} &amp; \dots &amp; W_{Cd}
\end{bmatrix}
\]</span></p>
<p>With this notation, our prediction function becomes:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{1...C\}}{\text{argmax}}\ (\mathbf{x}^T\mathbf{W}^T)_c, \quad \mathbf{W} \in \mathbb{R}^{C\times d}
\]</span></p>
</section>
<section id="multi-class-decision-boundaries" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-decision-boundaries">Multi-class decision boundaries</h2>
<p>If we only have two classes <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, so <span class="math inline">\(C=2\)</span>, then this multi-class prediction function reduces to the same as our binary prediction function. We can see this by noting that <span class="math inline">\(x &gt; y \equiv x-y&gt;0\)</span>:</p>
<p><span class="math display">\[
f(\mathbf{x}) = \underset{c\in\{0,1\}}{\text{argmax}}\ (\mathbf{x}^T\mathbf{W}^T)_c = \mathbb{I}(\mathbf{x}^T\mathbf{w}_1 - \mathbf{x}^T\mathbf{w}_0 \geq 0)
\]</span></p>
<p>If we factor out <span class="math inline">\(\mathbf{x}\)</span> we see that we can simply define a new parameter vector in order to get the same decision rule.</p>
<p><span class="math display">\[
=\mathbb{I}(\mathbf{x}^T(\mathbf{w}_1 - \mathbf{w}_0) \geq 0) \quad \longrightarrow \quad \mathbb{I}(\mathbf{x}^T\mathbf{w} \geq 0), \quad \mathbf{w}=\mathbf{w}_1-\mathbf{w}_0
\]</span></p>
<p>It follows that the decision boundary between any two classes is also linear! We can see this by plotting a prediction function. In this case for the <em>Iris</em> dataset we saw in the homework.</p>
</section>
<section id="categorical-distribution" class="level2">
<h2 class="anchored" data-anchor-id="categorical-distribution">Categorical distribution</h2>
<p>As a first step towards finding the optimal <span class="math inline">\(\mathbf{W}\)</span> for a multi-class model, let’s look at a distribution over multiple discrete outcomes: the <strong>Categorical</strong> distribution.</p>
<p>A categorical distribution needs to define a probability for each possible output. We’ll use <span class="math inline">\(q_c\)</span> to denote the probability of output <span class="math inline">\(c\)</span>.</p>
<p><span class="math display">\[
p(y=c) = q_c, \quad y\in \{1...C\}
\]</span></p>
<p>We can then denote the vector of all <span class="math inline">\(C\)</span> probabilities as <span class="math inline">\(\mathbf{q}\)</span>. Note that in order for this to be valid, every probability needs to be in the range <span class="math inline">\([0,1]\)</span> and the total probability of all outcomes needs to be <span class="math inline">\(1\)</span>, so:</p>
<p><span class="math display">\[
\mathbf{q} \in \mathbb{R}^C\quad q_c \geq 0\ \forall c\in \{1...C\}\quad \sum_{c=1}^C q_c=1
\]</span></p>
<p>As with the Bernoulli distribution, we can write this in a more compact form. Here we see that the probability of a given outcome is simply the corresponding entry in <span class="math inline">\(\mathbf{q}\)</span></p>
<p><span class="math display">\[
p(y)=\prod q_c^{\mathbb{I}(y=c)} = q_y
\]</span></p>
<p>Thus the log-probability is simply:</p>
<p><span class="math display">\[
\log p(y) = \sum_{c=1}^C \mathbb{I}(y=c)\log q_c = \log q_y
\]</span></p>
</section>
<section id="a-probabilistic-model-for-multi-class-classification" class="level2">
<h2 class="anchored" data-anchor-id="a-probabilistic-model-for-multi-class-classification">A probabilistic model for multi-class classification</h2>
<p>With the Categorical distribution defined, we can now ask if we can use it to define a linear probabilistic model for multi-class categorical outputs. As with our other models we’ll consider making the distribution parameter a linear function of our input.</p>
<p><span class="math display">\[
y_i\sim \mathbf{Categorical}(\mathbf{q}=?), \quad \mathbf{q}=\mathbf{x}_i^T\mathbf{W}^T?
\]</span></p>
<p>However, we once again run into the issue that the output of our linear function likely won’t satisfy the conditions we need for the parameter of a categorical distribution. In particular, the output is not guaranteed to be positive or to sum to <span class="math inline">\(1\)</span>.</p>
<p><span class="math display">\[
\mathbf{x}^T\mathbf{W}^T\in \mathbb{R}^C,\quad  q_c \ngeq 0\ \forall c\in \{1...C\}, \quad \sum_{c=1}^C q_c\neq1
\]</span></p>
<p>In this case we need a way to map arbitrary vectors to vectors that satisfy these conditions:</p>
<p><span class="math display">\[
\textbf{Need }\ f(\mathbf{x}):\ \mathbb{R}^C \longrightarrow [0,\infty)^C,\ \sum_{i=1}^Cf(\mathbf{x})_c = 1
\]</span></p>
</section>
<section id="softmax-function" class="level2">
<h2 class="anchored" data-anchor-id="softmax-function">Softmax function</h2>
<p>Such a mapping exists in the <strong>softmax</strong> function. This function maps vectors to positive vectors such that the entries sum to <span class="math inline">\(1\)</span>. Entry <span class="math inline">\(c\)</span> of <span class="math inline">\(\text{softmax}(\mathbf{x})\)</span> can be written as:</p>
<p><span class="math display">\[
\text{softmax}(\mathbf{x})_c = \frac{e^{x_c}}{\sum_{j=1}^Ce^{x_j}}
\]</span></p>
<p>We can also define the softmax function using vector notation as:</p>
<p><span class="math display">\[
\text{softmax}(\mathbf{x}) = \begin{bmatrix}\frac{e^{x_1}}{\sum_{j=1}^Ce^{x_j}} \\ \frac{e^{x_2}}{\sum_{j=1}^Ce^{x_j}} \\ \vdots \\ \frac{e^{x_C}}{\sum_{j=1}^Ce^{x_j}} \end{bmatrix}
\]</span></p>
<p>Intuitively, <span class="math inline">\(e^x\)</span> is positive for any <span class="math inline">\(x\)</span>, while dividing by the sum ensure the entries sum to 1 as:</p>
<p><span class="math display">\[
\sum_{i=1}^C \frac{e^{x_i}}{\sum_{j=1}^Ce^{x_j}} = \frac{\sum_{i=1}^C e^{x_i}}{\sum_{j=1}^Ce^{x_j}} = 1
\]</span></p>
<p>The softmax function also has the nice property that</p>
<p><span class="math display">\[
\underset{c\in\{1,...,C\}}{\text{argmax}}\ \mathbf{x}_c = \underset{c\in\{1,...,C\}}{\text{argmax}}\ \text{softmax}(\mathbf{x})_c
\]</span></p>
</section>
<section id="multonomial-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="multonomial-logistic-regression">Multonomial logistic regression</h2>
<p>With the softmax function we can now define our probabilistic model for categorical labels as:</p>
<p><span class="math display">\[
y_i\sim \mathbf{Categorical}\big(\text{softmax}(\mathbf{x}^T\mathbf{W})\big)
\]</span></p>
<p>We see that under this assumption, the probability of a particular output <span class="math inline">\((c)\)</span> is:</p>
<p><span class="math display">\[
p(y_i=c \mid \mathbf{x}, \mathbf{W}) = \text{softmax}(\mathbf{x}^T\mathbf{W})_c=\frac{e^{\mathbf{x}^T\mathbf{w}_c}}{\sum_{j=1}^Ce^{\mathbf{x}^T\mathbf{w}_j}}
\]</span></p>
<p>We call this particular probabilistic model: <strong>multinomial logistic regression</strong></p>
</section>
<section id="maximum-likelihood-estimation-for-multinomial-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-for-multinomial-logistic-regression">Maximum likelihood estimation for multinomial logistic regression</h2>
<p>We now have everything we need to define our negative log-likelihood loss for the multi-class classification model. Once again our loss is the negative sum of the log-probability of each observed output:</p>
<p><span class="math display">\[
\textbf{Loss}(\mathbf{W}) =\textbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})=- \sum_{i=1}^N \log p(y_i \mid \mathbf{x}_i, \mathbf{W})
\]</span></p>
<p>Using the log-probability of the multinomial logistic regression model we get:</p>
<p><span class="math display">\[
\textbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})= -\sum_{i=1}^N \log\ \text{softmax}(\mathbf{x}_i^T\mathbf{W}^T)_{y_i} = -\sum_{i=1}^N  \log \frac{e^{\mathbf{x}_i^T\mathbf{w}_{y_i}}}{\sum_{j=1}^Ce^{\mathbf{x}_i^T\mathbf{w}_{j}}}
\]</span></p>
<p>We can simplify this further to:</p>
<p><span class="math display">\[
\textbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})=-\sum_{i=1}^N \bigg(\mathbf{x}_i^T\mathbf{w}_{y_i}- \log\sum_{j=1}^Ce^{\mathbf{x}_i^T\mathbf{w}_{j}}\bigg)
\]</span></p>
</section>
<section id="gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent">Gradient descent</h2>
<p>In this case our parameters are a matrix <span class="math inline">\(\mathbf{W}\)</span>. The concept of a gradient, extends naturally to a matrix; we simply define the gradient matrix such that each element is the partial derivative with respect to the corresponding element of the input. For the multinomial logistic regression loss, the gradient this looks like:</p>
<p><span class="math display">\[
\nabla_{\mathbf{W}} \mathbf{NLL}(\mathbf{W}, \mathbf{X}, \mathbf{y})= \begin{bmatrix} \frac{\partial \mathbf{NLL}}{\partial W_{11}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{12}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{1C}} \\
\frac{\partial \mathbf{NLL}}{\partial W_{21}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{22}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{2C}} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\frac{\partial \mathbf{NLL}}{\partial W_{d1}} &amp; \frac{\partial \mathbf{NLL}}{\partial W_{d2}} &amp; \dots &amp; \frac{\partial \mathbf{NLL}}{\partial W_{dC}}
\end{bmatrix}
\]</span></p>
<p>We can still apply the same gradient descent updates in this case!</p>
<p><span class="math display">\[
\mathbf{W}^{(i+1)} \leftarrow \mathbf{W}^{(i)} - \alpha \nabla_{\mathbf{W}} \mathbf{NLL}(\mathbf{W}^{(i)}, \mathbf{X}, \mathbf{y})
\]</span></p>


</section>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
{"contents":[{"methodName":"interpret","cellName":"ojs-cell-1","inline":false,"source":"MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() => window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) => {\n    let globals = {};\n    const code = strings.reduce((result, string, index) => {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) => {\n    let globals = {};\n    const code = strings.reduce((result, string, index) => {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () => tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () => tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () => tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start < 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) > 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n"},{"methodName":"interpret","cellName":"ojs-cell-2","inline":false,"source":"mpg = FileAttachment(\"auto-mpg.csv\").csv()\n"},{"methodName":"interpret","cellName":"ojs-cell-3","inline":false,"source":"data = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std()) > -0\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x, y=None):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  if y is None:\n    return tf.sigmoid(tf.dot(x, w.T))\n  else:\n    y = y.reshape((-1, 1))\n    z = tf.dot(x, w.T)\n    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) \n\nwrange = tf.linspace(-15, 5, 25)\nbrange = tf.linspace(-10, 10, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps > 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta > 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta > 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())\nlosses = (errors)\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = σ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-4","inline":false,"source":"scatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-5","inline":false,"source":"viewof learningrate = Inputs.range([0, 100], {value: 1, step: 0.01, label: \" Learning rate\"})\n//learningrate = 0\n"},{"methodName":"interpret","cellName":"ojs-cell-6","inline":false,"source":"\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-7","inline":false,"source":"viewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})\n"},{"methodName":"interpretQuiet","source":"shinyInput('learningrate')"},{"methodName":"interpretQuiet","source":"shinyInput('weights')"},{"methodName":"interpretQuiet","source":"shinyInput('steps')"}]}
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../lecture3-logistic-regression";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>