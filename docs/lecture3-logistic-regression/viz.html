<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.319">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CS 152: Neural Networks â€“ viz</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">CS 152: Neural Networks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../calendar/calendar.html" rel="" target="">
 <span class="menu-text">Calendar</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://drive.google.com/drive/folders/1JFhwmcFBTHiRbfhQ0VRDj9xIPxFpHuWj?usp=drive_link" rel="" target="">
 <span class="menu-text">Homeworks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../assignments/final-project/outline.html" rel="" target="">
 <span class="menu-text">Project</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/orgs/CS152/" rel="" target="">
 <span class="menu-text">Github</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.gradescope.com/courses/710173" rel="" target="">
 <span class="menu-text">Gradescope</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">



<div class="cell">
<div class="sourceCode cell-code hidden" id="cb1" data-startfrom="5" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 4;"><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>MathJax <span class="op">=</span> {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> MathJax <span class="op">=</span> <span class="cf">await</span> <span class="pp">require</span>(<span class="st">'mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span><span class="fu">catch</span>(() <span class="kw">=&gt;</span> <span class="bu">window</span><span class="op">.</span><span class="at">MathJax</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">// configure MathJax</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  MathJax<span class="op">.</span><span class="at">Hub</span><span class="op">.</span><span class="fu">Config</span>({</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">tex2jax</span><span class="op">:</span> {<span class="dt">inlineMath</span><span class="op">:</span> [[<span class="st">'$'</span><span class="op">,</span><span class="st">'$'</span>]<span class="op">,</span> [<span class="st">'</span><span class="sc">\\</span><span class="st">('</span><span class="op">,</span><span class="st">'</span><span class="sc">\\</span><span class="st">)'</span>]]}<span class="op">,</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">displayMath</span><span class="op">:</span> [ [<span class="st">'$$'</span><span class="op">,</span><span class="st">'$$'</span>]<span class="op">,</span> [<span class="st">"</span><span class="sc">\\</span><span class="st">["</span><span class="op">,</span><span class="st">"</span><span class="sc">\\</span><span class="st">]"</span>] ]<span class="op">,</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="dt">processEscapes</span><span class="op">:</span> <span class="kw">true</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  })  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> MathJax</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>Plotly <span class="op">=</span> <span class="pp">require</span>(<span class="st">"https://cdn.plot.ly/plotly-latest.min.js"</span>)<span class="op">;</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>tfbase <span class="op">=</span> <span class="pp">require</span>(<span class="st">'@tensorflow/tfjs@4.11.0'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>pyodide <span class="op">=</span> {</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> p <span class="op">=</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> <span class="pp">require</span>(<span class="st">"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js"</span>)<span class="op">;</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="bu">console</span><span class="op">.</span><span class="fu">log</span>(p)<span class="op">;</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> p<span class="op">.</span><span class="fu">loadPyodide</span>()<span class="op">;</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>PyScope <span class="op">=</span> <span class="kw">function</span>() {</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> scope <span class="op">=</span> pyodide<span class="op">.</span><span class="fu">toPy</span>({})<span class="op">;</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> py <span class="op">=</span> <span class="kw">async</span> (strings<span class="op">,</span> <span class="op">...</span>expressions) <span class="kw">=&gt;</span> {</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> globals <span class="op">=</span> {}<span class="op">;</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> code <span class="op">=</span> strings<span class="op">.</span><span class="fu">reduce</span>((result<span class="op">,</span> string<span class="op">,</span> index) <span class="kw">=&gt;</span> {</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (expressions[index]) {</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> name <span class="op">=</span> <span class="vs">`x</span><span class="sc">${</span>index<span class="sc">}</span><span class="vs">`</span><span class="op">;</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        globals[name] <span class="op">=</span> expressions[index]<span class="op">;</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result <span class="op">+</span> string <span class="op">+</span> name<span class="op">;</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> result <span class="op">+</span> string<span class="op">;</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    }<span class="op">,</span> <span class="st">''</span>)<span class="op">;</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">loadPackagesFromImports</span>(code)<span class="op">;</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    scope<span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="at">globals</span>)<span class="op">;</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> result <span class="op">=</span> <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">runPythonAsync</span>(</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>      code<span class="op">,</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="dt">globals</span><span class="op">:</span> scope</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">t2Js</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">t2Js</span>()<span class="op">;</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">toJs</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">toJs</span>()<span class="op">;</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result<span class="op">;</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> py<span class="op">;</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>py <span class="op">=</span> {</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> testscope <span class="op">=</span> <span class="fu">PyScope</span>()<span class="op">;</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> py <span class="op">=</span> <span class="kw">async</span> (strings<span class="op">,</span> <span class="op">...</span>expressions) <span class="kw">=&gt;</span> {</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> globals <span class="op">=</span> {}<span class="op">;</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> code <span class="op">=</span> strings<span class="op">.</span><span class="fu">reduce</span>((result<span class="op">,</span> string<span class="op">,</span> index) <span class="kw">=&gt;</span> {</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (expressions[index]) {</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>        <span class="kw">const</span> name <span class="op">=</span> <span class="vs">`x</span><span class="sc">${</span>index<span class="sc">}</span><span class="vs">`</span><span class="op">;</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        globals[name] <span class="op">=</span> expressions[index]<span class="op">;</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result <span class="op">+</span> string <span class="op">+</span> name<span class="op">;</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> result <span class="op">+</span> string<span class="op">;</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    }<span class="op">,</span> <span class="st">''</span>)<span class="op">;</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">loadPackagesFromImports</span>(code)<span class="op">;</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    pyodide<span class="op">.</span><span class="at">globals</span><span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="fu">toPy</span>(globals))</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> result <span class="op">=</span> <span class="cf">await</span> pyodide<span class="op">.</span><span class="fu">runPythonAsync</span>(</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>      code<span class="op">,</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>      {<span class="dt">globals</span><span class="op">:</span> pyodide<span class="op">.</span><span class="at">globals</span>}</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    )<span class="op">;</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">t2Js</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">t2Js</span>()<span class="op">;</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (result<span class="op">?.</span><span class="at">toJs</span>) <span class="cf">return</span> result<span class="op">.</span><span class="fu">toJs</span>()<span class="op">;</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result<span class="op">;</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> sigmoidGradConfig  <span class="op">=</span> {</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Sigmoid</span><span class="op">,</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">sigmoid</span>(x)<span class="op">;</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(dy<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">mul</span>(y<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">sub</span>(tfbase<span class="op">.</span><span class="fu">scalar</span>(<span class="dv">1</span>)<span class="op">,</span> y)))}<span class="op">;</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(sigmoidGradConfig)<span class="op">;</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>  <span class="kw">const</span> tanhGradConfig <span class="op">=</span> {</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Tanh</span><span class="op">,</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">tanh</span>(x)<span class="op">;</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(tfbase<span class="op">.</span><span class="fu">sub</span>(tfbase<span class="op">.</span><span class="fu">scalar</span>(<span class="dv">1</span>)<span class="op">,</span> tfbase<span class="op">.</span><span class="fu">square</span>(y))<span class="op">,</span> dy)}<span class="op">;</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(tanhGradConfig)<span class="op">;</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>   <span class="kw">const</span> expGradConfig <span class="op">=</span> {</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>    <span class="dt">kernelName</span><span class="op">:</span> tfbase<span class="op">.</span><span class="at">Exp</span><span class="op">,</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>    <span class="dt">inputsToSave</span><span class="op">:</span> [<span class="st">'x'</span>]<span class="op">,</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>    <span class="dt">gradFunc</span><span class="op">:</span> (dy<span class="op">,</span> saved) <span class="kw">=&gt;</span> {</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> [x] <span class="op">=</span> saved<span class="op">;</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>      <span class="kw">const</span> y <span class="op">=</span> tfbase<span class="op">.</span><span class="fu">exp</span>(x)<span class="op">;</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> {<span class="dt">x</span><span class="op">:</span> () <span class="kw">=&gt;</span> tfbase<span class="op">.</span><span class="fu">mul</span>(dy<span class="op">,</span> y)}<span class="op">;</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>  }<span class="op">;</span> </span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>  tfbase<span class="op">.</span><span class="fu">registerGradient</span>(expGradConfig)<span class="op">;</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">dispatchEvent</span>(element){</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>    element<span class="op">.</span><span class="fu">dispatchEvent</span>(<span class="kw">new</span> <span class="bu">Event</span>(<span class="st">"input"</span><span class="op">,</span> {<span class="dt">bubbles</span><span class="op">:</span> <span class="kw">true</span>}))<span class="op">;</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>  pyodide<span class="op">.</span><span class="at">globals</span><span class="op">.</span><span class="fu">update</span>(pyodide<span class="op">.</span><span class="fu">toPy</span>({<span class="dt">Plotbase</span><span class="op">:</span> Plot<span class="op">,</span> <span class="dt">tfbase</span><span class="op">:</span> tfbase<span class="op">,</span> <span class="dt">Plotlybase</span><span class="op">:</span> Plotly<span class="op">,</span> <span class="dt">dispatchEvent</span><span class="op">:</span> dispatchEvent<span class="op">,</span> <span class="dt">d3base</span><span class="op">:</span> d3}))</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="cf">await</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="vs">from pyodide.ffi import create_once_callable</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="vs">from types import SimpleNamespace</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="vs">from pyodide.ffi import to_js</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="vs">from js import Object, document</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="vs">import pandas</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="vs">import numpy as np</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="vs">tfbase = SimpleNamespace(**tfbase)</span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_tensor(a, *args):</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Parameter):</span></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value.value</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Tensor):</span></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, np.ndarray):</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.tolist()</span></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a)</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert(a):</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Parameter):</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value.value</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, Tensor):</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.value</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(a, np.ndarray):</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="vs">    a = a.tolist()</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_start(shape, start):</span></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = start or 0</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="vs">  if start &lt; 0:</span></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="vs">    start = shape + start</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = min(start, shape - 1)</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="vs">  return start</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="vs">def convert_end(shape, start, end): </span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="vs">  start = convert_start(shape, start)</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="vs">  if end is None:</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="vs">    end = shape</span></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="vs">    end = convert_start(shape, end)</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="vs">  return end - start</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="vs">class Tensor:</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="vs">  keepall = False</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="vs">  class Keep:</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __enter__(self):</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.value = Tensor.keepall</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="vs">        Tensor.keepall = True</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __exit__(self, *args):</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="vs">        Tensor.keepall = self.value</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, *args, value=None, keep=None, **kwargs):</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="vs">    if keep is None:</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.keep = Tensor.keepall</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="vs">    else:</span></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.keep = keep</span></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="vs">    if not (value is None):</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = value</span></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="vs">    elif len(args) and isinstance(args[0], Tensor):</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.add(args[0].value, 0)</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="vs">    elif len(args) and args[0] is None:</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.tensor(0.)</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="vs">    else:</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="vs">      args = [convert(a) for a in args]</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="vs">      kwargs = {k: convert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value = tfbase.tensor(*args, **kwargs)</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getattr__(self, name):</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="vs">    if name == 'T':</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="vs">      return self.transpose()</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="vs">    attr = getattr(self.value, name)</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="vs">    if callable(attr):</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="vs">      def run(*args, **kwargs):</span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = [convert(a) for a in args]</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="vs">        kwargs = {k: convert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="vs">        output = attr(*args, **kwargs)</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a><span class="vs">        return Tensor(value=output)</span></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="vs">      # Prevent premature garbage collection</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="vs">      run._ref = self</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="vs">      return run</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="vs">    return attr</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __add__(a, b):</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.add(convert(a), convert(b)))</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __radd__(a, b):</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.add(convert(b), convert(a)))</span></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __sub__(a, b):</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.sub(convert(a), convert(b)))</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rsub__(a, b):</span></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.sub(convert(b), convert(a)))</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __mul__(a, b):</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.mul(convert(a), convert(b)))</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rmul__(a, b):</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.mul(convert(b), convert(a)))</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __truediv__(a, b):</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.div(convert(a), convert(b)))</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rtruediv__(a, b):</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.div(convert(b), convert(a)))</span></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __floordiv__(a, b):</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rfloordiv__(a, b):</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __pow__(a, b):</span></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.pow(convert(a), convert(b)))</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __rpow__(a, b):</span></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.pow(convert(b), convert(a)))</span></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __neg__(a):</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.neg(convert(a)))</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __eq__(a, b):</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.equal(convert(a), convert(b)))</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __neq__(a, b):</span></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))</span></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __lt__(a, b):</span></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.less(convert(a), convert(b)))</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __gt__(a, b):</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.greater(convert(a), convert(b)))</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __leq__(a, b):</span></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))</span></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __geq__(a, b):</span></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __del__(self):</span></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="vs">    if hasattr(self.value, 'dispose') and not self.keep:</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.value.dispose()</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __iter__(self):</span></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="vs">    for x in self.value.arraySync():</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="vs">        yield Tensor(x)</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getitem__(self, args):</span></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="vs">    tosqueeze = []</span></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="vs">    starts, ends, steps = [], [], []</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a><span class="vs">    value = self</span></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="vs">    if not (type(args) is tuple):</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a><span class="vs">      args = (args,)</span></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="vs">    for ind in range(len(args)):</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="vs">      if args[ind] is Ellipsis:</span></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="vs">        start = args[:ind]</span></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a><span class="vs">        rest = args[(ind + 1):]</span></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest</span></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a><span class="vs">        break</span></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a><span class="vs">    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):</span></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="vs">      if isinstance(dim, slice):</span></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a><span class="vs">        starts.append(dim.start or 0)</span></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="vs">        ends.append(dim.stop or shape)</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="vs">        steps.append(dim.step or 1)</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="vs">      elif Tensor(dim).shape:</span></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="vs">        t = Tensor(dim)</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="vs">        if t.value.dtype == 'bool':</span></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="vs">          value = tf.gather(value, inds, i)</span></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="vs">        else:</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="vs">          inds = tf.cast(tf.reshape(t, [-1]), 'int32')</span></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="vs">          value = tf.gather(value, inds, i)</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="vs">      else:</span></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="vs">        starts.append(dim)</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="vs">        ends.append(dim + 1)</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="vs">        steps.append(1)</span></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="vs">        tosqueeze.append(i)</span></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="vs">    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="vs">    if len(tosqueeze) &gt; 0:</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="vs">      value = tf.squeeze(value, tosqueeze)</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="vs">    return value</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="vs">  def t2Js(self):</span></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="vs">    return to_js(self.value.arraySync())</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="vs">class wrapper:</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, x, *args, **kwargs):</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="vs">    with Tensor.Keep():</span></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="vs">      return convert(self.f(Tensor(value=x), *args, **kwargs))</span></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a><span class="vs">class grad:</span></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.wrapper = wrapper(f)</span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, x, *args, **kwargs):</span></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="vs">    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="vs">    return Tensor(value=output)</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="vs">class wrappers:</span></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, *args):</span></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="vs">    with Tensor.Keep():</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="vs">      wrapped_args = [Tensor(value=x) for x in args]</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="vs">      return convert(self.f(*wrapped_args))</span></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a><span class="vs">class grads:</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, f):</span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.f = f</span></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.wrapper = wrappers(f)</span></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __call__(self, *args):</span></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="vs">    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))</span></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a><span class="vs">    return [Tensor(value=x) for x in output]</span></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a><span class="vs">tf = Tensor(value=tfbase)</span></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotbase = SimpleNamespace(**Plotbase)</span></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotlybase = SimpleNamespace(**Plotlybase)</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="vs">d3base = SimpleNamespace(**d3base)</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="vs">def meshgrid(*args):</span></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a><span class="vs">  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])</span></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="vs">tf.meshgrid = meshgrid</span></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="vs">def default_convert(obj, default_f, other):</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(obj, Tensor):</span></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="vs">    obj = obj.t2Js()</span></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a><span class="vs">  if isinstance(obj, pandas.DataFrame):</span></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="vs">    obj = obj.to_dict('records') </span></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a><span class="vs">  return default_f(obj)</span></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="vs">def plotconvert(a):</span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="vs">  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)</span></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="vs">class PlotWrapper:</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __init__(self, base=None):</span></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="vs">    self.base = base</span></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a><span class="vs">  def __getattr__(self, name):</span></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a><span class="vs">    attr = getattr(self.base, name)</span></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a><span class="vs">    if callable(attr):</span></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a><span class="vs">      def run(*args, **kwargs):</span></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="vs">        args = [plotconvert(a) for a in args]</span></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a><span class="vs">        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}</span></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="vs">        return attr(*args, **kwargs)</span></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a><span class="vs">      return run</span></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="vs">    return attr</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="vs">Plot = PlotWrapper(Plotbase)</span></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a><span class="vs">Plotly = PlotWrapper(Plotlybase)</span></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="vs">d3 = PlotWrapper(d3base)</span></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):</span></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a><span class="vs">  if height is None:</span></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a><span class="vs">    height = 0.75 * width</span></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a><span class="vs">  width, height = int(width), int(height)</span></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a><span class="vs">  container = document.createElement('div')</span></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.style.width = str(width) + 'px'</span></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.style.height = str(height) + 'px'</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot = document.createElement('div')</span></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot.classList.add("plotlydiv")</span></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a><span class="vs">  if hide_toolbar:</span></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.classList.add("hidetoolbar")</span></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.append(lineplot)</span></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a><span class="vs">  if overlay:</span></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay = document.createElement('div')</span></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.classList.add("plotlyoverlay")</span></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.append(overlay)</span></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="vs">    container.style.position = 'relative'</span></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.top = '0'</span></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.bottom = '0'</span></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.width = '100%'</span></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="vs">    overlay.style.position = 'absolute'</span></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="vs">  return container</span></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):</span></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="vs">  container = PlotlyFigure(width, height, hide_toolbar)</span></span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a><span class="vs">  lineplot, overlay = container.childNodes[0], container.childNodes[1]</span></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a><span class="vs">  if sync is None:</span></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a><span class="vs">    sync = container</span></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a><span class="vs">  class mover:</span></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self):</span></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a><span class="vs">      self.mousedown = False</span></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __call__(self, event):</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mousedown':</span></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = True</span></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mouseleave':</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = False</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="vs">      if event.type == 'mouseup':</span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.mousedown = False</span></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="vs">      if self.mousedown:</span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="vs">        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="vs">        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="vs">        sync.value = to_js([x, y])</span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="vs">        dispatchEvent(sync)</span></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="vs">  e = mover()</span></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mousemove', to_js(e))</span></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mousedown', to_js(e))</span></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mouseup', to_js(e))</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="vs">  overlay.addEventListener('mouseleave', to_js(e))</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="vs">  container.value = to_js([0., 0.])</span></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="vs">  return container</span></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="vs">def PlotlyReactive(container, traces=[], layout={}, options={}):</span></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_layout.update(layout)</span></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="vs">  full_options.update(options)</span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a><span class="vs">  plot = container.childNodes[0]</span></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="vs">  Plotly.react(plot, traces, full_layout, full_options)</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="vs">def colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="vs">  import matplotlib.cm as cm</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="vs">  if cmin is None:</span></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="vs">    cmin = tf.min(t)</span></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="vs">  if cmax is None:</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a><span class="vs">    cmax = tf.max(t)</span></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = (t - cmin) / (cmax - cmin)</span></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="vs">  if scale == 'log':</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="vs">    e = tf.exp(1)</span></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = t * (e - 1) + 1</span></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tf.log(t)</span></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="vs">  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))</span></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = t * res</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="vs">  shape = t.shape</span></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="vs">  tflat = tf.reshape(t, [-1])</span></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))</span></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a><span class="vs">  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))</span></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])</span></span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a><span class="vs">  tflat = tfrac * tceil + (1. - tfrac) * tfloor</span></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a><span class="vs">  t = tf.reshape(tflat, list(shape) + [4])</span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a><span class="vs">  return t</span></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a><span class="vs">def plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):</span></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a><span class="vs">  if not (cmap is None):</span></span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = colorMap(t, cmap, **kwargs)</span></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a><span class="vs">  if size is None:</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a><span class="vs">    size = (canvas.height, canvas.width)</span></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="vs">  if interpolation == 'bilinear':</span></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tfbase.image['resizeBilinear'](t.value, list(size))</span></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="vs">    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a><span class="vs">  tfbase.browser['toPixels'](t, canvas)</span></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="vs">from itertools import chain</span></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a><span class="vs">import math</span></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a><span class="vs">class Module:</span></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self):</span></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._submodules = dict()</span></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = False</span></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._store = False</span></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a><span class="vs">    def parameters(self):</span></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a><span class="vs">        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))</span></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __setattr__(self, name, value):</span></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a><span class="vs">        if isinstance(value, Module):</span></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a><span class="vs">            self._submodules[name] = value</span></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__setattr__(name, value)</span></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __call__(self, *args, **kwargs):</span></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a><span class="vs">        value = self.forward(*args, **kwargs)</span></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._store = False</span></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a><span class="vs">        return value</span></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self):</span></span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a><span class="vs">        raise NotImplementedError()</span></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a><span class="vs">    def train(self):</span></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = False</span></span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.train()</span></span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a><span class="vs">    def eval(self):</span></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.eval = True</span></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.eval()</span></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a><span class="vs">    def store(self):</span></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.store = True</span></span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a><span class="vs">        for sm in self._submodules.values():</span></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a><span class="vs">            sm.eval()</span></span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a><span class="vs">class Parameter(Module):</span></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, value):</span></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.value = value</span></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.temp = None</span></span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.grad = None</span></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a><span class="vs">    def parameters(self):</span></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a><span class="vs">        return [self]</span></span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a><span class="vs">class Sequential(Module):</span></span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, *args):</span></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.sequence = []</span></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a><span class="vs">        for arg in args:</span></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a><span class="vs">            if isinstance(arg, Module):</span></span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a><span class="vs">                self.sequence.append(arg)</span></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a><span class="vs">            else:</span></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a><span class="vs">                self.sequence.extend(arg)</span></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a><span class="vs">        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}</span></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __getitem__(self, index):</span></span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self.sequence[index]</span></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a><span class="vs">        for m in self.sequence:</span></span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a><span class="vs">            X = m(X)</span></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a><span class="vs">        return X</span></span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a><span class="vs">ModuleList = Sequential</span></span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a><span class="vs">class Sigmoid(Module):</span></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.sigmoid(X)</span></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a><span class="vs">class ReLU(Module):</span></span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.relu(X)</span></span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a><span class="vs">class Tanh(Module):</span></span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, X):</span></span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.tanh(X)</span></span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a><span class="vs">class Linear(Module):</span></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, in_features, out_features):</span></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__()</span></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a><span class="vs">        # Kaiming He initialization</span></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))</span></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))</span></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.input = None</span></span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a><span class="vs">    def forward(self, x):</span></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a><span class="vs">        # Returns a new Matrix</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.input = None</span></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a><span class="vs">        return tf.dot(x, self.W) + self.b</span></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a><span class="vs">class Optimizer:</span></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, model, loss=None, store=False):</span></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.parameters = list(model.parameters())</span></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.model = model</span></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.loss = loss</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.store = store</span></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _grads(self, loss, *args, **kwargs):</span></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a><span class="vs">        def loss_internal(*params):</span></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a><span class="vs">            for val, param in zip(params, self.parameters):</span></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a><span class="vs">                param.temp = param.value</span></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a><span class="vs">                param.value = val</span></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a><span class="vs">            try:</span></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a><span class="vs">                l = loss(self.model, *args, **kwargs)</span></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a><span class="vs">            finally:</span></span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a><span class="vs">                for param in self.parameters:</span></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a><span class="vs">                    param.value = param.temp</span></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a><span class="vs">                    param.temp = None</span></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a><span class="vs">            return l</span></span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a><span class="vs">        </span></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a><span class="vs">        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))</span></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _step(self, grads):</span></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a><span class="vs">        raise NotImplementedError()</span></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a><span class="vs">    def step(self, *args, **kwargs):</span></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a><span class="vs">        grads = self._grads(self.loss, *args, **kwargs)</span></span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a><span class="vs">        if self.store:</span></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a><span class="vs">          for grad, param in zip(grads, self.parameters):</span></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a><span class="vs">            param.grad = grad</span></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self._step(grads)</span></span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a><span class="vs">    def stepWithLoss(self, loss, *args, **kwargs):</span></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a><span class="vs">        grads = self._grads(loss, *args, **kwargs)</span></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a><span class="vs">        return self._step(grads)</span></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a><span class="vs">    </span></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a><span class="vs">class SGD(Optimizer):</span></span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a><span class="vs">    def __init__(self, model, loss, lr=0.001, store=False):</span></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="vs">        super().__init__(model, loss, store)</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a><span class="vs">        self.lr = lr</span></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a><span class="vs">    def _step(self, grads):</span></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a><span class="vs">        for grad, param in zip(grads, self.parameters):</span></span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a><span class="vs">            param.value = param.value - self.lr * grad</span></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> py<span class="op">;</span></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-6" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb2" data-startfrom="618" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 617;"><span id="cb2-618"><a href="#cb2-618" aria-hidden="true" tabindex="-1"></a>mpg <span class="op">=</span> <span class="fu">FileAttachment</span>(<span class="st">"auto-mpg.csv"</span>)<span class="op">.</span><span class="fu">csv</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb3" data-startfrom="636" data-source-offset="-0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 635;"><span id="cb3-636"><a href="#cb3-636" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb3-637"><a href="#cb3-637" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb3-638"><a href="#cb3-638" aria-hidden="true" tabindex="-1"></a><span class="vs"># Setup the data and prediction functions</span></span>
<span id="cb3-639"><a href="#cb3-639" aria-hidden="true" tabindex="-1"></a><span class="vs">import pandas as pd</span></span>
<span id="cb3-640"><a href="#cb3-640" aria-hidden="true" tabindex="-1"></a><span class="vs">df = pd.DataFrame(</span><span class="sc">${</span>mpg<span class="sc">}</span><span class="vs">)[['weight', 'mpg']]</span></span>
<span id="cb3-641"><a href="#cb3-641" aria-hidden="true" tabindex="-1"></a><span class="vs">df = df.astype(float).dropna().values</span></span>
<span id="cb3-642"><a href="#cb3-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-643"><a href="#cb3-643" aria-hidden="true" tabindex="-1"></a><span class="vs">x, y = df[:, :1], df[:, 1:]</span></span>
<span id="cb3-644"><a href="#cb3-644" aria-hidden="true" tabindex="-1"></a><span class="vs">x = Tensor((x - x.mean()) / x.std())</span></span>
<span id="cb3-645"><a href="#cb3-645" aria-hidden="true" tabindex="-1"></a><span class="vs">y = Tensor((y - y.mean()) / y.std()) &gt; -0</span></span>
<span id="cb3-646"><a href="#cb3-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-647"><a href="#cb3-647" aria-hidden="true" tabindex="-1"></a><span class="vs">def get_batch(batchsize, x, y):</span></span>
<span id="cb3-648"><a href="#cb3-648" aria-hidden="true" tabindex="-1"></a><span class="vs">  return x, y</span></span>
<span id="cb3-649"><a href="#cb3-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-650"><a href="#cb3-650" aria-hidden="true" tabindex="-1"></a><span class="vs">scale = Tensor([[1., 1.]])</span></span>
<span id="cb3-651"><a href="#cb3-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-652"><a href="#cb3-652" aria-hidden="true" tabindex="-1"></a><span class="vs">def predict(w, x, y=None):</span></span>
<span id="cb3-653"><a href="#cb3-653" aria-hidden="true" tabindex="-1"></a><span class="vs">  w = w.reshape((-1, 2)) * scale</span></span>
<span id="cb3-654"><a href="#cb3-654" aria-hidden="true" tabindex="-1"></a><span class="vs">  x = x.reshape((-1, 1))</span></span>
<span id="cb3-655"><a href="#cb3-655" aria-hidden="true" tabindex="-1"></a><span class="vs">  x = tf.concat([x, tf.onesLike(x)], 1)</span></span>
<span id="cb3-656"><a href="#cb3-656" aria-hidden="true" tabindex="-1"></a><span class="vs">  if y is None:</span></span>
<span id="cb3-657"><a href="#cb3-657" aria-hidden="true" tabindex="-1"></a><span class="vs">    return tf.sigmoid(tf.dot(x, w.T))</span></span>
<span id="cb3-658"><a href="#cb3-658" aria-hidden="true" tabindex="-1"></a><span class="vs">  else:</span></span>
<span id="cb3-659"><a href="#cb3-659" aria-hidden="true" tabindex="-1"></a><span class="vs">    y = y.reshape((-1, 1))</span></span>
<span id="cb3-660"><a href="#cb3-660" aria-hidden="true" tabindex="-1"></a><span class="vs">    z = tf.dot(x, w.T)</span></span>
<span id="cb3-661"><a href="#cb3-661" aria-hidden="true" tabindex="-1"></a><span class="vs">    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) </span></span>
<span id="cb3-662"><a href="#cb3-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-663"><a href="#cb3-663" aria-hidden="true" tabindex="-1"></a><span class="vs">wrange = tf.linspace(-15, 5, 25)</span></span>
<span id="cb3-664"><a href="#cb3-664" aria-hidden="true" tabindex="-1"></a><span class="vs">brange = tf.linspace(-10, 10, 25)</span></span>
<span id="cb3-665"><a href="#cb3-665" aria-hidden="true" tabindex="-1"></a><span class="vs">ww, bb = tf.meshgrid(wrange, brange)</span></span>
<span id="cb3-666"><a href="#cb3-666" aria-hidden="true" tabindex="-1"></a><span class="vs">paramgrid = tf.stack([ww.flatten(), bb.flatten()]).T</span></span>
<span id="cb3-667"><a href="#cb3-667" aria-hidden="true" tabindex="-1"></a><span class="vs">eyetheta = 0</span></span>
<span id="cb3-668"><a href="#cb3-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-669"><a href="#cb3-669" aria-hidden="true" tabindex="-1"></a><span class="vs">(x, y)</span></span>
<span id="cb3-670"><a href="#cb3-670" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb3-671"><a href="#cb3-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-672"><a href="#cb3-672" aria-hidden="true" tabindex="-1"></a>surfaces <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb3-673"><a href="#cb3-673" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>batch<span class="sc">}</span><span class="vs"> </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb3-674"><a href="#cb3-674" aria-hidden="true" tabindex="-1"></a><span class="vs"># Plot the loss surface</span></span>
<span id="cb3-675"><a href="#cb3-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-676"><a href="#cb3-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-677"><a href="#cb3-677" aria-hidden="true" tabindex="-1"></a><span class="vs">l1weight = 0.</span></span>
<span id="cb3-678"><a href="#cb3-678" aria-hidden="true" tabindex="-1"></a><span class="vs">l2weight = 0.</span></span>
<span id="cb3-679"><a href="#cb3-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-680"><a href="#cb3-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-681"><a href="#cb3-681" aria-hidden="true" tabindex="-1"></a><span class="vs">def loss(w, x, y):</span></span>
<span id="cb3-682"><a href="#cb3-682" aria-hidden="true" tabindex="-1"></a><span class="vs">  w = w.reshape((-1, 2))</span></span>
<span id="cb3-683"><a href="#cb3-683" aria-hidden="true" tabindex="-1"></a><span class="vs">  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) </span></span>
<span id="cb3-684"><a href="#cb3-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-685"><a href="#cb3-685" aria-hidden="true" tabindex="-1"></a><span class="vs">lossgrid = loss(paramgrid, x, y).reshape(ww.shape)</span></span>
<span id="cb3-686"><a href="#cb3-686" aria-hidden="true" tabindex="-1"></a><span class="vs">losscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))</span></span>
<span id="cb3-687"><a href="#cb3-687" aria-hidden="true" tabindex="-1"></a><span class="vs">losssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))</span></span>
<span id="cb3-688"><a href="#cb3-688" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb3-689"><a href="#cb3-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-690"><a href="#cb3-690" aria-hidden="true" tabindex="-1"></a><span class="fu">py</span><span class="vs">`</span></span>
<span id="cb3-691"><a href="#cb3-691" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>surfaces<span class="sc">}</span></span>
<span id="cb3-692"><a href="#cb3-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-693"><a href="#cb3-693" aria-hidden="true" tabindex="-1"></a><span class="vs">cweights = </span><span class="sc">${</span>weights<span class="sc">}</span></span>
<span id="cb3-694"><a href="#cb3-694" aria-hidden="true" tabindex="-1"></a><span class="vs">startpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))</span></span>
<span id="cb3-695"><a href="#cb3-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-696"><a href="#cb3-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-697"><a href="#cb3-697" aria-hidden="true" tabindex="-1"></a><span class="vs">fullweightlist = [Tensor(cweights)]</span></span>
<span id="cb3-698"><a href="#cb3-698" aria-hidden="true" tabindex="-1"></a><span class="vs">batchweightlist = [Tensor(cweights)]</span></span>
<span id="cb3-699"><a href="#cb3-699" aria-hidden="true" tabindex="-1"></a><span class="vs">steps = int(</span><span class="sc">${</span>steps<span class="sc">}</span><span class="vs">)</span></span>
<span id="cb3-700"><a href="#cb3-700" aria-hidden="true" tabindex="-1"></a><span class="vs">lr = float(</span><span class="sc">${</span>learningrate<span class="sc">}</span><span class="vs">) if steps &gt; 0 else 0.</span></span>
<span id="cb3-701"><a href="#cb3-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-702"><a href="#cb3-702" aria-hidden="true" tabindex="-1"></a><span class="vs">momentum = 0.</span></span>
<span id="cb3-703"><a href="#cb3-703" aria-hidden="true" tabindex="-1"></a><span class="vs">nxbatch, nybatch = batches[0]</span></span>
<span id="cb3-704"><a href="#cb3-704" aria-hidden="true" tabindex="-1"></a><span class="vs">batchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])</span></span>
<span id="cb3-705"><a href="#cb3-705" aria-hidden="true" tabindex="-1"></a><span class="vs">beta = 0.</span></span>
<span id="cb3-706"><a href="#cb3-706" aria-hidden="true" tabindex="-1"></a><span class="vs">velocity = batchgrad</span></span>
<span id="cb3-707"><a href="#cb3-707" aria-hidden="true" tabindex="-1"></a><span class="vs">magnitude = batchgrad ** 2</span></span>
<span id="cb3-708"><a href="#cb3-708" aria-hidden="true" tabindex="-1"></a><span class="vs">if beta &gt; 0:</span></span>
<span id="cb3-709"><a href="#cb3-709" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)</span></span>
<span id="cb3-710"><a href="#cb3-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-711"><a href="#cb3-711" aria-hidden="true" tabindex="-1"></a><span class="vs">for i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):</span></span>
<span id="cb3-712"><a href="#cb3-712" aria-hidden="true" tabindex="-1"></a><span class="vs">  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])</span></span>
<span id="cb3-713"><a href="#cb3-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-714"><a href="#cb3-714" aria-hidden="true" tabindex="-1"></a><span class="vs">  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])</span></span>
<span id="cb3-715"><a href="#cb3-715" aria-hidden="true" tabindex="-1"></a><span class="vs">  velocity = momentum * velocity + (1 - momentum) * bgrad</span></span>
<span id="cb3-716"><a href="#cb3-716" aria-hidden="true" tabindex="-1"></a><span class="vs">  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)</span></span>
<span id="cb3-717"><a href="#cb3-717" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchgrad = velocity</span></span>
<span id="cb3-718"><a href="#cb3-718" aria-hidden="true" tabindex="-1"></a><span class="vs">  if beta &gt; 0:</span></span>
<span id="cb3-719"><a href="#cb3-719" aria-hidden="true" tabindex="-1"></a><span class="vs">    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)</span></span>
<span id="cb3-720"><a href="#cb3-720" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb3-721"><a href="#cb3-721" aria-hidden="true" tabindex="-1"></a><span class="vs">  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())</span></span>
<span id="cb3-722"><a href="#cb3-722" aria-hidden="true" tabindex="-1"></a><span class="vs">  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())</span></span>
<span id="cb3-723"><a href="#cb3-723" aria-hidden="true" tabindex="-1"></a><span class="vs">  </span></span>
<span id="cb3-724"><a href="#cb3-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-725"><a href="#cb3-725" aria-hidden="true" tabindex="-1"></a><span class="vs">fullweights = tf.stack(fullweightlist)</span></span>
<span id="cb3-726"><a href="#cb3-726" aria-hidden="true" tabindex="-1"></a><span class="vs">batchweights = tf.stack(batchweightlist)</span></span>
<span id="cb3-727"><a href="#cb3-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-728"><a href="#cb3-728" aria-hidden="true" tabindex="-1"></a><span class="vs">gradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))</span></span>
<span id="cb3-729"><a href="#cb3-729" aria-hidden="true" tabindex="-1"></a><span class="vs">batchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))</span></span>
<span id="cb3-730"><a href="#cb3-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-731"><a href="#cb3-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-732"><a href="#cb3-732" aria-hidden="true" tabindex="-1"></a><span class="vs">zloss = loss(fullweights, x, y)</span></span>
<span id="cb3-733"><a href="#cb3-733" aria-hidden="true" tabindex="-1"></a><span class="vs">batchzloss = loss(batchweights, x, y)</span></span>
<span id="cb3-734"><a href="#cb3-734" aria-hidden="true" tabindex="-1"></a><span class="vs">threedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')</span></span>
<span id="cb3-735"><a href="#cb3-735" aria-hidden="true" tabindex="-1"></a><span class="vs">threedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')</span></span>
<span id="cb3-736"><a href="#cb3-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-737"><a href="#cb3-737" aria-hidden="true" tabindex="-1"></a><span class="vs">finalloss = zloss[0].t2Js()</span></span>
<span id="cb3-738"><a href="#cb3-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-739"><a href="#cb3-739" aria-hidden="true" tabindex="-1"></a><span class="vs">PlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {</span></span>
<span id="cb3-740"><a href="#cb3-740" aria-hidden="true" tabindex="-1"></a><span class="vs">      'text': 'Bias (b)'</span></span>
<span id="cb3-741"><a href="#cb3-741" aria-hidden="true" tabindex="-1"></a><span class="vs">    }}})</span></span>
<span id="cb3-742"><a href="#cb3-742" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-3" data-nodetype="expression">

</div>
</div>
</div>
<div class="sourceCode cell-code hidden" id="cb4" data-startfrom="744" data-source-offset="-3585"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 743;"><span id="cb4-744"><a href="#cb4-744" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb4-745"><a href="#cb4-745" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>batch<span class="sc">}</span></span>
<span id="cb4-746"><a href="#cb4-746" aria-hidden="true" tabindex="-1"></a><span class="vs"># Plot the data scatterplot and prediction function</span></span>
<span id="cb4-747"><a href="#cb4-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-748"><a href="#cb4-748" aria-hidden="true" tabindex="-1"></a><span class="vs">inweights = </span><span class="sc">${</span>weights<span class="sc">}</span></span>
<span id="cb4-749"><a href="#cb4-749" aria-hidden="true" tabindex="-1"></a><span class="vs">cweights = Tensor(inweights)</span></span>
<span id="cb4-750"><a href="#cb4-750" aria-hidden="true" tabindex="-1"></a><span class="vs">errors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())</span></span>
<span id="cb4-751"><a href="#cb4-751" aria-hidden="true" tabindex="-1"></a><span class="vs">losses = (errors)</span></span>
<span id="cb4-752"><a href="#cb4-752" aria-hidden="true" tabindex="-1"></a><span class="vs">batchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))</span></span>
<span id="cb4-753"><a href="#cb4-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-754"><a href="#cb4-754" aria-hidden="true" tabindex="-1"></a><span class="vs">xrange = tf.linspace(-2, 3, 50)</span></span>
<span id="cb4-755"><a href="#cb4-755" aria-hidden="true" tabindex="-1"></a><span class="vs">pfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))</span></span>
<span id="cb4-756"><a href="#cb4-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-757"><a href="#cb4-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-758"><a href="#cb4-758" aria-hidden="true" tabindex="-1"></a><span class="vs">PlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = Ïƒ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})</span></span>
<span id="cb4-759"><a href="#cb4-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-760"><a href="#cb4-760" aria-hidden="true" tabindex="-1"></a><span class="vs">histdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))</span></span>
<span id="cb4-761"><a href="#cb4-761" aria-hidden="true" tabindex="-1"></a><span class="vs">losses.mean()</span></span>
<span id="cb4-762"><a href="#cb4-762" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb4-763"><a href="#cb4-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-764"><a href="#cb4-764" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb4-765"><a href="#cb4-765" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>data<span class="sc">}</span></span>
<span id="cb4-766"><a href="#cb4-766" aria-hidden="true" tabindex="-1"></a><span class="vs">batchsize = 0</span></span>
<span id="cb4-767"><a href="#cb4-767" aria-hidden="true" tabindex="-1"></a><span class="vs">batches = [get_batch(batchsize, x, y) for i in range(max(1, int(</span><span class="sc">${</span>steps<span class="sc">}</span><span class="vs">)))]</span></span>
<span id="cb4-768"><a href="#cb4-768" aria-hidden="true" tabindex="-1"></a><span class="vs">xbatch, ybatch = batches[0]</span></span>
<span id="cb4-769"><a href="#cb4-769" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display hidden">
<div>
<div id="ojs-cell-3-5" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="column-screen columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb5" data-startfrom="775" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 774;"><span id="cb5-775"><a href="#cb5-775" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb5-776"><a href="#cb5-776" aria-hidden="true" tabindex="-1"></a><span class="vs"># Scatterplot figure</span></span>
<span id="cb5-777"><a href="#cb5-777" aria-hidden="true" tabindex="-1"></a><span class="vs">scatterfig = PlotlyFigure(width=500, height=500)</span></span>
<span id="cb5-778"><a href="#cb5-778" aria-hidden="true" tabindex="-1"></a><span class="vs">scatterfig</span></span>
<span id="cb5-779"><a href="#cb5-779" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb6" data-startfrom="784" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 783;"><span id="cb6-784"><a href="#cb6-784" aria-hidden="true" tabindex="-1"></a>viewof learningrate <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="fl">0.01</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">" Learning rate"</span>})</span>
<span id="cb6-785"><a href="#cb6-785" aria-hidden="true" tabindex="-1"></a><span class="co">//learningrate = 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-5" data-nodetype="declaration">

</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb7" data-startfrom="793" data-source-offset="-1"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 792;"><span id="cb7-793"><a href="#cb7-793" aria-hidden="true" tabindex="-1"></a>plots <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb7-794"><a href="#cb7-794" aria-hidden="true" tabindex="-1"></a><span class="vs">lossplot = PlotlyInput(width=500, height=500)</span></span>
<span id="cb7-795"><a href="#cb7-795" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span>
<span id="cb7-796"><a href="#cb7-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-797"><a href="#cb7-797" aria-hidden="true" tabindex="-1"></a>viewof weights <span class="op">=</span> <span class="fu">py</span><span class="vs">`</span></span>
<span id="cb7-798"><a href="#cb7-798" aria-hidden="true" tabindex="-1"></a><span class="vs"># </span><span class="sc">${</span>plots<span class="sc">}</span></span>
<span id="cb7-799"><a href="#cb7-799" aria-hidden="true" tabindex="-1"></a><span class="vs">lossplot</span></span>
<span id="cb7-800"><a href="#cb7-800" aria-hidden="true" tabindex="-1"></a><span class="vs">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-6-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-6-2" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code hidden" id="cb8" data-startfrom="803" data-source-offset="0"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 802;"><span id="cb8-803"><a href="#cb8-803" aria-hidden="true" tabindex="-1"></a>viewof steps <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">10</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">0</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"  Steps"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-7" data-nodetype="declaration">

</div>
</div>
</div>
</div>
</div>



</main> <!-- /main -->
<script type="ojs-module-contents">
{"contents":[{"methodName":"interpret","cellName":"ojs-cell-1","inline":false,"source":"MathJax = {\n  const MathJax = await require('mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML')\n    .catch(() => window.MathJax)\n  \n  // configure MathJax\n  MathJax.Hub.Config({\n    tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]},\n    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ],\n    processEscapes: true\n  })  \n  return MathJax\n}\n\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\");\ntfbase = require('@tensorflow/tfjs@4.11.0')\npyodide = {\n  const p =\n    await require(\"https://cdn.jsdelivr.net/pyodide/v0.22.1/full/pyodide.js\");\n  console.log(p);\n  return p.loadPyodide();\n}\n\nPyScope = function() {\n  let scope = pyodide.toPy({});\n  \n  let py = async (strings, ...expressions) => {\n    let globals = {};\n    const code = strings.reduce((result, string, index) => {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    scope.update(pyodide.globals);\n    const result = await pyodide.runPythonAsync(\n      code,\n      {\n        globals: scope\n      }\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n  \n  return py;\n}\n\npy = {\n  let testscope = PyScope();\n  let py = async (strings, ...expressions) => {\n    let globals = {};\n    const code = strings.reduce((result, string, index) => {\n      if (expressions[index]) {\n        const name = `x${index}`;\n        globals[name] = expressions[index];\n        return result + string + name;\n      }\n      return result + string;\n    }, '');\n    await pyodide.loadPackagesFromImports(code);\n    pyodide.globals.update(pyodide.toPy(globals))\n    const result = await pyodide.runPythonAsync(\n      code,\n      {globals: pyodide.globals}\n    );\n    if (result?.t2Js) return result.t2Js();\n    if (result?.toJs) return result.toJs();\n    return result;\n  };\n\n  const sigmoidGradConfig  = {\n    kernelName: tfbase.Sigmoid,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.sigmoid(x);\n      return {x: () => tfbase.mul(dy, tfbase.mul(y, tfbase.sub(tfbase.scalar(1), y)))};\n    }\n  };\n  tfbase.registerGradient(sigmoidGradConfig);\n\n  const tanhGradConfig = {\n    kernelName: tfbase.Tanh,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.tanh(x);\n      return {x: () => tfbase.mul(tfbase.sub(tfbase.scalar(1), tfbase.square(y)), dy)};\n    }\n  };\n  tfbase.registerGradient(tanhGradConfig);\n   const expGradConfig = {\n    kernelName: tfbase.Exp,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved) => {\n      const [x] = saved;\n      const y = tfbase.exp(x);\n      return {x: () => tfbase.mul(dy, y)};\n    }\n  }; \n  tfbase.registerGradient(expGradConfig);\n\n  function dispatchEvent(element){\n    element.dispatchEvent(new Event(\"input\", {bubbles: true}));\n  }\n  pyodide.globals.update(pyodide.toPy({Plotbase: Plot, tfbase: tfbase, Plotlybase: Plotly, dispatchEvent: dispatchEvent, d3base: d3}))\n  \nawait py`\nfrom pyodide.ffi import create_once_callable\nfrom types import SimpleNamespace\nfrom pyodide.ffi import to_js\nfrom js import Object, document\nimport pandas\nimport numpy as np\n\ntfbase = SimpleNamespace(**tfbase)\n\ndef convert_tensor(a, *args):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a)\n\ndef convert(a):\n  if isinstance(a, Parameter):\n    a = a.value.value\n  if isinstance(a, Tensor):\n    a = a.value\n  if isinstance(a, np.ndarray):\n    a = a.tolist()\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=convert_tensor)\n\ndef convert_start(shape, start):\n  start = start or 0\n  if start < 0:\n    start = shape + start\n  start = min(start, shape - 1)\n  return start\n\ndef convert_end(shape, start, end): \n  start = convert_start(shape, start)\n  if end is None:\n    end = shape\n  else:\n    end = convert_start(shape, end)\n  return end - start\n\nclass Tensor:\n  keepall = False\n\n  class Keep:\n    def __enter__(self):\n        self.value = Tensor.keepall\n        Tensor.keepall = True\n    \n    def __exit__(self, *args):\n        Tensor.keepall = self.value\n\n  def __init__(self, *args, value=None, keep=None, **kwargs):\n    if keep is None:\n      self.keep = Tensor.keepall\n    else:\n      self.keep = keep\n\n    if not (value is None):\n      self.value = value\n    elif len(args) and isinstance(args[0], Tensor):\n      self.value = tfbase.add(args[0].value, 0)\n    elif len(args) and args[0] is None:\n      self.value = tfbase.tensor(0.)\n    else:\n      args = [convert(a) for a in args]\n      kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n      self.value = tfbase.tensor(*args, **kwargs)\n\n  def __getattr__(self, name):\n    if name == 'T':\n      return self.transpose()\n    attr = getattr(self.value, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [convert(a) for a in args]\n        kwargs = {k: convert(a) for (k, a) in kwargs.items()}\n        output = attr(*args, **kwargs)\n        return Tensor(value=output)\n      # Prevent premature garbage collection\n      run._ref = self\n      return run\n    return attr\n\n  def __add__(a, b):\n    return Tensor(value=tfbase.add(convert(a), convert(b)))\n  def __radd__(a, b):\n    return Tensor(value=tfbase.add(convert(b), convert(a)))\n  def __sub__(a, b):\n    return Tensor(value=tfbase.sub(convert(a), convert(b)))\n  def __rsub__(a, b):\n    return Tensor(value=tfbase.sub(convert(b), convert(a)))\n  def __mul__(a, b):\n    return Tensor(value=tfbase.mul(convert(a), convert(b)))\n  def __rmul__(a, b):\n    return Tensor(value=tfbase.mul(convert(b), convert(a)))\n  def __truediv__(a, b):\n    return Tensor(value=tfbase.div(convert(a), convert(b)))\n  def __rtruediv__(a, b):\n    return Tensor(value=tfbase.div(convert(b), convert(a)))\n  def __floordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(a), convert(b)))\n  def __rfloordiv__(a, b):\n    return Tensor(value=tfbase.floorDiv(convert(b), convert(a)))\n  def __pow__(a, b):\n    return Tensor(value=tfbase.pow(convert(a), convert(b)))\n  def __rpow__(a, b):\n    return Tensor(value=tfbase.pow(convert(b), convert(a)))\n  def __neg__(a):\n    return Tensor(value=tfbase.neg(convert(a)))\n  def __eq__(a, b):\n    return Tensor(value=tfbase.equal(convert(a), convert(b)))\n  def __neq__(a, b):\n    return Tensor(value=tfbase.notEqual(convert(a), convert(b)))\n  def __lt__(a, b):\n    return Tensor(value=tfbase.less(convert(a), convert(b)))\n  def __gt__(a, b):\n    return Tensor(value=tfbase.greater(convert(a), convert(b)))\n  def __leq__(a, b):\n    return Tensor(value=tfbase.lessEqual(convert(a), convert(b)))\n  def __geq__(a, b):\n    return Tensor(value=tfbase.greaterEqual(convert(a), convert(b)))\n\n  def __del__(self):\n    if hasattr(self.value, 'dispose') and not self.keep:\n      self.value.dispose()\n\n  def __iter__(self):\n    for x in self.value.arraySync():\n        yield Tensor(x)\n\n  def __getitem__(self, args):\n    tosqueeze = []\n    starts, ends, steps = [], [], []\n    value = self\n    \n    if not (type(args) is tuple):\n      args = (args,)\n    \n    for ind in range(len(args)):\n      if args[ind] is Ellipsis:\n        start = args[:ind]\n        rest = args[(ind + 1):]\n        args = start + tuple([slice(None)] * (len(self.value.shape) - (len(start) + len(rest)))) + rest\n        break\n    \n    for i, (shape, dim) in enumerate(zip(self.value.shape, args)):\n      if isinstance(dim, slice):\n        starts.append(dim.start or 0)\n        ends.append(dim.stop or shape)\n        steps.append(dim.step or 1)\n      elif Tensor(dim).shape:\n        t = Tensor(dim)\n        if t.value.dtype == 'bool':\n          inds = [ind for (ind, e) in enumerate(t.value.arraySync()) if e]\n          inds = tf.cast(tf.reshape(Tensor(inds), [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n        else:\n          inds = tf.cast(tf.reshape(t, [-1]), 'int32')\n          value = tf.gather(value, inds, i)\n      else:\n        starts.append(dim)\n        ends.append(dim + 1)\n        steps.append(1)\n        tosqueeze.append(i)\n    value = tf.stridedSlice(value, convert(starts), convert(ends), convert(steps))\n    if len(tosqueeze) > 0:\n      value = tf.squeeze(value, tosqueeze)\n    return value\n\n  def t2Js(self):\n    return to_js(self.value.arraySync())\n\nclass wrapper:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, x, *args, **kwargs):\n    with Tensor.Keep():\n      return convert(self.f(Tensor(value=x), *args, **kwargs))\n\nclass grad:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrapper(f)\n\n  def __call__(self, x, *args, **kwargs):\n    output = tfbase.grad(create_once_callable(self.wrapper))(x.value, *args, **kwargs)\n    return Tensor(value=output)\n\nclass wrappers:\n  def __init__(self, f):\n    self.f = f\n\n  def __call__(self, *args):\n    with Tensor.Keep():\n      wrapped_args = [Tensor(value=x) for x in args]\n      return convert(self.f(*wrapped_args))\n\nclass grads:\n  def __init__(self, f):\n    self.f = f\n    self.wrapper = wrappers(f)\n\n  def __call__(self, *args):\n    output = tfbase.grads(create_once_callable(self.wrapper))(to_js([arg.value for arg in args]))\n    return [Tensor(value=x) for x in output]\n\ntf = Tensor(value=tfbase)\nPlotbase = SimpleNamespace(**Plotbase)\nPlotlybase = SimpleNamespace(**Plotlybase)\nd3base = SimpleNamespace(**d3base)\n\ndef meshgrid(*args):\n  return tuple([Tensor(value=a) for a in tfbase.meshgrid(*[convert(arg) for arg in args])])\ntf.meshgrid = meshgrid\n\ndef default_convert(obj, default_f, other):\n  if isinstance(obj, Tensor):\n    obj = obj.t2Js()\n  if isinstance(obj, pandas.DataFrame):\n    obj = obj.to_dict('records') \n  return default_f(obj)\n\ndef plotconvert(a):\n  return to_js(a, dict_converter=Object.fromEntries, default_converter=default_convert)\n\nclass PlotWrapper:\n  def __init__(self, base=None):\n    self.base = base\n    \n  def __getattr__(self, name):\n    attr = getattr(self.base, name)\n    if callable(attr):\n      def run(*args, **kwargs):\n        args = [plotconvert(a) for a in args]\n        kwargs = {k: plotconvert(a) for (k, a) in kwargs.items()}\n        return attr(*args, **kwargs)\n      return run\n    return attr\n\nPlot = PlotWrapper(Plotbase)\nPlotly = PlotWrapper(Plotlybase)\nd3 = PlotWrapper(d3base)\n\ndef PlotlyFigure(width=800, height=None, hide_toolbar=True, overlay=True):\n  if height is None:\n    height = 0.75 * width\n\n  width, height = int(width), int(height)\n  container = document.createElement('div')\n  container.style.width = str(width) + 'px'\n  container.style.height = str(height) + 'px'\n  \n  lineplot = document.createElement('div')\n  lineplot.classList.add(\"plotlydiv\")\n\n  if hide_toolbar:\n    container.classList.add(\"hidetoolbar\")\n\n  container.append(lineplot)\n  if overlay:\n    overlay = document.createElement('div')\n    overlay.classList.add(\"plotlyoverlay\")\n    \n    container.append(overlay)\n    \n    container.style.position = 'relative'\n    overlay.style.top = '0'\n    overlay.style.bottom = '0'\n    overlay.style.width = '100%'\n    overlay.style.position = 'absolute'\n  return container\n  \ndef PlotlyInput(width=800, height=None, hide_toolbar=True, sync=None):\n  container = PlotlyFigure(width, height, hide_toolbar)\n  lineplot, overlay = container.childNodes[0], container.childNodes[1]\n  if sync is None:\n    sync = container\n\n  class mover:\n    def __init__(self):\n      self.mousedown = False\n    \n    def __call__(self, event):\n      if event.type == 'mousedown':\n        self.mousedown = True\n      if event.type == 'mouseleave':\n        self.mousedown = False\n      if event.type == 'mouseup':\n        self.mousedown = False\n  \n      if self.mousedown:\n        x = float(lineplot._fullLayout.xaxis.p2c(event.layerX - lineplot._fullLayout.margin.l))\n        y = float(lineplot._fullLayout.yaxis.p2c(event.layerY - lineplot._fullLayout.margin.t))\n        sync.value = to_js([x, y])\n        dispatchEvent(sync)\n        \n  \n  e = mover()\n  overlay.addEventListener('mousemove', to_js(e))\n  overlay.addEventListener('mousedown', to_js(e))\n  overlay.addEventListener('mouseup', to_js(e))\n  overlay.addEventListener('mouseleave', to_js(e))\n  container.value = to_js([0., 0.])\n  return container\n\ndef PlotlyReactive(container, traces=[], layout={}, options={}):\n  full_layout = dict(width=int(container.style.width.replace('px', '')), height=int(container.style.height.replace('px', '')))\n  full_layout.update(layout)\n  full_options = {'displayModeBar' : not container.classList.contains('hidetoolbar')}\n  full_options.update(options)\n  plot = container.childNodes[0]\n  Plotly.react(plot, traces, full_layout, full_options)\n\ndef colorMap(t, cmap='inferno', cmin=None, cmax=None, scale='linear', res=100):\n  import matplotlib.cm as cm\n  if cmin is None:\n    cmin = tf.min(t)\n  if cmax is None:\n    cmax = tf.max(t)\n  \n  t = (t - cmin) / (cmax - cmin)\n  if scale == 'log':\n    e = tf.exp(1)\n    t = t * (e - 1) + 1\n    t = tf.log(t)\n  cmap = Tensor(cm.get_cmap(cmap, res + 1)(range(res + 1)))\n  t = t * res\n  shape = t.shape\n  tflat = tf.reshape(t, [-1])\n  tfloor = tf.gather(cmap, tf.floor(tflat).cast('int32'))\n  tceil = tf.gather(cmap, tf.ceil(tflat).cast('int32'))\n  tfrac = tf.reshape(tflat - tf.floor(tflat), [-1, 1])\n  tflat = tfrac * tceil + (1. - tfrac) * tfloor\n  t = tf.reshape(tflat, list(shape) + [4])\n  return t\n\ndef plotTensor(t, canvas, size=None, cmap=None, interpolation='nearest', **kwargs):\n  if not (cmap is None):\n    t = colorMap(t, cmap, **kwargs)\n  if size is None:\n    size = (canvas.height, canvas.width)\n  if interpolation == 'bilinear':\n    t = tfbase.image['resizeBilinear'](t.value, list(size))\n  else:\n    t = tfbase.image['resizeNearestNeighbor'](t.value, list(size))\n  tfbase.browser['toPixels'](t, canvas)\n\nfrom itertools import chain\nimport math\n\nclass Module:\n    def __init__(self):\n        self._submodules = dict()\n        self.eval = False\n        self._store = False\n\n    def parameters(self):\n        return chain.from_iterable(map(lambda x: x.parameters(), self._submodules.values()))\n    \n    def __setattr__(self, name, value):\n        if isinstance(value, Module):\n            self._submodules[name] = value\n        super().__setattr__(name, value)\n\n    def __call__(self, *args, **kwargs):\n        value = self.forward(*args, **kwargs)\n        self._store = False\n        return value\n    \n    def forward(self):\n        raise NotImplementedError()\n    \n    def train(self):\n        self.eval = False\n        for sm in self._submodules.values():\n            sm.train()\n    \n    def eval(self):\n        self.eval = True\n        for sm in self._submodules.values():\n            sm.eval()\n\n    def store(self):\n        self.store = True\n        for sm in self._submodules.values():\n            sm.eval()\n\nclass Parameter(Module):\n    def __init__(self, value):\n        super().__init__()\n        self.value = value\n        self.temp = None\n        self.grad = None\n\n    def parameters(self):\n        return [self]\n    \nclass Sequential(Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.sequence = []\n        for arg in args:\n            if isinstance(arg, Module):\n                self.sequence.append(arg)\n            else:\n                self.sequence.extend(arg)\n        \n        self._submodules = {k: v for (k,v) in enumerate(self.sequence)}\n\n    def __getitem__(self, index):\n        return self.sequence[index]\n\n    def forward(self, X):\n        for m in self.sequence:\n            X = m(X)\n        return X\n    \nModuleList = Sequential\n\nclass Sigmoid(Module):\n    def forward(self, X):\n        return tf.sigmoid(X)\n    \nclass ReLU(Module):\n    def forward(self, X):\n        return tf.relu(X)\n    \nclass Tanh(Module):\n    def forward(self, X):\n        return tf.tanh(X)\n    \nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        # Kaiming He initialization\n        self.W = Parameter(tf.randomNormal([in_features, out_features]) * math.sqrt((2 / out_features) / 3))\n        self.b = Parameter(tf.randomNormal([out_features]) * math.sqrt((2 / out_features) / 3))\n        self.input = None\n\n    def forward(self, x):\n        # Returns a new Matrix\n        self.input = None\n        return tf.dot(x, self.W) + self.b\n\n\n\n        \nclass Optimizer:\n    def __init__(self, model, loss=None, store=False):\n        self.parameters = list(model.parameters())\n        self.model = model\n        self.loss = loss\n        self.store = store\n\n    def _grads(self, loss, *args, **kwargs):\n        def loss_internal(*params):\n            for val, param in zip(params, self.parameters):\n                param.temp = param.value\n                param.value = val\n            try:\n                l = loss(self.model, *args, **kwargs)\n            finally:\n                for param in self.parameters:\n                    param.value = param.temp\n                    param.temp = None\n            return l\n        \n        return grads(loss_internal)(*map(lambda p: p.value, self.parameters))\n    \n    def _step(self, grads):\n        raise NotImplementedError()\n    \n    def step(self, *args, **kwargs):\n        grads = self._grads(self.loss, *args, **kwargs)\n        if self.store:\n          for grad, param in zip(grads, self.parameters):\n            param.grad = grad\n        return self._step(grads)\n    \n    def stepWithLoss(self, loss, *args, **kwargs):\n        grads = self._grads(loss, *args, **kwargs)\n        return self._step(grads)\n    \nclass SGD(Optimizer):\n    def __init__(self, model, loss, lr=0.001, store=False):\n        super().__init__(model, loss, store)\n        self.lr = lr\n\n    def _step(self, grads):\n        for grad, param in zip(grads, self.parameters):\n            param.value = param.value - self.lr * grad\n`\n  \n  return py;\n}\n"},{"methodName":"interpret","cellName":"ojs-cell-2","inline":false,"source":"mpg = FileAttachment(\"auto-mpg.csv\").csv()\n"},{"methodName":"interpret","cellName":"ojs-cell-3","inline":false,"source":"data = py`\n# ${plots}\n# Setup the data and prediction functions\nimport pandas as pd\ndf = pd.DataFrame(${mpg})[['weight', 'mpg']]\ndf = df.astype(float).dropna().values\n\nx, y = df[:, :1], df[:, 1:]\nx = Tensor((x - x.mean()) / x.std())\ny = Tensor((y - y.mean()) / y.std()) > -0\n\ndef get_batch(batchsize, x, y):\n  return x, y\n\nscale = Tensor([[1., 1.]])\n\ndef predict(w, x, y=None):\n  w = w.reshape((-1, 2)) * scale\n  x = x.reshape((-1, 1))\n  x = tf.concat([x, tf.onesLike(x)], 1)\n  if y is None:\n    return tf.sigmoid(tf.dot(x, w.T))\n  else:\n    y = y.reshape((-1, 1))\n    z = tf.dot(x, w.T)\n    return y * tf.sigmoid(z) + (1 - y) * tf.sigmoid(-z) \n\nwrange = tf.linspace(-15, 5, 25)\nbrange = tf.linspace(-10, 10, 25)\nww, bb = tf.meshgrid(wrange, brange)\nparamgrid = tf.stack([ww.flatten(), bb.flatten()]).T\neyetheta = 0\n\n(x, y)\n`\n\nsurfaces = py`\n# ${batch} ${plots}\n# Plot the loss surface\n\n\nl1weight = 0.\nl2weight = 0.\n\n\ndef loss(w, x, y):\n  w = w.reshape((-1, 2))\n  return (tf.mean(-tf.log(predict(w, x, y)), 0)) + l1weight * tf.abs(w).sum(1) + l2weight * (w ** 2).sum(1) \n\nlossgrid = loss(paramgrid, x, y).reshape(ww.shape)\nlosscontour = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='contour', ncontours=25, showscale=False, ))\nlosssurface = plotconvert(dict(x=wrange, y=brange, z=lossgrid, type='surface', showlegend=False, showscale=False, opacity=0.8,  contours=dict(x=dict(show=True), y=dict(show=True))))\n`\n\npy`\n# ${surfaces}\n\ncweights = ${weights}\nstartpoint = dict(x=[cweights[0]], y=[cweights[1]], mode='markers', showlegend=False, marker=dict(color='firebrick', size=10, line= {'color': 'black', 'width': 3}))\n\n\nfullweightlist = [Tensor(cweights)]\nbatchweightlist = [Tensor(cweights)]\nsteps = int(${steps})\nlr = float(${learningrate}) if steps > 0 else 0.\n\nmomentum = 0.\nnxbatch, nybatch = batches[0]\nbatchgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\nbeta = 0.\nvelocity = batchgrad\nmagnitude = batchgrad ** 2\nif beta > 0:\n  batchgrad = batchgrad / tf.sqrt(magnitude + 1e-8)\n\nfor i, (nxbatch, nybatch) in zip(range(max(1, steps)), batches):\n  fullgrad = lr * grad(lambda t: loss(t, x, y))(fullweightlist[-1])\n\n  bgrad = grad(lambda t: loss(t, nxbatch, nybatch))(batchweightlist[-1])\n  velocity = momentum * velocity + (1 - momentum) * bgrad\n  magnitude = beta * magnitude + (1. - beta) * (bgrad ** 2)\n  batchgrad = velocity\n  if beta > 0:\n    batchgrad = velocity / tf.sqrt(magnitude + 1e-8)\n  \n  fullweightlist.append((fullweightlist[-1] - fullgrad).flatten())\n  batchweightlist.append((batchweightlist[-1] - lr * batchgrad).flatten())\n  \n\nfullweights = tf.stack(fullweightlist)\nbatchweights = tf.stack(batchweightlist)\n\ngradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], showlegend=False, line=dict(color='black'))\nbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], showlegend=False, line=dict(color='orange'))\n\n\nzloss = loss(fullweights, x, y)\nbatchzloss = loss(batchweights, x, y)\nthreedgradplot = dict(x=fullweights[:, 0], y=fullweights[:, 1], z=zloss, showlegend=False, marker=dict(size=4), line=dict(color='black', width=4), type='scatter3d')\nthreedbatchgradplot = dict(x=batchweights[:, 0], y=batchweights[:, 1], z=batchzloss, showlegend=False, marker=dict(size=4), line=dict(color='orange', width=4), type='scatter3d')\n\nfinalloss = zloss[0].t2Js()\n\nPlotlyReactive(lossplot, [losscontour, startpoint, gradplot, batchgradplot], {'title': 'Loss = %.3f' % finalloss, 'showlegend': False, 'xaxis': {'range': [-15, 5], 'title': 'Slope (w)'}, 'yaxis': {'range': [-10, 10], 'title': {\n      'text': 'Bias (b)'\n    }}})\n`\n\nloss = py`\n# ${batch}\n# Plot the data scatterplot and prediction function\n\ninweights = ${weights}\ncweights = Tensor(inweights)\nerrors = -tf.log(predict(cweights, xbatch.reshape((-1,)), y).flatten())\nlosses = (errors)\nbatchdata = dict(x=xbatch.reshape((-1,)), y=ybatch.reshape((-1,)), mode='markers', marker=dict(color=tf.sqrt(losses), colorscale='RdBu', cmin=0, cmax=1))\n\nxrange = tf.linspace(-2, 3, 50)\npfunction = dict(x=xrange.flatten(), y=predict(cweights, xrange).flatten(), line=dict(color='black'))\n\n\nPlotlyReactive(scatterfig, [ batchdata, pfunction], {'title': 'p(y=1|x) = Ïƒ(%.2f x + %.2f)' % (inweights[0], inweights[1]), 'showlegend': False, 'xaxis': {'range': [-2, 3], 'title': {'text': 'x (weight)'}}, 'yaxis': {'range': [-1, 2], 'title': {'text': 'y (MPG)'} }})\n\nhistdata = dict(x=errors, type='histogram', xbins= dict(start=-3, end=3, size=0.15))\nlosses.mean()\n`\n\nbatch = py`\n# ${data}\nbatchsize = 0\nbatches = [get_batch(batchsize, x, y) for i in range(max(1, int(${steps})))]\nxbatch, ybatch = batches[0]\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-4","inline":false,"source":"scatter = py`\n# Scatterplot figure\nscatterfig = PlotlyFigure(width=500, height=500)\nscatterfig\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-5","inline":false,"source":"viewof learningrate = Inputs.range([0, 100], {value: 1, step: 0.01, label: \" Learning rate\"})\n//learningrate = 0\n"},{"methodName":"interpret","cellName":"ojs-cell-6","inline":false,"source":"\nplots = py`\nlossplot = PlotlyInput(width=500, height=500)\n`\n\nviewof weights = py`\n# ${plots}\nlossplot\n`\n"},{"methodName":"interpret","cellName":"ojs-cell-7","inline":false,"source":"viewof steps = Inputs.range([0, 10], {value: 0, step: 1, label: \"  Steps\"})\n"},{"methodName":"interpretQuiet","source":"shinyInput('learningrate')"},{"methodName":"interpretQuiet","source":"shinyInput('weights')"},{"methodName":"interpretQuiet","source":"shinyInput('steps')"}]}
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../lecture3-logistic-regression";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>