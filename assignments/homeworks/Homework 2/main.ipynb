{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEMNf-U0jzTB"
   },
   "source": [
    "# **Homework 2:** Linear regression and maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmM519OhjzTD"
   },
   "source": [
    "### Collaborators\n",
    "\n",
    "Please list anyone you discussed or collaborated on this assignment with below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQQyudHHjzTE"
   },
   "source": [
    "LIST COLLABORATORS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5_yw6pijzTE"
   },
   "source": [
    "### Course feedback\n",
    "\n",
    "Please submit this week's course survey here: https://forms.gle/waVksu5TnZLixvYH7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVoiwam8jzTF"
   },
   "outputs": [],
   "source": [
    "# Run me first!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjJxm7eUjzTG"
   },
   "source": [
    "In this homework, we will use the following convention for dimentionality:\n",
    "\n",
    "$N:\\quad\\text{Number of observations in a dataset, so } \\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}$\n",
    "\n",
    "$d:\\quad\\ \\text{Dimension of input (number of features), so } \\mathbf{x}_i \\in \\mathbb{R}^d$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inv8Yg90jzTG"
   },
   "source": [
    "## Part 1: Linear regression\n",
    "\n",
    "Let's begin by reviewing the context of linear regression.\n",
    "\n",
    "\n",
    "\n",
    "Recall that the linear regression model makes predictions of the following form:\n",
    "\n",
    "$$f(\\mathbf{x})=\\mathbf{x}^T\\mathbf{w} + b$$\n",
    "\n",
    "Or if we consdier the augmented representation:\n",
    "\n",
    "$$\\mathbf{x} \\rightarrow \\begin{bmatrix}\\mathbf{x} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\\\ 1 \\end{bmatrix},\\quad \\mathbf{w} \\rightarrow \\begin{bmatrix}\\mathbf{w} \\\\ b \\end{bmatrix} = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_d \\\\ b \\end{bmatrix}$$\n",
    "Then we can use the more convenient linear form:\n",
    "$$f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{w}$$\n",
    "\n",
    "\n",
    "#### **Q1** (5 points)\n",
    "Write a function that takes in an input $(\\mathbf{x})$ and a set of weights $(\\mathbf{w})$ and makes a prediction using the function above. **Your implementation should assume that the bias $(b)$ is included in the weights $(\\mathbf{w})$ and thus should *augment* the input to account for this (or separate $b$ from $\\mathbf{w}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEdzIx6MjzTG"
   },
   "outputs": [],
   "source": [
    "# Test inputs\n",
    "x = np.array([1, -3, 5])\n",
    "w = np.array([-1, 2, 0.5, 2])\n",
    "y = -2.5\n",
    "\n",
    "def linear_regression(x, w):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "## Validate the function\n",
    "assert y == linear_regression(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deOPaOG9jzTH"
   },
   "source": [
    "As discussed in class, we can compactly refer to an entire *dataset* of inputs and outputs using the notation $\\mathbf{X}$ and $\\mathbf{y}$ respectively. Our convention will be that *row* $i$ of $\\mathbf{X}$ will correspond to the $i^{th}$ observed input $\\mathbf{x}_i$, while the corresponding entry $y_i$ of $\\mathbf{y}$ is the observed output. In other words $\\mathbf{X}$ and $\\mathbf{y}$ are defined as:\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{bmatrix} X_{11} & X_{12} & \\dots  & X_{1d} & 1 \\\\\n",
    "                X_{21} & X_{22} & \\dots  & X_{2d} & 1 \\\\\n",
    "                \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "                X_{N1} & X_{N2} & \\dots  & X_{Nd} & 1 \\\\  \n",
    "                \\end{bmatrix} = \\begin{bmatrix} \\mathbf{x}_1^T \\\\ \\mathbf{x}_2^T \\\\ \\vdots \\\\ \\mathbf{x}_N^T \\end{bmatrix}, \\quad\n",
    "                \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "With this notation, we can make predictions for an entire set of inputs as:\n",
    "$$f(\\mathbf{X}) = \\mathbf{X}\\mathbf{w}$$\n",
    "Where the output is now a *vector* of predictions. We see that each entry corresponds to the prediction for input $\\mathbf{x}_i$:\n",
    " $$f(\\mathbf{X})_i = \\mathbf{x}_i^T\\mathbf{w} = f(\\mathbf{x}_i)$$\n",
    "\n",
    "#### **Q2** (10 points)\n",
    "Modify (if needed) your linear regression prediction function to accept a set of inputs *as a matrix* as described above and return a vector of predictions. Once again you should *not* assume the data includes the extra bias dimension. Then plot the prediction function given by the provided weights on the range $[0, 5]$. *Recall that `np.linspace(a, b, n)` produces a vector of `n` equally spaced numbers between `a` and `b`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UmsLx9FjzTI"
   },
   "outputs": [],
   "source": [
    "# Test inputs\n",
    "w = np.array([0.5, 2])\n",
    "\n",
    "def linear_regression(x, w):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "## CODE TO PLOT THE FUNCTION HERE\n",
    "X =\n",
    "y = linear_regression(X, w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-egBogWjzTJ"
   },
   "source": [
    "Recall that *ordinary least squares* finds the parameter $\\mathbf{w}$ that minimizes the *mean of squared error* between the true outputs $\\mathbf{y}$ and predictions.\n",
    "$$\\underset{\\mathbf{w}}{\\text{argmin}} \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2$$\n",
    "\n",
    "Observe that this is the same formula as the error we used for evaluating Richardson iteration in the last homework, we've simply renamed the variables from $(\\mathbf{A}, \\mathbf{x}, \\mathbf{b})$ to $(\\mathbf{X}, \\mathbf{w}, \\mathbf{y})$! *(We've also added the constant $\\frac{1}{N}$, but this doesn't change the optimal $\\mathbf{w}$)*\n",
    "\n",
    "We've now seen 3 equivalent ways to write the same formula. From most compact to least compact these are:\n",
    "$$\\textbf{1: } \\frac{1}{N} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 \\quad \\textbf{2: } \\frac{1}{N} \\sum_{i=1}^N \\left(\\mathbf{x}_i^T\\mathbf{w} - y_i\\right)^2 \\quad \\textbf{3: } \\frac{1}{N} \\sum_{i=1}^n \\left(\\sum_{j=1}^n X_{ij}w_j - y_i\\right)^2$$\n",
    "\n",
    "#### **Q3** (10 points)\n",
    "Using the gradient formula we derived in class, write a function that returns both the mean squared error *and* the gradient of the error with respect to $\\mathbf{w}$, given $\\mathbf{w}$, $\\mathbf{X}$ and $\\mathbf{y}$. *Hint: don't forget to augment X when computing the gradient!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQ-_ASyPjzTJ"
   },
   "outputs": [],
   "source": [
    "def mse_and_grad(w, X, y):\n",
    "    ### YOUR CODE HERE\n",
    "    return mse, grad_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t82c3nO5jzTK"
   },
   "source": [
    "Recall that we can use the *gradient descent* algorithm to find the input that minimizes a function, using the corresponding gradient function.\n",
    "\n",
    "Given an initial guess of the optimal input, $\\mathbf{w}^{(0)}$, gradient descent uses the following update to improve the guess:\n",
    "$$\\mathbf{w}^{(i+1)} \\longleftarrow \\mathbf{w}^{(i)} - \\alpha \\nabla f(\\mathbf{w}),$$\n",
    "where $\\alpha$ is the *learning rate* or *step size*.\n",
    "\n",
    "#### **Q4** (10 points)\n",
    "Write a function to perform gradient descent. The function should take as input:\n",
    "- `value_and_grad`: A function that produces the output and gradient of the function to optimize (e.g. the `mse_and_grad`)\n",
    "- `w0`: An inital guess $\\mathbf{w}^{(0)}$\n",
    "- `lr`: The learning rate $(\\alpha)$\n",
    "- `niter`: The number of updates to perform\n",
    "- `*args`: Any additional argumets to pass to `value_and_grad` (e.g. `X` and `y`)\n",
    "\n",
    "The function should return:\n",
    "- `w`: The final guess\n",
    "- `losses`: A list (or array) that tracks the value of the function at each update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiH-0z82jzTK"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(value_and_grad, w0, lr, niter, *args):\n",
    "    # Get the inital loss\n",
    "    initial_loss, _ = value_and_grad(w0, *args)\n",
    "    losses = []\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return w, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtPwG-Q2jzTK"
   },
   "source": [
    "## Part 2: Applications to real data\n",
    "\n",
    "Now that we've setup a full implementation of linear regression, let's test it on a real dataset. We'll use the MPG dataset that we saw in class. The following code will load the data and rescale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l89OoiH6jzTK"
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('auto-mpg.csv', delimiter=',', missing_values=['?'], filling_values=[0])\n",
    "# Uncomment if on Colab!\n",
    "# import urllib.request\n",
    "# link = 'https://gist.githubusercontent.com/gabehope/4df286bbd9a672ce7731d52afe3ca07e/raw/65026711d71affaafb9713ddf5b6ef29125ba0fb/auto.csv'\n",
    "# data = np.genfromtxt(urllib.request.urlopen(link), delimiter=',', missing_values=['?'], filling_values=[0])\n",
    "\n",
    "# MPG is the output value\n",
    "target = 'MPG'\n",
    "y = data[:, 0]\n",
    "\n",
    "# The other variables are inputs in the order listed\n",
    "features = ['displacement', 'weight', 'acceleration', 'year']\n",
    "X = data[:, [2, 4, 5, 6]]\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzpl3_OBjzTL"
   },
   "source": [
    "Let's start by fitting a model that just uses the feature `weight`.\n",
    "\n",
    "#### **Q5** (5 points)\n",
    "Use the `gradient_descent` and `mse_and_grad` functions you wrote above to fit a linear regression model that takes in a car's weight and predicts its MPG rating. Start with the weights equal to `0` and perform `100` updates of gradient descent with a learning rate of `0.1`. Plot the loss (MSE) as a function of the number of updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWa7xe9bjzTL"
   },
   "outputs": [],
   "source": [
    "Xweight = X[:, 1:2]\n",
    "w0 = np.zeros((2,))\n",
    "\n",
    "### YOUR CODE HERE\n",
    "w, losses =\n",
    "\n",
    "### PLOTTING CODE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdY9aUWQjzTL"
   },
   "source": [
    "#### **Q6** (5 points)\n",
    "Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range $[-3, 3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7NYR_nNjzTL"
   },
   "outputs": [],
   "source": [
    "### PLOTTING CODE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDbmJindjzTL"
   },
   "source": [
    "#### **Q7** (5 points)\n",
    "Repeat **Q5** using all 4 features and compare the final loss to the final loss using only `weight` as an input. Describe any differences you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o31j1gzHjzTL"
   },
   "outputs": [],
   "source": [
    "w0 = np.zeros((5,))\n",
    "\n",
    "### YOUR CODE HERE\n",
    "w, losses =\n",
    "\n",
    "### PLOTTING CODE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_DkQm8_jzTL"
   },
   "source": [
    "**DESCRIBE RESULTS HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUIHvixWjzTM"
   },
   "source": [
    "In machine learning we are typically less interested in how our model predicts the data we've already seen than we are in how well it makes predictions for *new* data. One way to estimate how well our model our model will generalize to new data is to *hold out* data while fitting our model. To do this we will split our dataset into two smaller datasets: a *training dataset* that we will use to fit our model, and a *test* or *held-out* dataset that we will only use to evaluate our model. By computing the loss on this test dataset, we can get a sense of how well our model will make prediction for new data.\n",
    "\n",
    "$$\\mathcal{D} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_N, y_N) \\}\\quad \\longrightarrow \\quad\n",
    "\\mathcal{D}_{train} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntrain}, y_{Ntrain}) \\},\\  \n",
    "\\mathcal{D}_{test} = \\{ (\\mathbf{x}_1, y_1),\\ (\\mathbf{x}_2, y_2),\\ ... \\,(\\mathbf{x}_{Ntest}, y_{Ntest}) \\}\n",
    "$$\n",
    "\n",
    "#### **Q8** (5 points)\n",
    "Split the MPG dataset into *training* and *test* datasets. Use 70\\% of the observations for training and 30\\% for test. Then repeat **Q5** to fit a linear regression model on *just the training dataset* using only the `weight` feature (you don't need to plot the loss for this question). Report the final loss (MSE) on the training dataset and on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6lPatA3jzTM"
   },
   "outputs": [],
   "source": [
    "### CODE TO SPLIT DATASET HERE\n",
    "Xweight_train =\n",
    "y_train =\n",
    "\n",
    "Xweight_test =\n",
    "y_test =\n",
    "\n",
    "### CODE TO FIT MODEL HERE\n",
    "w0 = np.zeros((2,))\n",
    "w, losses =\n",
    "\n",
    "### CODE TO EVALUATE MODEL HERE\n",
    "mse_train =\n",
    "mse_test =\n",
    "\n",
    "print('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPEUzEFNjzTM"
   },
   "source": [
    "#### **Q9** (5 points)\n",
    "Repeat **Q8** using the all 4 features. Compare the results to the model using only `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MStDXVxjzTM"
   },
   "outputs": [],
   "source": [
    "### CODE TO SPLIT DATASET HERE\n",
    "X_train =\n",
    "y_train =\n",
    "\n",
    "X_test =\n",
    "y_test =\n",
    "\n",
    "### CODE TO FIT MODEL HERE\n",
    "w0 = np.zeros((5,))\n",
    "w, losses =\n",
    "\n",
    "### CODE TO EVALUATE MODEL HERE\n",
    "mse_train =\n",
    "mse_test =\n",
    "\n",
    "print('Loss on training data: %.4f, loss on test data: %.4f' % (mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggaAW-eRjzTM"
   },
   "source": [
    "**DESCRIBE RESULTS HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrkoOZ0wjzTN"
   },
   "source": [
    "## Part 3: Maximum Likelihood Training\n",
    "\n",
    "### Background:\n",
    "We saw in lecture that we can view linear regression as the following probibalistic model:\n",
    "$$\n",
    "y_i \\sim \\mathcal{N}\\big(\\mathbf{x}_i^T \\mathbf{w},\\ \\sigma^2\\big)\n",
    "$$\n",
    "Where $\\mathcal{N}(\\mu, \\sigma)$ is the *Normal distribution*, which has the following probability density function:\n",
    "$$\n",
    "p(y\\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\text{exp}\\bigg(-\\frac{1}{2\\sigma^2} (y -\\mu)^2\\bigg)\n",
    "$$\n",
    "We saw that a reasonable way to choose the optimal $\\mathbf{w}$ is to *maximize the likelihood* of our observed dataset, which is equivalent to *minimizing the negative log likelihood*:\n",
    "$$\\underset{\\mathbf{w}}{\\text{argmax}} \\prod_{i=1}^N p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) =\n",
    "\\underset{\\mathbf{w}}{\\text{argmin}} -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, \\sigma) = \\underset{\\mathbf{w}}{\\text{argmin}}\\ \\frac{1}{2\\sigma^2}\\sum_{i=1}^N  (y_i -\\mathbf{x}_i^T\\mathbf{w})^2 + C\n",
    "$$\n",
    "Where $C$ is a constant: $C = N \\log \\sigma \\sqrt{2\\pi}$. We further saw that this is equivalent to minimizing the *mean squared error* for any choice of $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35XVXJvLjzTN"
   },
   "source": [
    "### Laplace Maximum Likelihood Estimation\n",
    "\n",
    "A natural question about the above model is: why choose the Normal distribution? In principal, we could define a linear model using *any* distribution over the real numbers $\\mathbb{R}$. Let's explore an alternative choice: the *Laplace distribution* ([Wiki](https://en.wikipedia.org/wiki/Laplace_distribution)). The Laplace distribution $L(\\mu, a)$ has the following PDF:\n",
    "\n",
    "$$p(y\\mid \\mu, a) = \\frac{1}{2a} \\exp\\bigg(- \\frac{|y-\\mu|}{a} \\bigg) $$\n",
    "\n",
    "As for the normal distribution $\\mu$ is the mean, while $a$ defines the \"width\" of the distribution (analogous to variance for the Normal). We can compare the two distributions visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO5XCAyJjzTN",
    "outputId": "85da6454-19e7-44c1-c048-745dec06a0ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylp = np.linspace(-3, 3, 200)\n",
    "mu, sigma2_or_a = 0, 1\n",
    "p_y_normal = (1 / np.sqrt(sigma2_or_a * 2 * np.pi)) * np.exp(- (0.5 / sigma2_or_a) * (ylp - mu) ** 2)\n",
    "p_y_laplace = (1 / (2 * sigma2_or_a)) * np.exp(- (1 / sigma2_or_a) * np.abs(ylp - mu))\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(ylp, p_y_normal, label=r\"Normal PDF\")\n",
    "plt.plot(ylp, p_y_laplace, label=r\"Laplace PDF\")\n",
    "plt.xlabel('$y$')\n",
    "plt.ylabel('$p(y)$')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl3OFfkCjzTN"
   },
   "source": [
    "Let's now consider the Laplace version of our probabilistic linear model:\n",
    "$$\n",
    "y_i \\sim L\\big(\\mathbf{x}_i^T \\mathbf{w},\\ a\\big)\n",
    "$$\n",
    "Recall that the negative log-likelihood is defined as:\n",
    "$$\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = -\\sum_{i=1}^N \\log p(y_i\\mid \\mathbf{x}_i, \\mathbf{w}, a)$$\n",
    "\n",
    "#### **Q10** (5 points)\n",
    "Write out the negative log-likelihood for this model in terms of $\\mathbf{w}, a, \\mathbf{X}, y$ using the Laplace PDF shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZja7gMfjzTN"
   },
   "source": [
    "**YOUR ANSWER HERE**\n",
    "$$\\mathbf{NLL}(\\mathbf{w}, a, \\mathbf{X}, \\mathbf{y}) = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtPo_qNLjzTO"
   },
   "source": [
    "Note that if we drop the constants, we would call this loss the *sum absolute error*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_e8Bv3QjzTO"
   },
   "source": [
    "#### **Q11** (10 points)\n",
    "Find the gradient with respect to $\\mathbf{w}$ of the negative log-likelihood for this model. *Hint: remember that the gradient is the vector of partial derivatives!*\n",
    "\n",
    "You should use the following definition of the derivative of the absolute value $|\\cdot |$ operator:\n",
    "$$\\frac{d}{dx}|x| = sign(x), \\quad sign(x) = \\begin{cases} +1 \\quad \\text{ if  } x > 0 \\\\ -1 \\quad \\text{ if  } x < 0 \\\\ \\ \\ \\ 0 \\quad \\text{ if  } x = 0 \\end{cases}$$\n",
    "(Technically $\\frac{d}{dx}|x|$ is undefined at $x=0$, but it is convinient to assume $\\frac{d}{dx}|0|=0$ in practice.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7oEmPYvjzTO"
   },
   "source": [
    "**YOUR ANSWER HERE**\n",
    "$$\\nabla_{\\mathbf{w}}\\mathbf{NLL}(\\mathbf{w}, b, \\mathbf{X}, \\mathbf{y}) = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THwzEy20jzTO"
   },
   "source": [
    "#### **Q12** (5 points)\n",
    "Using the formula you just derived, write a function that returns both the negative log-likelihood *and* the gradient of the negative log-likelihood with respect to $\\mathbf{w}$, given $\\mathbf{w}$, $\\mathbf{X}$ and $\\mathbf{y}$ (assume that $a=1$). We'll divide both outputs by $N$ to make our results more comparable to MSE. *Hint: `np.sign` will compute the sign function descibed above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Lc3dxt7jzTO"
   },
   "outputs": [],
   "source": [
    "def nll_and_grad(w, X, y):\n",
    "    N = X.shape[0]\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    return nll / N, grad_w / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmtlrdSLjzTO"
   },
   "source": [
    "#### **Q13** (5 points)\n",
    "Use the `gradient_descent` and `nll_and_grad` functions you wrote above to fit a linear regression model that takes in a car's weight and predicts its MPG rating. Start with the weights equal to `0` and perform `100` updates of gradient descent with a learning rate of `1.0`. Plot the loss (NLL) as a function of the number of updates. *Use the full dataset as in **Q5** and note the change in learning rate!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWOkTKBAjzTP"
   },
   "outputs": [],
   "source": [
    "Xweight = X[:, 1:2]\n",
    "w0 = np.zeros((2,))\n",
    "\n",
    "### YOUR CODE HERE\n",
    "w_laplace, losses_laplace =\n",
    "\n",
    "### PLOTTING CODE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgsUe_RWjzTP"
   },
   "source": [
    "#### **Q14** (5 points)\n",
    "Plot a scatterplot of weight vs. MPG. Then on the same plot, plot the prediction function for the linear regression model you just fit on the input range $[-3, 3]$. Finally, copy your code from **Q5** to once again find the optimal $\\mathbf{w}$ using the MSE loss and plot this function on the same plot in a different color. Describe any differences you see between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtolJ1PkjzTP"
   },
   "outputs": [],
   "source": [
    "### CODE FROM Q5 HERE\n",
    "w_mse, losses_mse =\n",
    "\n",
    "### PLOTTING CODE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ3vguUOjzTP"
   },
   "source": [
    "**WRITTEN ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sod9yRpfjzTP"
   },
   "source": [
    "#### **Q15** (10 points)\n",
    "Using the parameters that you just found, plot the Laplace NLL loss as a function of the first entry in `w` (`w1` below), holding the other (the bias) constant. Plot this loss on the range $[-10, 0]$. Then, in a separate cell, plot the MSE loss as a function of the first entry in `w` on the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvKHYGXUjzTQ"
   },
   "outputs": [],
   "source": [
    "# Example of deconstructing and reconstructing the parameter vector.\n",
    "w1, b = w\n",
    "wi = np.array([w1, b])\n",
    "\n",
    "### PLOTTING CODE FOR NLL HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ6-PXZIjzTQ"
   },
   "outputs": [],
   "source": [
    "### PLOTTING CODE FOR MSE HERE\n",
    "plt.figure(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqyIVZi7jzTQ"
   },
   "source": [
    "In the cells below, copy your code for **Q5** and **Q13**. Try out different learning rates and and numbers of iterations. Observe what happens to the loss plot in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsT5w7XGjzTQ"
   },
   "outputs": [],
   "source": [
    "### COPY Q5 CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1CEwJeijzTQ"
   },
   "outputs": [],
   "source": [
    "### COPY Q13 CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKwJigogjzTQ"
   },
   "source": [
    "Based on what you've obsevered above and in the previous questions, why might you choose the Normal distribution or the Laplace distribution for linear regression? What effect does the learning rate have (what happens if it's set too high or too low)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVclMjzijzTR"
   },
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
