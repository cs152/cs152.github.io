{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPM0-8V7gKH5"
   },
   "source": [
    "# **Homework 7:** PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "\n",
    "Please list anyone you discussed or collaborated on this assignment with below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST COLLABORATORS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course feedback\n",
    "\n",
    "Please submit this week's course survey here: https://forms.gle/ELjvh2PK7iiAHbaC8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to PDF\n",
    "\n",
    "Please convert this notebook to PDF for submission to Gradescope using this tool: https://blank-app-ufu2uvdeosc.streamlit.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEbDOooCgUbj"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run if using Colab!\n",
    "\n",
    "#!wget https://cs152.github.io/assignments/homeworks/Homework%207/hw7_support.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPC-KgxBgKIA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from hw7_support import *\n",
    "\n",
    "\n",
    "class LinearZeros(nn.Module):\n",
    "    '''\n",
    "    A PyTorch module representing a linear/affine function with weights W and bias b:\n",
    "        f(X) = XW + b\n",
    "    W is an (in_dimensions x out_dimensions) matrix and b is an (out_dimensions) vector.\n",
    "\n",
    "    This version of the Linear module initializes the parameters to 0.\n",
    "    '''\n",
    "    def __init__(self, in_dimensions, out_dimensions):\n",
    "        # Call the nn.Module __init__ function\n",
    "        super().__init__()\n",
    "\n",
    "        # Create parameters that we can fit with gradient descent.\n",
    "        self.weights = nn.Parameter(torch.zeros(in_dimensions, out_dimensions))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dimensions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute the function. Note that we use torch.matmul rather than torch.dot!\n",
    "        # This assumes X is 2-dimensional (a matrix)!\n",
    "        return torch.matmul(x, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftv03tyygKIC"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dj1S-QhgKIC"
   },
   "outputs": [],
   "source": [
    "def mse_loss(prediction, labels):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Test to check\n",
    "torch.manual_seed(0)\n",
    "assert torch.isclose(mse_loss(torch.randn(10, 1), torch.randn(10, 1)), torch.tensor(1.1550), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuIvipq2gKID"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8GQPS6OgKID"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=1000):\n",
    "    optimizer = # YOUR CODE HERE\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        # YOUR CODE HERE\n",
    "        loss =\n",
    "\n",
    "        valid_loss =\n",
    "        losses.append(loss.detach().numpy())\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    return losses, valid_losses\n",
    "\n",
    "# Test our function\n",
    "test_gradient_descent(gradient_descent, mse_loss, x, y, xvalid, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEmBxtKKgKID"
   },
   "outputs": [],
   "source": [
    "model = LinearZeros(1, 1)\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLCe6528gKIE"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEWMDuKQgKIE"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model =\n",
    "\n",
    "# Test the model build\n",
    "test_build(model, LinearZeros, dropout_type=None, type='zeros')\n",
    "\n",
    "# Run the model\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_FUnu6SgKIE"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBfYdma7gKIE"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5fr0_xygKIF"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2McYTjSJgKIF"
   },
   "outputs": [],
   "source": [
    "class LinearNormal(nn.Module):\n",
    "    def __init__(self, in_dimensions, out_dimensions):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.weights =\n",
    "        self.bias =\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weights) + self.bias\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model =\n",
    "\n",
    "# Test the model build and LinearNormal\n",
    "test_normal(LinearNormal)\n",
    "test_build(model, LinearNormal, dropout_type=None, type='normal')\n",
    "\n",
    "# Run the model\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=0.1)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZYoom5FgKIF"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUbFK4UegKIF"
   },
   "outputs": [],
   "source": [
    "# Modify this code to choose a good learning rate\n",
    "model =\n",
    "lr =\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI11PNhmgKIF"
   },
   "source": [
    "EXPLAIN YOUR APPROACH HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQT5A00PgKIF"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zM8hjsycgKIG"
   },
   "outputs": [],
   "source": [
    "class LinearKaiming(nn.Module):\n",
    "    def __init__(self, in_dimensions, out_dimensions):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.weights =\n",
    "        self.bias =\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weights) + self.bias\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model =\n",
    "lr =\n",
    "\n",
    "# Test the model build and LinearKaiming\n",
    "test_kaiming(LinearKaiming)\n",
    "test_build(model, LinearKaiming, dropout_type=None, type='normal')\n",
    "\n",
    "# Run the model\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8P3X0xmgKIG"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8A2ED-PUgKIG"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n",
    "    optimizer = # YOUR CODE HERE\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        # YOUR CODE HERE\n",
    "        loss =\n",
    "\n",
    "        valid_loss =\n",
    "        losses.append(loss.detach().numpy())\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    return losses, valid_losses\n",
    "\n",
    "model = # YOUR CODE HERE\n",
    "lr =\n",
    "losses, valid_losses = gradient_descent_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WnllPdEgKIG"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-keMQEMgKIH"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoHbinmXgKIH"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8edHuSb_gKIH"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_patient_early_stopping(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n",
    "    optimizer = # YOUR CODE HERE\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        # YOUR CODE HERE\n",
    "        loss =\n",
    "\n",
    "        valid_loss =\n",
    "        losses.append(loss.detach().numpy())\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    return losses, valid_losses\n",
    "\n",
    "model = # YOUR CODE HERE\n",
    "lr =\n",
    "losses, valid_losses = gradient_descent_patient_early_stopping(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ccG4sWegKIH"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6p-62P8gKIH"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def gradient_descent_l1(model, loss_func, x, y, xvalid, yvalid, lr=0.1, l1_weight=1., steps=5000):\n",
    "    optimizer = # YOUR CODE HERE\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        # YOUR CODE HERE\n",
    "        loss =\n",
    "        losses.append(loss.detach().numpy()) # Track loss without L2 terms\n",
    "\n",
    "        l2_loss =\n",
    "        loss = loss + l1_weight * l2_loss\n",
    "        # CODE FOR GRAIDENT DESCENT STEP HERE\n",
    "\n",
    "        valid_loss =\n",
    "\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    return losses, valid_losses\n",
    "\n",
    "# Test our function\n",
    "test_gradient_descent(gradient_descent_l1, mse_loss, x, y, xvalid, yvalid, l1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD4n_SrzgKII"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q12**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6rwe9k8gKII"
   },
   "outputs": [],
   "source": [
    "model = # YOUR CODE HERE\n",
    "lr =\n",
    "l1_weight =\n",
    "losses, valid_losses = gradient_descent_l1(model, mse_loss, x, y, xvalid, yvalid, lr=lr, l1_weight=l1_weight)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqQJ5VSFgKII"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCW_QPvygKII"
   },
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, rate=0.01):\n",
    "        # Rate specifies the dropout rate (r)\n",
    "        super().__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        if self.training:\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "# Test our module\n",
    "test_dropout(Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjr_Sub0gKIJ"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\">  \\pagebreak  </div>\n",
    "\n",
    "#### **Q14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Jm72lslgKIJ"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n",
    "    optimizer = # YOUR CODE HERE\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        # YOUR CODE HERE\n",
    "        loss =\n",
    "\n",
    "        valid_loss =\n",
    "        losses.append(loss.detach().numpy())\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    return losses, valid_losses\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model =\n",
    "\n",
    "# Test our model build\n",
    "test_build(model, LinearKaiming, dropout_type=Dropout, type='normal')\n",
    "\n",
    "lr =\n",
    "losses, valid_losses = gradient_descent(model, mse_loss, x, y, xvalid, yvalid, lr=lr)\n",
    "plotRegression(x, y, xvalid, yvalid, loss_history=losses, valid_loss_history=valid_losses, model=model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
